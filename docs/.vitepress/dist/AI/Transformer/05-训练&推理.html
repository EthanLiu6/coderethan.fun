<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>探秘Transformer系列之（5）--- 训练&amp;推理 | 码医森</title>
    <meta name="description" content="计算机知识的学习站点">
    <meta name="generator" content="VitePress v1.3.4">
    <link rel="preload stylesheet" href="/assets/style.CflK-Lwn.css" as="style">
    
    <script type="module" src="/assets/app.CP5QrAO4.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DC78O2cf.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DA-Pb-tg.js">
    <link rel="modulepreload" href="/assets/AI_Transformer_05-训练_推理.md.BJLWHSwO.lean.js">
    <link rel="icon" type="image/svg+xml" href="/imgs/home-page-logo.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/imgs/home-page-logo.svg" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>CoderEthan学习站</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-dc692963 data-v-9c663999><!--[--><span data-v-9c663999>主页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/guide/" tabindex="0" data-v-dc692963 data-v-9c663999><!--[--><span data-v-9c663999>博客指南</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/生活与算法/" tabindex="0" data-v-dc692963 data-v-9c663999><!--[--><span data-v-9c663999>生活与算法</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>AI</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/deep_learning_theory/" data-v-43f1e123><!--[-->DL基础理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/Transformer/" data-v-43f1e123><!--[-->Transformer系列<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>计算机学科内容</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/408知识/" data-v-43f1e123><!--[-->计算机知识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/c++基础/" data-v-43f1e123><!--[-->C++基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Java/" data-v-43f1e123><!--[-->Java后端<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Linux/" data-v-43f1e123><!--[-->Linux技术<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/计算机图形学/" data-v-43f1e123><!--[-->计算机图形学<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>自我提升</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/improve/阅读/" data-v-43f1e123><!--[-->阅读<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/improve/金融投资/" data-v-43f1e123><!--[-->金融投资<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>求职面试</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/面试求职/Java面经/" data-v-43f1e123><!--[-->Java面经<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/面试求职/场景问题/" data-v-43f1e123><!--[-->场景问题<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/面试求职/经验分享/" data-v-43f1e123><!--[-->经验分享<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/面试求职/算法岗/" data-v-43f1e123><!--[-->算法岗<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>其他维护</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/update/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97.html" data-v-43f1e123><!--[-->站点更新<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/技术问题清单/" data-v-43f1e123><!--[-->问题清单<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>感悟和日常</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/我的感悟/" data-v-43f1e123><!--[-->站长感悟<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link vp-external-link-icon" href="https://EthanLiu6.github.io" target="_blank" rel="noreferrer" data-v-43f1e123><!--[-->站长旧版博客<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>深色模式</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b7550ba0><!----><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-1 collapsible has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>Transformer</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/01-注意力机制.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-注意力机制</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/02-总体架构.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-总体架构</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/03-数据处理.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-数据处理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/04-编码器 &amp; 解码器.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-编码器 & 解码器</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/05-训练&amp;推理.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-训练&推理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/06-token.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06-token</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/07-embedding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07-embedding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/08-位置编码.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08-位置编码</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/09-位置编码分类.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09-位置编码分类</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/10-自注意力.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10-自注意力</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/11-掩码.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-掩码</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/12-多头自注意力.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12-多头自注意力</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/13- FFN.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13- FFN</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/14-残差网络和归一化.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14-残差网络和归一化</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>deep_learning_theory</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/00-DL_Base_Notes.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00-DL_Base_Notes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/01-feedforward_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-feedforward_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/02-back_propagation.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-back_propagation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/03-bp_example_demo.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-bp_example_demo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/04-convolution_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-convolution_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/05-deep_learning_model.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-deep_learning_model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/06-pytorch_install.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06-pytorch_install</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/07-operators.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07-operators</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/08-activation_functions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08-activation_functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/09-recurrent_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09-recurrent_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/10-seq2seq.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10-seq2seq</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/11-1attentions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-1attentions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/11-2attention-extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-2attention-extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/12-weight-initialization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12-weight-initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/13-optimizers.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13-optimizers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/14-regularization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14-regularization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/15-deep-learning-tuning-guide.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15-deep-learning-tuning-guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/20-pytorch-tensor.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20-pytorch-tensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/21-pytorch-autograd.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21-pytorch-autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/22-pytorch-module.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22-pytorch-module</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-1training-example-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-1training-example-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-2decoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-2decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-3encoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-3encoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-4transformer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-4transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/24-pytorch-optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24-pytorch-optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/25-pytorch-lr-scheduler.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25-pytorch-lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/26-pytorch-dataloader.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26-pytorch-dataloader</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/27-pytorch-model-save.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27-pytorch-model-save</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/28-pytorch-tensorboard.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28-pytorch-tensorboard</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/29-pytorch-graph-mode.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29-pytorch-graph-mode</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/30-3main.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-3main</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/30-training-example-2.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-training-example-2</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/40-ner.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>40-ner</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/41-question-answering.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>41-question-answering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/42-1stable-diffusion.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-1stable-diffusion</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/42-2SDXL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-2SDXL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/42-3VAE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-3VAE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/44-scaling-law.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>44-scaling-law</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/45-distribute-training.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>45-distribute-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/46-nlp-llama.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-nlp-llama</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/47-nlp-deepseek.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-nlp-deepseek</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>本文目录</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _AI_Transformer_05-%E8%AE%AD%E7%BB%83&amp;%E6%8E%A8%E7%90%86" data-v-39a288b8><div><h1 id="探秘transformer系列之-5-训练-推理" tabindex="-1">探秘Transformer系列之（5）--- 训练&amp;推理 <a class="header-anchor" href="#探秘transformer系列之-5-训练-推理" aria-label="Permalink to &quot;探秘Transformer系列之（5）--- 训练&amp;推理&quot;">​</a></h1><h2 id="_0x00-概述" tabindex="-1">0x00 概述 <a class="header-anchor" href="#_0x00-概述" aria-label="Permalink to &quot;0x00 概述&quot;">​</a></h2><p>Transformer训练的目的是通过对输入源序列和模型输出序列的学习，来拟合真正的目标序列。推理的目的则是仅通过输入序列来产生目标序列，作为输入传递给解码器的只有输入序列，而没有目标序列。</p><p>本篇依然以文本翻译为例进行学习。</p><h2 id="_0x01-训练" tabindex="-1">0x01 训练 <a class="header-anchor" href="#_0x01-训练" aria-label="Permalink to &quot;0x01 训练&quot;">​</a></h2><p>LLM是自回归模型，其只能以串行方式进行预测。而为了提高训练效率，理想的训练方式应该是并行计算：一次性输入整个序列，一次性并行解码把各个位置上的预测全部输出。Transformer通过Teacher Forcing结合掩码来满足这个需求。我们接下来就看看训练中的各个要点具体如何实施。</p><h3 id="_1-1-输入" tabindex="-1">1.1 输入 <a class="header-anchor" href="#_1-1-输入" aria-label="Permalink to &quot;1.1 输入&quot;">​</a></h3><p>训练数据由两部分组成：</p><ul><li>源序列，比如”我喜欢吃苹果“。</li><li>目标序列，比如”I love apple“。</li></ul><p>源序列会输入给编码器。目标序列会输入给解码器。同时，目标序列也被转换为真值标签传递给优化器。我们期望解码器的输出尽可能接近真实标签，因此要优化器要最小化交叉熵。因为是并行操作，所以我们会把源序列拆分之后组装成矩阵，一次性给到Transformer。这样通过矩阵运算实现并行操作，一次即可给出所有序列的预测。但是效果等同于一个一个词输入到编码器进行串行解码。</p><h3 id="_1-2-dropout" tabindex="-1">1.2 Dropout <a class="header-anchor" href="#_1-2-dropout" aria-label="Permalink to &quot;1.2 Dropout&quot;">​</a></h3><p>dropout（丢弃）率，即随机丢弃的神经元比例，是一个训练时的超参数，需要根据具体任务进行调整。因为Dropout引入了随机性，因此在测试（或推理）阶段，通常会禁用Dropout，确保所有的神经元都参与到计算中，以获得最稳定的模型输出。</p><h4 id="原理" tabindex="-1">原理 <a class="header-anchor" href="#原理" aria-label="Permalink to &quot;原理&quot;">​</a></h4><p>Dropout（正则化）是一种广泛用于机器学习和深度学习的通过给参数增加约束项来限制参数取值范围的方法。它的目的就是阻碍模型过度学习（过拟合），从而提升算法的泛化能力。正则化不仅可以防止模型过拟合，还可以在一定程度上缓解梯度爆炸问题。因为通过给参数增加约束项，可以限制参数在更新过程中的取值范围，从而避免梯度因参数值过大而爆炸。</p><p>Dropout概念是Hilton在论文“Improving neural networks by preventing co-adaptation of feature detectors”中提出。如下图所示，实施dropout之后，原始网络相当于变成一个更瘦更稀疏的网络。dropout通过随机丢弃的神经元来削弱节点彼此之间的依赖，这样可以有效的缓解过拟合的发生，在一定程度上达到正则化的效果，有助于模型更快地收敛并提高性能，进而解决深度学习神经网络在用小数据集训练时常见的两大问题：过拟合和训练时间长。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093643996-185614801.jpg" alt=""></p><p>如果从集成学习角度来看，每做一次Dropout，相当于从原始的网络中采样得到一个子网络。Dropout对于每个batch的step所优化的参数都不同，每次迭代都相当于训练一个不同的子网络，这些子网络都共享原始网络的部分参数。而且它会不断在这个基础上进行叠加训练。那么，最终的网络可以近似看作集成了若干个不同网络的组合模型。即，Dropout的子网络的平均，提供了一种廉价的近似的Bagging集成。</p><p>另外，Dropout 实际上也可以被看作是一种稀疏性表现。论文“On the Effectiveness of Parameter-Efficient Fine-Tuning”就指出稀疏性在模型训练中的两个主要优势：增强模型的鲁棒性和降低泛化误差。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093655194-966476640.jpg" alt=""></p><p>Dropout 可以在一定程度上达到这种稀疏性理论分析效果。</p><h4 id="位置" tabindex="-1">位置 <a class="header-anchor" href="#位置" aria-label="Permalink to &quot;位置&quot;">​</a></h4><p>Dropout layer 在 Transformer 结构中随处可见，如下图所示，具体分为四种：</p><ul><li>输入时的dropout（对应图上序号1）。</li><li>注意力机制中对注意力权重会施加dropout（对应图上序号2）。</li><li>FFN中两个全连接层之间会施加dropout（对应图上序号3）。</li><li>&quot;Add &amp; Norm&quot;之间也有dropout（对应图上序号4）。</li></ul><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093711571-934559338.jpg" alt=""></p><p>具体对应如下代码片段。</p><ul><li>在 token embedding，positional encoding 求和之后，有 Dropout。</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> PositionalEncoding</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Implement the PE function.&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pe[:, : x.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)].requires_grad_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dropout(x) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这里用到Dropout</span></span></code></pre></div><ul><li>在注意力中，QKTQKTQK^T 经过 scale、掩码、softmax 得到权重之后，要经过 Dropout 才会与 V 相乘。此时随机“丢弃”一些权重的目的是防止模型过分依赖某些特定的输入。用数学公式展示如下。</li></ul><p>Z=Attention(Q,K,V)=Dropout(softmax(QKT√dk))VZ=Attention(Q,K,V)=Dropout(softmax(QKTdk))VZ = Attention(Q,K,V) = Dropout(softmax(\frac{QK^T}{\sqrt d_k}))V</p><p>具体代码如下。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> attention</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(query, key, value, mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, dropout</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query.size(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(query, key.transpose(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> math.sqrt(d_k)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.masked_fill(mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    p_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.softmax(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dropout </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        p_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dropout(p_attn) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这里用到Dropout</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(p_attn, value), p_attn</span></span></code></pre></div><ul><li>在 FFN 中两个全连接层中间也有 Dropout。</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> PositionwiseFeedForward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.w_2(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dropout(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.w_1(x).relu())) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这里用到Dropout</span></span></code></pre></div><ul><li>在每个注意力层和 FFN 层的输出（残差连接之前）都有 Dropout。</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SublayerConnection</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, sublayer):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dropout(sublayer(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.norm(x))) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在Norm&amp;Add之中用到Dropout</span></span></code></pre></div><h4 id="源码" tabindex="-1">源码 <a class="header-anchor" href="#源码" aria-label="Permalink to &quot;源码&quot;">​</a></h4><p>大家可以通过下面PyTorch的源码来了解到Dropout的内部机制。</p><div class="language-cpp vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">template</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">bool</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> feature_dropout</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">bool</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> alpha_dropout</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">bool</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> inplace</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">typename</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> T</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Ctype</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">inplace</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">_dropout_impl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">T</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&amp;</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">double</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> p</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">bool</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> train</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ||</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> !</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">||</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">numel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> multiply</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">inplace</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;(input, </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">at</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">zeros</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({}, input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">options</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()));</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">  at</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::Tensor b;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> // used for alpha_dropout only</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  auto</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> noise </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> feature_dropout </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">?</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> make_feature_noise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> at</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">empty_like</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input, LEGACY_CONTIGUOUS_MEMORY_FORMAT);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  noise.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">bernoulli_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p);</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (alpha_dropout) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    constexpr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> double</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.7580993408473766</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    double</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> /</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> std</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sqrt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">((alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p));</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> noise.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">add</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mul_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a).</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">add_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    noise.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mul_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(a);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    noise.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">div_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">alpha_dropout) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> multiply</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">inplace</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;(input, noise);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> multiply</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">inplace</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;(input, noise).</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">add_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(b);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ALIAS_SPECIALIZATION</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(_dropout,               </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ALIAS_SPECIALIZATION</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(_feature_dropout,       </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ALIAS_SPECIALIZATION</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(_alpha_dropout,         </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> )</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ALIAS_SPECIALIZATION</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(_feature_alpha_dropout, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Tensor</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> make_feature_noise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Tensor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&amp;</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  auto</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input_sizes </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sizes</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">  std</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::vector</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;int64_t&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sizes;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  sizes.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">reserve</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">dim</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">());</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  sizes.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">push_back</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input_sizes[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  sizes.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">push_back</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input_sizes[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]);</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> auto</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i : </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">c10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">irange</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">dim</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">())) {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">void</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)i; </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sizes.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">push_back</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">new_empty</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sizes);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><h4 id="发展" tabindex="-1">发展 <a class="header-anchor" href="#发展" aria-label="Permalink to &quot;发展&quot;">​</a></h4><p>在小模型中可能dropout的效果比较显著，因为小模型针对的是特定领域且少量数据的情况，容易过拟合。而在大模型时代是否需要使用dropout？答案不一。</p><p>认为大模型不需要dropout的主要原因有如下几点：</p><ul><li>因为大模型都是深层结构，以及在训练过程中会使用损失低精度量化计算。使用dropout操作固然可以增加模型的泛化性，但其引入噪声会导致模型训练的不稳定性。</li><li>使用dropout会导致计算资源的增加和效率的降低，首先要生成一个mask（需要额外显存），然后计算结果也需要存下来（需要额外显存）。反向传播也需要执行额外的逻辑操作等，因此总体效率上肯定是更低的。</li><li>现在的大模型都是decoder-only的结构，模型中使用了大量的如MQA、多头、pre-norm，residual等技术，且使用到了大量的多领域的数据进行预训练，在某种程度上也增加了泛化性，去掉一个dropout影响不大。</li></ul><p>然而某些大模型中也的确依然使用dropout，其作用点依然如下：</p><ul><li>对自注意力的输出表示进行操作。</li><li>对MLP输出表示进行操作。</li></ul><p>当然其设置会依据大模型的特点进行调整，比如：</p><ul><li>对于输入层的神经元，其保留率通常设为更接近1的数，使得输入变化不会太大。这是因为对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性。</li><li>对于中间隐藏层的神经元，一般来讲， 设置0.5时效果最好，这对大部分的网络和任务都比较有效。 当 = 0.5时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随机生成的网络结构最具多样性。</li><li>输出层一般不加dropout。</li></ul><p>而且近期也有把dropout进一步应用的工作，比如论文“LoRA Dropout as a Sparsity Regularizer for Overfitting Control”对 LoRA 矩阵 𝐴 和 𝐵 的输入和输出维度进行随机 Dropout来达到更好的效果。之所以不对 𝑟 的维度进行Dropout，是因为这样会导致矩阵秩的降低，相当于在结构上使用更少的 𝑟，从而削弱模型的表达能力。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093735979-1240955064.jpg" alt=""></p><h3 id="_1-3-损失函数" tabindex="-1">1.3 损失函数 <a class="header-anchor" href="#_1-3-损失函数" aria-label="Permalink to &quot;1.3 损失函数&quot;">​</a></h3><p>损失函数通过评估模型预测值与真实值之间的差异来直观地了解模型的预测性能，从而为优化算法提供明确的目标和方向，然后通过最小化损失来逐步优化模型参数。对于自回归语言模型而言，关键之处是看模型能否正确预测到下一个单词，因此优化目标是最小化交叉熵（cross entropy）。这里的交叉熵就是信息熵。或者说，预训练阶段量学习的目标就是最小化各领域的信息熵。</p><p>在Transformer架构中，解码器输出后面接了一个模块Generator。该模块的作用是把解码器输出的隐向量从word embedding维度映射到词表长度，得到logits。logits对应着该token取不同字的概率，接下来模型会依据这些概率，按照一定的采样规则来采样下一个token。模型的效果好坏就是看看模型是否可以把下一个token分类到真值对应的token。因此，每次预测新token都是一个分类任务，Generator就是一个分类头。训练会依据分类结果来计算损失。</p><h4 id="交叉熵" tabindex="-1">交叉熵 <a class="header-anchor" href="#交叉熵" aria-label="Permalink to &quot;交叉熵&quot;">​</a></h4><p>哈佛代码中使用交叉熵损失函数来比较模型的预测的概率分布（logits）和真实分布（targets）之间的差异。然后对损失计算梯度，用反向传播算法来略微调整所有模型的权重，以便接下来生成更接近结果的输出。具体代码如下。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.KLDivLoss(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">reduction</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sum&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>我们用下图来进行分析。假设词表包含6个单词，我们希望得到与预期的目标序列 &quot;I love you&quot;相符的概率分布。图中上方是目标概率分布。第一个输出词的概率分布中，“I”的概率应该是1，而词表中其它词的概率都应该是0。类似的，第二个和第三个输出词的概率分布中，“love”和&quot;you&quot;的概率都应该是1，词表中其它词的概率都应该是0。图下方则是模型对应预测输出的概率分布。损失函数就是要计算两者之间的差异。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093753039-801034104.jpg" alt=""></p><p>计算损失函数的代码如下，传入的参数criterion是损失函数。该类除了包含损失计算外，还包含模型generator部分的前向传播逻辑。下面代码有个正则化的细节，这是为了平滑。假设有两个batch，第一个batch有6个字，则loss是这6个预测结果计算损失的和。第二个batch有60个字，则loss是这60个预测结果计算损失的和。显然第二个损失大，这不符合逻辑。所以我们用除以有效token数目来进行平均。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SimpleLossCompute</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;A simple loss compute and train function.&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, generator, criterion):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.generator </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generator </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Generator类对象，依据解码器的输出预测下一个token</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criterion </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># LabelSmoothing类对象，对标签进行平滑和计算损失</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __call__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, y, norm):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        x: 解码器的输出</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        y: batch.tgt_y，要被预测的所有token，例如src为`&lt;bos&gt;我吃了一个苹果&lt;eos&gt;`，</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">           则tgt_y是&quot;I ate an apple&lt;eos&gt;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        norm: batch.ntokens, tgt_y中的有效token数  </span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.generator(x) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 生成预测输出</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 首先使用KLDivLoss进行了损失计算，随后又除以batch.ntokens对损失进行正则化。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sloss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                x.contiguous().view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x.size(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)), y.contiguous().view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            /</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> norm </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对损失进行正则化</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sloss.data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> norm, sloss</span></span></code></pre></div><h4 id="label-smoothing" tabindex="-1">Label Smoothing <a class="header-anchor" href="#label-smoothing" aria-label="Permalink to &quot;Label Smoothing&quot;">​</a></h4><p>Transformer论文中也使用了Label Smoothing（Label Smoothing Regularization）作为正则化技术来防止过拟合。这么做的原因是因为：现实生活中得到的训练数据是存在噪声的，训练得到的模型也趋向于出现多样性的数据，所以需要在真值中添加噪声，对模型进行约束。下面是论文中的摘录。</p><blockquote><p>Label Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.</p></blockquote><p>Label Smoothing主要针对的是softmax层，其思路是：在真值（gound-truth）中加入噪声，即不要把真值完全标记成非0即1，而是用一种概率的方式标记，或者说是对标签做平滑处理，把最高值去掉一些，去掉的这些概率均分给其它人。调整之后，虽然所有类别的概率和仍然是归一的，但是这样可以让模型不那么自信，从而减少过拟合。</p><p>Label Smoothing起到的作用实际上是抑制了feature norm，损失函数值曲面上不再存在平缓区域，处处都有较大的梯度指向各个类中心，所以特征会更加聚拢。Label Smoothing的原理如下图所示。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093803201-441715704.jpg" alt=""></p><p>我们用实例来进行演示。比如我们的标签是2，词典大小为6。原先的真值向量是：[0，0，1，0，0，0]，我们现在取平滑因子ϵ = 0.2，则平滑之后的标签是：[0.2/5, 0.2/5, 1-0.2, 0.2/5, 0.2/5, 0.2/5] = [0.04, 0.04, 1, 0.04, 0.04, 0.04]。这样可以即使模型预测对了，也不要太自信，而是给模型一点惩罚，防止其过度相信预测结果。</p><p>Label Smoothing的代码如下。该类除了负责平滑标签外，还负责计算损失。另外，因为词典包括填充符，而预测时候不应该预测到这个词，所以所以公式中的 K-1也在算法中要变成 K − 2。常见的做法是把 Pytorch CrossEntropy 中 ignore_index设置为 idx，比如loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LabelSmoothing</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Implement label smoothing.&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 该类除了平滑标签外，还会计算损失</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, size, padding_idx, smoothing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        size: 目标语言词典大小。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        padding_idx: &lt;pad&gt;在词典中对应的序号</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        smoothing: 平滑因子，0表示不做平滑处理</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(LabelSmoothing, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.KLDivLoss(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">reduction</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sum&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 最终使用的损失函数</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.padding_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> padding_idx</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.confidence </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> smoothing</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.smoothing </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> smoothing</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> size</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.true_dist </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # 平滑后的标签</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, target):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        x: generator输出的概率分布。形状为(batch_size, voc_size)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        target: 目标真值标签，内容是token index。形状为(batch_size)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 确保generator的输出维度和词典大小一致，否则后面计算loss的时候就会出错</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        assert</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.size</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 创建一个与x有相同形状的张量</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        true_dist </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.data.clone()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将true_dist全部填充为 self.smoothing / (self.size - 2)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        假设 smoothing=0.2，词表大小为6，batch size为2</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        则true_dist全部填充为 0.2 / (6-2)= 0.05，此时true_dist为：</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        [[0.05, 0.05, 0.05, 0.05, 0.05, 0.05],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">         [0.05, 0.05, 0.05, 0.05, 0.05, 0.05]]</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        true_dist.fill_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.smoothing </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># K - 2 = 6 - 2</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        target.data.unsqueeze(1)会给target.data增加一维，假设target.data是[2,3]，则target.data.unsqueeze(1)的结果是[[2],[3]]</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        将true_dist的第一个1维度上与target.data.unsqueeze(1)对应的值变为self.confidence。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        假设此例中target.data.unsqueeze(1) 为[[2], [3]]，即2个数据的标签分别为2，3，就是把true_dist上设置为self.confidence，则true_dist执行过scatter后变为:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        [[0.05, 0.05, 0.8, 0.05, 0.05, 0.05],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">         [0.05, 0.05, 0.05, 0.8, 0.05, 0.05]]</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">         </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        true_dist.scatter_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, target.data.unsqueeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.confidence) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1代表作用到第一个维度上</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将&lt;pad&gt;所在的index填充为0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        true_dist[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.padding_idx] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 找出target中为&lt;pad&gt;的标签。例如target为[&#39;i&#39;, &#39;love&#39;, &#39;you&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;]，mask则为[[3], [4]]，表示第3个和第4个为空格。       </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nonzero(target.data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.padding_idx)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mask.dim() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # 将&quot;&lt;pad&gt;&quot;所在的label设置为0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            true_dist.index_fill_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, mask.squeeze(), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 保存平滑标签后的label    </span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.true_dist </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> true_dist</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        使用平滑后的标签计算损失</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        由于对`&lt;pad&gt;`部分进行了mask，所以这部分不会参与损失计算</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion(x, true_dist.clone().detach())</span></span></code></pre></div><p>下图给出了上面代码中的部分数据流程示例。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093853851-1828725711.jpg" alt=""></p><p>因为训练是并行执行，难以展示，因此下图进行了简化，只展示前三步中单个输出的损失计算。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093904878-1018194659.jpg" alt=""></p><p>具体调用损失函数的精简代码如下，因为前面提到了LabelSmoothing类分装了损失函数，所以这里的criterion就是LabelSmoothing类的实例。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LabelSmoothing(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">V, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding_idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">smoothing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_model(V, V, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">N</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">batch_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 80</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.train()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    run_epoch(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        data_gen(V, batch_size, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        SimpleLossCompute(model.generator, criterion),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        lr_scheduler,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># run_epoch()函数中会调用损失函数</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> run_epoch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    data_iter,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss_compute,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    scheduler,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    accum_iter</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    train_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">TrainState(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_iter):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.forward(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 计算损失</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss, loss_node </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss_compute(out, batch.tgt_y, batch.ntokens)</span></span></code></pre></div><p>下面是另一个平滑的例子，从该例子可以看到当模型非常自信的时候就会给予其一个微小的惩罚，越自信，损失反而越大。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> loss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x, crit):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # x是从0到100的一个不断增大的数。 d=x+3，比x大一点。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    模拟模型的输出。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    一开始x为1，输出为：[[0.0000, 0.2500, 0.2500, 0.2500, 0.2500]]，此时模型还不太会预测</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    当x到100时，输出为：[[0.0000, 0.9706, 0.0098, 0.0098, 0.0098]]，此时模型很自信的说结果就是 1</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    predict </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.FloatTensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> /</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> /</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> /</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d]])</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 计算模型损失。由于使用的是KLDivLoss，所以要对predict进行log操作</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crit(predict.log(), torch.LongTensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])).data</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> penalization_visualization</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    crit </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LabelSmoothing(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.DataFrame(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        {</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # x从1开始不断增大，模拟模型的表现越来越好</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;Loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [loss(x, crit) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;Steps&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">list</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">99</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ).astype(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;float&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        alt.Chart(loss_data)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        .mark_line()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        .properties(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">width</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">350</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        .encode(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            x</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Steps&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            y</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        .interactive()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">show_example(penalization_visualization)</span></span></code></pre></div><h3 id="_1-4-学习率" tabindex="-1">1.4 学习率 <a class="header-anchor" href="#_1-4-学习率" aria-label="Permalink to &quot;1.4 学习率&quot;">​</a></h3><p>学习率决定了模型参数更新的步长。如果学习率设置得过高，那么模型参数在更新时可能会因为步长过大而跳出最优解的范围。同时，过高的学习率会使模型在更新参数时过于激进，从而加剧梯度的波动，导致梯度爆炸。如果学习率过低，模型收敛速度可能会变慢，训练时间变长。因此，学习率的选择需要根据具体任务和模型结构进行调整。在实际应用中，可以使用自适应学习率算法来根据参数梯度的统计信息来调整学习率。例如，Adam、Adagrad、RMSprop等优化算法都可以根据梯度的历史信息来动态调整学习率，从而提高训练的稳定性和效率。</p><h4 id="warmup" tabindex="-1">Warmup <a class="header-anchor" href="#warmup" aria-label="Permalink to &quot;Warmup&quot;">​</a></h4><p>Warmup（热身）方案也属于动态调整学习率的一种。具体是指在训练开始阶段，将学习率从 0 缓增到指定大小，而不是一开始就从一个指定大小开始训练。如果不进行Warmup，则模型可能在训练开始就快速学习。因为梯度消失的原因，模型对越靠后的层越敏感，也就是越靠后的层学习得越快。然而，靠后的层是以考前层的输出为基础进行学习，如果前面层没有学习好，靠后层的学习就会建立在错误基础上，最终导致模型崩盘。</p><h4 id="noam" tabindex="-1">Noam <a class="header-anchor" href="#noam" aria-label="Permalink to &quot;Noam&quot;">​</a></h4><p>Transformer论文使用了一种特殊的自适应学习率调整策略，称为“Noam”学习率预热策略。它包括warmup（热身）和decay（衰减）两个部分，总体趋势是学习率先增加再减少。“Noam”学习率预热策略具体如下图所示，是一个以warmup_steps为分界点的分段函数。其中dmodeldmodeld_{model}是模型维度，step_num是当前训练步数，armup_steps是预热部署。</p><ul><li>warmup阶段：从0到warmup_steps是热启动阶段，此时先让学习率线性增长到某个最大的值。大型网络在训练初期尚不稳定，较大学习率会增加收敛难度。warmup阶段用较小的学习率可以有助于模型在训练初期快速收敛。而且大型网络往往使用超大的批量大小（batch size），为了实现超大批量大小，需要保证“k 个 minibatch , size = n , lr = η” 和 “1 个 minibatch , size = kn , lr = kη”的梯度近似相等。但是在模型变化剧烈时，这个等式会被打破。warmup 可以有效缓解这个问题。</li><li>decay阶段：冷却阶段，此时让学习率按指数的方式衰减。这样可以在训练后期通过减小学习率来让模型稳定训练。常用方法有指数衰减（exponential）、分段常数衰减（piecewise-constant）、反时限衰减（inverse-time）等等。Transformer 采用了负幂形式，衰减速度先快后慢。</li></ul><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093919676-1131543537.jpg" alt=""></p><p>Noam机制主要是受人类的学习机制启发：每当我们学习一个新的的领域的时候，刚开始需要摸索入门，不断尝试，此时训练速度很慢；随着吸收基础知识增多，我们学习速度会渐渐加快；当掌握了大量的比较杂的知识之后，我们一般会遇到一个瓶颈期，需要知识整合和感悟，速度又会变慢下来。总结一下，人类学习能力是一个螺旋式的渐进过程，是慢与快的交叉过程。Noam机制就是这个进程的具体体现。</p><p>下图给出了具体推导过程。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093932022-303106393.jpg" alt=""></p><p>哈佛代码中rate()函数就是对下面公式的实现。</p><p>lrate=d−0.5model⋅min(step_num−0.5,step_num⋅warmup_steps−1.5)lrate=dmodel−0.5⋅min(step_num−0.5,step_num⋅warmup_steps−1.5)lrate = d_{\text{model}}^{-0.5} \cdot \min({step\_num}^{-0.5}, {step\_num} \cdot {warmup\_steps}^{-1.5})</p><p>具体代码如下。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> rate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(step, model_size, factor, warmup):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    we have to default the step to 1 for LambdaLR function</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    to avoid zero raising to negative power.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果未提供步数，则设为1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> min</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> warmup </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span></code></pre></div><p>具体使用方式如下。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.Adam(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">betas</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.98</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-9</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">lr_scheduler </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LambdaLR(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    optimizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    lr_lambda</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> step: rate(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        step, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.src_embed[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].d_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">factor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">warmup</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">400</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>在实际应用中，也可以用不同的学习率调整每一层，或者把若干层分为一组，对于不同组应用不同的学习率。这是因为 Transformer 模型中不同层通常捕获不同类型的信息，底层通常编码通用和基础的信息，顶层通常编码更接近预训练任务的信息，因此可以对顶层应用较高学习率而对底层应用较低学习率。</p><h3 id="_1-5-初始化" tabindex="-1">1.5 初始化 <a class="header-anchor" href="#_1-5-初始化" aria-label="Permalink to &quot;1.5 初始化&quot;">​</a></h3><p>权重初始化是神经网络训练的重要步骤之一。如果权重初始化过大，那么在反向传播过程中，梯度的计算会受到很大的影响，容易导致梯度爆炸。例如，如果权重由标准正态分布初始化，其期望数量级为1，那么在多层传播后，梯度值可能会变得非常大。</p><p>使用合适的权重初始化策略可以有效控制梯度的大小，减少梯度爆炸的可能性。常见的权重初始化方法包括Xavier初始化（也称为Glorot初始化）和He初始化。这些方法根据网络的层数和激活函数的特点来设置权重的初始值，使得在反向传播过程中梯度的变化更加平稳。</p><p>例如，Xavier初始化方法根据输入和输出神经元的数量来调整权重的初始值，使得前向传播和反向传播中的激活值和梯度值保持相近的方差。He初始化方法则特别适用于ReLU激活函数，因为它考虑了ReLU激活函数在零点的不连续性，从而更加准确地设置了权重的初始值。</p><p>vanilla Transformer使用的就是Xavier初始化。</p><h3 id="_1-6-teacher-forcing" tabindex="-1">1.6 Teacher Forcing <a class="header-anchor" href="#_1-6-teacher-forcing" aria-label="Permalink to &quot;1.6 Teacher Forcing&quot;">​</a></h3><p>本质上来讲，Teacher Forcing 是一种引导和加速模型学习过程的方法，在训练的每一步都为其提供正确的输作为指导，而不是让训练根据之前的输出来生成下一步。</p><h4 id="问题" tabindex="-1">问题 <a class="header-anchor" href="#问题" aria-label="Permalink to &quot;问题&quot;">​</a></h4><p>前文提到过，自回归推理有两个问题：</p><ul><li>容易累积错误，导致训练效果不佳。在训练时，我们可以使用与推理时相同的方法，即用自回归模式进行。然而这样整个模式就是串行化过程，如果编码器在某一轮预测错了，那么这个错误的输出就会作为下一轮解码器的输入，这样基于错误输入继续解码就是在错误道路上越走越远，这将导致模型向全局最优收敛的速度减慢。</li><li>只能以串行方式进行，这就意味着很难以并行化的方式开展训练以提升效率。这种现象和人说话的逻辑是相似的，人也许可以在脑中构思整个句子，但是表述一定是一个词一个词说出来的，而且后面的词一定会被前面的词所影响，这就是说话的逻辑。</li></ul><p>我们用下面表格来看看上面两个问题。</p><ul><li><p>首先，对于所提供的输入，模型必须经过5个时间步才能完成推理，因为Decoder每一次只会预测一个单词。但是，按照上述流程进行训练会过于缓慢，我们应采用并行（矩阵计算）的方式去训练。</p></li><li><p>其次，推理步骤中会出现错误，而且容易在错误道路上越走越远。</p></li></ul><table tabindex="0"><thead><tr><th>时间步</th><th>解码器输入1</th><th>解码器输入2</th><th>解码器输出</th><th>真值</th><th>说明</th></tr></thead><tbody><tr><td>1</td><td></td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>I</td><td>I</td><td>预测正确</td></tr><tr><td>2</td><td>I</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>like</td><td>ate</td><td>预测错误</td></tr><tr><td>3</td><td>I like</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>play</td><td>an</td><td>预测错误</td></tr><tr><td>4</td><td>I like play</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>football</td><td>apple</td><td>预测错误</td></tr><tr><td>5</td><td>I like play football</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td></td><td></td><td>预测正确，但是没啥用处</td></tr></tbody></table><h4 id="概念" tabindex="-1">概念 <a class="header-anchor" href="#概念" aria-label="Permalink to &quot;概念&quot;">​</a></h4><p>为了提升训练效率，我们需要用并行手段来保证在一次训练中输出一个序列中所有的单词的预测结果。为了实现这种理想训练方式，研究人员提出了Teacher Forcing（教师强制训练），这种技术可以通过在训练时向解码器输入整个目标序列来一次性并行解码全部输出。</p><p>具体来说，Teacher Forcing就是每次推理给解码器输入时，不使用前次推理的输出作为下一次推理的增加输入，而是使用训练标签的真值（ground truth）作为下一次推理的增加输入。Teacher Forcing机制保证了 Transformer 在训练阶段可以并行地输出所有的词，而不需要循环，这大大加快了训练速度。这种模式具体如下图所示，图中简化了输入，实际上解码器的输入是一个拼接，而非单纯输入某个标签。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222093947380-201646227.jpg" alt=""></p><p>向解码器提供目标序列实际上是给了模型一个正确指导，即使上一个词预测错误，在下一时间步，它也可以用正确的第一个词（即真值）来预测第二个词，这就避免了错误的持续累加，可以保证对每次推理的监督训练都是从正确的输入出发，因而可以期待正确的结果。其名称中的“Teacher”指的就是真值，自回归模式是“靠自己”进行训练，Teacher Forcing就是有老师带着做训练，即使我们计算出错误的答案，老师也会为我们提供问题的正确答案。我们可以知道是在哪个阶段出现问题，从而很容易地分析自己的错误，更好更快地学习，即“靠标准答案”指导来进行训练。</p><p>注：与 Teacher forcing 模式相对的是 free-running 模型。free-running是直接用上一个状态的输出，来作为下一个状态的输入。</p><h4 id="示例" tabindex="-1">示例 <a class="header-anchor" href="#示例" aria-label="Permalink to &quot;示例&quot;">​</a></h4><p>我们假设要把“我吃了一个苹果”翻译成“I ate an apple”。“我吃了一个苹果”是编码器的输入，“I ate an apple”是真值标签。我们看看模型是如何利用Teacher Forcing模型在训练中纠正错误，防止错误的累积，从而提高训练效果。</p><p>首先，真值标签是目标序列，会作为解码器的输入。为了做更好的训练，我们要把输入的所有token向右移一个位置（Shifted Right），然后在最左边放上一个表示开始的token（）。与之对照，自回归模型本时刻的输入是上一时刻自己输出的值，该值是上一时刻预测出来的，不一定正确；而Teacher Forcing本时刻的输入是上一时刻的真值标签，这肯定是正确的，可以确保解码器本次预测是基于正确基础上进行。</p><p>其次，我们再看看解码过程中的历次推理。可以看到，如果第二步预测之后，模型接受了“like”，会导致模型在后续训练中偏离正轨，导致学习速度变慢，模型也变得不稳定。在Teacher Forcing模式中，因为发现了错误，模型会丢弃这个输出，把“ate“作为下一次的输入。或者说，在训练时，不管解码器本次输出是什么，它下次的输入都是本次输出对应的真值。这样模型将更正训练过程中的统计属性，增加了后续单词成功预测的几率，从而更快地学会生成正确的序列。</p><table tabindex="0"><thead><tr><th>时间步</th><th>解码器输入1</th><th>解码器输入2</th><th>解码器输出</th><th>真值</th><th>说明</th></tr></thead><tbody><tr><td>1</td><td></td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>I</td><td>I</td><td>预测正确</td></tr><tr><td>2</td><td>I</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>like</td><td>ate</td><td>预测错误，用真值纠正</td></tr><tr><td>3</td><td>I ate</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>an</td><td>an</td><td>预测正确</td></tr><tr><td>4</td><td>I ate an</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>orange</td><td>apple</td><td>预测错误，用真值纠正</td></tr><tr><td>5</td><td>I ate an apple</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td></td><td></td><td>预测正确</td></tr></tbody></table><p>具体对应下图所示。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094002661-492886186.jpg" alt=""></p><p>图片思路来源 ：<a href="https://zhuanlan.zhihu.com/p/552573482" target="_blank" rel="noreferrer">解剖Transformer 第二部分：你会用注意力机制组装出一个Transformer吗？</a> <a href="https://www.zhihu.com/people/anthony_shi" target="_blank" rel="noreferrer">大方</a></p><h4 id="原理-1" tabindex="-1">原理 <a class="header-anchor" href="#原理-1" aria-label="Permalink to &quot;原理&quot;">​</a></h4><p>实质上，Teacher Foring是在训练过程中去掉了每次推理的序贯关系，使得原先自回归推理先后依赖被解除，解码器的输入就是真值标签，因此具备了并行推理的可能。我们可以将整个句子”I ate an apple“复制5次构成一个矩阵，使得矩阵每一行代表一个时间步的输入，然后把矩阵作为一个批量一次性输入给解码器，这样就可以利用GPU的并行能力，一次并行做5次推理来得到所有时间步的结果。然后对每个对输出序列的每个元素都计算损失即可，这就是Transformer训练时可以并行计算的原因。</p><p>在执行的过程中，我们在初始输出中添加了起始符<code>&lt;bos&gt;</code>，相当于将输出整体右移一位（Shifted Right）。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094017577-1955721626.jpg" alt=""></p><p>对应到具体数据构建，训练代码会先把目标句子扩展为&quot; I ate an apple&quot;，然后向右移动一位构建标签&quot;I ate an apple&quot;。再构建一个批量如下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bos</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">I ate an apple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bos</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">I ate an apple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bos</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">I ate an apple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bos</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">I ate an apple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bos</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">I ate an apple</span></span></code></pre></div><p>最后把这个批量传给解码器。</p><h4 id="掩码" tabindex="-1">掩码 <a class="header-anchor" href="#掩码" aria-label="Permalink to &quot;掩码&quot;">​</a></h4><p>虽然上述的并行可以一次性计算所有时间步对应的输出，但是却存在一个问题，即注意力在预测某个词时可以提前关注到其后面的单词，从而模型学会作弊。比如上图的每个推理步的输入都是”I ate an apple“这整个句子。所以在预测第一个输出”I“时，模型实际上可以关注到目标序列中”“后面的单词，模型直接输出”I“就可以满足需求。这样的偷窥行为会让模型学会偷懒而不是学习规律。也就是说，仅仅使用Shifted Right，并不能实现teacher forcing，这是因为如果注意力模块是没有mask的self-attention，就会造成数据泄漏的问题。</p><p>因此人们引入了掩码机制来隐藏未来信息。具体做法时在计算注意力时加入一个掩码（mask）该掩码是一个跟输入矩阵一样形状的矩阵，其作用就是遮掉输入矩阵的一部分，让模型只能看到目标序列的一部分（前缀）：在输出第i个元素的时候，不能看目标序列的第i个元素及其后面的部分，只能用到第i个元素之前的信息，从而切断它从未来获得信息的通路，不能泄露天机（把对应的注意力强制置零），这样才能在训练时候模拟实际推理的效果。或者说，通过掩码可以单独调节每一个源元素与每一个目标元素之间的注意力强度。</p><p>在训练时，假如Decoder当前的输入为&quot; I ate an apple&quot;，对于单词an 来讲，只需要让其关注自身及I 和ate 即可，后面的apple作为我们将要预测的单词，此时还未出现，因此不用去关注。下图是四个单词各自应该关注的情况。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094028394-266098203.jpg" alt=""></p><p>下图是加入了掩码之后的Teacher Foring示例。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094041178-501859248.jpg" alt=""></p><h4 id="实现" tabindex="-1">实现 <a class="header-anchor" href="#实现" aria-label="Permalink to &quot;实现&quot;">​</a></h4><p>Teacher Forcing的实现相对简单，就是传入了目标序列，用真实目标序列和掩码作为输入来指导解码器的生成过程。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_iter):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.forward(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        batch.src, batch.tgt, batch.src_mask, batch.tgt_mask</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss, loss_node </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss_compute(out, batch.tgt_y, batch.ntokens)</span></span></code></pre></div><p>而损失函数是把所有的out放在一起，然后看损失。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SimpleLossCompute</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __call__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, y, norm):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.generator(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sloss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.criterion(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                x.contiguous().view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x.size(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)), y.contiguous().view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            /</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> norm</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sloss.data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> norm, sloss</span></span></code></pre></div><h4 id="优劣" tabindex="-1">优劣 <a class="header-anchor" href="#优劣" aria-label="Permalink to &quot;优劣&quot;">​</a></h4><p>Teacher Forcing的优势是因为模型是在“正确答案”指引下进行预测，训练的稳定性得到大大增强，收敛速度也得以大幅提升。而且我们可以一次性的输入全部目标序列，然后以并行的方式一次性的输出完整的目标序列，训练效率大幅提升。</p><p>但是Teacher Forcing也存在一定的问题。因为训练可以“靠老师”，推理还得“靠自己”，这样推理时遇到的错误输出对于下次推理来说就是在训练数据分布之外（out of distribution）的异常输入，所以会导致用Teacher Forcing模式训练出来的模型在训练环节和预测环节存在行为差异。这种因为训练和推理之间数据分布存在差异，导致模型在部署中表现变差的现象叫做exposure bias（曝光误差）。另外，因为模型生成的结果都必须和参考句一一对应。这种约束在训练过程中减少模型发散，加快收敛速度。但是一方面也扼杀了翻译多样性的可能。</p><p>因此研究人员也针对exposure bias做了一些改进工作。比如其中一个变种是Curriculum Learning，它的思路是：既然自回归模式的全靠自身预测结果和Teacher Forcing模式的全靠真值均不可取，那么就不如折中方案，进行有计划的学习。在训练过程的每一步会以一定的概率随机选择是用模型输出还是用真值。上述选择概率是随着训练的推进不断调整的：训练过程会从Teacher Forcing开始，慢慢降低在训练阶段输入真值的频率。即一开始学生是小白，只能老师带着学，后续随着学生的进步，老师慢慢放手让学生自主学。</p><h4 id="小结" tabindex="-1">小结 <a class="header-anchor" href="#小结" aria-label="Permalink to &quot;小结&quot;">​</a></h4><p>训练流程是之所以是一步操作，这是因为ground-truth已知，而结合Teacher Forcing和掩码，能够让第i个时间步的上下文向量只是由前i个时间步的向量计算而来，这样就保证了第i个单词的预测只使用了前i个时间步的信息，即提高了计算效率，又符合语言模型的内在规律。</p><h3 id="_1-7-并行" tabindex="-1">1.7 并行 <a class="header-anchor" href="#_1-7-并行" aria-label="Permalink to &quot;1.7 并行&quot;">​</a></h3><p>我们接下来看看训练时候的并行机制。总的来说，Transformer的并行化主要体现在训练阶段，特别是在自注意力和FFN中。</p><p>在推理阶段，因为ground-truth未知，我们只知道前i-1个时间步预测的单词，显然只能使用自回归迭代操作来预测所有的单词，所以需要多步来预测序列中所有的单词，难以并行。尽管Decoder端在推理阶段的并行化存在挑战，但通过一些先进的技术和模型变种，这个问题也可以得到一定缓解。</p><h4 id="逻辑维度" tabindex="-1">逻辑维度 <a class="header-anchor" href="#逻辑维度" aria-label="Permalink to &quot;逻辑维度&quot;">​</a></h4><p>我们首先从seq2seq模型维度来看看。 encoder-decoder 架构是自回归的：通过上一步产生的token和这一步的输入来预测这一步的输出。我们看看Transformer对此做了哪些改进从而完成并行。</p><h5 id="编码器" tabindex="-1">编码器 <a class="header-anchor" href="#编码器" aria-label="Permalink to &quot;编码器&quot;">​</a></h5><p>编码器天然支持并行。整个架构从原来的序列模型变成了一个全连接图模型，每个词之间是可以直接关联的，这就很方便的进行矩阵计算，从而享受并行计算或者 GPU 加速带来的运行效率的提升。</p><p>下图是使用“北国的特产”为例来看Transformer计算时候的信息流。注意力机制的感知域是整个句子，Transformer在计算任意一个词的特征时，会用到所有词的信息，即”北“的特征L(北)是由所有词共同计算得到的。L(北)是所有单词的加权和，这样就没有距离的概念，不会有长依赖的问题，即序列中任意两个单词之间距离都是一个固定的常数。另外，输入序列中每个位置的单词都各自单独的路径流入编码器，所有单词可以同时流入编码器中，不需要排队进入，这样就可以进行并行处理。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094053709-1658058776.jpg" alt=""></p><h5 id="解码器" tabindex="-1">解码器 <a class="header-anchor" href="#解码器" aria-label="Permalink to &quot;解码器&quot;">​</a></h5><p>在自回归模式下，解码器需要两种隐向量：</p><ul><li>编码器生成的编码隐向量。</li><li>解码器在解码过程中产生的隐向量，即上一状态的输出。</li></ul><p>对于第一种隐向量，编码器通过并行操作可以一次性计算出来，传递给交叉注意力。对于第二种隐向量，在Teacher Forcing模型下，每次推理的序贯关系被打破，原先自回归推理先后依赖被解除，不再需要解码过程中的隐向量。所以配合掩码，我们可以把全量输入和真值标签一次性直接投入到解码器中来完成并行训练。</p><h4 id="模型维度" tabindex="-1">模型维度 <a class="header-anchor" href="#模型维度" aria-label="Permalink to &quot;模型维度&quot;">​</a></h4><p>模块即指编码器，也指解码器。因为在训练中，编码器解码器都可以并行。从模型来看，以下维度可以并行。</p><ul><li>Q、K、V生成可以并行化。使用WQWQW^Q，WKWKW^K，WVWVW^V这三个权重矩阵的计算过程可以并行化。</li><li>自注意力机制的并行化。在自注意力层中，模型计算输入序列中所有位置的单词之间的注意力分数，并且这些计算是相互独立的。因此，它们可以在不同的处理单元上并行执行。</li><li>多头注意力机制的并行化。多头注意力机制中，不同的注意力头可以在不同的处理单元上并行计算。</li><li>FFN的并行化。FFN对输入序列的每个位置执行相同的操作，并且这些操作是独立的。因此，它们也可以在不同的处理单元上并行执行。</li></ul><h5 id="自注意力" tabindex="-1">自注意力 <a class="header-anchor" href="#自注意力" aria-label="Permalink to &quot;自注意力&quot;">​</a></h5><p>编码器可以并行的关键是在自注意力机制中，计算ZiZiZ_i要依赖全部元素x1,...,xnx1,...,xnx_1,...,x_n，而非依赖Zi−1Zi−1Z_{i-1}。参见下图，以”吃了“这个token为例，自注意力机制利用输入元素两两之间的相关性作为权重，然后加权求和把每一个输入元素xixix_i映射到语义向量ziziz_i。ziziz_i是考虑了全局依赖之后的产物，不需要严格时序依次迭代，能够并行，因此我们可以用矩阵运算一下子把所有的ziziz_i计算出来。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094105338-1438300873.jpg" alt=""></p><h5 id="ffn" tabindex="-1">FFN <a class="header-anchor" href="#ffn" aria-label="Permalink to &quot;FFN&quot;">​</a></h5><p>输入序列中每个位置的单词都按照各自单独的路径流入编码器，即各个单词同时流入编码器中，不是排队进入。<br> 在自注意力self-attention层中，这些路径两两之间是相互依赖的，而FFN则没有这些依赖性，所以这些路径在流经FFN时可以并行计算。</p><p>对于输入序列中的每个位置 x 会使用相同的变换矩阵来计算，且每个子层使用的不用的参数。在计算完Multi-Head Attention后，FFN层的输入矩阵为 X∈Rdinput×dmodelX∈Rdinput×dmodelX∈R^{d_{input} \times d_{model}}，可以看作是由每个输入位置（ dinputdinputd_{input} 行）的attention结果（ dmodeldmodeld_{model} 列）堆叠而成。这些行进行相同的线性变换后，维度改变，重新堆叠成FFN层的输出。行与行之间无交错，完全是“separately and identically”，按位置进行变换。论文的3.3小节Position-wise Feed-Forward Networks中，对“Position-wise”做了注解，如下图所示。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094115267-312393953.jpg" alt=""></p><h4 id="张量维度" tabindex="-1">张量维度 <a class="header-anchor" href="#张量维度" aria-label="Permalink to &quot;张量维度&quot;">​</a></h4><p>输入到 Transformer 的 Tokens 有 <code>batch_size</code>、<code>sequence_length</code>、<code>embedding_dim</code> 三个维度，而 Attention 计算的 multi head 机制把 <code>embedding_dim</code> 维度再拆分为 <code>head_num</code> 个 <code>head_dim</code>，因此从计算量角度来看一共有五个维度：</p><ul><li>batch_size</li><li>sequence_length</li><li>token</li><li>head_num</li><li>head_dim</li></ul><p>其中 batch_size、head_num和token这三个维度本身就支持并行。而人们最近也在序列维度上进行了并行尝试，即序列并行。序列并行首先由论文&quot;Sequence Parallelism: Long Sequence Training from System Perspective&quot;提出，目的是要解决序列长度过长导致内存使用量过大的问题，我们知道LLM推理主要有两个阶段：prefill和decode。前者瓶颈在于计算，而后者在于带宽。在prefill中已经有将sequence length拆开计算再汇总的做法，序列并行则是将这个过程并行完成，具体是把输入序列切分为多个块，每个块放到不同GPU上进行计算，以减少长序列输入对显存大小的需求。为了合并计算结果，论文也提出了环自注意力（RSA）机制。</p><p>另外，也有一种说法叫做上下文并行 Context Parallelism，其最先出现在NVIDIA Megatron-Core中，上下文并行主要是针对self-attention（Linear，LayerNorm）进行优化，它将原本的输入按照sequence length维度拆开，分到不同的device上，分别计算，然后通过all-gather和reduce-scatter通信操作来整合其他device上算出的结果。</p><h3 id="_1-7-代码" tabindex="-1">1.7 代码 <a class="header-anchor" href="#_1-7-代码" aria-label="Permalink to &quot;1.7 代码&quot;">​</a></h3><h4 id="训练方式" tabindex="-1">训练方式 <a class="header-anchor" href="#训练方式" aria-label="Permalink to &quot;训练方式&quot;">​</a></h4><p>train_model()函数会依据配置选择是进行分布式训练还是单机训练。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train_distributed_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab_src, vocab_tgt, spacy_de, spacy_en, config):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> the_annotated_transformer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_worker</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ngpus </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.cuda.device_count()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    os.environ[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;MASTER_ADDR&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;localhost&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    os.environ[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;MASTER_PORT&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;12356&quot;</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Number of GPUs detected: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ngpus</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Spawning training processes ...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    mp.spawn(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        train_worker,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        nprocs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ngpus,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab_src, vocab_tgt, spacy_de, spacy_en, config):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;distributed&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        train_distributed_model( </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分布式训练</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            vocab_src, vocab_tgt, spacy_de, spacy_en, config</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        train_worker( </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 使用0号GPU进行单机训练</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, vocab_src, vocab_tgt, spacy_de, spacy_en, config, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span></code></pre></div><h4 id="单机训练代码" tabindex="-1">单机训练代码 <a class="header-anchor" href="#单机训练代码" aria-label="Permalink to &quot;单机训练代码&quot;">​</a></h4><p>单机训练代码如下，它遍历一个 epoch 的数据，然后调用 forward()函数，接着用 loss_compute() 函数计算梯度，更新参数并且返回 loss。这里的 loss_compute() 函数的输入是：模型的预测 out，真实的标签序列 batch.trg_y 和 batch 中词的个数。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train_worker</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpu,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ngpus_per_node,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    vocab_src, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 源语言词典</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    vocab_tgt, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 目标语言词典</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    spacy_de, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 源语言分词器</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    spacy_en, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 目标语言分词器</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    config,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    is_distributed</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Train worker process using GPU: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> for training&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">flush</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    torch.cuda.set_device(gpu)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pad_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> vocab_tgt[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&lt;pad&gt;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 得到目标语言词典中&quot;&lt;pad&gt;&quot;所对应的索引</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 512</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # 词嵌入大小</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_model(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab_src), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab_tgt), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">N</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 构建一个6层模型</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.cuda(gpu)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    is_main_process </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> is_distributed:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dist.init_process_group(</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;nccl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">init_method</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;env://&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">rank</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">world_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ngpus_per_node</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DDP(model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">device_ids</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[gpu])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.module</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        is_main_process </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gpu </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 构建损失函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LabelSmoothing(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab_tgt), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding_idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pad_idx, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">smoothing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criterion.cuda(gpu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 构建数据加载器</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    train_dataloader, valid_dataloader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> create_dataloaders(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpu,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        vocab_src,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        vocab_tgt,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        spacy_de,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        spacy_en,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;batch_size&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">//</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ngpus_per_node,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        max_padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;max_padding&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        is_distributed</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">is_distributed,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 构建优化器</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.Adam(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;base_lr&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">betas</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.98</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-9</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 构建学习率策略，依据配置来设定warmup参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    lr_scheduler </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LambdaLR(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        optimizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        lr_lambda</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> step: rate(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            step, d_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">factor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">warmup</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;warmup&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    train_state </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TrainState()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;num_epochs&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> is_distributed:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            train_dataloader.sampler.set_epoch(epoch)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            valid_dataloader.sampler.set_epoch(epoch)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.train()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;[GPU</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">] Epoch </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">epoch</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Training ====&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">flush</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        _, train_state </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> run_epoch(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            (Batch(b[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], b[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], pad_idx) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_dataloader),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            SimpleLossCompute(module.generator, criterion),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            optimizer,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            lr_scheduler,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train+log&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            accum_iter</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;accum_iter&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            train_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_state,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        GPUtil.showUtilization()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> is_main_process:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            file_path </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">%s%.2d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">.pt&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> %</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;file_prefix&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], epoch)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            torch.save(module.state_dict(), file_path)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        torch.cuda.empty_cache()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;[GPU</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">] Epoch </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">epoch</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Validation ====&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">flush</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.eval()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sloss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> run_epoch(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            (Batch(b[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], b[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], pad_idx) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> valid_dataloader),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            SimpleLossCompute(module.generator, criterion),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            DummyOptimizer(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            DummyScheduler(),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;eval&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sloss)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        torch.cuda.empty_cache()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> is_main_process:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        file_path </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">%s</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">final.pt&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> %</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> config[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;file_prefix&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        torch.save(module.state_dict(), file_path)</span></span></code></pre></div><h4 id="总体代码" tabindex="-1">总体代码 <a class="header-anchor" href="#总体代码" aria-label="Permalink to &quot;总体代码&quot;">​</a></h4><p>总体代码如下所示，里面包含了训练和使用训练好的模型进行推理。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> example_simple_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    V </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 11</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LabelSmoothing(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">V, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding_idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">smoothing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_model(V, V, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">N</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.Adam(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">betas</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.98</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-9</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    lr_scheduler </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LambdaLR(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        optimizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        lr_lambda</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> step: rate(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            step, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.src_embed[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].d_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">factor</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">warmup</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">400</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 80</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.train()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        run_epoch(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            data_gen(V, batch_size, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            SimpleLossCompute(model.generator, criterion),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            optimizer,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            lr_scheduler,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.eval()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        run_epoch(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            data_gen(V, batch_size, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            model,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            SimpleLossCompute(model.generator, criterion),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            DummyOptimizer(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            DummyScheduler(),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;eval&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.eval()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.LongTensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">7</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    max_len </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> src.shape[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, max_len)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(greedy_decode(model, src, src_mask, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">max_len</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">max_len, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">start_symbol</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><h2 id="_0x02-推理" tabindex="-1">0x02 推理 <a class="header-anchor" href="#_0x02-推理" aria-label="Permalink to &quot;0x02 推理&quot;">​</a></h2><p>当我们谈论大型语言模型（LLM）的推断过程时，我们指的是使用已经训练好的模型来对输入文本进行处理，从而生成相应的输出。因为训练和推理的基本流程类似，所以我们在此处主要看两者的差异点和推理的独有特性。</p><h3 id="_2-1-输入输出" tabindex="-1">2.1 输入输出 <a class="header-anchor" href="#_2-1-输入输出" aria-label="Permalink to &quot;2.1 输入输出&quot;">​</a></h3><p>首先，无论是训练和推理，编码器模块的输入（要被翻译的句子）和执行过程都相同。</p><p>其次，对于解码器来说，训练和预测的执行过程存在不同。</p><ul><li>目标输入不同。虽然都是把新词加到之前的输入上，拼接成解码器的新输入，但是新词的来源不同。 <ul><li>推理阶段是用上一次的输出拼接成下一次输入。即tgt是从开始，然后每次加入上一次的输出。</li><li>训练阶段时时用真值拼接成下一次输入。即tgt是从开始，然后每次加入下一个真值。而且是一次性把输入序列全部传给解码器。</li></ul></li><li>输出不同。 <ul><li>推理：每次输出一个新token。Decoder的并行化仅在训练阶段，在推理阶段，因为我们没有正确的目标语句，t时刻的输入必然依赖t-1时刻的输出，这时跟之前的seq2seq就没什么区别了。</li><li>训练：transformer会一次输出多个概率分布。在训练时，得到输出概率分布后就可以计算loss了，并不需要将概率分布再转成对应的token。</li></ul></li></ul><h3 id="_2-2-流程" tabindex="-1">2.2 流程 <a class="header-anchor" href="#_2-2-流程" aria-label="Permalink to &quot;2.2 流程&quot;">​</a></h3><p>在推理时，因为在预测场景下不存在答案文本，只能从位置开始预测，因此预测场景的解码器必定是串行的循环输出。在后续步骤的预测中，会将前一个时间步的输出序列和历史预测单词一齐送到下一个时间步的解码器，直到遇到句末标记。 与Seq2Seq模型的区别在于，在每个时间步，我们重新输入迄今为止生成的整个输出序列，而不仅仅是最后一个单词。</p><p>推理过程的逻辑流程如下</p><table tabindex="0"><thead><tr><th>时间步</th><th>解码器输入1</th><th>解码器输入2</th><th>解码器输出</th></tr></thead><tbody><tr><td>1</td><td></td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>I</td></tr><tr><td>2</td><td>I</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>ate</td></tr><tr><td>3</td><td>I ate</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>an</td></tr><tr><td>4</td><td>I ate an</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td>apple</td></tr><tr><td>5</td><td>I ate an apple</td><td>&quot;我吃了一个苹果&quot;编码后的隐向量</td><td></td></tr></tbody></table><p>对应的逻辑图如下。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094131971-366479802.jpg" alt=""></p><p>训练过程就是简单地在上述推理过程的基础之上加上对每次推理预测的新元素的监督即可，具体见下图。</p><p>注意：下图只是为了展示流程，实际上是一并输入，并行预测。</p><p><img src="https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250222094141063-809544615.jpg" alt=""></p><p>最后，我们总结训练和推理在流程上的区别如下表。</p><table tabindex="0"><thead><tr><th>步骤</th><th></th><th>训练</th><th>推理</th></tr></thead><tbody><tr><td></td><td>输入</td><td>源语言序列 + 目标语言序列（真值）</td><td>源语言序列 + 目标语言序列（预测的输出）</td></tr><tr><td>1</td><td>编码器处理</td><td>产生整个源语言序列的编码表示</td><td>产生整个源语言序列的编码表示</td></tr><tr><td>2</td><td>解码器处理输入</td><td>目标序列首先加一个句首标记，被转换成嵌入后送入解码器。</td><td>在第一个时间步使用仅包含句子开头标记的空序列，而非目标序列。后续时间步会输入迄今为止生成的整个输出序列。序列被转换成嵌入后送入解码器。</td></tr><tr><td>3</td><td>解码器解码</td><td>解码器将目标嵌入与编码器的编码表示一起处理，生成目标序列的解码表示</td><td>解码器将目标嵌入与编码器的编码表示一起处理，生成目标序列的解码表示</td></tr><tr><td>4</td><td>解码器处理输出</td><td>输出层将目标序列的编码表转换为单词概率和最终输出序列</td><td>输出层将目标序列的编码表转换为单词概率和最终输出序列</td></tr><tr><td>5</td><td>计算损失</td><td>损失函数将此输出序列与训练数据中的目标序列进行比较，计算损失</td><td>无</td></tr><tr><td>7</td><td>迭代</td><td>无迭代，一次性处理完毕</td><td>迭代运行2~4，逐步输出token</td></tr></tbody></table><h3 id="_2-3-代码" tabindex="-1">2.3 代码 <a class="header-anchor" href="#_2-3-代码" aria-label="Permalink to &quot;2.3 代码&quot;">​</a></h3><p>下面是哈佛源码中的推理测试代码。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># ## Inference:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># &gt; Here we make a forward step to generate a prediction of the</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># model. We try to use our transformer to memorize the input. As you</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># will see the output is randomly generated due to the fact that the</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># model is not trained yet. In the next tutorial we will build the</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># training function and try to train our model to memorize the numbers</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># from 1 to 10.</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> inference_test</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 构建，源词典和目标词典大小都为11，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # EncoderLayer和DecoderLayer的数量为2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    test_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_model(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    test_model.eval()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 输入形状为(1, 10)，即一个句子，该句子10个单词。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.LongTensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">7</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 定义源序列掩码，即所有的词都是有效的，没有填充词</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 将输入送给编码器，获取输出，记作memory</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> test_model.encode(src, src_mask)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 初始化ys为[[0]]，用于保存预测结果，其中0表示&#39;&lt;bos&gt;&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ys </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.zeros(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).type_as(src)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 循环调用解码器来预测下一个token。例如：假设我们要将“I love you”翻译成</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">	# “我爱你”，则第一次的`ys`为(&lt;bos&gt;)，然后输出为“I”。然后第二次`ys`为(&lt;bos&gt;, I)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">	# 输出为&quot;love&quot;，依次类推，直到decoder输出“&lt;eos&gt;”或达到句子长度。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将编码器的输出memory和之前解码器的所有输出作为参数，让解码器来预测下一个token</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> test_model.decode(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # ys就是Decoder之前的所有输出</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            memory, src_mask, ys, subsequent_mask(ys.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)).type_as(src.data)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将Decoder的输出送给generator进行预测。这里只取最后一个词的输出进行预测。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 因为传入tgt的词数是变化的，第一次是(&lt;bos&gt;)，第二次是(&lt;bos&gt;, I)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 所以输出out的维度也是变化的，变化的就是(batch_size, 词数，词向量)中词数这个维度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> test_model.generator(out[:, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 取出数值最大的那个token，它的index在词典中对应的词就是预测结果</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        _, next_word </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.max(prob, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 取出预测结果</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        next_word </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> next_word.data[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将这一次的预测结果和之前的拼到一块，作为之后Decoder的输入</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ys </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.cat(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            [ys, torch.empty(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).type_as(src.data).fill_(next_word)], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Example Untrained Model Prediction:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ys)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> run_tests</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        inference_test()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">show_example(run_tests)</span></span></code></pre></div><h2 id="_0xff-参考" tabindex="-1">0xFF 参考 <a class="header-anchor" href="#_0xff-参考" aria-label="Permalink to &quot;0xFF 参考&quot;">​</a></h2><p><a href="https://arxiv.org/abs/2202.06417" target="_blank" rel="noreferrer">A Contrastive Framework for Neural Text Generation (Su et al., 2022)</a><br><a href="https://arxiv.org/abs/2404.14294" target="_blank" rel="noreferrer">A Survey on Efficient Inference for Large Language Models</a><br><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer">Attention Is All You Need (Vaswani et al., 2017)</a><br><a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/" target="_blank" rel="noreferrer">Breaking the Sequential Dependency of LLM Inference Using Lookahead Decoding (Fu et al. 2023)</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI2MjU4MDYwOA==&amp;mid=2247484251&amp;idx=1&amp;sn=a3ed8006077c2d21e1c7829c11f021c2&amp;scene=21#wechat_redirect" target="_blank" rel="noreferrer">ChatGPT是第一个真正意义的人工通用智能</a><br><a href="https://arxiv.org/abs/2211.17192" target="_blank" rel="noreferrer">Fast Inference from Transformers via Speculative Decoding (Leviathan et al., 2022)</a><br><a href="https://arxiv.org/abs/1801.06146" target="_blank" rel="noreferrer">https://arxiv.org/abs/1801.06146</a><br><a href="https://arxiv.org/abs/1803.05407" target="_blank" rel="noreferrer">https://arxiv.org/abs/1803.05407</a><br><a href="https://arxiv.org/abs/2006.05987" target="_blank" rel="noreferrer">https://arxiv.org/abs/2006.05987</a><br><a href="https://github.com/1311440131/deep_blue_writings/tree/main/2021_9_18_%E5%BE%AE%E8%B0%83Transformer%E7%9A%84%E9%AB%98%E7%BA%A7%E6%8A%80%E6%B3%95" target="_blank" rel="noreferrer">https://github.com/1311440131/deep_blue_writings/tree/main/2021_9_18_%E5%BE%AE%E8%B0%83Transformer%E7%9A%84%E9%AB%98%E7%BA%A7%E6%8A%80%E6%B3%95</a><br><a href="https://medium.com/%40plienhar/llm-inference-series-1-introduction-9c78e56ef49d" target="_blank" rel="noreferrer">https://medium.com/@plienhar/llm-inference-series-1-introduction-9c78e56ef49d</a><br><a href="https://medium.com/%40plienhar/llm-inference-series-2-the-two-phase-process-behind-llms-responses-1ff1ff021cd5" target="_blank" rel="noreferrer">https://medium.com/@plienhar/llm-inference-series-2-the-two-phase-process-behind-llms-responses-1ff1ff021cd5</a><br><a href="https://pytorch.org/blog/ch-1.6-now-includes-stochastic-weight-averaging/" target="_blank" rel="noreferrer">https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/</a><br><a href="https://pytorch.org/docs/stable/.html%23stochastic-weight-averaging" target="_blank" rel="noreferrer">https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&amp;mid=2247531933&amp;idx=2&amp;sn=27fa53abb35fbec186cd3801983779f8&amp;chksm=c060731f8427a4c6d32de787447d8604fecf0739f6dcacc599153285a7c4683cf9dfb590d239&amp;mpshare=1&amp;scene=1&amp;srcid=0821UThfJG2X8cWUw2eUOuwb&amp;sharer_shareinfo=41b3507fb5f2282a9516d6c002e13797&amp;sharer_shareinfo_first=41b3507fb5f2282a9516d6c002e13797#rd" target="_blank" rel="noreferrer">LaViT：这也行，微软提出直接用上一层的注意力权重生成当前层的注意力权重 | CVPR 2024</a> VincentLee<br><a href="https://arxiv.org/pdf/2402.16363" target="_blank" rel="noreferrer">LLM Inference Unveiled: Survey and Roofline Model Insights</a><br><a href="https://zhuanlan.zhihu.com/p/688687624" target="_blank" rel="noreferrer">LLM的几种并行机制</a> <a href="https://www.zhihu.com/people/mrdoghead" target="_blank" rel="noreferrer">认输你就真了</a><br><a href="https://arxiv.org/pdf/2404.09610" target="_blank" rel="noreferrer">LoRA Dropout as a Sparsity Regularizer for Overfitting Control</a><br><a href="https://blog.csdn.net/qq_36533552/article/details/104034759" target="_blank" rel="noreferrer">nn.KLDivLoss_咕噜咕噜day的博客-CSDN博客_kldivloss pytorch</a><br><a href="https://arxiv.org/pdf/2211.15583" target="_blank" rel="noreferrer">On the Effectiveness of Parameter-Efficient Fine-Tuning</a><br><a href="https://blog.csdn.net/qq_36560894/article/details/118424356" target="_blank" rel="noreferrer">Pytorch：交叉熵损失(CrossEntropyLoss)以及标签平滑(LabelSmoothing)的实现_我是大黄同学呀的博客-CSDN博客_标签平滑交叉熵</a><br><a href="https://jalammar.github.io/illustrated-word2vec/" target="_blank" rel="noreferrer">The Illustrated Word2vec</a> <a href="https://jalammar.github.io/" target="_blank" rel="noreferrer">Jay Alammar</a><br><a href="https://arxiv.org/abs/2312.15234" target="_blank" rel="noreferrer">Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems</a><br><a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noreferrer">《Rethinking the Inception Architecture for Computer Vision》</a><br><a href="https://blog.csdn.net/zhaohongfei_358/article/details/126085246" target="_blank" rel="noreferrer">万字逐行解析与实现Transformer，并进行德译英实战（一）</a><br><a href="https://blog.csdn.net/zhaohongfei_358/article/details/126085598" target="_blank" rel="noreferrer">万字逐行解析与实现Transformer，并进行德译英实战（三）</a><br><a href="https://blog.csdn.net/zhaohongfei_358/article/details/126085557" target="_blank" rel="noreferrer">万字逐行解析与实现Transformer，并进行德译英实战（二）</a> <a href="https://blog.csdn.net/zhaohongfei_358" target="_blank" rel="noreferrer">iioSnail</a><br><a href="https://zhuanlan.zhihu.com/p/2893564859" target="_blank" rel="noreferrer">大模型参数微调：Sparsity和Dropout</a> <a href="https://www.zhihu.com/people/89-47-66-58-20" target="_blank" rel="noreferrer">Chongjie</a><br><a href="https://zhuanlan.zhihu.com/p/701877920" target="_blank" rel="noreferrer">大模型时代是否还需Dropout，一次关于GLM4-9B-Chat的分析</a> <a href="https://www.zhihu.com/people/lei-yi-43-4" target="_blank" rel="noreferrer">LeonYi</a><br><a href="https://blog.csdn.net/qq_41805511/article/details/99438838" target="_blank" rel="noreferrer">实现 pytorch 中 torch.nn.CrossEntropyLoss_Agwave的博客-CSDN博客</a><br><a href="https://zhuanlan.zhihu.com/p/552573482" target="_blank" rel="noreferrer">解剖Transformer 第二部分：你会用注意力机制组装出一个Transformer吗？</a> <a href="https://www.zhihu.com/people/anthony_shi" target="_blank" rel="noreferrer">大方</a><br> Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and Christian Jauvin. A neural probabilistic language model. Journal of Machine Learning Research (JMLR), 3:1137–1155, 2003. [PDF]</p><p>本文转自 <a href="https://www.cnblogs.com/rossiXYZ/p/18730583" target="_blank" rel="noreferrer">https://www.cnblogs.com/rossiXYZ/p/18730583</a>，如有侵权，请联系删除。</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/AI/Transformer/05-训练&amp;推理.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页面 OR 提出修改意见<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/AI/Transformer/04-编码器 &amp; 解码器.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>上一篇</span><span class="title" data-v-e257564d>04-编码器 & 解码器</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/AI/Transformer/06-token.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>下一篇</span><span class="title" data-v-e257564d>06-token</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>ICP备案号: <a href="https://beian.miit.gov.cn/" target="_blank">蜀ICP备2024103116号</a><br>公安备案号: <a href="https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928" rel="noreferrer" target="_blank">川公网安备51012202001928</a></p><p class="copyright" data-v-e315a0ad>版权所有 © 2024-present  <a href="mailto:16693226842@163.com" target="_blank">Ethan.Liu</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai_deep_learning_theory_00-dl_base_notes.md\":\"CAdB7Lmh\",\"ai_deep_learning_theory_01-feedforward_network.md\":\"Dc0-nIKA\",\"ai_deep_learning_theory_02-back_propagation.md\":\"t66HZ6KH\",\"ai_deep_learning_theory_03-bp_example_demo.md\":\"CdKkr9wb\",\"ai_deep_learning_theory_04-convolution_neural_network.md\":\"CKyKqVoU\",\"ai_deep_learning_theory_05-deep_learning_model.md\":\"B3Ib7-iT\",\"ai_deep_learning_theory_06-pytorch_install.md\":\"C08X_AVj\",\"ai_deep_learning_theory_07-operators.md\":\"BKFjU-RC\",\"ai_deep_learning_theory_08-activation_functions.md\":\"Como81rR\",\"ai_deep_learning_theory_09-recurrent_neural_network.md\":\"D7qCdZEy\",\"ai_deep_learning_theory_10-seq2seq.md\":\"CIAyZr6Y\",\"ai_deep_learning_theory_11-1attentions.md\":\"CB-r_QHy\",\"ai_deep_learning_theory_11-2attention-extension.md\":\"D9uu1g-H\",\"ai_deep_learning_theory_12-weight-initialization.md\":\"tjnwIO-Q\",\"ai_deep_learning_theory_13-optimizers.md\":\"Qk82FVfW\",\"ai_deep_learning_theory_14-regularization.md\":\"CWzAanem\",\"ai_deep_learning_theory_15-deep-learning-tuning-guide.md\":\"CMQIvWo9\",\"ai_deep_learning_theory_20-pytorch-tensor.md\":\"3GYXzMSK\",\"ai_deep_learning_theory_21-pytorch-autograd.md\":\"BPcbnDeO\",\"ai_deep_learning_theory_22-pytorch-module.md\":\"D3W47z47\",\"ai_deep_learning_theory_23-1training-example-1.md\":\"BSbXuKLm\",\"ai_deep_learning_theory_23-2decoder.md\":\"BCYdFt2l\",\"ai_deep_learning_theory_23-3encoder.md\":\"BpaKSKIz\",\"ai_deep_learning_theory_23-4transformer.md\":\"Deo9x8So\",\"ai_deep_learning_theory_24-pytorch-optimizer.md\":\"D38W_WfI\",\"ai_deep_learning_theory_25-pytorch-lr-scheduler.md\":\"BrPX5Pww\",\"ai_deep_learning_theory_26-pytorch-dataloader.md\":\"C1VXfMIC\",\"ai_deep_learning_theory_27-pytorch-model-save.md\":\"D0btqXT_\",\"ai_deep_learning_theory_28-pytorch-tensorboard.md\":\"CGiQm8lw\",\"ai_deep_learning_theory_29-pytorch-graph-mode.md\":\"Dh2sBoD6\",\"ai_deep_learning_theory_30-3main.md\":\"Cf3sjvsp\",\"ai_deep_learning_theory_30-training-example-2.md\":\"DVUt4gEj\",\"ai_deep_learning_theory_40-ner.md\":\"dpC65KCz\",\"ai_deep_learning_theory_41-question-answering.md\":\"CvkK4DNb\",\"ai_deep_learning_theory_42-1stable-diffusion.md\":\"CGgf4cC2\",\"ai_deep_learning_theory_42-2sdxl.md\":\"CC6w4ggh\",\"ai_deep_learning_theory_42-3vae.md\":\"CD94bkcz\",\"ai_deep_learning_theory_44-scaling-law.md\":\"B0JM9xx_\",\"ai_deep_learning_theory_45-distribute-training.md\":\"DZ9YG6ih\",\"ai_deep_learning_theory_46-nlp-llama.md\":\"8zU0XjzU\",\"ai_deep_learning_theory_47-nlp-deepseek.md\":\"CjtxEpY3\",\"ai_deep_learning_theory_index.md\":\"TlMKjhkI\",\"ai_index.md\":\"DZAAGaZE\",\"ai_transformer_01-注意力机制.md\":\"CAUQ-ZlO\",\"ai_transformer_02-总体架构.md\":\"ChkPOSG5\",\"ai_transformer_03-数据处理.md\":\"I5H3eYdL\",\"ai_transformer_04-编码器 _ 解码器.md\":\"zSoU6yVz\",\"ai_transformer_05-训练_推理.md\":\"BJLWHSwO\",\"ai_transformer_06-token.md\":\"6NkY4MDx\",\"ai_transformer_07-embedding.md\":\"CQvHLv6j\",\"ai_transformer_08-位置编码.md\":\"D1gfu21J\",\"ai_transformer_09-位置编码分类.md\":\"BTP3xgL5\",\"ai_transformer_10-自注意力.md\":\"cLYDSTGu\",\"ai_transformer_11-掩码.md\":\"D3BVR142\",\"ai_transformer_12-多头自注意力.md\":\"fflE1jcD\",\"ai_transformer_13- ffn.md\":\"D5pP50b2\",\"ai_transformer_14-残差网络和归一化.md\":\"CGidK7tQ\",\"ai_transformer_index.md\":\"D8JcJLy1\",\"guide_index.md\":\"0LVzN69w\",\"guide_博客结构.md\":\"x1FQx-jf\",\"improve_index.md\":\"CH8Euwro\",\"improve_金融投资_index.md\":\"Vw_D3eRw\",\"improve_阅读_index.md\":\"Dj8DDADt\",\"index.md\":\"mK1aVFiR\",\"it-learning_408知识_index.md\":\"DlbfR44a\",\"it-learning_408知识_os-4.1 进程同步.md\":\"BL8WmbXW\",\"it-learning_408知识_os-4.4 信号量机制.md\":\"ZCxX2ify\",\"it-learning_408知识_os-4.4 信号量机制pv操作之“可见”.md\":\"DcOjbMF_\",\"it-learning_c__基础_01_开发环境搭建与基础数据类型.md\":\"BDKy9qJ5\",\"it-learning_c__基础_02_控制流语句与复合数据类型.md\":\"SKbyo4op\",\"it-learning_c__基础_03_指针与引用.md\":\"DHwgRso8\",\"it-learning_c__基础_04_自定义数据类型与函数.md\":\"DRE6vCJj\",\"it-learning_c__基础_05_头文件与指针的算术运算.md\":\"D1SjIWSd\",\"it-learning_c__基础_06_字符串、数组、指针与函数.md\":\"CgPOPn1g\",\"it-learning_c__基础_07_函数进阶与内存管理.md\":\"6qEwY-bi\",\"it-learning_c__基础_08_运算符优先级表.md\":\"BJfq7pJh\",\"it-learning_c__基础_09_指针、内存管理和类的基础.md\":\"B67kgruM\",\"it-learning_c__基础_10_深入类和对象.md\":\"BWMMnRaW\",\"it-learning_c__基础_11_类的大小、继承与权限控制.md\":\"CRDT26Xm\",\"it-learning_c__基础_12_继承进阶.md\":\"6AJ13KSU\",\"it-learning_c__基础_13_类型转换和多态与虚函数.md\":\"CYE5ie6q\",\"it-learning_c__基础_14_纯虚函数、抽象类、深浅拷贝及智能指针.md\":\"UvlEbqGK\",\"it-learning_c__基础_15_运算符重载与 string 类详解.md\":\"1S48Obum\",\"it-learning_c__基础_16_有序容器与无序容器.md\":\"1sbF57hZ\",\"it-learning_c__基础_17_模板.md\":\"Bp6hiaoG\",\"it-learning_c__基础_18_迭代器与其应用.md\":\"DhitqtBz\",\"it-learning_c__基础_19_c__ 标准库常用算法.md\":\"DiYIRHYc\",\"it-learning_c__基础_20_c__ 异常处理 - 第19次课.md\":\"CJMeMX9w\",\"it-learning_c__基础_21_友元及友元相关内容.md\":\"Cx439b0I\",\"it-learning_c__基础_22_c__ io 流详解-feadbc607d7f.md\":\"BAPGehpe\",\"it-learning_c__基础_23_c__ io 流详解.md\":\"I4ZE0Tau\",\"it-learning_c__基础_24_位运算符总结.md\":\"CRY59I0U\",\"it-learning_c__基础_25_c__三种继承方式.md\":\"Bm4ge_Dq\",\"it-learning_c__基础_26_c__11 高级特性.md\":\"b4HnWfxf\",\"it-learning_c__基础_27_c__14 新特性.md\":\"C5KOu8gX\",\"it-learning_c__基础_28_c__17 新特性.md\":\"DGt5Tcb-\",\"it-learning_c__基础_29_多文件和 makefile工程管理.md\":\"BDridL3y\",\"it-learning_c__基础_30_c__大型项目cmake工程管理.md\":\"DOufPDWu\",\"it-learning_c__基础_31_c__ 主要就业方向与技术能力分析报告.md\":\"AOV7PjqE\",\"it-learning_c__基础_32_c__ 基础知识回顾.md\":\"A-5IxrZu\",\"it-learning_c__基础_index.md\":\"BTWU73w9\",\"it-learning_index.md\":\"B2k5NgZE\",\"it-learning_java_01.java-se.md\":\"CV9z-Ph2\",\"it-learning_java_02.sql.md\":\"gilr6jOh\",\"it-learning_java_03.java-web.md\":\"DXRkrx3K\",\"it-learning_java_05.mybatis.md\":\"HjU_MlJz\",\"it-learning_java_index.md\":\"DkRBc8cW\",\"it-learning_linux_01.linux基础.md\":\"BBs1RcBf\",\"it-learning_linux_02.shell.md\":\"BCfUk33T\",\"it-learning_linux_03.mpi并行计算.md\":\"gpRl9TGp\",\"it-learning_linux_04.docker.md\":\"DN_C173y\",\"it-learning_linux_index.md\":\"BVALaZgc\",\"it-learning_计算机图形学_02.直线光栅化.md\":\"C0uFebpu\",\"it-learning_计算机图形学_index.md\":\"Be4gO7hA\",\"readme.md\":\"m88s5xF2\",\"update_更新日志.md\":\"BVtQLf5o\",\"我的感悟_2024_index.md\":\"DNiQxEmG\",\"我的感悟_2024_不同商家的视野.md\":\"5Pu9Bj7-\",\"我的感悟_2024_学而篇.md\":\"C-hCBgCG\",\"我的感悟_2024_重温士兵突击.md\":\"C2-8pk9-\",\"我的感悟_2025_index.md\":\"DfcTEU3d\",\"我的感悟_2026_index.md\":\"ByieJetu\",\"我的感悟_index.md\":\"CridsN6k\",\"技术问题清单_doccano账户管理.md\":\"Ba1HQxQq\",\"技术问题清单_index.md\":\"-lH6BxFw\",\"技术问题清单_专英翻转课堂—pytorch.md\":\"Dodyf68o\",\"技术问题清单_虚拟机网络问题.md\":\"B5YN-iPU\",\"生活与算法_index.md\":\"Bz6rRKIq\",\"生活与算法_贪心算法_1.人的本性——贪心！.md\":\"ByHAGPXB\",\"生活与算法_贪心算法_2.初步感受贪心.md\":\"BKL_n967\",\"生活与算法_贪心算法_3. 分发饼干问题.md\":\"D-sOMxS6\",\"面试求职_java面经_index.md\":\"Dt5psx-c\",\"面试求职_场景问题_index.md\":\"Bq1aCqXq\",\"面试求职_算法岗_index.md\":\"B0mkLyz0\",\"面试求职_经验分享_index.md\":\"7Buq_LXu\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"码医森\",\"description\":\"计算机知识的学习站点\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"CoderEthan学习站\",\"logo\":\"/imgs/home-page-logo.svg\",\"outline\":{\"label\":\"本文目录\",\"level\":[2,4]},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 496 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\\\"/></svg>\"},\"link\":\"https://github.com/ethanliu6/\"},{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 512 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z\\\"/></svg>\"},\"link\":\"https://space.bilibili.com/1327099977/\"}],\"nav\":[{\"text\":\"主页\",\"link\":\"/\"},{\"text\":\"博客指南\",\"link\":\"/guide/\"},{\"text\":\"生活与算法\",\"link\":\"/生活与算法/\"},{\"text\":\"AI\",\"items\":[{\"text\":\"DL基础理论\",\"link\":\"/AI/deep_learning_theory/\"},{\"text\":\"Transformer系列\",\"link\":\"/AI/Transformer/\"}]},{\"text\":\"计算机学科内容\",\"items\":[{\"text\":\"计算机知识\",\"link\":\"/IT-learning/408知识/\"},{\"text\":\"C++基础\",\"link\":\"/IT-learning/c++基础/\"},{\"text\":\"Java后端\",\"link\":\"/IT-learning/Java/\"},{\"text\":\"Linux技术\",\"link\":\"/IT-learning/Linux/\"},{\"text\":\"计算机图形学\",\"link\":\"/IT-learning/计算机图形学/\"}]},{\"text\":\"自我提升\",\"items\":[{\"text\":\"阅读\",\"link\":\"/improve/阅读/\"},{\"text\":\"金融投资\",\"link\":\"/improve/金融投资/\"}]},{\"text\":\"求职面试\",\"items\":[{\"text\":\"Java面经\",\"link\":\"/面试求职/Java面经/\"},{\"text\":\"场景问题\",\"link\":\"/面试求职/场景问题/\"},{\"text\":\"经验分享\",\"link\":\"/面试求职/经验分享/\"},{\"text\":\"算法岗\",\"link\":\"/面试求职/算法岗/\"}]},{\"text\":\"其他维护\",\"items\":[{\"text\":\"站点更新\",\"link\":\"/update/更新日志\"},{\"text\":\"问题清单\",\"link\":\"/技术问题清单/\"}]},{\"text\":\"感悟和日常\",\"items\":[{\"text\":\"站长感悟\",\"link\":\"/我的感悟/\"},{\"text\":\"站长旧版博客\",\"link\":\"https://EthanLiu6.github.io\"}]}],\"footer\":{\"message\":\"ICP备案号: <a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\">蜀ICP备2024103116号</a><br>公安备案号: <a href=\\\"https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928\\\" rel=\\\"noreferrer\\\" target=\\\"_blank\\\">川公网安备51012202001928</a>\",\"copyright\":\"版权所有 © 2024-present  <a href=\\\"mailto:16693226842@163.com\\\" target=\\\"_blank\\\">Ethan.Liu</a>\"},\"editLink\":{\"pattern\":\"https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/:path\",\"text\":\"在 GitHub 上编辑此页面 OR 提出修改意见\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"long\",\"timeStyle\":\"short\"}},\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"darkModeSwitchLabel\":\"深色模式\",\"lightModeSwitchTitle\":\"切换到浅色模式\",\"darkModeSwitchTitle\":\"切换到深色模式\",\"sidebar\":{\"/AI/\":[{\"items\":[{\"text\":\"Transformer\",\"items\":[{\"text\":\"01-注意力机制\",\"link\":\"/AI/Transformer/01-注意力机制.html\"},{\"text\":\"02-总体架构\",\"link\":\"/AI/Transformer/02-总体架构.html\"},{\"text\":\"03-数据处理\",\"link\":\"/AI/Transformer/03-数据处理.html\"},{\"text\":\"04-编码器 & 解码器\",\"link\":\"/AI/Transformer/04-编码器 & 解码器.html\"},{\"text\":\"05-训练&推理\",\"link\":\"/AI/Transformer/05-训练&推理.html\"},{\"text\":\"06-token\",\"link\":\"/AI/Transformer/06-token.html\"},{\"text\":\"07-embedding\",\"link\":\"/AI/Transformer/07-embedding.html\"},{\"text\":\"08-位置编码\",\"link\":\"/AI/Transformer/08-位置编码.html\"},{\"text\":\"09-位置编码分类\",\"link\":\"/AI/Transformer/09-位置编码分类.html\"},{\"text\":\"10-自注意力\",\"link\":\"/AI/Transformer/10-自注意力.html\"},{\"text\":\"11-掩码\",\"link\":\"/AI/Transformer/11-掩码.html\"},{\"text\":\"12-多头自注意力\",\"link\":\"/AI/Transformer/12-多头自注意力.html\"},{\"text\":\"13- FFN\",\"link\":\"/AI/Transformer/13- FFN.html\"},{\"text\":\"14-残差网络和归一化\",\"link\":\"/AI/Transformer/14-残差网络和归一化.html\"}],\"collapsed\":false},{\"text\":\"deep_learning_theory\",\"items\":[{\"text\":\"00-DL_Base_Notes\",\"link\":\"/AI/deep_learning_theory/00-DL_Base_Notes.html\"},{\"text\":\"01-feedforward_network\",\"link\":\"/AI/deep_learning_theory/01-feedforward_network.html\"},{\"text\":\"02-back_propagation\",\"link\":\"/AI/deep_learning_theory/02-back_propagation.html\"},{\"text\":\"03-bp_example_demo\",\"link\":\"/AI/deep_learning_theory/03-bp_example_demo.html\"},{\"text\":\"04-convolution_neural_network\",\"link\":\"/AI/deep_learning_theory/04-convolution_neural_network.html\"},{\"text\":\"05-deep_learning_model\",\"link\":\"/AI/deep_learning_theory/05-deep_learning_model.html\"},{\"text\":\"06-pytorch_install\",\"link\":\"/AI/deep_learning_theory/06-pytorch_install.html\"},{\"text\":\"07-operators\",\"link\":\"/AI/deep_learning_theory/07-operators.html\"},{\"text\":\"08-activation_functions\",\"link\":\"/AI/deep_learning_theory/08-activation_functions.html\"},{\"text\":\"09-recurrent_neural_network\",\"link\":\"/AI/deep_learning_theory/09-recurrent_neural_network.html\"},{\"text\":\"10-seq2seq\",\"link\":\"/AI/deep_learning_theory/10-seq2seq.html\"},{\"text\":\"11-1attentions\",\"link\":\"/AI/deep_learning_theory/11-1attentions.html\"},{\"text\":\"11-2attention-extension\",\"link\":\"/AI/deep_learning_theory/11-2attention-extension.html\"},{\"text\":\"12-weight-initialization\",\"link\":\"/AI/deep_learning_theory/12-weight-initialization.html\"},{\"text\":\"13-optimizers\",\"link\":\"/AI/deep_learning_theory/13-optimizers.html\"},{\"text\":\"14-regularization\",\"link\":\"/AI/deep_learning_theory/14-regularization.html\"},{\"text\":\"15-deep-learning-tuning-guide\",\"link\":\"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html\"},{\"text\":\"20-pytorch-tensor\",\"link\":\"/AI/deep_learning_theory/20-pytorch-tensor.html\"},{\"text\":\"21-pytorch-autograd\",\"link\":\"/AI/deep_learning_theory/21-pytorch-autograd.html\"},{\"text\":\"22-pytorch-module\",\"link\":\"/AI/deep_learning_theory/22-pytorch-module.html\"},{\"text\":\"23-1training-example-1\",\"link\":\"/AI/deep_learning_theory/23-1training-example-1.html\"},{\"text\":\"23-2decoder\",\"link\":\"/AI/deep_learning_theory/23-2decoder.html\"},{\"text\":\"23-3encoder\",\"link\":\"/AI/deep_learning_theory/23-3encoder.html\"},{\"text\":\"23-4transformer\",\"link\":\"/AI/deep_learning_theory/23-4transformer.html\"},{\"text\":\"24-pytorch-optimizer\",\"link\":\"/AI/deep_learning_theory/24-pytorch-optimizer.html\"},{\"text\":\"25-pytorch-lr-scheduler\",\"link\":\"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html\"},{\"text\":\"26-pytorch-dataloader\",\"link\":\"/AI/deep_learning_theory/26-pytorch-dataloader.html\"},{\"text\":\"27-pytorch-model-save\",\"link\":\"/AI/deep_learning_theory/27-pytorch-model-save.html\"},{\"text\":\"28-pytorch-tensorboard\",\"link\":\"/AI/deep_learning_theory/28-pytorch-tensorboard.html\"},{\"text\":\"29-pytorch-graph-mode\",\"link\":\"/AI/deep_learning_theory/29-pytorch-graph-mode.html\"},{\"text\":\"30-3main\",\"link\":\"/AI/deep_learning_theory/30-3main.html\"},{\"text\":\"30-training-example-2\",\"link\":\"/AI/deep_learning_theory/30-training-example-2.html\"},{\"text\":\"40-ner\",\"link\":\"/AI/deep_learning_theory/40-ner.html\"},{\"text\":\"41-question-answering\",\"link\":\"/AI/deep_learning_theory/41-question-answering.html\"},{\"text\":\"42-1stable-diffusion\",\"link\":\"/AI/deep_learning_theory/42-1stable-diffusion.html\"},{\"text\":\"42-2SDXL\",\"link\":\"/AI/deep_learning_theory/42-2SDXL.html\"},{\"text\":\"42-3VAE\",\"link\":\"/AI/deep_learning_theory/42-3VAE.html\"},{\"text\":\"44-scaling-law\",\"link\":\"/AI/deep_learning_theory/44-scaling-law.html\"},{\"text\":\"45-distribute-training\",\"link\":\"/AI/deep_learning_theory/45-distribute-training.html\"},{\"text\":\"46-nlp-llama\",\"link\":\"/AI/deep_learning_theory/46-nlp-llama.html\"},{\"text\":\"47-nlp-deepseek\",\"link\":\"/AI/deep_learning_theory/47-nlp-deepseek.html\"}],\"collapsed\":false}]}],\"/IT-learning/\":[{\"items\":[{\"text\":\"408知识\",\"items\":[{\"text\":\"OS-4.1 进程同步\",\"link\":\"/IT-learning/408知识/OS-4.1 进程同步.html\"},{\"text\":\"OS-4.4 信号量机制\",\"link\":\"/IT-learning/408知识/OS-4.4 信号量机制.html\"},{\"text\":\"OS-4.4 信号量机制pv操作之“可见”\",\"link\":\"/IT-learning/408知识/OS-4.4 信号量机制pv操作之“可见”.html\"}],\"collapsed\":false},{\"text\":\"Java\",\"items\":[{\"text\":\"01.java-se\",\"link\":\"/IT-learning/Java/01.java-se.html\"},{\"text\":\"02.sql\",\"link\":\"/IT-learning/Java/02.sql.html\"},{\"text\":\"03.java-web\",\"link\":\"/IT-learning/Java/03.java-web.html\"},{\"text\":\"05.MyBatis\",\"link\":\"/IT-learning/Java/05.MyBatis.html\"}],\"collapsed\":false},{\"text\":\"Linux\",\"items\":[{\"text\":\"01.Linux基础\",\"link\":\"/IT-learning/Linux/01.Linux基础.html\"},{\"text\":\"02.Shell\",\"link\":\"/IT-learning/Linux/02.Shell.html\"},{\"text\":\"03.MPI并行计算\",\"link\":\"/IT-learning/Linux/03.MPI并行计算.html\"},{\"text\":\"04.Docker\",\"link\":\"/IT-learning/Linux/04.Docker.html\"}],\"collapsed\":false},{\"text\":\"c++基础\",\"items\":[{\"text\":\"01_开发环境搭建与基础数据类型\",\"link\":\"/IT-learning/c++基础/01_开发环境搭建与基础数据类型.html\"},{\"text\":\"02_控制流语句与复合数据类型\",\"link\":\"/IT-learning/c++基础/02_控制流语句与复合数据类型.html\"},{\"text\":\"03_指针与引用\",\"link\":\"/IT-learning/c++基础/03_指针与引用.html\"},{\"text\":\"04_自定义数据类型与函数\",\"link\":\"/IT-learning/c++基础/04_自定义数据类型与函数.html\"},{\"text\":\"05_头文件与指针的算术运算\",\"link\":\"/IT-learning/c++基础/05_头文件与指针的算术运算.html\"},{\"text\":\"06_字符串、数组、指针与函数\",\"link\":\"/IT-learning/c++基础/06_字符串、数组、指针与函数.html\"},{\"text\":\"07_函数进阶与内存管理\",\"link\":\"/IT-learning/c++基础/07_函数进阶与内存管理.html\"},{\"text\":\"08_运算符优先级表\",\"link\":\"/IT-learning/c++基础/08_运算符优先级表.html\"},{\"text\":\"09_指针、内存管理和类的基础\",\"link\":\"/IT-learning/c++基础/09_指针、内存管理和类的基础.html\"},{\"text\":\"10_深入类和对象\",\"link\":\"/IT-learning/c++基础/10_深入类和对象.html\"},{\"text\":\"11_类的大小、继承与权限控制\",\"link\":\"/IT-learning/c++基础/11_类的大小、继承与权限控制.html\"},{\"text\":\"12_继承进阶\",\"link\":\"/IT-learning/c++基础/12_继承进阶.html\"},{\"text\":\"13_类型转换和多态与虚函数\",\"link\":\"/IT-learning/c++基础/13_类型转换和多态与虚函数.html\"},{\"text\":\"14_纯虚函数、抽象类、深浅拷贝及智能指针\",\"link\":\"/IT-learning/c++基础/14_纯虚函数、抽象类、深浅拷贝及智能指针.html\"},{\"text\":\"15_运算符重载与 String 类详解\",\"link\":\"/IT-learning/c++基础/15_运算符重载与 String 类详解.html\"},{\"text\":\"16_有序容器与无序容器\",\"link\":\"/IT-learning/c++基础/16_有序容器与无序容器.html\"},{\"text\":\"17_模板\",\"link\":\"/IT-learning/c++基础/17_模板.html\"},{\"text\":\"18_迭代器与其应用\",\"link\":\"/IT-learning/c++基础/18_迭代器与其应用.html\"},{\"text\":\"19_C++ 标准库常用算法\",\"link\":\"/IT-learning/c++基础/19_C++ 标准库常用算法.html\"},{\"text\":\"20_C++ 异常处理 - 第19次课\",\"link\":\"/IT-learning/c++基础/20_C++ 异常处理 - 第19次课.html\"},{\"text\":\"21_友元及友元相关内容\",\"link\":\"/IT-learning/c++基础/21_友元及友元相关内容.html\"},{\"text\":\"22_C++ IO 流详解-feadbc607d7f\",\"link\":\"/IT-learning/c++基础/22_C++ IO 流详解-feadbc607d7f.html\"},{\"text\":\"23_C++ IO 流详解\",\"link\":\"/IT-learning/c++基础/23_C++ IO 流详解.html\"},{\"text\":\"24_位运算符总结\",\"link\":\"/IT-learning/c++基础/24_位运算符总结.html\"},{\"text\":\"25_C++三种继承方式\",\"link\":\"/IT-learning/c++基础/25_C++三种继承方式.html\"},{\"text\":\"26_C++11 高级特性\",\"link\":\"/IT-learning/c++基础/26_C++11 高级特性.html\"},{\"text\":\"27_C++14 新特性\",\"link\":\"/IT-learning/c++基础/27_C++14 新特性.html\"},{\"text\":\"28_C++17 新特性\",\"link\":\"/IT-learning/c++基础/28_C++17 新特性.html\"},{\"text\":\"29_多文件和 Makefile工程管理\",\"link\":\"/IT-learning/c++基础/29_多文件和 Makefile工程管理.html\"},{\"text\":\"30_C++大型项目CMake工程管理\",\"link\":\"/IT-learning/c++基础/30_C++大型项目CMake工程管理.html\"},{\"text\":\"31_C++ 主要就业方向与技术能力分析报告\",\"link\":\"/IT-learning/c++基础/31_C++ 主要就业方向与技术能力分析报告.html\"},{\"text\":\"32_C++ 基础知识回顾\",\"link\":\"/IT-learning/c++基础/32_C++ 基础知识回顾.html\"}],\"collapsed\":false},{\"text\":\"计算机图形学\",\"items\":[{\"text\":\"02.直线光栅化\",\"link\":\"/IT-learning/计算机图形学/02.直线光栅化.html\"}],\"collapsed\":false}]}],\"/guide/\":[{\"items\":[{\"text\":\"博客结构\",\"link\":\"/guide/博客结构.html\"}]}],\"/update/\":[{\"items\":[{\"text\":\"更新日志\",\"link\":\"/update/更新日志.html\"}]}],\"/我的感悟/\":[{\"items\":[{\"text\":\"2024\",\"items\":[{\"text\":\"不同商家的视野\",\"link\":\"/我的感悟/2024/不同商家的视野.html\"},{\"text\":\"学而篇\",\"link\":\"/我的感悟/2024/学而篇.html\"},{\"text\":\"重温士兵突击\",\"link\":\"/我的感悟/2024/重温士兵突击.html\"}],\"collapsed\":false}]}],\"/技术问题清单/\":[{\"items\":[{\"text\":\"doccano账户管理\",\"link\":\"/技术问题清单/doccano账户管理.html\"},{\"text\":\"专英翻转课堂—PyTorch\",\"link\":\"/技术问题清单/专英翻转课堂—PyTorch.html\"},{\"text\":\"虚拟机网络问题\",\"link\":\"/技术问题清单/虚拟机网络问题.html\"}]}],\"/生活与算法/\":[{\"items\":[{\"text\":\"贪心算法\",\"items\":[{\"text\":\"1.人的本性——贪心！\",\"link\":\"/生活与算法/贪心算法/1.人的本性——贪心！.html\"},{\"text\":\"2.初步感受贪心\",\"link\":\"/生活与算法/贪心算法/2.初步感受贪心.html\"},{\"text\":\"3. 分发饼干问题\",\"link\":\"/生活与算法/贪心算法/3. 分发饼干问题.html\"}],\"collapsed\":false}]}]}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>