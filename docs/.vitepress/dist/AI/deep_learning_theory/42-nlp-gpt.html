<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>从 GPT1 到 GPT4 | 码医森</title>
    <meta name="description" content="计算机知识的学习站点">
    <meta name="generator" content="VitePress v1.3.4">
    <link rel="preload stylesheet" href="/assets/style.CflK-Lwn.css" as="style">
    
    <script type="module" src="/assets/app.BJNs-OI8.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.QXQ-4epU.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DA-Pb-tg.js">
    <link rel="modulepreload" href="/assets/AI_deep_learning_theory_42-nlp-gpt.md.BBE-o7PM.lean.js">
    <link rel="icon" type="image/svg+xml" href="/imgs/home-page-logo.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/imgs/home-page-logo.svg" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>CoderEthan学习站</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>AI</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/deep_learning_theory/" data-v-43f1e123><!--[-->DL基础理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/Transformer/" data-v-43f1e123><!--[-->Transformer系列<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/distribute_training/" data-v-43f1e123><!--[-->分布式训练<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>计算机学科内容</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/408/" data-v-43f1e123><!--[-->408知识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/c++/" data-v-43f1e123><!--[-->C++基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Java/" data-v-43f1e123><!--[-->Java后端<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Linux/" data-v-43f1e123><!--[-->Linux技术<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>求职面试</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Java/" data-v-43f1e123><!--[-->Java面经<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Algorithm_post/" data-v-43f1e123><!--[-->算法岗<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>其他维护</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/update/update_log.html" data-v-43f1e123><!--[-->站点更新<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/question_list/" data-v-43f1e123><!--[-->问题清单<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>感悟和日常</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/my_think/" data-v-43f1e123><!--[-->站长感悟<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link vp-external-link-icon" href="https://EthanLiu6.github.io" target="_blank" rel="noreferrer" data-v-43f1e123><!--[-->旧版博客<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>深色模式</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b7550ba0><!----><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-1 collapsible" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>Transformer</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/01-Transformer的由来.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-Transformer的由来</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/02-Transformer架构解读.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-Transformer架构解读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/Transformer/03-Transformer架构源码构建.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-Transformer架构源码构建</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>deep_learning_theory</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/00-DL_Base_Notes.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00-DL_Base_Notes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/01-feedforward_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-feedforward_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/02-back_propagation.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-back_propagation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/03-bp_example_demo.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-bp_example_demo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/04-convolution_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-convolution_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/05-deep_learning_model.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-deep_learning_model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/06-pytorch_install.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06-pytorch_install</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/07-operators.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07-operators</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/08-activation_functions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08-activation_functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/09-recurrent_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09-recurrent_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/10-seq2seq.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10-seq2seq</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/11-1attentions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-1attentions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/11-2attention-extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-2attention-extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/12-weight-initialization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12-weight-initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/13-optimizers.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13-optimizers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/14-regularization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14-regularization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/15-deep-learning-tuning-guide.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15-deep-learning-tuning-guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/20-pytorch-tensor.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20-pytorch-tensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/21-pytorch-autograd.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21-pytorch-autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/22-pytorch-module.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22-pytorch-module</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-1training-example-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-1training-example-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-2decoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-2decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-3encoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-3encoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/23-4transformer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-4transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/24-pytorch-optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24-pytorch-optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/25-pytorch-lr-scheduler.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25-pytorch-lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/26-pytorch-dataloader.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26-pytorch-dataloader</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/27-pytorch-model-save.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27-pytorch-model-save</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/28-pytorch-tensorboard.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28-pytorch-tensorboard</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/29-pytorch-graph-mode.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29-pytorch-graph-mode</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/30-1training-example-cv.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-1training-example-cv</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/30-3main.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-3main</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/31-1stable-diffusion.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-1stable-diffusion</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/31-2SDXL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-2SDXL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/31-3VAE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-3VAE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/40-nlp-bert_ner.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>40-nlp-bert_ner</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/41-nlp-t5_question-answering.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>41-nlp-t5_question-answering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/42-nlp-gpt.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-nlp-gpt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/43-scaling-law.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>43-scaling-law</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/44-distribute-training.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>44-distribute-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/45-LLM-History.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>45-LLM-History</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/46-LLM-GPT-Extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-LLM-GPT-Extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/46-nlp-llama.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-nlp-llama</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/47-LLM-DeepSeek-Structure.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-LLM-DeepSeek-Structure</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/deep_learning_theory/47-nlp-deepseek.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-nlp-deepseek</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>distribute_training</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/00_large-scale-model-trainning.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00_large-scale-model-trainning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/01_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/01_offload-and-recompute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_offload-and-recompute</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/02_amp.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02_amp</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/03_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/03_pytorch-DP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_pytorch-DP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/04_pytorch-DDP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04_pytorch-DDP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/05_pytorch-DDP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL_DDP_ORIGIN</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/06_collective-comm.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_collective-comm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/06_torchrun-process-group.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_torchrun-process-group</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/07_ZeRO-Optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07_ZeRO-Optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/08_pytorch-ZeRO-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08_pytorch-ZeRO-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/09_pytorch-FSDP-v1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09_pytorch-FSDP-v1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/10_pytorch-FSDP-v2.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10_pytorch-FSDP-v2</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11_deepspeed-ZeRO-1-2-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/12_deepspeed-ZeRO-3-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12_deepspeed-ZeRO-3-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/13_megatron-ZeRO-1-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13_megatron-ZeRO-1-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/14_TP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14_TP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/15_megatron-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15_megatron-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/16_pytorch-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>16_pytorch-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/17_PP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>17_PP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/18_pytorch-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>18_pytorch-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/19_deepspeed-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>19_deepspeed-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/20_megatron-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20_megatron-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/21_SP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21_SP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/22_megatron-SP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22_megatron-SP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/23_3D-Parallel-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23_3D-Parallel-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/24_megatron-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24_megatron-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/25_pytorch-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25_pytorch-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/26_CP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26_CP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/27_megatron-CP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27_megatron-CP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/28_MOE-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/28_MOE-Theory_DeepSeekMOE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory_DeepSeekMOE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/29_megatron-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29_megatron-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/30_deepspeed-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30_deepspeed-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/31_deepspeed-code-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31_deepspeed-code-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/32_collective-operations.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>32_collective-operations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/distribute_training/33_pytorch_distribute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>33_pytorch_distribute</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>本文目录</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _AI_deep_learning_theory_42-nlp-gpt" data-v-39a288b8><div><h1 id="从-gpt1-到-gpt4" tabindex="-1">从 GPT1 到 GPT4 <a class="header-anchor" href="#从-gpt1-到-gpt4" aria-label="Permalink to &quot;从 GPT1 到 GPT4&quot;">​</a></h1><p><img src="https://i-blog.csdnimg.cn/img_convert/b8ba84401754e981ec885952cf3758a1.png" alt="论文时间线"></p><h1 id="_1-gpt1" tabindex="-1">1 GPT1 <a class="header-anchor" href="#_1-gpt1" aria-label="Permalink to &quot;1 GPT1&quot;">​</a></h1><h2 id="_1-1-自回归模型" tabindex="-1">1.1 自回归模型 <a class="header-anchor" href="#_1-1-自回归模型" aria-label="Permalink to &quot;1.1 自回归模型&quot;">​</a></h2><ul><li><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noreferrer">Improving Language Understanding by Generative Pre-Training</a></li></ul><p>        Google 的 Transformer（Attention is All You Need） 于 2017 年 6 月发表，一年后，OpenAI 的团队发表了 GPT ，又过了两个月，Google 的另一个团队发表了 BERT。<br></p><p><code>缩写 GPT 来自论文题目的 Generative Pre-Training，生成式预训练，维基百科2中的表述是 Generative Pre-trained Transformer，二者指代一致。这是一个通用概念，当前常见的具有聊天功能的 AI 或者说 LLM 其实都可以称作 GPT。</code></p><p>GPT 是一种自回归（Auto-Regressive，AR）模型，在进一步了解 GPT 之前，我们重识自回归和非自回归：<br></p><p><img src="https://i-blog.csdnimg.cn/img_convert/73c1641d86f3d08d985fc53e217772dd.png" alt="图示"></p><p><strong>自回归（Auto-Regressive）</strong></p><p>自回归生成是指序列生成过程中，每个新生成的 token 依赖于之前生成的 token。这意味着生成过程是串行的，每一步的输入由前面已生成的 token 组成的上下文序列构成。例如：</p><p>假设要生成一个长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span></span> 的句子 y = (y_1, y_2, \dots, y_T)，在生成句子的过程中，</p><ul><li>首先生成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，</li><li>然后在生成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 时需要考虑 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>；</li><li>在生成 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">y_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 时，需要考虑 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">(y_1, y_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span>，</li></ul><p>以此类推，直到生成结束符号 &quot;&lt;end&gt;&quot;。</p><p>这种设计确保了生成过程中的连贯性和逻辑一致性。</p><p><strong>非自回归（Non-Autoregressive）</strong> 非自回归生成是一种并行生成的方式，一次性生成多个甚至全部的 token，从而显著提高生成速度，但也会牺牲一定的生成质量。<br></p><p><em>EXTENSION: 现在也有工作使用非自回归模型作为“预言家”来指导自回归模型并行生成，从而在生成质量不变的情况下大幅度提高生成速度，以“空间”换时间。例如：</em> <br></p><p><img src="https://i-blog.csdnimg.cn/img_convert/e524b81a65a2f52d53ffea937a917f3e.png" alt="投机采样"></p><h2 id="_1-2-gpt1-贡献" tabindex="-1">1.2 GPT1 贡献 <a class="header-anchor" href="#_1-2-gpt1-贡献" aria-label="Permalink to &quot;1.2 GPT1 贡献&quot;">​</a></h2><ul><li><p><strong>预训练 + 微调」范式的验证（基于 Transformer 解码器）</strong></p><ul><li>采用了仅由 Transformer decoder 堆叠的架构（使用 Masked self-attention 从左到右预测下一个词），在大规模未标注语料上进行<strong>生成式预训练</strong>。</li><li>随后，模型在下游任务（文本蕴含、文本分类、问答等）上通过<strong>有监督微调</strong>来适配不同场景，最终在 9/12 的任务上取得了 SOTA，证明了 Transformer 架构在语言建模上的<code>可行性</code>。</li><li>虽然在 GPT 出现之前已有基于预训练词向量（Word2Vec [MCCD13]、GloVe [PSM14]）或 ELMo 等双向语言模型的类似思路，但 <strong>GPT-1</strong> <code>首次在一个大规模、纯 Transformer 解码器上系统性地验证了「预训练 + 微调」范式的有效性</code>，为后续基于 Transformer 架构的预训练语言模型（如 BERT、T5）奠定了基础。</li></ul></li><li><p><strong>引入统一的任务输入格式</strong></p><ul><li>通过<code>在输入文本中添加特殊标记以及拼接文本</code>，将不同下游任务（文本蕴含、问答、情感分析等）的结构化输入统一转换为连续序列的形式。</li><li>这种方法<code>减少了为不同任务单独设计模型结构的需求</code>，仅通过调整输入格式即可适应不同任务，使得同一个预训练语言模型可以在不同任务之间复用。</li></ul></li></ul><h2 id="_1-3-gpt1-模型架构" tabindex="-1">1.3 GPT1 模型架构 <a class="header-anchor" href="#_1-3-gpt1-模型架构" aria-label="Permalink to &quot;1.3 GPT1 模型架构&quot;">​</a></h2><p>Transformer 是 GPT 的“巨人肩膀”，而 GPT 对于 BERT 也是如此。在阅读过 BERT 的论文后，可以感受到许多思想与 GPT 完全同频：</p><ol><li>预训练与微调范式的使用</li><li>Transformer 架构的使用</li></ol><ul><li>GPT 使用 Transformer 解码器（decoder-only）。</li><li>BERT 使用 Transformer 编码器（encoder-only）。</li></ul><p><img src="https://i-blog.csdnimg.cn/img_convert/b7a53b2e2ba149b7fb091fa5082e6ea4.png" alt="不同任务处理方式"></p><p><strong>decoder 模型结构</strong></p><p><img src="https://i-blog.csdnimg.cn/img_convert/02e14c332dd1cf65e130c95186ae6cdd.png" alt="decoder"></p><p><strong>让我们自顶向下的理解这个架构，下文所说的词/词元实际上就是 Token。</strong></p><ol><li>顶部：Text Prediction 和 Task Classifier</li></ol><ul><li>Text Prediction：用于生成任务，预测下一个词。</li><li>Task Classifier：用于分类任务，如情感分析或文本蕴含任务。</li></ul><ol start="2"><li>中部：Transformer 架构</li></ol><ul><li><p>遵循原论文的表达将其称之为 transformer_block，其中每一层包含：</p><ul><li><p>Layer Norm (LN) + 残差连接 (+) 对应于 Transformer 架构中的 Add &amp; Norm。</p></li><li><p>Masked Multi-Head Self-Attention: 掩码多头自注意力机制，在生成任务中，每次预测一个词时，当前词只能看到左侧的上下文信息，未来的词和预测的词都会被掩盖。</p></li><li><p>对应于 Transformer 架构中 Masked Multi-Head Attention。</p></li><li><p>前馈网络 (Feed-Forward Network, FFN)</p></li></ul></li><li><p>左侧的 12x 表示堆叠了12层 transformer_block。</p></li></ul><ol start="3"><li>底部：Text &amp; Position Embed</li></ol><ul><li>Text Embed：将输入的词转化为可训练的嵌入向量。</li><li>Position Embed：使用可学习的位置信息嵌入，这里和 Transformer 默认的正余弦位置编码不同，但 Transformer 论文的 Table 3 (E) 中有对比二者的性能差异，所以并非一个新的方法。</li></ul><p>从架构上看，Decoder 相较于 Encoder 多了掩码机制和交叉注意力，实际上真正区分二者的是自注意力中的掩码机制，防止模型在生成时看到未来的词。GPT 的架构可以被视为去除了交叉注意力的 Decoder。<br></p><h2 id="_1-4-gpt1-vs-bert" tabindex="-1">1.4 GPT1 VS BERT <a class="header-anchor" href="#_1-4-gpt1-vs-bert" aria-label="Permalink to &quot;1.4 GPT1 VS BERT&quot;">​</a></h2><p>在《BERT 论文精读》中有说到：“BERT 是第一个使用预训练与微调范式，在一系列 NLP 任务（包括句子层面和词元层面）都达到 SOTA 的模型。”这句话的关键在于“都”字，因为实际上，GPT 更早地使用了预训练与微调的范式，只不过当时并没有在 12 个任务上全都达到最佳，而是在 9 个任务上超越了当时的 SOTA。<br></p><p><strong>Transformer 是 GPT 的“巨人肩膀”</strong>，而 GPT 对于 BERT 也是如此。在阅读过 BERT 的论文后，可以感受到许多思想与 GPT 完全同频：</p><ul><li>预训练与微调范式的使用</li><li>Transformer 架构的使用</li><li>GPT 使用 Transformer 解码器（decoder-only）。</li><li>BERT 使用 Transformer 编码器（encoder-only）。</li></ul><h2 id="_1-5-处理不同任务" tabindex="-1">1.5 处理不同任务 <a class="header-anchor" href="#_1-5-处理不同任务" aria-label="Permalink to &quot;1.5 处理不同任务&quot;">​</a></h2><p><img src="https://i-blog.csdnimg.cn/img_convert/681d501b79f52f83773c6f2182b90804.png" alt=""></p><h3 id="gpt-将不同的自然语言处理-nlp-任务统一为序列格式" tabindex="-1">GPT 将不同的自然语言处理（NLP）任务统一为序列格式 <a class="header-anchor" href="#gpt-将不同的自然语言处理-nlp-任务统一为序列格式" aria-label="Permalink to &quot;GPT 将不同的自然语言处理（NLP）任务统一为序列格式&quot;">​</a></h3><p>GPT 将不同的自然语言处理（NLP）任务的输入转化为统一的序列格式，使得预训练的生成模型（图中的 Transformer）可以直接接受它们进行处理，避免为每个任务设计特定的模型架构。以下符号将遵循原论文的表述，这里将用到三种特殊词元（Special Token）：</p><ul><li><strong>开始词元（Start Token）</strong>: ⟨s⟩，表示序列起始。</li><li><strong>结束词元（End Token）</strong>: ⟨e⟩，表示序列结束。</li><li><strong>分隔词元（Delimiter Token）</strong>: $，用于分隔子序列，例如前提句和假设句，问题和答案。</li></ul><p>这种统一的序列格式使得 GPT 能够灵活地处理各种 NLP 任务，而无需为每个任务单独设计模型架构。</p><p><em>这些标记并不是为人类设计的，而是为模型提供明确的语义提示，以便在训练中建立序列关系。注意，这些符号在预训练时是不存在的，微调赋予了它们意义。</em><br></p><ol><li>文本分类（Classification） 文本分类任务的输入是单一文本，目标是根据文本内容预测类别（例如电影评论情感分析：积极或消极）。</li></ol><p>输入格式：</p> ⟨ s ⟩ 文本 ⟨ e ⟩ <ol start="2"><li>文本蕴含（Textual Entailment） 文本蕴含任务，也称自然语言推理（NLI）4，目标是判断前提（Premise）与假设（Hypothesis）之间的关系：</li></ol><ul><li>蕴含（Entailment）：由前提可以推出假设，p ⇒ \Rightarrow⇒ h。</li><li>矛盾（Contradiction）：前提与假设相矛盾。</li><li>无关（Neutral）：前提和假设无直接关联。</li></ul><p>这是一个三分类问题，举个例子：</p><p>蕴含（positive TE，premise entails hypothesis）：</p><p>前提：“所有鸟类都有翅膀。” 假设：“麻雀有翅膀。” 关系：假设可以从前提推导出，因此为蕴含。 矛盾（negative TE，premise contradicts hypothesis）：</p><p>前提：“所有鸟类都有翅膀。” 假设：“企鹅没有翅膀。” 关系：假设与前提的事实相矛盾，因此为矛盾（对了，企鹅是鸟）。 无关（non-TE，premise does not entail nor contradict）：</p><p>前提：“所有鸟类都有翅膀。” 假设：“所有鸟类都会飞。” 关系：假设无法从前提中推导，也不矛盾，因此为无关。</p><p>输入格式：</p><p>⟨ s ⟩ 前提 $ 假设 ⟨ e ⟩</p><ol start="3"><li>语义相似性（Semantic Similarity） 在语义相似性任务中，目标是判断两个句子是否在语义上相似，例如 Quora 问题对检测（Quora Question Pairs，QQP）要求识别两个问题是否相似。</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">“Similarity For similarity tasks, there </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> no inherent ordering of the two sentences \</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> being compared. To reflect this, we modify the </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sequence to contain both \ </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">possible sentence orderings (with a delimiter in between) and process each independently to produce two sequence representations h^m_{l}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">which are added element</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">wise before being fed into the linear output layer.”</span></span></code></pre></div><p>处理句子对以判断语义相似性</p><ul><li><p>将句子对按照两种可能的顺序输入模型（即 <code>A;B</code> 和 <code>B;A</code>）。</p></li><li><p>对两种输入序列分别处理，生成的最后一层激活向量 $ h^m_l $ 进行逐元素相加（element-wise addition）。</p></li><li><p>加和后的表示被输入到线性层中，用于判断语义相似性。</p></li></ul><p>⟨s⟩ 句子A $ 句子B ⟨e⟩</p><p>⟨s⟩ 句子B $ 句子A ⟨e⟩</p><ol start="4"><li>选择题（Multiple Choice） 在选择题任务中，模型需要从多个候选答案中选择一个最可能的正确答案，例如问答（Question Answering，QA）和常识推理（Commonsense Reasoning）。</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">“For these tasks, we are given a context document z zz, a question q qq, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">set</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> of possible answers { a k } \</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">{a_k\}{a</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">k</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">​</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> }. We concatenate the document context </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> question </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> each possible answer, adding a delimiter token </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> between to get </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">$</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[z; q; </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">$</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; a_k]</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">$</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">. Each of these sequences are processed independently </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> our model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> then normalized via a softmax layer to produce an output distribution over possible answers.”</span></span></code></pre></div><p>此时的输入通常包括三个部分，以问答任务为例：</p><ul><li>上下文文档 z zz :问题的背景信息。</li><li>问题 q qq :需要解答的问题。</li><li>候选答案集 a_{k}:多个可能的答案。</li></ul><p>⟨s⟩文档z 问题q $ 答案a_1 ⟨e⟩</p><p>⟨s⟩文档z 问题q $ 答案a_2 ⟨e⟩</p><p>⋮</p><p>⟨s⟩文档z 问题q $ 答案a_k ⟨e⟩</p><p>这些序列会被独立处理，最后通过 softmax 归一化生成概率分布。</p><h2 id="_1-6-训练细节" tabindex="-1">1.6 训练细节 <a class="header-anchor" href="#_1-6-训练细节" aria-label="Permalink to &quot;1.6 训练细节&quot;">​</a></h2><p><strong>无监督预训练（Unsupervised pre-training）</strong></p><p>在预训练阶段，模型的目标是最大化未标注语料的语言建模函数：</p><p>$ L_1(\mathcal{U}) = \sum_i \log P(u_i \mid u_{i-k}, \ldots, u_{i-1}; \Theta) $</p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="script">U</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathcal" style="margin-right:0.09931em;">U</span></span></span></span></span>: 未标注的文本语料。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>u</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">u_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">u</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">i</span></span></span></span> 个词。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span>: 上下文窗口的大小（即当前词基于前 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span> 个词预测）。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span></span></span></span>: 模型参数。</li></ul><p><strong>具体流程</strong></p><p><strong>输入嵌入</strong></p><p>将输入序列 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo>=</mo><mrow><msub><mi>u</mi><mrow><mo>−</mo><mi>k</mi></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>u</mi><mrow><mo>−</mo><mn>1</mn></mrow></msub></mrow></mrow><annotation encoding="application/x-tex">U = {u_{-k}, \ldots, u_{-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mrel">=</span><span class="mord textstyle uncramped"><span class="mord"><span class="mord mathit">u</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord">−</span><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="minner">…</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">u</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span> 映射到嵌入空间：</p><p>$ h_0 = U W_e + W_p $</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">W_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">e</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 词嵌入矩阵。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">W_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">p</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 位置嵌入矩阵。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 初始输入的嵌入表示。</li></ul><p><strong>多层 Transformer 编码</strong></p><p>输入嵌入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 通过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span></span></span></span> 层 <code>transformer_block</code> 逐层处理：</p><p>$ h_l = \texttt{transformer_block}(h_{l-1}) ; \forall i \in [1, n] $</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">h_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span> 层的输出。</li></ul><p><strong>预测下一个词</strong></p><p>最后一层的输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">h_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 被映射回词汇表维度，生成下一个词的概率分布：</p><p>$ P(u) = \texttt{softmax}(h_n W_e^T) $</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>W</mi><mi>e</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">W_e^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.088331em;vertical-align:-0.247em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">e</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: 词嵌入矩阵的转置，将隐藏状态映射回词汇表。</li><li><code>softmax</code>: 归一化概率分布。</li></ul><h2 id="_1-7-数据集" tabindex="-1">1.7 数据集 <a class="header-anchor" href="#_1-7-数据集" aria-label="Permalink to &quot;1.7 数据集&quot;">​</a></h2><p>使用 BooksCorpus 数据集56，包含大约 7,000 本未出版的书籍，数据主要从电子书分发平台 Smashwords 抓取。</p><p><code>BERT 预训练时除了 BooksCorpus 数据集（8 亿词元）外，还使用了英文维基百科（English Wikipedia， 25 亿词元），所以 BERT 的训练资料大概为 GPT 的四倍。 “… 所以它在这个数据集上训练了一个比 GPT 大三倍的模型 (BERT LARGE) 也是可以理解的”</code></p><p>使用 ftfy 库清理原始文本，标准化标点符号和空白字符，然后使用 spaCy 分词器。</p><p>使用 Byte-Pair Encoding (BPE) 进行子词分解，词汇表大小为 40,000。</p><h2 id="_1-8-超参数设置" tabindex="-1">1.8 超参数设置 <a class="header-anchor" href="#_1-8-超参数设置" aria-label="Permalink to &quot;1.8 超参数设置&quot;">​</a></h2><p><strong>Transformer 相关</strong></p><ul><li><p><strong>层数</strong> $ n_{layers} = 12 $：Transformer 解码器的层数。</p><p>我们训练了一个具有遮蔽自注意力头的12层仅解码器Transformer（状态维度为768，注意力头数为12）。</p></li><li><p><strong>隐藏层维度</strong> $ d_{model} = 768 $：每个隐藏层的维度为768。</p></li><li><p><strong>注意力头数</strong> $ n_{heads} = 12 ：每层的多头注意力机制包含12个注意力头，每个头的维度为64。 12 \times 64 = 768 $。</p><p>上述数学符号与GPT-3的表2-1保持一致。</p></li><li><p><strong>前向层维度</strong>：Transformer中FFN的隐藏层维度为3072。</p></li><li><p><strong>Dropout率</strong>：残差连接、嵌入层和注意力中均设置为0.1。</p></li><li><p><strong>总参数量</strong>：约117M。</p></li></ul><p><strong>其他配置</strong></p><ul><li><p><strong>训练轮数</strong>：100。</p></li><li><p><strong>批量大小</strong>：64。</p></li><li><p><strong>最大序列长度</strong>：512。</p></li><li><p><strong>优化器</strong>：Adam。</p></li><li><p><strong>学习率调度</strong>：</p><p>初始学习率为0，在前2000步线性增加至最大值 $ 2.5 \times 10^{-4} $。之后采用余弦衰减策略逐渐减小学习率。与Transformer一样有线性增加热身的过程，但具体的衰减方式和热身步数不同。</p></li><li><p><strong>L2正则化</strong>：权重 $ w = 0.01 $。</p></li><li><p><strong>激活函数</strong>：GELU（Gaussian Error Linear Unit）。</p></li><li><p><strong>位置嵌入</strong>：采用可学习的位置嵌入矩阵，而非原始Transformer中的正弦嵌入。</p></li></ul><h2 id="_1-9-有监督微调" tabindex="-1">1.9 有监督微调 <a class="header-anchor" href="#_1-9-有监督微调" aria-label="Permalink to &quot;1.9 有监督微调&quot;">​</a></h2><p>在预训练阶段完成后，模型可以根据具体的下游任务进行微调。假设我们现在有一个标注数据集 C，其中每个样本包含一个输入序列 x = (x^1, …, x^m) 和对应的标签 y。此时的目标是最大化标签 y 在输入序列 x 下的条件概率，表示为：</p> L_2(C) = ∑_(x,y) log P(y | x^1, …, x^m) <p>具体流程涉及特定任务的输入处理，例如：</p><ul><li><strong>文本分类</strong>：输入处理为 ⟨s⟩ 文本 ⟨e⟩。</li><li><strong>文本蕴含</strong>：输入处理为 ⟨s⟩ 前提 $ 假设 ⟨e⟩。</li><li><strong>语义相似性</strong>：输入处理有两种形式，一种是 ⟨s⟩ 句子A $ 句子B ⟨e⟩，另一种是 ⟨s⟩ 句子B $ 句子A ⟨e⟩（注意这里句子A和句子B的顺序可以互换，具体取决于数据集的设计）。</li><li><strong>选择题</strong>：输入处理为 ⟨s⟩ 上下文 $ 问题 $ 答案 ⟨e⟩。</li></ul><p>微调阶段的目标是优化以下条件概率：</p> P(y | x^1, …, x^m) = softmax(h_l^m W_y) <p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mi>l</mi><mi>m</mi></msubsup></mrow><annotation encoding="application/x-tex">h_l^m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.9775479999999999em;vertical-align:-0.2831079999999999em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.2831079999999999em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">m</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 表示输入序列 x = (x^1, …, x^m) 经过预训练模型的最后一层隐藏状态。上标 m 代表位置。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">W_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 是线性层的权重矩阵，该层接在预训练模型之后，用于将隐藏状态 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mi>l</mi><mi>m</mi></msubsup></mrow><annotation encoding="application/x-tex">h_l^m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.9775479999999999em;vertical-align:-0.2831079999999999em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.2831079999999999em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">m</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 映射到标签空间。</li></ul><p>可以理解为预训练模型后接一个线性层，比如对于二分类任务，对应的代码是 nn.Linear(hidden_size, 2)。这个线性层直接输出最终的预测结果。</p><p>3 辅助目标</p><p>为了提高泛化能力和加速收敛，微调阶段还引入了预训练的语言建模目标函数作为辅助，最终的目标函数如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>3</mn></msub><mo>(</mo><mi>C</mi><mo>)</mo><mo>=</mo><msub><mi>L</mi><mn>2</mn></msub><mo>(</mo><mi>C</mi><mo>)</mo><mo>+</mo><mi>λ</mi><msub><mi>L</mi><mn>1</mn></msub><mo>(</mo><mi>C</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">L_3(C) = L_2(C) + \lambda L_1(C) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit">λ</span><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span></span></p><p>其中：</p><ul><li>$ L_2(C) $：主要任务的目标函数。</li><li>$ L_1(C) $：辅助任务的目标函数。</li><li>$ \lambda $：辅助目标函数的权重，用于平衡两个目标函数之间的相对重要性。</li></ul><p><strong>辅助目标函数的意义</strong></p><ul><li><p>特征增强：通过多任务或自监督学习，引导模型捕捉更通用的特征。</p></li><li><p>训练稳定性：缓解梯度消失/爆炸（如中间层监督）或对抗训练中的模式崩溃。</p></li><li><p>数据效率：利用无标签数据（自监督）或跨任务信息（多任务），减少对标注数据的依赖。</p></li><li><p>泛化能力：通过正则化或领域对齐，提升模型在未见数据上的表现。</p></li></ul><h2 id="_1-10-相关设置" tabindex="-1">1.10 相关设置 <a class="header-anchor" href="#_1-10-相关设置" aria-label="Permalink to &quot;1.10 相关设置&quot;">​</a></h2><p>微调阶段对12个下游任务进行了实验，按照之前的分类如下：</p><ul><li><strong>数据集文本分类</strong>：Stanford Sentiment Treebank-2 (SST-2)、Corpus of Linguistic Acceptability (CoLA)。</li><li><strong>文本蕴含</strong>：SNLI、MultiNLI、Question NLI、RTE、SciTail。</li><li><strong>语义相似性</strong>：MSR Paraphrase Corpus (MRPC)、Quora Question Pairs (QQP)、STS Benchmark (STS-B)。</li><li><strong>选择题</strong>：RACE、Story Cloze。</li></ul><h4 id="超参数设置-大多数任务" tabindex="-1">超参数设置（大多数任务） <a class="header-anchor" href="#超参数设置-大多数任务" aria-label="Permalink to &quot;超参数设置（大多数任务）&quot;">​</a></h4><p>除了以下超参数，其余均复用预训练阶段的参数设置：</p><ul><li><strong>微调轮数</strong>：3</li><li><strong>批量大小</strong>：32</li><li><strong>学习率调度</strong>：热身步数为训练总步数的0.2%。最大学习率调整为6.25 × 10^(-5)，热身后采用线性衰减策略。</li><li><strong>Dropout率</strong>：分类器层（即预训练模型之后的线性层）设置为0.1。</li><li><strong>辅助目标权重</strong>：λ = 0.5</li></ul><p>到目前为止，还看不到<strong>ChatGPT的影子</strong>，因为针对不同的任务还需要进行微调，不能简单地直接用对话的形式获取答案。即便论文后续有提及Zero-shot，但实际效果一般。</p><p><strong>关于Zero-shot</strong></p><p>其实Zero-shot并非GPT-2才引入，在GPT-1中（第7页的Zero-shot Behaviors部分）就已经探讨了生成式预训练模型的<code>Zero-shot性能</code>，即模型在没有针对某些特定任务进行微调的情况下，也能通过预训练过程中学习到的知识直接完成这些任务。</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">“A</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hypothesis</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> is</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> that</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> underlying</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> generative</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> learns</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> perform</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> many</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tasks</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> we</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> evaluate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> on</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> in</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> order</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> improve</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> its</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> language</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> modeling</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> capability</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> and</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> that</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> more</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> structured</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> attentional</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> memory</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> transformer</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> assists</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> in</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> transfer</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> compared</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> LSTMs.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ”</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">论文假设，预训练语言模型的生成目标让模型在学习语言建模能力的过程中，掌握了大量任务相关的语言知识。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Transformer</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 架构的结构化注意力机制（Structured</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Attentional</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Memory）相比于</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> LSTM</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 具有更好的迁移性。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">“We</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> designed</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> a</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> series</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> of</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> heuristic</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> solutions</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> that</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> use</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> the</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> underlying</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> generative</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> to</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> perform</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tasks</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> without</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> supervised</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> finetuning.”</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">作者设计了一系列启发式方法，通过直接使用生成预训练模型（无需监督微调）解决不同下游任务。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">“For</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SST-2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (sentiment </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">analysis</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), we append the token very to each example and restrict the language model’s output distribution to only the words positive and negative and guess the token it assigns higher probability to as the prediction…”</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">以情感分析任务为例，对于输入：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">The</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> movie</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> was</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> incredibly</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> entertaining.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">增加</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> very：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">The</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> movie</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> was</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> incredibly</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> entertaining.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> very</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">限制生成的输出仅包含“positive”和“negative”，最后根据预测的概率确定情感。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">下图展示了模型在不同任务上的零样本性能随预训练迭代次数的变化趋势。性能指标归一化到随机猜测与当前</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SOTA</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 之间：</span></span></code></pre></div><p><img src="https://i-blog.csdnimg.cn/img_convert/d3f7802ed09998accf0f2fe80d573ad5.png" alt=""></p><p><em>可以看到，随着训练的进行，任务性能稳定增长，但离 SOTA 还有不小的差距。</em> <br></p><h1 id="_2-gpt2" tabindex="-1">2 GPT2 <a class="header-anchor" href="#_2-gpt2" aria-label="Permalink to &quot;2 GPT2&quot;">​</a></h1><ul><li><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noreferrer">Language Models are Unsupervised Multitask Learners</a></li></ul><p>GPT-2 的整体设计思想相较于 GPT-1 没有变化，但通过模型规模的扩展和数据集的优化，在零样本学习（Zero-Shot Learning）上迈出了一大步。此前该领域的模型或受限于架构或受限于规模，性能远不如 GPT-2。<br></p><p><strong>关键改进</strong></p><ol><li>更大的数据集</li></ol><p>GPT-2 使用了 WebText 数据集进行训练。WebText 的文本来源是 4500 万个经过 Reddit 用户过滤后的网页链接（至少有 3 karma，karma 可以视为点赞数），经过去重和清理后，最终包含 800 万篇文档，总计约 40GB 的文本（GPT-1 数据集的大小约为 1GB）。为了避免评估数据的“泄漏”，数据集还特意去除了常见的数据来源（比如维基百科）。同时，由于数据集的变化，词汇表从 40,000 扩展到了 50,257。值得一提的是，GPT-2 采用了字节级的 BPE (Byte-level Byte Pair Encoding) 进行分词（GPT-1 使用的是传统的 BPE）。</p><ol start="2"><li>更大的模型</li></ol><p>GPT-2 的参数规模（15 亿参数）远超其前身 GPT-1（1.1 亿参数）以及当时的主流模型（如 BERT_LARGE 的 3.4 亿参数）。但模型主体架构并没有修改，只是调整了一些超参数：</p><ul><li>层数 n_{layers}：12 → 48</li><li>隐藏层维度 d_{model}：768 → 1,600</li><li>最大序列长度：512 → 1,024</li><li>批量大小：64 → 512</li></ul><p>另外，还引入了一些细节优化：</p><ul><li><strong>层归一化（Layer Normalization）</strong>：调整至每个子模块的输入端（Pre-Norm），类似于预激活残差网络，同时在最后的自注意力模块后增加额外的层归一化。</li><li><strong>残差权重初始化</strong>：采用了 1 / \sqrt{N} 的权重缩放因子，其中 N 是残差层的深度。</li></ul><p>这些改进共同提升了 GPT-2 的性能和泛化能力。</p><p><img src="https://i-blog.csdnimg.cn/img_convert/bda7985b826dc505b056aef45cc4ae4b.png" alt=""></p><p>其中，最小的模型（117M）对标 GPT-1，第二个模型（345M）对标 BERT LARGE，最大的模型（1152M）称为 GPT-2，它的另一个名字是 GPT2-XL。</p><h1 id="_2-2-零样本学习-zero-shot-learning" tabindex="-1">2.2 零样本学习（Zero-shot Learning） <a class="header-anchor" href="#_2-2-零样本学习-zero-shot-learning" aria-label="Permalink to &quot;2.2 零样本学习（Zero-shot Learning）&quot;">​</a></h1><p>GPT-2 的创新在于对零样本学习的进一步探索。GPT-1 微调时引入了三种特殊符号: ⟨ s ⟩ \langle s \rangle⟨s⟩, $, ⟨ e ⟩ \langle e \rangle⟨e⟩，这些符号在预训练时并没有见过，所以会在微调的时候学习表示。而 GPT-2 不再引入这些特殊符号，采用与 GPT-1 预训练数据格式更相似的自然输入格式（其实就是不做多余操作，单纯的预训练），这也是后续文献常提及以及我们现在耳熟能详的 Prompt，作者给出了两个例子：</p><ul><li>翻译：translate to French, English text, French text。</li></ul><p><img src="https://i-blog.csdnimg.cn/img_convert/15c9bea983cc6d883d01d6c1b4d27d9e.png" alt=""></p><ul><li>阅读理解：answer the question, document, question, answer</li></ul><p>正如论文标题 「Language Models are Unsupervised Multitask Learners」 所暗示的，在 GPT-2 的原始论文中，模型并未针对任何下游任务进行有监督的微调（fine-tuning），而是直接在大规模文本上进行预训练，然后在各种 NLP 任务上测试性能。</p><p>所以 Zero-shot 或许可以片面地理解为只进行预训练。</p><p>Q1：什么是 Pre-Norm？和 GPT-1 的区别？</p><p><img src="https://i-blog.csdnimg.cn/img_convert/957d5105ad3493a9e1d526e07c36269e.png" alt=""></p><p>GPT-1 和 GPT-2 的区别</p><p>GPT-1：Post-Norm，层归一化放置在残差连接之后。 GPT-2：Pre-Norm，层归一化放置在残差连接之前。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, sublayer):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 子层的输出 + 残差连接后，进行归一化</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.norm(x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sublayer(x))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, sublayer):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 输入先进行归一化，再传入子层，最后进行残差连接</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sublayer(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.norm(x))</span></span></code></pre></div><h1 id="_3-gpt-3" tabindex="-1">3. GPT-3 <a class="header-anchor" href="#_3-gpt-3" aria-label="Permalink to &quot;3. GPT-3&quot;">​</a></h1><ul><li><a href="https://arxiv.org/pdf/2005.14165" target="_blank" rel="noreferrer">Language Models are Few-Shot Learners</a></li></ul><p>GPT-3 关键改进: <strong>秉承传统：更大的数据集和更大的模型。</strong></p><h2 id="_3-1-摘要" tabindex="-1">3.1 摘要 <a class="header-anchor" href="#_3-1-摘要" aria-label="Permalink to &quot;3.1 摘要&quot;">​</a></h2><p>人类有时只需少数示例或简单说明，便能轻松应对全新的语言任务，然而当前的自然语言处理系统仍面临巨大挑战。很多情况下，系统仍需通过特定任务的微调才能获得出色的效果。在这个挑战的推动下，OpenAI的研究人员努力改进了GPT-2 模型的有效性，并发布了GPT-3模型。</p><p><strong>GPT-3是一个拥有1750亿模型参数的自回归语言模型。</strong> 与GPT-2相比，GPT-3的参数量翻了116倍。与此同时，GPT-3采用了GPT-1最初提出的Few- shot设置，即模型在处理子任务时不再依赖大量样例，而是在可控范围内给出一些样本。这种设置的成本非常低，但却能为模型提供足够的信息。最令人惊叹的是，<strong>GPT-3在任何任务上都无需任何梯度更新或微调，只需通过与模型的文本交互来指定任务和展示少量样本。</strong></p><p><strong>GPT-3在多个自然语言处理任务中展现出了惊艳的性能</strong> ，如翻译、问答和填空，同时还能够应对那些需要即时推理或领域适应的挑战，如拼写校正、引入新词和进行三位数算术运算。OpenAI 的科研人员发现，增加语言模型的规模可以极大地提升任务无关的少样本学习性能，有时甚至能够与当前最领先的微调方法媲美，这一突破在当时引发了极大的关注和赞誉。</p><h2 id="_3-2-引言" tabindex="-1">3.2 引言 <a class="header-anchor" href="#_3-2-引言" aria-label="Permalink to &quot;3.2 引言&quot;">​</a></h2><p>为了在各类任务中实现卓越性能，通常需要对特定任务的数据集进行大规模微调，这涉及数千到数十万个需要人工标注的数据集。然而，消除这种限制是可取的，原因如下所述：</p><p>首先，<strong>从实践角度来看，为每个新任务收集大规模标记示例数据集的需求限制了语言模型的适用性</strong> 。语言任务的种类繁多，涵盖了从语法纠错到生成抽象概念示例，再到批评短篇故事等各种内容。对许多任务而言，要收集大规模的监督训练数据集往往具有挑战性，特别是当必须为每个新任务重复这个过程时。</p><p>其次，<strong>训练数据中的偶然相关性与模型表达能力和训练分布的狭隘性之间存在直接关系，这对于预训练后进行微调的模型来说可能带来问题</strong> 。尽管这些模型在预训练阶段被设计得很大，能够吸收大量信息，但在非常狭隘的任务分布上进行微调。有证据表明，这种范式下的泛化能力可能较弱，因为模型过于特定于训练分布，并且在其之外的泛化能力不强。</p><p>最后，<strong>人类在学习大多数语言任务时并不需要大规模的监督数据集</strong> 。仅仅凭借自然语言中的简短指令或少数示例，人类就能够在新任务上胜任并达到合理水平。这种适应性不仅揭示了当前自然语言处理技术的限制，而且具有实际优势。它使人类能够无缝地混合或切换多个任务和技能，例如在长时间对话中进行加法运算。为了广泛应用，研究者们希望有朝一日自然语言处理系统也能具备类似的灵活性和普适性。</p><p>为了解决上述问题，OpenAI的研究人员训练了一个<strong>巨大的自回归语言模型，拥有着惊人的1750亿参数，即GPT-3</strong> 。在应对各类后续任务时，他们主要采用了Few-shot、One-shot和Zero- shot这三种不同的设定策略，并在不需要对模型进行任何形式微调的情况下取得了引人注目的成果。简言之，<strong>这意味着通过提供一些任务样例（即上下文信息），该模型能够自主探索并掌握处理这些任务的能力</strong> 。这种能力主要来源于以下两方面：</p><p>第一，<strong>通过在语言模型的训练中培养广泛的技能和模式识别能力，然后在推理过程中利用这些能力来适应或识别所需的任务</strong> <strong>。</strong></p><p>如Figure 1.1所示，每个样本来自于不同的任务，涵盖了各种领域，如加法运算、语法纠正和翻译。这些任务提供了大量的训练数据，为模型提供了广泛的语言样本。通过在这些多样化的数据上进行训练，模型能够理解和处理各种任务。从上下文学习的角度来看，对于同一任务的处理，模型能够通过上下文中的信息进行准确推断，从而提高任务的效果。在这个过程中，模型能够从上下文中提取相关的知识和洞察，以支持对不同任务的有效适应。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure1.png" alt=""></p><p>第二，<strong>增加语言模型的参数规模，通过模型参数规模的显著增加，可以提升自然语言处理任务的性能</strong> 。</p><p>如Figure 1.2所示，随着模型参数规模的增加，上下文学习能力会获得类似的强大增益。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure2.png" alt=""></p><h2 id="_3-3-训练数据集" tabindex="-1">3.3 训练数据集 <a class="header-anchor" href="#_3-3-训练数据集" aria-label="Permalink to &quot;3.3 训练数据集&quot;">​</a></h2><h3 id="_3-3-1-数据集概述" tabindex="-1">3.3.1 数据集概述 <a class="header-anchor" href="#_3-3-1-数据集概述" aria-label="Permalink to &quot;3.3.1 数据集概述&quot;">​</a></h3><p>GPT-3的训练需要大量的训练数据，这些数据主要来源于<strong>精心筛选过的CommonCrawl、WebText数据集的扩展版本、两个基于互联网的图书语料库（Books1和Books2）和英语维基百科数据集</strong> 。</p><p>Table2.2呈现了最终训练数据集的混合情况。可以看到，在训练过程中，研究人员并非按照数据集大小的比例进行采样，而更倾向于频繁采样质量较高的数据集。因此，CommonCrawl和Books2数据集在训练中的采样次数不到一次，而其他数据集则采样2-3次。这种方法在一定程度上容忍了轻微的过拟合，以换取更高质量的训练数据。</p><p>GPT-3 的训练数据集来自 Common Crawl、WebText2、Books1、Books2 和 Wikipedia，论文的表 2.2 列出了它们的规模、在训练中的权重分布以及训练 3000 亿 tokens 时经过的轮次:</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure3.png" alt=""></p><h3 id="_3-3-2-数据集详情" tabindex="-1">3.3.2 数据集详情 <a class="header-anchor" href="#_3-3-2-数据集详情" aria-label="Permalink to &quot;3.3.2 数据集详情&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:center;">数据集</th><th style="text-align:center;">数据量（tokens 数）</th><th style="text-align:center;">训练混合中的权重</th><th style="text-align:center;">训练 3000 亿 tokens 时的轮次</th></tr></thead><tbody><tr><td style="text-align:center;">Common Crawl（过滤后）</td><td style="text-align:center;">约 4100 亿</td><td style="text-align:center;">60%</td><td style="text-align:center;">0.44</td></tr><tr><td style="text-align:center;">WebText2</td><td style="text-align:center;">约 190 亿</td><td style="text-align:center;">22%</td><td style="text-align:center;">2.9</td></tr><tr><td style="text-align:center;">Books1</td><td style="text-align:center;">约 120 亿</td><td style="text-align:center;">8%</td><td style="text-align:center;">1.9</td></tr><tr><td style="text-align:center;">Books2</td><td style="text-align:center;">约 550 亿</td><td style="text-align:center;">8%</td><td style="text-align:center;">0.43</td></tr><tr><td style="text-align:center;">Wikipedia</td><td style="text-align:center;">约 30 亿</td><td style="text-align:center;">3%</td><td style="text-align:center;">3.4</td></tr></tbody></table><p>需要注意的是，尽管 Common Crawl 是规模最大的数据集，数据量远超其他来源（是 WebText2 的 21.58 倍），但由于质量参差不齐，其训练权重被适当降低，仅为总权重的 60%，而较小但质量更高的 WebText2 则分配了 22% 的训练权重。</p><h3 id="_3-3-3-对于数据集-common-crawl-的处理" tabindex="-1">3.3.3 对于数据集 Common Crawl 的处理 <a class="header-anchor" href="#_3-3-3-对于数据集-common-crawl-的处理" aria-label="Permalink to &quot;3.3.3 对于数据集 Common Crawl 的处理&quot;">​</a></h3><p>Common Crawl 是一个非盈利组织，会定期抓取互联网上的网页数据并免费开放给研究者使用。为了准备更大的数据集以匹配更大的模型，OpenAI 团队从 Common Crawl 中下载了 2016-2019 年的 41 个数据分片，总量约 45TB（压缩后）。在经过一系列自动化过滤、重新采样和去重处理后，最终得到约 570GB 的文本，对应约 4100 亿 Byte-Pair Encoding (BPE) 子词。</p><ol><li><strong>自动过滤 (Automatic Filtering)</strong></li></ol><ul><li><p>训练集与分类器 为了从原始 Common Crawl 中挑选更高质量的文档，研究团队采取了以下步骤：</p><ul><li><strong>数据集准备</strong>：将高质量语料（如 WebText、Wikipedia、以及 web books corpus）合并为“正例”数据集，并将未经过滤的 Common Crawl 用作“负例”。</li><li><strong>特征提取</strong>：利用 Spark 的标准分词器（Tokenizer）和 HashingTF 提取文本特征。</li><li><strong>分类器训练</strong>：以此特征训练 Logistic Regression（逻辑回归）分类器，为每篇文档打分。得分越高，表示该文档越“接近”高质量语料；得分较低则表明该文档的质量“可能”欠佳。</li></ul></li><li><p>重新采样 (Resampling) 与 Pareto 分布</p></li></ul><p>        基于上述“质量分数”，研究团队利用以下条件进行重新采样：</p> \texttt{np.random.pareto}(\alpha) &gt; 1 - \texttt{document\_score} <p>        其中，(\alpha = 9)。文档得分越高，越容易保留；但低分文档也有一定概率被保留，以维持多样性。以下代码示例有助于理解上述概念：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> filter_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(doc_score, alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, trials</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    doc_score: 文档分数 (0 - 1)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    alpha: Pareto 分布的形状参数</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    trials: 模拟采样次数</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 1. 生成很多个 Pareto(α=9) 随机数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    samples </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.random.pareto(alpha, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trials)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 2. 计算阈值</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    threshold </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc_score</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 3. 看看有多少随机数满足：sample &gt; threshold</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pass_count </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.sum(samples </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> threshold)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pass_count </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> trials</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 测试不同的 document_score</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> s </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rate </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> filter_rate(s)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;doc_score=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">s</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, 通过过滤的模拟比例=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:.4f</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc_score</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 通过过滤的模拟比例</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0021</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc_score</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 通过过滤的模拟比例</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0051</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc_score</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 通过过滤的模拟比例</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0268</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc_score</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 通过过滤的模拟比例</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1950</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc_score</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 通过过滤的模拟比例</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4243</span></span></code></pre></div><p><em>注意：上述代码仅为示例，实际使用时需根据具体数据和需求进行调整。</em></p><p>输出：</p><ul><li>当 doc_score=0，约 0.2% 的保留率。</li><li>当 doc_score=0.9，约 42% 的保留率。</li></ul><p>核心思路：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.random.pareto(alpha) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> document_score:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keep_doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    keep_doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span></span></code></pre></div><ol start="2"><li>模糊去重 (Fuzzy Deduplication)         为进一步提升模型质量并降低过拟合风险，研究团队还对各训练集做了模糊去重（使用和上面分类相同的特征）：</li></ol><ul><li>在 Spark 中使用 MinHashLSH（配置 10 个哈希），利用与上面分类相同的特征来检测文档间的相似度，对相似度较高的文档进行删除。</li><li>同时将 WebText 中出现的内容从 Common Crawl 里删除（方式同上）。<br></li></ul><p>整体来看，模糊去重将减少 10% 的数据量。</p><p>        在论文中提到尽管他们尝试去重（训练集和测试集之间，train-test overlap），但因为某些 bug，有可能存在少量测试集内容被模型“见”过，从而造成一定的数据泄漏。而由于训练成本太大，他们没法重来，论文的第 4 节评估了数据泄露的影响。</p><h2 id="_3-4-模型和架构" tabindex="-1">3.4 模型和架构 <a class="header-anchor" href="#_3-4-模型和架构" aria-label="Permalink to &quot;3.4 模型和架构&quot;">​</a></h2><p><strong>GPT-3采用与GPT-2相同的模型和架构，唯一的区别在于GPT-3在Transformer层中引入了交替的稠密和局部带状稀疏注意力模式，类似于Sparse Transformer。</strong></p><p>为了深入探究模型规模对学习性能的影响，研究人员训练了<strong>8种不同规模的模型，涵盖了从1.25亿个参数到1750亿个参数的三个数量级范围</strong> 。其中，最庞大的模型被命名为GPT-3。</p><p>        在Table2.1中展示了8个模型的规模和架构。其中，nparams代表可训练参数的总数，nlayers表示Transformer的总层数，dmodel指每个bottleneck layer中的神经元数量，而前馈层的大小是bottleneck layer大小的四倍，即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo>=</mo><mn>4</mn><mo>∗</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{ff} = 4 *d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit" style="margin-right:0.10764em;">f</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">4</span><span class="mbin">∗</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> ，dhead表示每个注意力头的维度。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure4.png" alt=""></p><p>        所有的模型的上下文窗口都为nctx=2048个tokens。为了减少节点之间的数据传输，研究人员将模型根据其深度和宽度分割到不同的GPU上。具体的模型架构参数是根据计算效率和负载均衡在GPU上选择的。</p><h2 id="_3-5-训练过程" tabindex="-1">3.5 训练过程 <a class="header-anchor" href="#_3-5-训练过程" aria-label="Permalink to &quot;3.5 训练过程&quot;">​</a></h2><p>        为了在训练更大的模型时避免内存耗尽，<strong>GPT-3在训练过程中采用了一种模型并行化的混合方法，既在每个矩阵乘法运算内部采用模型并行化，又在网络的各个层之间采用模型并行化</strong> 。所有模型都是在由微软提供的高带宽集群中的V100 GPU上进行训练的。</p><p>        GPT-3在训练过程中采用了Adam优化器，参数设置为β1 = 0.9，β2 = 0.95，ε = 10-8，为了控制梯度的范围，将梯度的全局范数裁剪为1.0。</p><p>        在处理2600亿个tokens的过程中，会通过余弦衰减逐步降低学习率至初始值的10%（即：<strong>在处理完2600亿个tokens后，学习率会继续以原始学习率的10%进行训练</strong>）。此外，在训练的前40-120亿个tokens中，会逐渐增加BatchSize大小，从较小的值（32k个tokens）增加到设定的最大值。具体参数设置可见Table 2.1。</p><p>        为了减小过拟合现象，采用了无替换的数据采样策略，直到达到一个epoch的边界。所有模型都使用0.1的权重衰减进行轻微的正则化。在训练过程中，<strong>始终使用2048个tokens的上下文窗口序列进行训练，当文档长度小于2048个tokens时，我们将多个文档打包成一个序列，以提高计算效率。</strong> 序列中的多个文档通过特殊的文本结束标记进行分隔，为语言模型提供了上下文无关信息的推断。这种方式实现了高效的训练，无需进行特殊的序列屏蔽操作。</p><p>        Figure 2.2展示了GPT-3在训练过程中的总计算量。显而易见，随着模型参数规模的增加，计算量的也在显著增加。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure5.png" alt=""></p><h2 id="_3-6-上下文学习的三种设置" tabindex="-1">3.6 上下文学习的三种设置 <a class="header-anchor" href="#_3-6-上下文学习的三种设置" aria-label="Permalink to &quot;3.6 上下文学习的三种设置&quot;">​</a></h2><p>        GPT-3在训练完成之后，就可以使用Few-Shot、One-Shot和Zero- Shot三种不同的方式在特定任务上进行使用。值得注意的是，GPT-3在特定任务上使用时无需进行微调或参数更新。这三种使用方式的简单介绍如下所示：</p><p>• <strong>Few-Shot（FS）：</strong> 模型在推理时给出K个任务示例作为上下文信息，同时提供任务的自然语言描述，但不允许模型进行权重更新。通常将K设置在10到100的范围内，以适应模型的上下文窗口。</p><p>• <strong>One-Shot（1S）：</strong> 模型在推理时通过提供一个任务示例作为上下文信息，同时还有任务的自然语言描述。这种方式最接近于人类在解决某些任务时所使用的方式。</p><p>• <strong>Zero-Shot（0S）：</strong> 不提供任何上下文信息，模型只给出一个描述任务的自然语言指令。</p><p>        下图以英语翻译成法语的示例说明了Few-Shot、One-Shot和Zero-Shot这三种方法，并展示了传统Fine-tuning方法的一般流程。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/gpt3-figure6.png" alt=""></p><p><em>注释：In-Context Learning 是通过提示（Prompt）完成任务，而微调是通过训练更新参数来适应任务。一个不更新参数，一个更新参数。一个是 eval，一个是 train。</em></p><h2 id="_3-7-gpt-3的局限性" tabindex="-1">3.7 GPT-3的局限性 <a class="header-anchor" href="#_3-7-gpt-3的局限性" aria-label="Permalink to &quot;3.7 GPT-3的局限性&quot;">​</a></h2><p>尽管与GPT-2相比，GPT-3的性能有了显著的提升，但仍然存在以下局限性：</p><ol><li><strong>GPT-3在文本合成任务中偶尔会出现语义上的重复，随着段落变长，连贯性下降，同时还存在自相矛盾和不相关的句子。</strong> 而对于&quot;常识物理&quot;问题，例如&quot;奶酪放进冰箱是否会融化&quot;，GPT-3表现困难。</li><li><strong>GPT-3存在结构和算法上的限制</strong> ，GPT-3专注于自回归语言模型的上下文学习行为，模型未包括双向架构或其他训练目标，这种设计决策可能导致在实际受益于双向性的任务上性能较差。</li><li>GPT-3的训练目标对每个token赋予相同的权重，缺乏对于预测中什么是最重要和什么是次要的概念。</li><li>GPT-3缺乏与其他领域（如视频或现实世界的物理交互）相关联的背景知识和大量上下文信息，<strong>知识的缺失</strong> 会对模型性能造成影响。</li><li>GPT-3少样本学习面临的一个<strong>不确定性</strong> 是，在推理过程中难以确定模型到底是“从零开始”学习新任务，还是仅仅在区分和识别训练期间学到的任务。</li><li>由于GPT-3的庞大参数规模，不论是训练还是推理部署过程都具备<strong>高昂的成本</strong> 和不便之处，这或许对目前这种规模的模型在实际应用中带来一定的挑战。</li><li>GPT-3训练数据中的偏见<strong>可能导致模型生成的内容变得刻板化或带有偏见。</strong></li></ol><h2 id="_3-8-总结" tabindex="-1">3.8 总结 <a class="header-anchor" href="#_3-8-总结" aria-label="Permalink to &quot;3.8 总结&quot;">​</a></h2><p>        GPT-3是一个拥有1750亿个参数的语言模型，与15亿参数的GPT-2相比，GPT-3更像是一个暴力出奇迹的结果。GPT-3在Zero-shot、One-shot和Few-shot 的设置下，在众多自然语言处理任务中展现出强大的性能。</p><p>        本文详细探讨了GPT-3 的基本原理以及其所面临的局限性。尽管GPT-3存在一些限制，但它的出现印证了大规模语言模型有可能成为发展适应能力强、通用的语言系统的重要组成部分。在当前大模型盛行的时代背景下，GPT-3的工作仍具备极大的价值。</p><h1 id="_4-gpt-4" tabindex="-1">4 GPT-4 <a class="header-anchor" href="#_4-gpt-4" aria-label="Permalink to &quot;4 GPT-4&quot;">​</a></h1><ul><li><a href="https://arxiv.org/pdf/2303.08774" target="_blank" rel="noreferrer">报告地址</a></li><li><a href="https://openai.com/index/gpt-4-research/" target="_blank" rel="noreferrer">精简版</a></li></ul><p><strong>代续</strong></p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/AI/deep_learning_theory/42-nlp-gpt.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页面 OR 提出修改意见<!--]--></a></div><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>最后更新于: <time datetime="2025-03-22T08:26:57.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/AI/deep_learning_theory/41-nlp-t5_question-answering.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>上一篇</span><span class="title" data-v-e257564d>41-nlp-t5_question-answering</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/AI/deep_learning_theory/43-scaling-law.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>下一篇</span><span class="title" data-v-e257564d>43-scaling-law</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>ICP备案号: <a href="https://beian.miit.gov.cn/" target="_blank">蜀ICP备2024103116号</a><br>公安备案号: <a href="https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928" rel="noreferrer" target="_blank">川公网安备51012202001928</a></p><p class="copyright" data-v-e315a0ad>版权所有 © 2024-present  <a href="mailto:16693226842@163.com" target="_blank">Ethan.Liu</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai_deep_learning_theory_00-dl_base_notes.md\":\"ynjQHcnq\",\"ai_deep_learning_theory_01-feedforward_network.md\":\"Dc0-nIKA\",\"ai_deep_learning_theory_02-back_propagation.md\":\"t66HZ6KH\",\"ai_deep_learning_theory_03-bp_example_demo.md\":\"CdKkr9wb\",\"ai_deep_learning_theory_04-convolution_neural_network.md\":\"CKyKqVoU\",\"ai_deep_learning_theory_05-deep_learning_model.md\":\"B3Ib7-iT\",\"ai_deep_learning_theory_06-pytorch_install.md\":\"C08X_AVj\",\"ai_deep_learning_theory_07-operators.md\":\"BKFjU-RC\",\"ai_deep_learning_theory_08-activation_functions.md\":\"Como81rR\",\"ai_deep_learning_theory_09-recurrent_neural_network.md\":\"D7qCdZEy\",\"ai_deep_learning_theory_10-seq2seq.md\":\"CIAyZr6Y\",\"ai_deep_learning_theory_11-1attentions.md\":\"CB-r_QHy\",\"ai_deep_learning_theory_11-2attention-extension.md\":\"D9uu1g-H\",\"ai_deep_learning_theory_12-weight-initialization.md\":\"tjnwIO-Q\",\"ai_deep_learning_theory_13-optimizers.md\":\"Qk82FVfW\",\"ai_deep_learning_theory_14-regularization.md\":\"CWzAanem\",\"ai_deep_learning_theory_15-deep-learning-tuning-guide.md\":\"CMQIvWo9\",\"ai_deep_learning_theory_20-pytorch-tensor.md\":\"3GYXzMSK\",\"ai_deep_learning_theory_21-pytorch-autograd.md\":\"BPcbnDeO\",\"ai_deep_learning_theory_22-pytorch-module.md\":\"D3W47z47\",\"ai_deep_learning_theory_23-1training-example-1.md\":\"BSbXuKLm\",\"ai_deep_learning_theory_23-2decoder.md\":\"BCYdFt2l\",\"ai_deep_learning_theory_23-3encoder.md\":\"BpaKSKIz\",\"ai_deep_learning_theory_23-4transformer.md\":\"Deo9x8So\",\"ai_deep_learning_theory_24-pytorch-optimizer.md\":\"D38W_WfI\",\"ai_deep_learning_theory_25-pytorch-lr-scheduler.md\":\"BrPX5Pww\",\"ai_deep_learning_theory_26-pytorch-dataloader.md\":\"C1VXfMIC\",\"ai_deep_learning_theory_27-pytorch-model-save.md\":\"D0btqXT_\",\"ai_deep_learning_theory_28-pytorch-tensorboard.md\":\"CGiQm8lw\",\"ai_deep_learning_theory_29-pytorch-graph-mode.md\":\"Dh2sBoD6\",\"ai_deep_learning_theory_30-1training-example-cv.md\":\"p904AaTO\",\"ai_deep_learning_theory_30-3main.md\":\"Cf3sjvsp\",\"ai_deep_learning_theory_31-1stable-diffusion.md\":\"DJ3G17UM\",\"ai_deep_learning_theory_31-2sdxl.md\":\"BtjJ2uGH\",\"ai_deep_learning_theory_31-3vae.md\":\"DZnDlKEi\",\"ai_deep_learning_theory_40-nlp-bert_ner.md\":\"CK9my62E\",\"ai_deep_learning_theory_41-nlp-t5_question-answering.md\":\"4magtn5l\",\"ai_deep_learning_theory_42-nlp-gpt.md\":\"BBE-o7PM\",\"ai_deep_learning_theory_43-scaling-law.md\":\"BA7OGtiT\",\"ai_deep_learning_theory_44-distribute-training.md\":\"6V2dXfti\",\"ai_deep_learning_theory_45-llm-history.md\":\"nsfzyD6J\",\"ai_deep_learning_theory_46-llm-gpt-extension.md\":\"CdKqxRH1\",\"ai_deep_learning_theory_46-nlp-llama.md\":\"8zU0XjzU\",\"ai_deep_learning_theory_47-llm-deepseek-structure.md\":\"COr7_JoP\",\"ai_deep_learning_theory_47-nlp-deepseek.md\":\"CjtxEpY3\",\"ai_deep_learning_theory_index.md\":\"C8q3dXoG\",\"ai_distribute_training_00_large-scale-model-trainning.md\":\"BIx_bpi5\",\"ai_distribute_training_01_coding.md\":\"DZD5TEUW\",\"ai_distribute_training_01_offload-and-recompute.md\":\"DOdh7cVu\",\"ai_distribute_training_02_amp.md\":\"CINc-aE7\",\"ai_distribute_training_03_coding.md\":\"BxkUE-WM\",\"ai_distribute_training_03_pytorch-dp.md\":\"DFYuzILV\",\"ai_distribute_training_04_pytorch-ddp.md\":\"DUa8gj9P\",\"ai_distribute_training_05_pytorch-ddp-impl.md\":\"CIvKwbxv\",\"ai_distribute_training_05_pytorch-ddp-impl_ddp_origin.md\":\"YhBoLvWG\",\"ai_distribute_training_06_collective-comm.md\":\"C7kP9P1h\",\"ai_distribute_training_06_torchrun-process-group.md\":\"CTdQ1CQt\",\"ai_distribute_training_07_zero-optimizer.md\":\"LZIDWQVk\",\"ai_distribute_training_08_pytorch-zero-1.md\":\"DOc1kgb8\",\"ai_distribute_training_09_pytorch-fsdp-v1.md\":\"CHM2amj-\",\"ai_distribute_training_10_pytorch-fsdp-v2.md\":\"DVEJZb2f\",\"ai_distribute_training_11_deepspeed-zero-1-2-impl.md\":\"CZCWDD8-\",\"ai_distribute_training_12_deepspeed-zero-3-impl.md\":\"vr_yo7YL\",\"ai_distribute_training_13_megatron-zero-1-impl.md\":\"BJ42Bg5C\",\"ai_distribute_training_14_tp-theory.md\":\"BBrDmNI4\",\"ai_distribute_training_15_megatron-tp-impl.md\":\"Cq037ojz\",\"ai_distribute_training_16_pytorch-tp-impl.md\":\"mmh4fsaH\",\"ai_distribute_training_17_pp-theory.md\":\"Dm_Y1QSM\",\"ai_distribute_training_18_pytorch-pp-impl.md\":\"CGFHxzoR\",\"ai_distribute_training_19_deepspeed-pp-impl.md\":\"ZgOT2aeL\",\"ai_distribute_training_20_megatron-pp-impl.md\":\"BJ7EBnhk\",\"ai_distribute_training_21_sp-theory.md\":\"Do0FqeDo\",\"ai_distribute_training_22_megatron-sp-impl.md\":\"CUU9e02Y\",\"ai_distribute_training_23_3d-parallel-theory.md\":\"fCC1ggoF\",\"ai_distribute_training_24_megatron-3d-parallel-impl.md\":\"BTCqp9YR\",\"ai_distribute_training_25_pytorch-3d-parallel-impl.md\":\"BmIpVSgN\",\"ai_distribute_training_26_cp-theory.md\":\"DuPLtngs\",\"ai_distribute_training_27_megatron-cp-impl.md\":\"C5XlSfug\",\"ai_distribute_training_28_moe-theory.md\":\"BT5VUyC-\",\"ai_distribute_training_28_moe-theory_deepseekmoe.md\":\"u--Y_vZ7\",\"ai_distribute_training_29_megatron-moe-impl.md\":\"-U_1oAtH\",\"ai_distribute_training_30_deepspeed-moe-impl.md\":\"Rs44L6qt\",\"ai_distribute_training_31_deepspeed-code-impl.md\":\"CLlrtRUb\",\"ai_distribute_training_32_collective-operations.md\":\"BHB1yddN\",\"ai_distribute_training_33_pytorch_distribute.md\":\"DFBy-gIA\",\"ai_distribute_training_index.md\":\"DS2GTGnc\",\"ai_index.md\":\"FceT-BLG\",\"ai_transformer_01-transformer的由来.md\":\"DkVMs2oL\",\"ai_transformer_02-transformer架构解读.md\":\"uW3WzF8Y\",\"ai_transformer_03-transformer架构源码构建.md\":\"BcHq2u5q\",\"ai_transformer_index.md\":\"D8JcJLy1\",\"index.md\":\"wFgcyqtU\",\"it-learning_408_index.md\":\"DQ7Ub8n-\",\"it-learning_408_os-4.1 进程同步.md\":\"ImosRfCq\",\"it-learning_408_os-4.4 信号量机制.md\":\"CnMjdS0S\",\"it-learning_408_os-4.4 信号量机制pv操作之“可见”.md\":\"KW2s8fDp\",\"it-learning_c___01_开发环境搭建与基础数据类型.md\":\"DVAfnfKI\",\"it-learning_c___02_控制流语句与复合数据类型.md\":\"o_Iw4hag\",\"it-learning_c___03_指针与引用.md\":\"Bw6bYMMc\",\"it-learning_c___04_自定义数据类型与函数.md\":\"Cyyzd5R-\",\"it-learning_c___05_头文件与指针的算术运算.md\":\"DejaB1_U\",\"it-learning_c___06_字符串、数组、指针与函数.md\":\"D3aHSP55\",\"it-learning_c___07_函数进阶与内存管理.md\":\"DqUS2M8n\",\"it-learning_c___08_运算符优先级表.md\":\"CtazDwSH\",\"it-learning_c___09_指针、内存管理和类的基础.md\":\"L48egUic\",\"it-learning_c___10_深入类和对象.md\":\"BpLLILo4\",\"it-learning_c___11_类的大小、继承与权限控制.md\":\"DYFJyGgE\",\"it-learning_c___12_继承进阶.md\":\"CqNcG1Ig\",\"it-learning_c___13_类型转换和多态与虚函数.md\":\"DaeCEerH\",\"it-learning_c___14_纯虚函数、抽象类、深浅拷贝及智能指针.md\":\"B5cvBNtL\",\"it-learning_c___15_运算符重载与 string 类详解.md\":\"CZX-FnOl\",\"it-learning_c___16_有序容器与无序容器.md\":\"CJwgGEAo\",\"it-learning_c___17_模板.md\":\"4CdEsdGf\",\"it-learning_c___18_迭代器与其应用.md\":\"DmftJhgX\",\"it-learning_c___19_c__ 标准库常用算法.md\":\"Bymm15dk\",\"it-learning_c___20_c__ 异常处理 - 第19次课.md\":\"Sn8BieQI\",\"it-learning_c___21_友元及友元相关内容.md\":\"D1xuHqMb\",\"it-learning_c___22_c__ io 流详解-feadbc607d7f.md\":\"BD7P3tXk\",\"it-learning_c___23_c__ io 流详解.md\":\"azsZ5g77\",\"it-learning_c___24_位运算符总结.md\":\"BOkaz89o\",\"it-learning_c___25_c__三种继承方式.md\":\"DUn7n_et\",\"it-learning_c___26_c__11 高级特性.md\":\"CyrPVDkT\",\"it-learning_c___27_c__14 新特性.md\":\"6YQuRCGz\",\"it-learning_c___28_c__17 新特性.md\":\"BqJAdDo-\",\"it-learning_c___29_多文件和 makefile工程管理.md\":\"DvfAbEZ0\",\"it-learning_c___30_c__大型项目cmake工程管理.md\":\"CJvCgGVT\",\"it-learning_c___31_c__ 主要就业方向与技术能力分析报告.md\":\"CqJbtbjv\",\"it-learning_c___32_c__ 基础知识回顾.md\":\"Dx5_xIPx\",\"it-learning_c___index.md\":\"BAg94tAw\",\"it-learning_index.md\":\"D1maUb85\",\"it-learning_java_01.java-se.md\":\"CV9z-Ph2\",\"it-learning_java_02.sql.md\":\"gilr6jOh\",\"it-learning_java_03.java-web.md\":\"DXRkrx3K\",\"it-learning_java_05.mybatis.md\":\"HjU_MlJz\",\"it-learning_java_index.md\":\"DkRBc8cW\",\"it-learning_linux_01.linux基础.md\":\"BBs1RcBf\",\"it-learning_linux_02.shell.md\":\"BCfUk33T\",\"it-learning_linux_03.mpi并行计算.md\":\"gpRl9TGp\",\"it-learning_linux_04.docker.md\":\"DN_C173y\",\"it-learning_linux_index.md\":\"BVALaZgc\",\"job_interview_algorithm_post_index.md\":\"C27zE7CJ\",\"job_interview_index.md\":\"BRrP26o2\",\"job_interview_java_index.md\":\"C0TwjbqV\",\"my_think_2024_index.md\":\"CyRijovT\",\"my_think_2024_不同商家的视野.md\":\"BLSO_EiV\",\"my_think_2024_学而篇.md\":\"D8kGXmCD\",\"my_think_2024_重温士兵突击.md\":\"DpaabISk\",\"my_think_2025_index.md\":\"BVwhay16\",\"my_think_2026_index.md\":\"BZ9APZkM\",\"my_think_index.md\":\"BPu000Aw\",\"question_list_doccano账户管理.md\":\"4xMMl7Bn\",\"question_list_index.md\":\"Bx3eFS0B\",\"question_list_专英翻转课堂—pytorch.md\":\"C2nclqWo\",\"question_list_虚拟机网络问题.md\":\"Cxh_Plki\",\"readme.md\":\"DJufORId\",\"update_update_log.md\":\"C5I2JMwC\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"码医森\",\"description\":\"计算机知识的学习站点\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"CoderEthan学习站\",\"logo\":\"/imgs/home-page-logo.svg\",\"outline\":{\"label\":\"本文目录\",\"level\":[2,4]},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 496 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\\\"/></svg>\"},\"link\":\"https://github.com/ethanliu6/\"},{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 512 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z\\\"/></svg>\"},\"link\":\"https://space.bilibili.com/1327099977/\"}],\"nav\":[{\"text\":\"AI\",\"items\":[{\"text\":\"DL基础理论\",\"link\":\"/AI/deep_learning_theory/\"},{\"text\":\"Transformer系列\",\"link\":\"/AI/Transformer/\"},{\"text\":\"分布式训练\",\"link\":\"/AI/distribute_training/\"}]},{\"text\":\"计算机学科内容\",\"items\":[{\"text\":\"408知识\",\"link\":\"/IT-learning/408/\"},{\"text\":\"C++基础\",\"link\":\"/IT-learning/c++/\"},{\"text\":\"Java后端\",\"link\":\"/IT-learning/Java/\"},{\"text\":\"Linux技术\",\"link\":\"/IT-learning/Linux/\"}]},{\"text\":\"求职面试\",\"items\":[{\"text\":\"Java面经\",\"link\":\"/Job_Interview/Java/\"},{\"text\":\"算法岗\",\"link\":\"/Job_Interview/Algorithm_post/\"}]},{\"text\":\"其他维护\",\"items\":[{\"text\":\"站点更新\",\"link\":\"/update/update_log\"},{\"text\":\"问题清单\",\"link\":\"/question_list/\"}]},{\"text\":\"感悟和日常\",\"items\":[{\"text\":\"站长感悟\",\"link\":\"/my_think/\"},{\"text\":\"旧版博客\",\"link\":\"https://EthanLiu6.github.io\"}]}],\"footer\":{\"message\":\"ICP备案号: <a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\">蜀ICP备2024103116号</a><br>公安备案号: <a href=\\\"https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928\\\" rel=\\\"noreferrer\\\" target=\\\"_blank\\\">川公网安备51012202001928</a>\",\"copyright\":\"版权所有 © 2024-present  <a href=\\\"mailto:16693226842@163.com\\\" target=\\\"_blank\\\">Ethan.Liu</a>\"},\"editLink\":{\"pattern\":\"https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/:path\",\"text\":\"在 GitHub 上编辑此页面 OR 提出修改意见\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"long\",\"timeStyle\":\"short\"}},\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"darkModeSwitchLabel\":\"深色模式\",\"lightModeSwitchTitle\":\"切换到浅色模式\",\"darkModeSwitchTitle\":\"切换到深色模式\",\"sidebar\":{\"/AI/\":[{\"items\":[{\"text\":\"Transformer\",\"items\":[{\"text\":\"01-Transformer的由来\",\"link\":\"/AI/Transformer/01-Transformer的由来.html\"},{\"text\":\"02-Transformer架构解读\",\"link\":\"/AI/Transformer/02-Transformer架构解读.html\"},{\"text\":\"03-Transformer架构源码构建\",\"link\":\"/AI/Transformer/03-Transformer架构源码构建.html\"}],\"collapsed\":false},{\"text\":\"deep_learning_theory\",\"items\":[{\"text\":\"00-DL_Base_Notes\",\"link\":\"/AI/deep_learning_theory/00-DL_Base_Notes.html\"},{\"text\":\"01-feedforward_network\",\"link\":\"/AI/deep_learning_theory/01-feedforward_network.html\"},{\"text\":\"02-back_propagation\",\"link\":\"/AI/deep_learning_theory/02-back_propagation.html\"},{\"text\":\"03-bp_example_demo\",\"link\":\"/AI/deep_learning_theory/03-bp_example_demo.html\"},{\"text\":\"04-convolution_neural_network\",\"link\":\"/AI/deep_learning_theory/04-convolution_neural_network.html\"},{\"text\":\"05-deep_learning_model\",\"link\":\"/AI/deep_learning_theory/05-deep_learning_model.html\"},{\"text\":\"06-pytorch_install\",\"link\":\"/AI/deep_learning_theory/06-pytorch_install.html\"},{\"text\":\"07-operators\",\"link\":\"/AI/deep_learning_theory/07-operators.html\"},{\"text\":\"08-activation_functions\",\"link\":\"/AI/deep_learning_theory/08-activation_functions.html\"},{\"text\":\"09-recurrent_neural_network\",\"link\":\"/AI/deep_learning_theory/09-recurrent_neural_network.html\"},{\"text\":\"10-seq2seq\",\"link\":\"/AI/deep_learning_theory/10-seq2seq.html\"},{\"text\":\"11-1attentions\",\"link\":\"/AI/deep_learning_theory/11-1attentions.html\"},{\"text\":\"11-2attention-extension\",\"link\":\"/AI/deep_learning_theory/11-2attention-extension.html\"},{\"text\":\"12-weight-initialization\",\"link\":\"/AI/deep_learning_theory/12-weight-initialization.html\"},{\"text\":\"13-optimizers\",\"link\":\"/AI/deep_learning_theory/13-optimizers.html\"},{\"text\":\"14-regularization\",\"link\":\"/AI/deep_learning_theory/14-regularization.html\"},{\"text\":\"15-deep-learning-tuning-guide\",\"link\":\"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html\"},{\"text\":\"20-pytorch-tensor\",\"link\":\"/AI/deep_learning_theory/20-pytorch-tensor.html\"},{\"text\":\"21-pytorch-autograd\",\"link\":\"/AI/deep_learning_theory/21-pytorch-autograd.html\"},{\"text\":\"22-pytorch-module\",\"link\":\"/AI/deep_learning_theory/22-pytorch-module.html\"},{\"text\":\"23-1training-example-1\",\"link\":\"/AI/deep_learning_theory/23-1training-example-1.html\"},{\"text\":\"23-2decoder\",\"link\":\"/AI/deep_learning_theory/23-2decoder.html\"},{\"text\":\"23-3encoder\",\"link\":\"/AI/deep_learning_theory/23-3encoder.html\"},{\"text\":\"23-4transformer\",\"link\":\"/AI/deep_learning_theory/23-4transformer.html\"},{\"text\":\"24-pytorch-optimizer\",\"link\":\"/AI/deep_learning_theory/24-pytorch-optimizer.html\"},{\"text\":\"25-pytorch-lr-scheduler\",\"link\":\"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html\"},{\"text\":\"26-pytorch-dataloader\",\"link\":\"/AI/deep_learning_theory/26-pytorch-dataloader.html\"},{\"text\":\"27-pytorch-model-save\",\"link\":\"/AI/deep_learning_theory/27-pytorch-model-save.html\"},{\"text\":\"28-pytorch-tensorboard\",\"link\":\"/AI/deep_learning_theory/28-pytorch-tensorboard.html\"},{\"text\":\"29-pytorch-graph-mode\",\"link\":\"/AI/deep_learning_theory/29-pytorch-graph-mode.html\"},{\"text\":\"30-1training-example-cv\",\"link\":\"/AI/deep_learning_theory/30-1training-example-cv.html\"},{\"text\":\"30-3main\",\"link\":\"/AI/deep_learning_theory/30-3main.html\"},{\"text\":\"31-1stable-diffusion\",\"link\":\"/AI/deep_learning_theory/31-1stable-diffusion.html\"},{\"text\":\"31-2SDXL\",\"link\":\"/AI/deep_learning_theory/31-2SDXL.html\"},{\"text\":\"31-3VAE\",\"link\":\"/AI/deep_learning_theory/31-3VAE.html\"},{\"text\":\"40-nlp-bert_ner\",\"link\":\"/AI/deep_learning_theory/40-nlp-bert_ner.html\"},{\"text\":\"41-nlp-t5_question-answering\",\"link\":\"/AI/deep_learning_theory/41-nlp-t5_question-answering.html\"},{\"text\":\"42-nlp-gpt\",\"link\":\"/AI/deep_learning_theory/42-nlp-gpt.html\"},{\"text\":\"43-scaling-law\",\"link\":\"/AI/deep_learning_theory/43-scaling-law.html\"},{\"text\":\"44-distribute-training\",\"link\":\"/AI/deep_learning_theory/44-distribute-training.html\"},{\"text\":\"45-LLM-History\",\"link\":\"/AI/deep_learning_theory/45-LLM-History.html\"},{\"text\":\"46-LLM-GPT-Extension\",\"link\":\"/AI/deep_learning_theory/46-LLM-GPT-Extension.html\"},{\"text\":\"46-nlp-llama\",\"link\":\"/AI/deep_learning_theory/46-nlp-llama.html\"},{\"text\":\"47-LLM-DeepSeek-Structure\",\"link\":\"/AI/deep_learning_theory/47-LLM-DeepSeek-Structure.html\"},{\"text\":\"47-nlp-deepseek\",\"link\":\"/AI/deep_learning_theory/47-nlp-deepseek.html\"}],\"collapsed\":false},{\"text\":\"distribute_training\",\"items\":[{\"text\":\"00_large-scale-model-trainning\",\"link\":\"/AI/distribute_training/00_large-scale-model-trainning.html\"},{\"text\":\"01_coding\",\"link\":\"/AI/distribute_training/01_coding.html\"},{\"text\":\"01_offload-and-recompute\",\"link\":\"/AI/distribute_training/01_offload-and-recompute.html\"},{\"text\":\"02_amp\",\"link\":\"/AI/distribute_training/02_amp.html\"},{\"text\":\"03_coding\",\"link\":\"/AI/distribute_training/03_coding.html\"},{\"text\":\"03_pytorch-DP\",\"link\":\"/AI/distribute_training/03_pytorch-DP.html\"},{\"text\":\"04_pytorch-DDP\",\"link\":\"/AI/distribute_training/04_pytorch-DDP.html\"},{\"text\":\"05_pytorch-DDP-IMPL\",\"link\":\"/AI/distribute_training/05_pytorch-DDP-IMPL.html\"},{\"text\":\"05_pytorch-DDP-IMPL_DDP_ORIGIN\",\"link\":\"/AI/distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html\"},{\"text\":\"06_collective-comm\",\"link\":\"/AI/distribute_training/06_collective-comm.html\"},{\"text\":\"06_torchrun-process-group\",\"link\":\"/AI/distribute_training/06_torchrun-process-group.html\"},{\"text\":\"07_ZeRO-Optimizer\",\"link\":\"/AI/distribute_training/07_ZeRO-Optimizer.html\"},{\"text\":\"08_pytorch-ZeRO-1\",\"link\":\"/AI/distribute_training/08_pytorch-ZeRO-1.html\"},{\"text\":\"09_pytorch-FSDP-v1\",\"link\":\"/AI/distribute_training/09_pytorch-FSDP-v1.html\"},{\"text\":\"10_pytorch-FSDP-v2\",\"link\":\"/AI/distribute_training/10_pytorch-FSDP-v2.html\"},{\"text\":\"11_deepspeed-ZeRO-1-2-IMPL\",\"link\":\"/AI/distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html\"},{\"text\":\"12_deepspeed-ZeRO-3-IMPL\",\"link\":\"/AI/distribute_training/12_deepspeed-ZeRO-3-IMPL.html\"},{\"text\":\"13_megatron-ZeRO-1-IMPL\",\"link\":\"/AI/distribute_training/13_megatron-ZeRO-1-IMPL.html\"},{\"text\":\"14_TP-Theory\",\"link\":\"/AI/distribute_training/14_TP-Theory.html\"},{\"text\":\"15_megatron-TP-IMPL\",\"link\":\"/AI/distribute_training/15_megatron-TP-IMPL.html\"},{\"text\":\"16_pytorch-TP-IMPL\",\"link\":\"/AI/distribute_training/16_pytorch-TP-IMPL.html\"},{\"text\":\"17_PP-Theory\",\"link\":\"/AI/distribute_training/17_PP-Theory.html\"},{\"text\":\"18_pytorch-PP-IMPL\",\"link\":\"/AI/distribute_training/18_pytorch-PP-IMPL.html\"},{\"text\":\"19_deepspeed-PP-IMPL\",\"link\":\"/AI/distribute_training/19_deepspeed-PP-IMPL.html\"},{\"text\":\"20_megatron-PP-IMPL\",\"link\":\"/AI/distribute_training/20_megatron-PP-IMPL.html\"},{\"text\":\"21_SP-Theory\",\"link\":\"/AI/distribute_training/21_SP-Theory.html\"},{\"text\":\"22_megatron-SP-IMPL\",\"link\":\"/AI/distribute_training/22_megatron-SP-IMPL.html\"},{\"text\":\"23_3D-Parallel-Theory\",\"link\":\"/AI/distribute_training/23_3D-Parallel-Theory.html\"},{\"text\":\"24_megatron-3D-Parallel-IMPL\",\"link\":\"/AI/distribute_training/24_megatron-3D-Parallel-IMPL.html\"},{\"text\":\"25_pytorch-3D-Parallel-IMPL\",\"link\":\"/AI/distribute_training/25_pytorch-3D-Parallel-IMPL.html\"},{\"text\":\"26_CP-Theory\",\"link\":\"/AI/distribute_training/26_CP-Theory.html\"},{\"text\":\"27_megatron-CP-IMPL\",\"link\":\"/AI/distribute_training/27_megatron-CP-IMPL.html\"},{\"text\":\"28_MOE-Theory\",\"link\":\"/AI/distribute_training/28_MOE-Theory.html\"},{\"text\":\"28_MOE-Theory_DeepSeekMOE\",\"link\":\"/AI/distribute_training/28_MOE-Theory_DeepSeekMOE.html\"},{\"text\":\"29_megatron-MOE-IMPL\",\"link\":\"/AI/distribute_training/29_megatron-MOE-IMPL.html\"},{\"text\":\"30_deepspeed-MOE-IMPL\",\"link\":\"/AI/distribute_training/30_deepspeed-MOE-IMPL.html\"},{\"text\":\"31_deepspeed-code-IMPL\",\"link\":\"/AI/distribute_training/31_deepspeed-code-IMPL.html\"},{\"text\":\"32_collective-operations\",\"link\":\"/AI/distribute_training/32_collective-operations.html\"},{\"text\":\"33_pytorch_distribute\",\"link\":\"/AI/distribute_training/33_pytorch_distribute.html\"}],\"collapsed\":false}]}],\"/IT-learning/\":[{\"items\":[{\"text\":\"408\",\"items\":[{\"text\":\"OS-4.1 进程同步\",\"link\":\"/IT-learning/408/OS-4.1 进程同步.html\"},{\"text\":\"OS-4.4 信号量机制\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制.html\"},{\"text\":\"OS-4.4 信号量机制pv操作之“可见”\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制pv操作之“可见”.html\"}],\"collapsed\":false},{\"text\":\"Java\",\"items\":[{\"text\":\"01.java-se\",\"link\":\"/IT-learning/Java/01.java-se.html\"},{\"text\":\"02.sql\",\"link\":\"/IT-learning/Java/02.sql.html\"},{\"text\":\"03.java-web\",\"link\":\"/IT-learning/Java/03.java-web.html\"},{\"text\":\"05.MyBatis\",\"link\":\"/IT-learning/Java/05.MyBatis.html\"}],\"collapsed\":false},{\"text\":\"Linux\",\"items\":[{\"text\":\"01.Linux基础\",\"link\":\"/IT-learning/Linux/01.Linux基础.html\"},{\"text\":\"02.Shell\",\"link\":\"/IT-learning/Linux/02.Shell.html\"},{\"text\":\"03.MPI并行计算\",\"link\":\"/IT-learning/Linux/03.MPI并行计算.html\"},{\"text\":\"04.Docker\",\"link\":\"/IT-learning/Linux/04.Docker.html\"}],\"collapsed\":false},{\"text\":\"c++\",\"items\":[{\"text\":\"01_开发环境搭建与基础数据类型\",\"link\":\"/IT-learning/c++/01_开发环境搭建与基础数据类型.html\"},{\"text\":\"02_控制流语句与复合数据类型\",\"link\":\"/IT-learning/c++/02_控制流语句与复合数据类型.html\"},{\"text\":\"03_指针与引用\",\"link\":\"/IT-learning/c++/03_指针与引用.html\"},{\"text\":\"04_自定义数据类型与函数\",\"link\":\"/IT-learning/c++/04_自定义数据类型与函数.html\"},{\"text\":\"05_头文件与指针的算术运算\",\"link\":\"/IT-learning/c++/05_头文件与指针的算术运算.html\"},{\"text\":\"06_字符串、数组、指针与函数\",\"link\":\"/IT-learning/c++/06_字符串、数组、指针与函数.html\"},{\"text\":\"07_函数进阶与内存管理\",\"link\":\"/IT-learning/c++/07_函数进阶与内存管理.html\"},{\"text\":\"08_运算符优先级表\",\"link\":\"/IT-learning/c++/08_运算符优先级表.html\"},{\"text\":\"09_指针、内存管理和类的基础\",\"link\":\"/IT-learning/c++/09_指针、内存管理和类的基础.html\"},{\"text\":\"10_深入类和对象\",\"link\":\"/IT-learning/c++/10_深入类和对象.html\"},{\"text\":\"11_类的大小、继承与权限控制\",\"link\":\"/IT-learning/c++/11_类的大小、继承与权限控制.html\"},{\"text\":\"12_继承进阶\",\"link\":\"/IT-learning/c++/12_继承进阶.html\"},{\"text\":\"13_类型转换和多态与虚函数\",\"link\":\"/IT-learning/c++/13_类型转换和多态与虚函数.html\"},{\"text\":\"14_纯虚函数、抽象类、深浅拷贝及智能指针\",\"link\":\"/IT-learning/c++/14_纯虚函数、抽象类、深浅拷贝及智能指针.html\"},{\"text\":\"15_运算符重载与 String 类详解\",\"link\":\"/IT-learning/c++/15_运算符重载与 String 类详解.html\"},{\"text\":\"16_有序容器与无序容器\",\"link\":\"/IT-learning/c++/16_有序容器与无序容器.html\"},{\"text\":\"17_模板\",\"link\":\"/IT-learning/c++/17_模板.html\"},{\"text\":\"18_迭代器与其应用\",\"link\":\"/IT-learning/c++/18_迭代器与其应用.html\"},{\"text\":\"19_C++ 标准库常用算法\",\"link\":\"/IT-learning/c++/19_C++ 标准库常用算法.html\"},{\"text\":\"20_C++ 异常处理 - 第19次课\",\"link\":\"/IT-learning/c++/20_C++ 异常处理 - 第19次课.html\"},{\"text\":\"21_友元及友元相关内容\",\"link\":\"/IT-learning/c++/21_友元及友元相关内容.html\"},{\"text\":\"22_C++ IO 流详解-feadbc607d7f\",\"link\":\"/IT-learning/c++/22_C++ IO 流详解-feadbc607d7f.html\"},{\"text\":\"23_C++ IO 流详解\",\"link\":\"/IT-learning/c++/23_C++ IO 流详解.html\"},{\"text\":\"24_位运算符总结\",\"link\":\"/IT-learning/c++/24_位运算符总结.html\"},{\"text\":\"25_C++三种继承方式\",\"link\":\"/IT-learning/c++/25_C++三种继承方式.html\"},{\"text\":\"26_C++11 高级特性\",\"link\":\"/IT-learning/c++/26_C++11 高级特性.html\"},{\"text\":\"27_C++14 新特性\",\"link\":\"/IT-learning/c++/27_C++14 新特性.html\"},{\"text\":\"28_C++17 新特性\",\"link\":\"/IT-learning/c++/28_C++17 新特性.html\"},{\"text\":\"29_多文件和 Makefile工程管理\",\"link\":\"/IT-learning/c++/29_多文件和 Makefile工程管理.html\"},{\"text\":\"30_C++大型项目CMake工程管理\",\"link\":\"/IT-learning/c++/30_C++大型项目CMake工程管理.html\"},{\"text\":\"31_C++ 主要就业方向与技术能力分析报告\",\"link\":\"/IT-learning/c++/31_C++ 主要就业方向与技术能力分析报告.html\"},{\"text\":\"32_C++ 基础知识回顾\",\"link\":\"/IT-learning/c++/32_C++ 基础知识回顾.html\"}],\"collapsed\":false}]}],\"/my_think/\":[{\"items\":[{\"text\":\"2024\",\"items\":[{\"text\":\"不同商家的视野\",\"link\":\"/my_think/2024/不同商家的视野.html\"},{\"text\":\"学而篇\",\"link\":\"/my_think/2024/学而篇.html\"},{\"text\":\"重温士兵突击\",\"link\":\"/my_think/2024/重温士兵突击.html\"}],\"collapsed\":false}]}],\"/question_list/\":[{\"items\":[{\"text\":\"doccano账户管理\",\"link\":\"/question_list/doccano账户管理.html\"},{\"text\":\"专英翻转课堂—PyTorch\",\"link\":\"/question_list/专英翻转课堂—PyTorch.html\"},{\"text\":\"虚拟机网络问题\",\"link\":\"/question_list/虚拟机网络问题.html\"}]}],\"/update/\":[{\"items\":[{\"text\":\"update_log\",\"link\":\"/update/update_log.html\"}]}]}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>