import{_ as i,c as a,o as n,a2 as l}from"./chunks/framework.DA-Pb-tg.js";const E=JSON.parse('{"title":"1 Pytorch DDP 理论","description":"","frontmatter":{},"headers":[],"relativePath":"AI/02_distribute_training/05_pytorch-DDP-IMPL.md","filePath":"AI/02_distribute_training/05_pytorch-DDP-IMPL.md","lastUpdated":1743069065000}'),p={name:"AI/02_distribute_training/05_pytorch-DDP-IMPL.md"};function h(e,s,t,k,r,d){return n(),a("div",null,s[0]||(s[0]=[l(`<h1 id="_1-pytorch-ddp-理论" tabindex="-1">1 Pytorch DDP 理论 <a class="header-anchor" href="#_1-pytorch-ddp-理论" aria-label="Permalink to &quot;1 Pytorch DDP 理论&quot;">​</a></h1><ul><li><a href="https://arxiv.org/pdf/2006.15704" target="_blank" rel="noreferrer">论文链接</a></li></ul><h1 id="_2-pytorch-ddp-代码实现" tabindex="-1">2 pytorch DDP 代码实现 <a class="header-anchor" href="#_2-pytorch-ddp-代码实现" aria-label="Permalink to &quot;2 pytorch DDP 代码实现&quot;">​</a></h1><ul><li><a href="https://github.com/pytorch/examples/tree/main/distributed/ddp" target="_blank" rel="noreferrer">https://github.com/pytorch/examples/tree/main/distributed/ddp</a></li></ul><p>启动脚本</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># https://github.com/pytorch/examples/blob/main/distributed/ddp-tutorial-series/multigpu_torchrun.py</span></span>
<span class="line"><span></span></span>
<span class="line"><span>torchrun --standalone --nnodes=1 --nproc-per-node=2 multigpu_torchrun.py 4 1 --batch_size 4</span></span></code></pre></div><h1 id="_3-pytorch-ddp-代码解析" tabindex="-1">3 pytorch DDP 代码解析 <a class="header-anchor" href="#_3-pytorch-ddp-代码解析" aria-label="Permalink to &quot;3 pytorch DDP 代码解析&quot;">​</a></h1><ul><li><a href="https://github1s.com/pytorch/pytorch/blob/main/torch/nn/parallel/distributed.py#L326" target="_blank" rel="noreferrer">https://github.com/pytorch/pytorch/blob/main/torch/nn/parallel/distributed.py</a></li></ul><h2 id="_3-1-distributeddataparallel-属性和方法" tabindex="-1">3.1 DistributedDataParallel 属性和方法 <a class="header-anchor" href="#_3-1-distributeddataparallel-属性和方法" aria-label="Permalink to &quot;3.1 DistributedDataParallel 属性和方法&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> DistributedDataParallel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Joinable</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.logger</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.process_group</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device_mesh</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._delay_all_reduce_params</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.parameters_to_ignore</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._module_parameters</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.is_multi_device_module</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device_type</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device_ids</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.output_device</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.static_graph</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dim</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.module</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.broadcast_buffers</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.find_unused_parameters</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.require_backward_grad_sync</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.require_forward_grad_sync</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gradient_as_bucket_view</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.mixed_precision</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.broadcast_bucket_size</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.bucket_bytes_cap_default</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.bucket_bytes_cap</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.use_side_stream_for_tensor_copies</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._delay_grad_buffer</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._delay_grad_views</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._delay_all_reduce_all_params</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._comm_hooks</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._mp_stream</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._submodule_to_event</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._has_rebuilt_buckets</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._lazy_init_ran</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._accum_grad_hooks</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._use_python_reducer</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._force_to_disable_cpp_reducer</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._ddp_sink_clone</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_accum_grad_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _delayed_all_reduce_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_delay_all_reduce_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _setup_in_backward_optimizers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _fire_reducer_autograd_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _root_copy_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _module_wait_for_copy_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _log_and_throw</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _ddp_init_helper</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __getstate__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __setstate__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _build_params_for_reducer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _assign_modules_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _build_debug_param_to_name_mapping</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_parameters</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_default_group</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> no_sync</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_active_ddp_module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _inside_ddp_forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _run_ddp_forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _clear_grad_buffer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _lazy_init</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _should_disable_cpp_reducer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _pre_forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _post_forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> scatter</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to_kwargs</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> gather</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_global_requires_backward_grad_sync</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_and_sync_module_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _sync_final_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _match_all_reduce_for_bwd_pass</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _match_unused_params_allreduce</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> join</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> join_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> join_device</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> join_process_group</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_buffer_comm_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_comm_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_builtin_comm_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_fused_optim</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _distributed_broadcast_coalesced</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_sync_bufs_post_fwd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_sync_bufs_pre_fwd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> will_sync_module_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _find_common_rank</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _sync_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _sync_module_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _default_broadcast_coalesced</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _passing_sync_batchnorm_handle</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_comm_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _distributed_rank</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_data_parallel_params</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _set_params_and_buffers_to_ignore_for_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_ddp_logging_data</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _set_ddp_runtime_logging_sample_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _set_static_graph</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _remove_autograd_hooks</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _check_reducer_finalized</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _set_sparse_metadata</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _update_process_group</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _set_ddp_sink_clone</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span></code></pre></div><h2 id="_3-2-self-process-group-的初始化" tabindex="-1">3.2 self.process_group 的初始化 <a class="header-anchor" href="#_3-2-self-process-group-的初始化" aria-label="Permalink to &quot;3.2 self.process_group 的初始化&quot;">​</a></h2><ul><li>process_group is not None and device_mesh is not None : RuntimeError</li><li>process_group is None and device_mesh is None : self.process_group = _get_default_group()</li><li>process_group is not None and device_mesh is None : self.process_group = process_group</li><li>process_group is None and device_mesh is Not None : # 这里针对 DDP + TP(用到了DTensor) 的情况</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  #这个函数 _pre_dp_module_transform 的作用是在将一个已经应用了张量并行（Tensor Parallelism, TP）的模块包装到数据并行（Data Parallelism, DP）时，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 确保张量并行和数据并行之间的兼容性。具体来说，它处理分布式张量（DTensor）和本地张量之间的转换，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 以避免 DistributedDataParallel（DDP）对 DTensor 进行特殊处理，并确保梯度能够正确传播。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> device_mesh.ndim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">      raise</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> RuntimeError</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">          f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Only 1D device mesh is supported, but got </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">device_mesh</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      )</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device_mesh </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> device_mesh</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.process_group </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> device_mesh.get_group(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mesh_dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.distributed.device_mesh </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _mesh_resources</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  root_mesh </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _mesh_resources.get_root_mesh(device_mesh)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # if a root mesh is not the same as device_mesh,</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # meaning the device_mesh is sliced out from the root mesh.</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> root_mesh </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> device_mesh:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">      # </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">TODO</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">: This is a temporary work around to enable DDP + TP.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">      # We should do the logic in DDP so that the 2D implementation is</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">      # sound and the state_dict works out of the box.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">      # This has to be done before check UninitializedParameter.</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">      from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.distributed.tensor.parallel.ddp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          _pre_dp_module_transform,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      _pre_dp_module_transform(module)</span></span></code></pre></div><p><strong>_pre_dp_module_tranform 的实现</strong> <br></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 启用在使用 DDP 时 PyTorch 中张量并行（TP）和数据并行（DP）之间的组合性。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 我们需要在使用数据并行 API 包装模块之前，将 DTensor 类型的参数转换为本地张量。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 然后，我们注册两个钩子：一个用于在前向传播前将本地张量转换回 DTensor，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. 另一个用于在前向传播后将 DTensor 转换回本地张量。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如此，我们在前向传播时按照DTesor来计算，前向传播后转换为local tensor，反向传播再转为DTensor ？？？ 这里可能有点疑问.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过这种方式集成，我们可以避免 DDP 对 DTensor 参数进行任何特殊处理，并确保 DTensor 的梯度能够正确传播回 DP，例如 DDP 的梯度桶。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _pre_dp_module_transform</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module: nn.Module):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Enable the composability between Tensor Parallelism (TP) and Data</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Parallelism(DP) in PyTorch when using DDP. We need to convert Parameters which</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    are DTensors to local tensors before wrapping with data parallelism API.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    We then register two hooks, one for converting local tensors back to DTensor</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    preforward and one to convert DTensors back to tensors after Forward. By</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    integrating this way, we avoid any special handling of DTensor parameters by DDP</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    and get DTensor&#39;s gradients propagated back to DP, e.g. gradient buckets of DDP.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    For now, this API only works with \`\`DistributedDataParallel\`\`. It will later support</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    other DP methods such as FSDP.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Args:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        module (:class:\`nn.Module\`):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            Module which has been applied TP on.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Example::</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"># xdoctest: +SKIP(&quot;distributed&quot;)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">from torch.distributed.tensor.parallel import parallelize_module, PairwiseParallel</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">from torch.nn.parallel import DistributedDataParallel as DDP</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">from torch.distributed.tensor.parallel.ddp import pre_dp_module_transform</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &gt;&gt;&gt;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"># Define the module.</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">m = module(...)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">parallelize_module(m, PairwiseParallel())</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">m = pre_dp_module_transform(m)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        &gt;&gt;&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">m = DDP(m)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &gt;&gt;&gt;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    _localize_dtensor(module, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># DTensor --&gt; Local Tensor</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">TODO</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">: To add test cases and ensure that it works for nested modules</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    module.register_forward_pre_hook(_reconstruct_dtensor) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Local Tensor --&gt; DTensor</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    module.register_forward_hook(_localize_dtensor) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># DTensor --&gt; LocalTensor</span></span></code></pre></div><h2 id="_3-3-ddp-中的-reducer" tabindex="-1">3.3 DDP 中的 Reducer <a class="header-anchor" href="#_3-3-ddp-中的-reducer" aria-label="Permalink to &quot;3.3 DDP 中的 Reducer&quot;">​</a></h2><ul><li><a href="https://github1s.com/pytorch/pytorch/blob/main/torch/csrc/distributed/c10d/reducer.hpp#L44" target="_blank" rel="noreferrer">reducer.cpp</a></li></ul><p><strong>作用：</strong> <br></p><ul><li>将参数分桶以进行规约。</li><li>重置分桶状态(第二个step)。</li><li>注册梯度钩子。</li><li>记录构造时的 DDP 日志数据。</li><li>将 DDP 的句柄传递给 SyncBatchNorm 层。</li></ul><p>reducer 中允许自定义通信算子:</p><ul><li>外部通信函数时： register_comm_hook(distributed.py) --&gt; register_comm_hook(reducer.hpp)</li><li>使用pytorch自带通信函数，指定type就行：_register_builtin_comm_hook(distributed.py) --&gt; register_builtin_comm_hook(reducer.hpp)</li></ul><h2 id="_3-4-register-fused-optim" tabindex="-1">3.4 _register_fused_optim <a class="header-anchor" href="#_3-4-register-fused-optim" aria-label="Permalink to &quot;3.4 _register_fused_optim&quot;">​</a></h2><p>        在 DDP 中注册优化器以在参数的梯度规约完成后立即对其进行优化。<br></p><p>        将优化器注册到 DDP 中，使得某个参数的优化将<strong>在该参数的梯度规约完成后立即运行</strong>，而不是等待所有参数的梯度规约完成。这可以根据工作负载的不同带来训练速度的提升，因为优化器可以在其他参数的梯度规约仍在进行时就开始运行。此外，这种方法还有潜力减少训练过程中的峰值内存消耗，因为它只需要逐个加载单个参数的优化器状态，而不需要一次性加载所有参数的优化器状态。<br></p><p><strong>register_fused_optim : 将DDP 注册到optimizer中</strong></p><ul><li><a href="https://github1s.com/pytorch/pytorch/blob/main/torch/nn/parallel/distributed.py#L2049" target="_blank" rel="noreferrer">register_fused_optim</a></li></ul><p><strong>_setup_in_backward_optimizers进行backward 和 optimizer的overlap</strong> <br></p><ul><li><a href="https://github1s.com/pytorch/pytorch/blob/main/torch/nn/parallel/distributed.py#L1018" target="_blank" rel="noreferrer">register_fused_optim</a></li></ul>`,28)]))}const o=i(p,[["render",h]]);export{E as __pageData,o as default};
