import{_ as n,c as l,o as i,a2 as a,j as s,a as e}from"./chunks/framework.DA-Pb-tg.js";const y=JSON.parse('{"title":"回顾和复习整理DL","description":"","frontmatter":{},"headers":[],"relativePath":"AI/04_some_notes/05-Review_DL.md","filePath":"AI/04_some_notes/05-Review_DL.md","lastUpdated":1744215890000}'),r={name:"AI/04_some_notes/05-Review_DL.md"};function m(p,t,o,c,d,u){return i(),l("div",null,t[0]||(t[0]=[a('<h1 id="回顾和复习整理dl" tabindex="-1">回顾和复习整理DL <a class="header-anchor" href="#回顾和复习整理dl" aria-label="Permalink to &quot;回顾和复习整理DL&quot;">​</a></h1><h2 id="_00-python基础-未补" tabindex="-1">00. python基础（未补） <a class="header-anchor" href="#_00-python基础-未补" aria-label="Permalink to &quot;00. python基础（未补）&quot;">​</a></h2><blockquote><p>抽空补充</p></blockquote><ul><li>迭代器</li><li>装饰器</li><li>callable</li><li></li></ul><h2 id="_01-激活函数🌟🌟🌟" tabindex="-1">01. 激活函数🌟🌟🌟 <a class="header-anchor" href="#_01-激活函数🌟🌟🌟" aria-label="Permalink to &quot;01. 激活函数🌟🌟🌟&quot;">​</a></h2><h3 id="_1-我的记录" tabindex="-1">1. 我的记录： <a class="header-anchor" href="#_1-我的记录" aria-label="Permalink to &quot;1. 我的记录：&quot;">​</a></h3><ul><li><p>为啥需要Activation？（深度学习往往只说非线性Attention）</p><blockquote><p>都是Linear（或者Covn）的话网络还是线性的，多层和一层没啥太大区别。</p></blockquote></li><li><p>有哪些类型？（工程上主要类别）</p><blockquote><p>一种是point wise的操作（或者叫做element wise操作），也就是逐元素操作；另一种是具有相关性操作</p></blockquote><blockquote><blockquote><p>Note: 公式、图像、导数图像、优缺点……</p></blockquote><p>A类：数据间独立</p><ol><li><p>S型：</p><ul><li><p>sigmoid（0.5的二分类问题）</p></li><li><p>Tanh（NLP的递归系列常用）</p></li></ul></li><li><p>==ReLU==：AlexNet里面提出。</p><ul><li><p>ReLU</p></li><li><p>缓解激活值指数性增长=&gt;ReLU6</p></li><li><p>缓解神经元坏死现象=&gt;Leakey ReLU=&gt;PReLU/RReLU</p></li><li><p>x=0处平滑过渡=&gt;ELU/SELU</p></li><li><p>==GeLU==（工程上有点简化，现在大模型都会用他的变种）</p></li></ul></li><li><p>Swish：</p><ul><li>Switch（对sigmoid进行修改）</li><li>Hard Swish（对ReLU6做修改，计算更简单）。“凑图像”</li></ul></li><li><p>mish：平滑性更高（看一阶和二阶导图像）</p></li></ol><p>B类：数据间有相互作用</p><ol><li><p>==softmax==；想想sigmoid。这个是多分类，单调非负归一</p><p>类似操作还有矩阵乘法等</p></li></ol></blockquote> sigmoid = \\frac{1}{1 + e^{-x}} \\\\ \\frac{d(sigmoid)}{dx} = sigmoid(x) · (1 - sigmoid(x)) <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408113044493.png" alt="image-20250408113044493"></p> Tanh = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\\\ \\frac{dTanh}{dx} = 1 - Tanh^2 <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408114522622.png" alt="image-20250408114522622"></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408150852517.png" alt="image-20250408150852517"></p> ReLU = max(0, x)\\\\\\\\ \\frac{d(ReLU)}{dx} = \\left\\{\\begin{matrix} 1,\\ \\ x &gt; 0 \\\\ \\ \\ 0,\\ \\ x &lt;= 0 \\end{matrix}\\right. <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408115631449.png" alt="image-20250408115631449"></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mn>6</mn><mo>=</mo><mrow><mo fence="true">{</mo><mtable><mtr><mtd><mrow><mi>x</mi><mo separator="true">,</mo><mtext> </mtext><mtext> </mtext><mn>0</mn><mo>&lt;</mo><mo>=</mo><mi>x</mi><mo>&lt;</mo><mo>=</mo><mn>6</mn></mrow></mtd></mtr><mtr><mtd><mrow><mtext> </mtext><mtext> </mtext><mn>6</mn><mo separator="true">,</mo><mtext> </mtext><mtext> </mtext><mi>x</mi><mo>&lt;</mo><mn>0</mn><mtext> </mtext><mi>o</mi><mi>r</mi><mtext> </mtext><mi>x</mi><mo>&gt;</mo><mn>6</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">ReLU6 = \\left\\{\\begin{matrix} x,\\ \\ 0 &lt;= x &lt;= 6 \\\\ \\ \\ 6,\\ \\ x &lt; 0 \\ or \\ x &gt;6 \\end{matrix}\\right. </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.45em;"></span><span class="strut bottom" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit">e</span><span class="mord mathit">L</span><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mord mathrm">6</span><span class="mrel">=</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist"><span style="top:-0.6099999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mspace"> </span><span class="mord mspace"> </span><span class="mord mathrm">0</span><span class="mrel">&lt;</span><span class="mrel">=</span><span class="mord mathit">x</span><span class="mrel">&lt;</span><span class="mrel">=</span><span class="mord mathrm">6</span></span></span><span style="top:0.5900000000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mspace"> </span><span class="mord mspace"> </span><span class="mord mathrm">6</span><span class="mpunct">,</span><span class="mord mspace"> </span><span class="mord mspace"> </span><span class="mord mathit">x</span><span class="mrel">&lt;</span><span class="mord mathrm">0</span><span class="mord mspace"> </span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mspace"> </span><span class="mord mathit">x</span><span class="mrel">&gt;</span><span class="mord mathrm">6</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></span></p></li></ul> Leakey \\ ReLU = \\left\\{\\begin{matrix} x,\\ \\ x &gt;= 0 \\\\ ax,\\ \\ x &lt; 0 \\end{matrix}\\right. \\ a为常数 \\\\ PReLU = \\left\\{\\begin{matrix} x,\\ \\ x &gt;= 0 \\\\ ax,\\ \\ x &lt; 0 \\end{matrix}\\right. \\ a为训练参数 \\\\ RReLU =\\left\\{\\begin{matrix} x,\\ \\ x &gt;= 0 \\\\ ax,\\ \\ x &lt; 0 \\end{matrix}\\right. \\ a为随机数 ELU = \\left\\{\\begin{matrix} &amp;x,&amp;x &gt;= 0 \\\\ &amp;a(e^x-1),&amp;x &lt; 0 \\end{matrix}\\right. \\ a为超参数 \\\\\\\\ SELU =\\lambda ·\\left\\{\\begin{matrix} &amp;x,&amp;x &gt;= 0 \\\\ &amp;a(e^x-1),&amp;x &lt; 0 \\end{matrix}\\right. \\ \\lambda和a为超参数 <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408152548266.png" alt="image-20250408152548266"></p><blockquote><p>超参数a=1时</p></blockquote> GELU(x)=xP(X≤x)\\\\ \\ \\ \\ \\ \\ \\ \\ \\ =xΦ(x) xΦ(x)≈xσ(1.702x) \\\\ xΦ(x)≈\\frac{1}{2} ×[1+tanh(\\sqrt{\\frac{π}{2}}(x+0.044715x^3))] <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408175314814.png" alt="image-20250408175314814"><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250408175719134.png" alt="image-20250408175719134"></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/op-activation-figure9.jpg" alt=""></p> Swish = x·Sigmoid(\\beta x) Hard\\ Swish = x·\\frac{ReLU6(x + 3)}{6} <p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/op-activation-figure13.jpg" alt=""></p> \\text{Softmax}(x_{i}) = \\frac{e^{x_i}}{\\sum_je^{x_j}} \\\\ \\frac{\\partial y_i}{\\partial x_j} = \\begin{cases} y_i (1 - y_i), &amp; \\text{if } i = j \\\\ - y_i y_j, &amp; \\text{if } i \\ne j \\end{cases} \\\\ \\\\ J = \\begin{bmatrix} y_1(1 - y_1) &amp; -y_1 y_2 &amp; \\cdots &amp; -y_1 y_n \\\\ -y_2 y_1 &amp; y_2(1 - y_2) &amp; \\cdots &amp; -y_2 y_n \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ -y_n y_1 &amp; -y_n y_2 &amp; \\cdots &amp; y_n(1 - y_n) \\end{bmatrix} <p>源码里面有所优化：</p>',17),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"S"),s("mi",{mathvariant:"normal"},"o"),s("mi",{mathvariant:"normal"},"f"),s("mi",{mathvariant:"normal"},"t"),s("mi",{mathvariant:"normal"},"m"),s("mi",{mathvariant:"normal"},"a"),s("mi",{mathvariant:"normal"},"x")]),s("mo",null,"("),s("msub",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"i")])]),s("mo",null,")"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",null,"−"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")")])])]),s("mrow",null,[s("msub",null,[s("mo",null,"∑"),s("mi",null,"j")]),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"j")]),s("mo",null,"−"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")")])])])])]),s("annotation",{encoding:"application/x-tex"},"\\text{Softmax}(x_{i}) = \\frac{e^{x_i - max(x)}}{\\sum_je^{x_j - max(x)}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.565em"}}),s("span",{class:"strut bottom",style:{height:"2.726088em","vertical-align":"-1.161088em"}}),s("span",{class:"base displaystyle textstyle uncramped"},[s("span",{class:"text mord displaystyle textstyle uncramped"},[s("span",{class:"mord mathrm"},"S"),s("span",{class:"mord mathrm"},"o"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mathrm"},"t"),s("span",{class:"mord mathrm"},"m"),s("span",{class:"mord mathrm"},"a"),s("span",{class:"mord mathrm"},"x")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mclose"},")"),s("span",{class:"mrel"},"="),s("span",{class:"mord reset-textstyle displaystyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.7249699999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle cramped"},[s("span",{class:"mord textstyle cramped"},[s("span",{class:"mop"},[s("span",{class:"op-symbol small-op mop",style:{top:"-0.0000050000000000050004em"}},"∑"),s("span",{class:"vlist"},[s("span",{style:{top:"0.30001em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.30997em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15000000000000002em","margin-right":"0.07142857142857144em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"−"),s("span",{class:"mord mathit"},"m"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.677em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped"},[s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.07142857142857144em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"−"),s("span",{class:"mord mathit"},"m"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])])],-1),s("p",null,"💡 实际意义：",-1),s("ul",null,[s("li",null,"Softmax 的导数不是独立的，每个输出值的梯度都跟其它的有关。")],-1),s("h3",{id:"_2-简单总结-未优化",tabindex:"-1"},[e("2. 简单总结（未优化）： "),s("a",{class:"header-anchor",href:"#_2-简单总结-未优化","aria-label":'Permalink to "2. 简单总结（未优化）："'},"​")],-1),s("table",{tabindex:"0"},[s("thead",null,[s("tr",null,[s("th",{style:{"text-align":"center"}},"激活函数"),s("th",{style:{"text-align":"center"}},"数学表达式"),s("th",{style:{"text-align":"center"}},"优点"),s("th",{style:{"text-align":"center"}},"缺点"),s("th",{style:{"text-align":"center"}},"适用场景")])]),s("tbody",null,[s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Sigmoid")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mn",null,"1")]),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])]),s("annotation",{encoding:"application/x-tex"},"\\frac{1}{1 + e^{-x}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.845108em"}}),s("span",{class:"strut bottom",style:{height:"1.2484389999999999em","vertical-align":"-0.403331em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.345em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathrm"},"1"),s("span",{class:"mbin"},"+"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.289em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord scriptscriptstyle cramped"},[s("span",{class:"mord"},"−"),s("span",{class:"mord mathit"},"x")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.394em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"输出在 (0,1)，适合概率输出"),s("td",{style:{"text-align":"center"}},"梯度消失、非零均值、计算较慢"),s("td",{style:{"text-align":"center"}},"二分类输出层")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Softmax")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])])])]),s("mrow",null,[s("msub",null,[s("mo",null,"∑"),s("mi",null,"j")]),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"j")])])])])])]),s("annotation",{encoding:"application/x-tex"},"\\frac{e^{x_i}}{\\sum_j e^{x_j}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.86338em"}}),s("span",{class:"strut bottom",style:{height:"1.525892em","vertical-align":"-0.662512em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.355285em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mop"},[s("span",{class:"op-symbol small-op mop",style:{top:"0.074995em"}},"∑"),s("span",{class:"vlist"},[s("span",{style:{top:"0.30001em","margin-right":"0.07142857142857144em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.47143571428571435em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord scriptscriptstyle cramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.31472000000000006em","margin-right":"0.1em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptscriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.394em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle uncramped"},[s("span",{class:"mord scriptscriptstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.31472em","margin-right":"0.1em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptscriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"多分类概率分布，输出总和为 1"),s("td",{style:{"text-align":"center"}},"对极端值敏感，计算成本高"),s("td",{style:{"text-align":"center"}},"多分类输出层")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Tanh")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"−"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])]),s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])]),s("annotation",{encoding:"application/x-tex"},"\\frac{e^x - e^{-x}}{e^x + e^{-x}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.939765em"}}),s("span",{class:"strut bottom",style:{height:"1.343096em","vertical-align":"-0.403331em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.345em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.289em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"+"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.289em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord scriptscriptstyle cramped"},[s("span",{class:"mord"},"−"),s("span",{class:"mord mathit"},"x")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.394em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle uncramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"−"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.07142857142857144em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle uncramped"},[s("span",{class:"mord scriptscriptstyle uncramped"},[s("span",{class:"mord"},"−"),s("span",{class:"mord mathit"},"x")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"输出在 (-1,1)，零均值"),s("td",{style:{"text-align":"center"}},"梯度消失问题"),s("td",{style:{"text-align":"center"}},"RNN、数据对称场景")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"ReLU")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"max"),s("mo",null,"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mi",null,"x"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"\\max(0, x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])])]),s("td",{style:{"text-align":"center"}},"计算高效，缓解梯度消失"),s("td",{style:{"text-align":"center"}},"神经元死亡（负值输出为 0）"),s("td",{style:{"text-align":"center"}},"CNN、默认隐藏层激活")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Leaky ReLU")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",null,[s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mi",null,"x")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"≥"),s("mn",null,"0")])])]),s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mi",null,"α"),s("mi",null,"x")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"<"),s("mn",null,"0")])])])])])]),s("annotation",{encoding:"application/x-tex"},"\\begin{cases} x & \\text{if } x \\geq 0 \\\\ \\alpha x & \\text{if } x < 0 \\end{cases}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.75em"}}),s("span",{class:"strut bottom",style:{height:"3.0000299999999998em","vertical-align":"-1.25003em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"minner textstyle uncramped"},[s("span",{class:"style-wrap reset-textstyle textstyle uncramped",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mord mathit"},"x")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"arraycolsep",style:{width:"1em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"≥"),s("span",{class:"mord mathrm"},"0")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"<"),s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"缓解神经元死亡问题"),s("td",{style:{"text-align":"center"}},"需手动调参（如 α=0.01）"),s("td",{style:{"text-align":"center"}},"深层网络替代 ReLU")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"PReLU")]),s("td",{style:{"text-align":"center"}},"Leaky ReLU，但α可学习"),s("td",{style:{"text-align":"center"}},"自适应斜率，更灵活"),s("td",{style:{"text-align":"center"}},"增加参数量"),s("td",{style:{"text-align":"center"}},"复杂任务、深层网络")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"ELU")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",null,[s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mi",null,"x")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"≥"),s("mn",null,"0")])])]),s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mi",null,"α"),s("mo",null,"("),s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"−"),s("mn",null,"1"),s("mo",null,")")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"<"),s("mn",null,"0")])])])])])]),s("annotation",{encoding:"application/x-tex"},"\\begin{cases} x & \\text{if } x \\geq 0 \\\\ \\alpha(e^x - 1) & \\text{if } x < 0 \\end{cases}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.75em"}}),s("span",{class:"strut bottom",style:{height:"3.0000299999999998em","vertical-align":"-1.25003em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"minner textstyle uncramped"},[s("span",{class:"style-wrap reset-textstyle textstyle uncramped",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"−"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},")")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"arraycolsep",style:{width:"1em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"≥"),s("span",{class:"mord mathrm"},"0")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"<"),s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"平滑负值，缓解梯度消失"),s("td",{style:{"text-align":"center"}},"计算复杂（含指数运算）"),s("td",{style:{"text-align":"center"}},"需要处理负值的场景")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"GELU")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"⋅"),s("mi",{mathvariant:"normal"},"Φ"),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x \\cdot \\Phi(x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"mbin"},"⋅"),s("span",{class:"mord mathrm"},"Φ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),e(" Φ 为标准正态 CDF")]),s("td",{style:{"text-align":"center"}},"平滑柔和，适合深度网络"),s("td",{style:{"text-align":"center"}},"计算复杂"),s("td",{style:{"text-align":"center"}},"Transformer、BERT 等模型")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Swish")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"⋅"),s("mi",null,"σ"),s("mo",null,"("),s("mi",null,"β"),s("mi",null,"x"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x \\cdot \\sigma(\\beta x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"mbin"},"⋅"),s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit",style:{"margin-right":"0.05278em"}},"β"),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),e("（β可调）")]),s("td",{style:{"text-align":"center"}},"非单调，实验性能优于 ReLU"),s("td",{style:{"text-align":"center"}},"计算较复杂"),s("td",{style:{"text-align":"center"}},"EfficientNet 等先进网络")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Mish")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"⋅"),s("mi",null,"tanh"),s("mo",null,"("),s("mi",null,"ln"),s("mo",null,"("),s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,")"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x \\cdot \\tanh(\\ln(1 + e^x))")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"mbin"},"⋅"),s("span",{class:"mop"},"tanh"),s("span",{class:"mopen"},"("),s("span",{class:"mop"},"ln"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mbin"},"+"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathit"},"x")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},")")])])])]),s("td",{style:{"text-align":"center"}},"平滑、无上界，缓解梯度消失"),s("td",{style:{"text-align":"center"}},"计算成本高"),s("td",{style:{"text-align":"center"}},"计算机视觉任务")]),s("tr",null,[s("td",{style:{"text-align":"center"}},[s("strong",null,"Step")]),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",null,[s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mn",null,"1")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"≥"),s("mn",null,"0")])])]),s("mtr",null,[s("mtd",null,[s("mrow",null,[s("mn",null,"0")])]),s("mtd",null,[s("mrow",null,[s("mtext",null,[s("mi",{mathvariant:"normal"},"i"),s("mi",{mathvariant:"normal"},"f"),s("mtext",null," ")]),s("mi",null,"x"),s("mo",null,"<"),s("mn",null,"0")])])])])])]),s("annotation",{encoding:"application/x-tex"},"\\begin{cases} 1 & \\text{if } x \\geq 0 \\\\ 0 & \\text{if } x < 0 \\end{cases}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.75em"}}),s("span",{class:"strut bottom",style:{height:"3.0000299999999998em","vertical-align":"-1.25003em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"minner textstyle uncramped"},[s("span",{class:"style-wrap reset-textstyle textstyle uncramped",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"1")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"arraycolsep",style:{width:"1em"}}),s("span",{class:"col-align-l"},[s("span",{class:"vlist"},[s("span",{style:{top:"-0.6819999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"≥"),s("span",{class:"mord mathrm"},"0")])]),s("span",{style:{top:"0.7579999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"mord textstyle uncramped"},[s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"i"),s("span",{class:"mord mathrm",style:{"margin-right":"0.07778em"}},"f"),s("span",{class:"mord mspace"}," ")]),s("span",{class:"mord mathit"},"x"),s("span",{class:"mrel"},"<"),s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])]),s("td",{style:{"text-align":"center"}},"二元输出"),s("td",{style:{"text-align":"center"}},"不可微，无法用于梯度下降"),s("td",{style:{"text-align":"center"}},"早期感知机（现已少用）")])])],-1),a('<h3 id="_3-我的思考" tabindex="-1">3. 我的思考： <a class="header-anchor" href="#_3-我的思考" aria-label="Permalink to &quot;3. 我的思考：&quot;">​</a></h3><ul><li>对于类似softmax这种同一条数据的分母相同的，每次是否需要重新计算分母？（底层是否会做cache？）</li><li>PyTorch源码里面的<code>Softmax</code>激活提及了<code>NLLLoss</code>，这是什么？与交叉熵又是什么关系？</li><li>softmax的导数推导。</li><li>softmax输入的shape和梯度的shape不一样大吗？参数更新的时候又是怎样子的？</li></ul><hr><h2 id="_02-常用torch算子" tabindex="-1">02. 常用Torch算子 <a class="header-anchor" href="#_02-常用torch算子" aria-label="Permalink to &quot;02. 常用Torch算子&quot;">​</a></h2><p>torch.nn</p><ul><li><a href="https://pytorch.org/docs/stable/nn.html#containers" target="_blank" rel="noreferrer">Containers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#convolution-layers" target="_blank" rel="noreferrer">Convolution Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#pooling-layers" target="_blank" rel="noreferrer">Pooling layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#padding-layers" target="_blank" rel="noreferrer">Padding Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity" target="_blank" rel="noreferrer">Non-linear Activations (weighted sum, nonlinearity)</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-other" target="_blank" rel="noreferrer">Non-linear Activations (other)</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#normalization-layers" target="_blank" rel="noreferrer">Normalization Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers" target="_blank" rel="noreferrer">Recurrent Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#transformer-layers" target="_blank" rel="noreferrer">Transformer Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#linear-layers" target="_blank" rel="noreferrer">Linear Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#dropout-layers" target="_blank" rel="noreferrer">Dropout Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#sparse-layers" target="_blank" rel="noreferrer">Sparse Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#distance-functions" target="_blank" rel="noreferrer">Distance Functions</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noreferrer">Loss Functions</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#vision-layers" target="_blank" rel="noreferrer">Vision Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#shuffle-layers" target="_blank" rel="noreferrer">Shuffle Layers</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#module-torch.nn.parallel" target="_blank" rel="noreferrer">DataParallel Layers (multi-GPU, distributed)</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#module-torch.nn.utils" target="_blank" rel="noreferrer">Utilities</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#quantized-functions" target="_blank" rel="noreferrer">Quantized Functions</a></li><li><a href="https://pytorch.org/docs/stable/nn.html#lazy-modules-initialization" target="_blank" rel="noreferrer">Lazy Modules Initialization</a><ul><li><a href="https://pytorch.org/docs/stable/nn.html#aliases" target="_blank" rel="noreferrer">Aliases</a></li></ul></li></ul><h3 id="_1-convolution-未补" tabindex="-1">1. Convolution（未补） <a class="header-anchor" href="#_1-convolution-未补" aria-label="Permalink to &quot;1. Convolution（未补）&quot;">​</a></h3><h3 id="_2-线性变换层" tabindex="-1">2. 线性变换层 <a class="header-anchor" href="#_2-线性变换层" aria-label="Permalink to &quot;2. 线性变换层&quot;">​</a></h3><ul><li><p>Linear/Gemm</p><blockquote><p>Note: Linear的weight是转置存放的</p></blockquote></li><li><p>Matmul</p><blockquote><p>type与Linear的不同</p><p>要满足广播机制</p></blockquote></li></ul><h3 id="_3-normlization-🌟🌟🌟🌟" tabindex="-1">3. Normlization（🌟🌟🌟🌟） <a class="header-anchor" href="#_3-normlization-🌟🌟🌟🌟" aria-label="Permalink to &quot;3. Normlization（🌟🌟🌟🌟）&quot;">​</a></h3><ul><li>类型Batch Norm，Layer Norm，Instance Norm，Group Norm，RMS Norm </li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/op-figure4.jpg" alt="figure4"></p><ul><li><p>公式</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mrow><mi mathvariant="normal">E</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo></mrow><mrow><msqrt><mrow><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow></mfrac><mo>∗</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.427em;"></span><span class="strut bottom" style="height:2.55701em;vertical-align:-1.13001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.825005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.04500500000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm" style="margin-right:0.01389em;">V</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span><span class="mbin">+</span><span class="mord mathit">ϵ</span></span></span><span style="top:-0.855005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathit">x</span><span class="mbin">−</span><span class="mord textstyle uncramped"><span class="mord mathrm">E</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p></li><li><p>功能</p><blockquote><ul><li><p>去量纲，把数据调整到更强烈的数据分布</p></li><li><p>减少梯度消失和梯度爆炸</p></li><li><p>主要是有一个计算期望和方差的过程</p></li><li><p>做Norm的粒度不同，应用场景不同</p></li><li><p>其他资料：<a href="https://blog.csdn.net/LoseInVain/article/details/86476010" target="_blank" rel="noreferrer">Batch Norm的技术博客</a></p></li></ul></blockquote></li><li><p>特征和不同</p><blockquote><ul><li>粒度不同（维度不同），对应应用领域不同</li></ul><p><strong>Batch Norm是逐channel（每个batch的同一个channel）进行标准化</strong>，也就是垮batch的。图片恰好需要这种方式。</p><p>LN是逐batch进行标准化的。NLP中往往是一个一个的seq进行训练的，而且长度不同，更适合这种。<strong>这让我想起了Attention的soft max操作是对一个行向量进行归一化的</strong></p><p>LayerNorm有助于稳定训练过程并提高收敛性。它的工作原理是对输入的各个特征进行归一化，确保激活的均值和方差一致。**普遍认为这种归一化有助于缓解与内部协变量偏移相关的问题，使模型能够更有效地学习并降低对初始权重的敏感性。**从架构图上看，LayerNorm在每个Transformer 块中应用两次，一次在自注意力机制之后，一次在FFN层之后，但是在实际工作中不一定如此。</p><p>文本长度不确定，而在LN层可以。</p><p>应用场景确定LN</p></blockquote></li><li><p>BN期望和方差计算策略</p><blockquote><p><code>采用移动指数平均</code>，会有历史信息在，有点类似RNN了</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>n</mi></msub><mo>=</mo><mi>α</mi><mi>E</mi><mo>+</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo>)</mo><msub><mi>E</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">E_n = \\alpha E + (1- \\alpha)E_{n-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mbin">+</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">n</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></p><p>Var 同理</p></blockquote></li><li><p>在训练和推理时有何不同？</p><blockquote><p>pytorch的模型有两种模式，在module模块里面有个<code>training</code>属性，也有对应的API，里面明确指出了这个</p><p>在BatchNorm采用训练时计算的结果（E和Var），应用到测试或者推理的时候</p><p>在Dropout后续会说，训练会drop掉，但推理不会，会改成（1-rate）</p></blockquote><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, mode: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;Set the module in training mode.</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    This has any effect only on certain modules. See documentations of</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    particular modules for details of their behaviors in training/evaluation</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    etc.</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Args:</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        mode (bool): whether to set training mode (``True``) or evaluation</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                     mode (``False``). Default: ``True``.</span></span></code></pre></div></li><li><p><strong>RMS Norm</strong>(大模型使用)🌟🌟🌟</p><blockquote><p>来源于LN，简化了LN</p><p>减均值相当于平移，这里直接去掉平移，只保留缩放</p><p>把乘法直接放进来了，</p></blockquote></li></ul><p>对LN做简化，对于NLP，对缩放敏感，对平移不敏感，所以分子不减<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">E_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，减少了很大计算量</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250326224954810.png" alt="image-20250326224954810"></p><p><strong>补充部分：</strong></p><ul><li><p><strong>DyT</strong>(Transformers without normlization)</p><p><a href="https://yiyibooks.cn/arxiv/2503.10622v1/index.html" target="_blank" rel="noreferrer">Transformers without normlization</a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo>:</mo><mtext> </mtext><mi>γ</mi><mo>∗</mo><mfrac><mrow><msub><mo>(</mo><mi>x</mi></msub><mo>−</mo><msub><mi>E</mi><mrow><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mo>)</mo></mrow><mrow><msqrt><mo>(</mo></msqrt><mi>V</mi><mi>a</mi><msub><mi>r</mi><mrow><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mo>)</mo></mrow></mfrac><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">Norm:\\ \\gamma * \\frac{(_x - E_{_x})}{\\sqrt (Var_{_x})} + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.427em;"></span><span class="strut bottom" style="height:2.55701em;vertical-align:-1.13001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">m</span><span class="mrel">:</span><span class="mord mspace"> </span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">∗</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.825005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.04500500000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mopen">(</span></span><span style="top:-0.855005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mord mathit">a</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="vlist"><span style="top:0.15000000000000002em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord"><span></span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mopen"><span class="mopen">(</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15000000000000002em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord"><span></span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>y</mi><mi>T</mi><mo>:</mo><mtext> </mtext><mi>γ</mi><mo>∗</mo><mi>T</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo>(</mo><mi>α</mi><mo>∗</mo><mi>x</mi><mo>)</mo><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">DyT:\\ \\gamma * Tanh(\\alpha * x) + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mrel">:</span><span class="mord mspace"> </span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">h</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mbin">∗</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250410151122973.png" alt="image-20250410151122973"></p></li><li><p><strong>Pre-Norm（大模型使用）和Post-Norm</strong></p><blockquote><p>结合Transformer那块知识，一个是在残差前，一个在残差后</p></blockquote> Output_{post}=LayerNorm(x+SubLayer(x)) \\\\ Output_{pre}=x+SubLayer(LayerNorm(x)) </li></ul> 公式1:PostNorm(x)=x+LayerNorm(FeedForward(x+LayerNorm(Attention(x)))) \\\\\\\\ 公式2:PreNorm(x)=x+FeedForward(LayerNorm(x))+Attention(LayerNorm(x)) <table tabindex="0"><thead><tr><th>特性</th><th style="text-align:center;">Post-Norm</th><th style="text-align:center;">Pre-Norm</th></tr></thead><tbody><tr><td>公式</td><td style="text-align:center;">公式1</td><td style="text-align:center;">公式2</td></tr><tr><td>位置</td><td style="text-align:center;">残差后</td><td style="text-align:center;">残差前</td></tr><tr><td>出现时间</td><td style="text-align:center;">原始 Transformer（Vaswani et al., 2017）</td><td style="text-align:center;">之后发展（如 GPT-2 等）</td></tr><tr><td>优点</td><td style="text-align:center;">收敛后表现略好（某些任务）</td><td style="text-align:center;">更稳定，训练深层模型不易梯度消失</td></tr><tr><td>缺点</td><td style="text-align:center;">深层模型中容易梯度消失/爆炸</td><td style="text-align:center;">可能最终性能略低，但更容易训练</td></tr><tr><td>应用情况</td><td style="text-align:center;">BERT、初版Transformer</td><td style="text-align:center;">GPT系列、T5、LLama等大模型</td></tr></tbody></table><table tabindex="0"><thead><tr><th style="text-align:center;">模型</th><th style="text-align:center;">归一化类型</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>DeepSeek</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>GPT-2/3/4</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>BERT</strong></td><td style="text-align:center;">Post-Norm</td></tr><tr><td style="text-align:center;"><strong>T5</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>LLaMA</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>Transformer XL</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>原始 Transformer</strong></td><td style="text-align:center;">Post-Norm</td></tr></tbody></table>',20),s("ul",null,[s("li",null,[s("p",null,"DeepNorm"),s("p",null,[e("DeepNorm 是微软在 2022 年提出的改进方法（论文 "),s("em",null,[e('"'),s("a",{href:"https://arxiv.org/abs/2203.00555",target:"_blank",rel:"noreferrer"},"DeepNet: Scaling Transformers to 1,000 Layers"),e('"')]),e("），"),s("strong",null,"基于 Post-Norm 但大幅提升了深层训练的稳定性"),e("，可支持超深层（如 1000 层）Transformer 的训练。")]),s("p",null,[s("img",{src:"https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164334392.png",alt:"image-20250409164334392"})]),s("p",null,[s("img",{src:"https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409162034019.png",alt:"image-20250409162034019"})]),s("p",null,"原始残差结构:"),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"l"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"a"),s("mi",null,"y"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"N"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",null,"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",null,"+"),s("mi",null,"F"),s("mo",null,"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",null,")"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x_{l+1} = LayerNorm(x_l + F(x_l)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base displaystyle textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mrel"},"="),s("span",{class:"mord mathit"},"L"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mord mathit"},"e"),s("span",{class:"mord mathit",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathit",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathit"},"o"),s("span",{class:"mord mathit",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathit"},"m"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit",style:{"margin-right":"0.13889em"}},"F"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},")")])])])])]),s("p",null,"DeepNorm:"),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"l"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("mtext",null,[s("mi",{mathvariant:"normal"},"L"),s("mi",{mathvariant:"normal"},"N")]),s("mo",null,"("),s("mi",null,"α"),s("mo",null,"⋅"),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",null,"+"),s("msub",null,[s("mi",null,"G"),s("mi",null,"l")]),s("mo",null,"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"θ"),s("mi",null,"l")]),s("mo",null,")"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x_{l+1} = \\text{LN}(\\alpha \\cdot x_l + G_l(x_l, \\theta_l)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base displaystyle textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mrel"},"="),s("span",{class:"text mord displaystyle textstyle uncramped"},[s("span",{class:"mord mathrm"},"L"),s("span",{class:"mord mathrm"},"N")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mbin"},"⋅"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mbin"},"+"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"G"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mpunct"},","),s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.02778em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},")")])])])])]),s("p",null,[s("img",{src:"https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164837814.png",alt:"image-20250409164837814"})])])],-1),a('<p>**思考：**DeepNorm中的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span>是哪里的参数？</p><blockquote><p>Note：整体回顾一下算子部分，引入后面的算子，不然大脑还停留在norm部分</p></blockquote><h3 id="_4-polling-cv" tabindex="-1">4. Polling(CV) <a class="header-anchor" href="#_4-polling-cv" aria-label="Permalink to &quot;4. Polling(CV)&quot;">​</a></h3><ul><li>作用</li></ul><blockquote><p>增大感受野</p><p>减少特征图尺寸，保留重要信息，降低计算量</p><p>降采样，减少噪音</p><p>位置变化鲁棒性增强</p></blockquote><ul><li>其他</li></ul><blockquote><p>对应有个out position矩阵</p></blockquote><ul><li>类型</li></ul><blockquote><p>Max、Avg等</p></blockquote><h3 id="_5-activations-看01部分" tabindex="-1">5. activations（看01部分） <a class="header-anchor" href="#_5-activations-看01部分" aria-label="Permalink to &quot;5. activations（看01部分）&quot;">​</a></h3><blockquote><p>这里面内容较多，直接看01章节</p></blockquote><p>[01. 激活函数🌟🌟🌟](#01. 激活函数🌟🌟🌟)</p><h3 id="_6-其他" tabindex="-1">6. 其他 <a class="header-anchor" href="#_6-其他" aria-label="Permalink to &quot;6. 其他&quot;">​</a></h3><h3 id="_7-特别的一些operator" tabindex="-1">7. 特别的一些Operator <a class="header-anchor" href="#_7-特别的一些operator" aria-label="Permalink to &quot;7. 特别的一些Operator&quot;">​</a></h3> reshape、view、permute、transpose <blockquote><p>可能需要补充一下PyTorch的Tensor知识</p><p>比如：matedata和storage；data、storage、data_ptr、stride、contiguous；state、state_dict等</p></blockquote><ul><li><p>reshape</p><blockquote><p>原始数据内存排布不变，只变shape</p></blockquote></li><li><p>view</p><blockquote><p>类似reshape，原始数据不变</p></blockquote></li><li><p>permute</p><blockquote><p>permute会对数据底层重排，支持多个轴进行交换</p></blockquote></li><li><p>transpose</p><blockquote><p>类似permute，会对数据重排，支持两轴交换</p></blockquote></li></ul><p><strong>Tips:</strong></p><blockquote><ol><li><p>view()：当tensor连续时tensor.view()不改变存储区的真实数据，只改变元数据（Metadata）中的信息, 调用view方法张量必须连续的。</p></li><li><p>reshape()：当tensor连续时和view()相同，不连续时等价于contiguous().view()</p></li><li><p>permute()：通过改变张量的步长（stride）重新排列张量的维度，但会导致张量在内存中的存储变得不连续</p></li><li><p>contiguous()：开辟新的存储区，确保张量在内存中是连续存储，在permute()操作后需要接contiguous()才能接view()</p></li><li><p>stride()：在指定维度（dim）上，存储区中的数据元素，从一个元素跳到下一个元素所必须的步长</p></li><li><p>pytorch的存储方式：metadata+storage</p><p>metadata保存：size,dimension,stride等元信息</p><p>storage保存：以一维数组保存对应的张量数据</p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409174658632.png" alt="image-20250409174658632" style="zoom:50%;"></li></ol></blockquote> squeeze、unsqueeze <ul><li><p>是对维度的压缩和扩充</p><blockquote><p>增加一个维度，减少一个维度</p></blockquote></li></ul> concat、stack、expand、flatten <ul><li><p>concat</p><blockquote><p>与split相反操作，可以指定某轴</p></blockquote></li><li><p>stack</p><blockquote><p>支持新增一个轴进行拼接</p></blockquote></li><li><p>expand</p><blockquote><p>支持广播机制</p></blockquote></li><li><p>flatten</p><blockquote><p>拉平成一维</p></blockquote></li></ul> pointwize类型 <p>……</p> split、slice reduce类型 <h3 id="_8-embedding-可能需要单独一节" tabindex="-1">8. Embedding（可能需要单独一节） <a class="header-anchor" href="#_8-embedding-可能需要单独一节" aria-label="Permalink to &quot;8. Embedding（可能需要单独一节）&quot;">​</a></h3><blockquote><p>结合Tokenizer</p></blockquote><ul><li><p>对分词器分到的结果进行Embedding</p></li><li><p>有一个Embedding表，直接根据index查到</p></li><li><p>计算原理：传入weight大小，把Embedding table里面的提取</p></li></ul><h3 id="_9-dropout-🌟🌟🌟" tabindex="-1">9. Dropout（🌟🌟🌟） <a class="header-anchor" href="#_9-dropout-🌟🌟🌟" aria-label="Permalink to &quot;9. Dropout（🌟🌟🌟）&quot;">​</a></h3><ul><li><p>功能</p></li><li><p>原理</p><blockquote><p>丢弃 =&gt; 置零</p><p>随机性，不然会神经元坏死</p></blockquote></li><li><p>训练和推理有啥不同</p><blockquote><p>推理直接去掉，把连接weight乘以（1-p）</p></blockquote></li></ul><h3 id="_10-我的思考" tabindex="-1">10 . 我的思考： <a class="header-anchor" href="#_10-我的思考" aria-label="Permalink to &quot;10 . 我的思考：&quot;">​</a></h3><ul><li><p>不同的Norm的参数量</p><blockquote><p>可学习参数和均值方差</p></blockquote></li><li><p>不同Norm操作维度，Conv操作维度，Polling操作维度</p></li><li><p>其他哪些算子的底层是copy还是in-place</p></li><li><p>如何实现训练和推理不同的情况？（相当于加锁或者if else）</p></li></ul><hr><h2 id="_03-bp神经网络-baseline" tabindex="-1">03. BP神经网络&amp;BaseLine <a class="header-anchor" href="#_03-bp神经网络-baseline" aria-label="Permalink to &quot;03. BP神经网络&amp;BaseLine&quot;">​</a></h2>',35)]))}const x=n(r,[["render",m]]);export{y as __pageData,x as default};
