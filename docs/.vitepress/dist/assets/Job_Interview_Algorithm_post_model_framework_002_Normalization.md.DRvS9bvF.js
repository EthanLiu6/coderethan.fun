import{_ as t,c as e,o as l,a2 as i,j as s,a}from"./chunks/framework.DA-Pb-tg.js";const y=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"Job_Interview/Algorithm_post/model_framework/002_Normalization.md","filePath":"Job_Interview/Algorithm_post/model_framework/002_Normalization.md","lastUpdated":1746438847000}'),p={name:"Job_Interview/Algorithm_post/model_framework/002_Normalization.md"};function r(h,n,m,k,o,c){return l(),e("div",null,n[0]||(n[0]=[i('<h1 align="center"><p>002_Normalization</p></h1><h2 id="_1-引入" tabindex="-1">1. 引入 <a class="header-anchor" href="#_1-引入" aria-label="Permalink to &quot;1. 引入&quot;">​</a></h2><h3 id="_1-1-为啥norm" tabindex="-1">1.1 为啥Norm？ <a class="header-anchor" href="#_1-1-为啥norm" aria-label="Permalink to &quot;1.1 为啥Norm？&quot;">​</a></h3><p>由于在模型训练的时候往往层数较多，我个人尝试过，<strong>如果对输入和中间层不进行归一化操作，往往收敛效果比较差</strong>。但是我又在思考，在每模型结构的每层输出之后不都有一个非线性操作吗，很多都有类似缩放的操作，为什么还要进行Norm？于是我查阅了相关的原始论文，原来是因为：<strong>每层的激活输出会影响数据的分布情况，而进行Norm后的数据分布，在梯度计算的时候更容易进行收敛（这是结论，具体原因相关论文有指出，下面思考也进行了标注）</strong>。还有一点就能能够起到一定的正则化效果。</p><p>当然，我暂时对数据分布情况的了解和测试几乎为0，所以只能感受到一个大致的思想，后续再慢慢细磨也不迟，大方向没问题对我来说很重要。</p><p>这里引用一下RMS Norm作者的原话：</p><blockquote><p>&quot;One bottleneck deep neural networks have been hypothesized to suffer from is the <em>internal covariate shift</em> issue [27], where a layer’s input distribution changes as previous layers are updated, which significantly slows the training.1&quot;</p><p>“深度神经网络被假设存在的一个瓶颈是 <em>内部协变量偏移</em> 问题 [27]，其中层的输入分布随着先前层的更新而变化，这会显著减慢训练速度。1”</p></blockquote><h3 id="_1-2-作用" tabindex="-1">1.2 作用 <a class="header-anchor" href="#_1-2-作用" aria-label="Permalink to &quot;1.2 作用&quot;">​</a></h3><ul><li><p>解决多层神经网络中间层的<strong>协方差偏移</strong>（Internal Covariate Shift）</p></li><li><p>缓解梯度消失/爆炸（Gradient Vanishing/Explosion）</p><blockquote><p>在LN论文里面好像有说明（也可能是在BN论文里面）</p></blockquote></li><li><p>加速模型收敛</p></li><li><p>对权重初始化的依赖降低（AI说的）</p><blockquote><p>想想权重初始化的方式有哪些？（论文支撑）</p></blockquote></li></ul><p><strong>思考</strong>：</p><ul><li>在NLP任务中，是在哪个维度进行Normalize？</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502162400673.png" alt="image-20250502162400673"></p><ul><li>都进行过Softmax操作了，为啥还需要进行Normalize？</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502163007166.png" alt="image-20250502163007166"></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502163945501.png" alt="image-20250502163945501"></p><h2 id="_2-类型" tabindex="-1">2. 类型 <a class="header-anchor" href="#_2-类型" aria-label="Permalink to &quot;2. 类型&quot;">​</a></h2>',16),s("table",{tabindex:"0"},[s("thead",null,[s("tr",null,[s("th",{style:{"text-align":"center"}},"类型"),s("th",{style:{"text-align":"center"}},"公式"),s("th",{style:{"text-align":"center"}},"特点/应用场景")])]),s("tbody",null,[s("tr",null,[s("td",{style:{"text-align":"center"}},"Batch Norm"),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"−"),s("mrow",null,[s("mi",{mathvariant:"normal"},"E")]),s("mo",null,"["),s("mi",null,"x"),s("mo",null,"]")]),s("mrow",null,[s("msqrt",null,[s("mrow",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"V"),s("mi",{mathvariant:"normal"},"a"),s("mi",{mathvariant:"normal"},"r")]),s("mo",null,"["),s("mi",null,"x"),s("mo",null,"]"),s("mo",null,"+"),s("mi",null,"ϵ")])])])]),s("mo",null,"∗"),s("mi",null,"γ"),s("mo",null,"+"),s("mi",null,"β")]),s("annotation",{encoding:"application/x-tex"},"y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.01em"}}),s("span",{class:"strut bottom",style:{height:"1.86em","vertical-align":"-0.8500000000000001em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mrel"},"="),s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.5700000000000001em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"sqrt mord"},[s("span",{class:"sqrt-sign",style:{top:"0.11428571428571432em"}},[s("span",{class:"style-wrap reset-scriptstyle textstyle uncramped"},"√")]),s("span",{class:"vlist"},[s("span",{style:{top:"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathrm",style:{"margin-right":"0.01389em"}},"V"),s("span",{class:"mord mathrm"},"a"),s("span",{class:"mord mathrm"},"r")]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},"]"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit"},"ϵ")])]),s("span",{style:{top:"-0.9714285714285715em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),s("span",{class:"reset-scriptstyle textstyle uncramped sqrt-line"})]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),a("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.485em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"mbin"},"−"),s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"E")]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},"]")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mbin"},"∗"),s("span",{class:"mord mathit",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit",style:{"margin-right":"0.05278em"}},"β")])])])]),s("td",{style:{"text-align":"center"}},"等长序列（cv）")]),s("tr",null,[s("td",{style:{"text-align":"center"}},"Layer Norm"),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"−"),s("mrow",null,[s("mi",{mathvariant:"normal"},"E")]),s("mo",null,"["),s("mi",null,"x"),s("mo",null,"]")]),s("mrow",null,[s("msqrt",null,[s("mrow",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"V"),s("mi",{mathvariant:"normal"},"a"),s("mi",{mathvariant:"normal"},"r")]),s("mo",null,"["),s("mi",null,"x"),s("mo",null,"]"),s("mo",null,"+"),s("mi",null,"ϵ")])])])]),s("mo",null,"∗"),s("mi",null,"γ"),s("mo",null,"+"),s("mi",null,"β")]),s("annotation",{encoding:"application/x-tex"},"y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.01em"}}),s("span",{class:"strut bottom",style:{height:"1.86em","vertical-align":"-0.8500000000000001em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mrel"},"="),s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.5700000000000001em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"sqrt mord"},[s("span",{class:"sqrt-sign",style:{top:"0.11428571428571432em"}},[s("span",{class:"style-wrap reset-scriptstyle textstyle uncramped"},"√")]),s("span",{class:"vlist"},[s("span",{style:{top:"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathrm",style:{"margin-right":"0.01389em"}},"V"),s("span",{class:"mord mathrm"},"a"),s("span",{class:"mord mathrm"},"r")]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},"]"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit"},"ϵ")])]),s("span",{style:{top:"-0.9714285714285715em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),s("span",{class:"reset-scriptstyle textstyle uncramped sqrt-line"})]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1.4285714285714286em"}},"​")]),a("​")])])])])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.485em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"mbin"},"−"),s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"E")]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},"]")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mbin"},"∗"),s("span",{class:"mord mathit",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit",style:{"margin-right":"0.05278em"}},"β")])])])]),s("td",{style:{"text-align":"center"}},"变长序列（nlp）")]),s("tr",null,[s("td",{style:{"text-align":"center"}},"RMS Norm"),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("mrow",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"R"),s("mi",{mathvariant:"normal"},"M"),s("mi",{mathvariant:"normal"},"S")]),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")")])]),s("mo",null,"∗"),s("msub",null,[s("mi",null,"γ"),s("mi",null,"i")]),s("mo",{separator:"true"},","),s("mspace",{width:"1em"}),s("mtext",null,[s("mi",{mathvariant:"normal"},"w"),s("mi",{mathvariant:"normal"},"h"),s("mi",{mathvariant:"normal"},"e"),s("mi",{mathvariant:"normal"},"r"),s("mi",{mathvariant:"normal"},"e")]),s("mspace",{width:"1em"}),s("mtext",null,[s("mi",{mathvariant:"normal"},"R"),s("mi",{mathvariant:"normal"},"M"),s("mi",{mathvariant:"normal"},"S")]),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")"),s("mo",null,"="),s("msqrt",null,[s("mrow",null,[s("mi",null,"ϵ"),s("mo",null,"+"),s("mfrac",null,[s("mrow",null,[s("mn",null,"1")]),s("mrow",null,[s("mi",null,"n")])]),s("msubsup",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mrow",null,[s("mi",null,"n")])]),s("msubsup",null,[s("mi",null,"x"),s("mi",null,"i"),s("mn",null,"2")])])])]),s("annotation",{encoding:"application/x-tex"},"y_i = \\frac{x_i}{\\mathrm{RMS}(x)} * \\gamma_i, \\quad \\text{where} \\quad \\text{RMS}(x) = \\sqrt{\\epsilon + \\frac{1}{n} \\sum_{i=1}^{n} x_i^2}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"1.235064em"}}),s("span",{class:"strut bottom",style:{height:"1.84002em","vertical-align":"-0.604956em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.03588em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mrel"},"="),s("span",{class:"mord reset-textstyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.34500000000000003em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathrm"},"R"),s("span",{class:"mord mathrm"},"M"),s("span",{class:"mord mathrm"},"S")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.4149999999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.07142857142857144em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-scriptstyle scriptscriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mbin"},"∗"),s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.05556em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mpunct"},","),s("span",{class:"mord mspace quad"}),s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm",style:{"margin-right":"0.01389em"}},"w"),s("span",{class:"mord mathrm"},"h"),s("span",{class:"mord mathrm"},"e"),s("span",{class:"mord mathrm"},"r"),s("span",{class:"mord mathrm"},"e")]),s("span",{class:"mord mspace quad"}),s("span",{class:"text mord textstyle uncramped"},[s("span",{class:"mord mathrm"},"R"),s("span",{class:"mord mathrm"},"M"),s("span",{class:"mord mathrm"},"S")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mrel"},"="),s("span",{class:"sqrt mord"},[s("span",{class:"sqrt-sign",style:{top:"-0.04506399999999999em"}},[s("span",{class:"style-wrap reset-textstyle textstyle uncramped"},[s("span",{class:"delimsizing size2"},"√")])]),s("span",{class:"vlist"},[s("span",{style:{top:"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"mord textstyle cramped"},[s("span",{class:"mord mathit"},"ϵ"),s("span",{class:"mbin"},"+"),s("span",{class:"mord reset-textstyle textstyle cramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.345em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"n")])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.394em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mop"},[s("span",{class:"op-symbol small-op mop",style:{top:"-0.0000050000000000050004em"}},"∑"),s("span",{class:"vlist"},[s("span",{style:{top:"0.30001em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"i"),s("span",{class:"mrel"},"="),s("span",{class:"mord mathrm"},"1")])])]),s("span",{style:{top:"-0.364em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"n")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.27686399999999994em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{style:{top:"-0.34480000000000005em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathrm"},"2")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])])])]),s("span",{style:{top:"-1.1550639999999999em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped sqrt-line"})]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),a("​")])])])])])])]),s("td",{style:{"text-align":"center"}},"LN的一种优化")]),s("tr",null,[s("td",{style:{"text-align":"center"}},"DyT"),s("td",{style:{"text-align":"center"}},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"γ"),s("mo",null,"∗"),s("mi",null,"T"),s("mi",null,"a"),s("mi",null,"n"),s("mi",null,"h"),s("mo",null,"("),s("mi",null,"α"),s("mo",null,"∗"),s("mi",null,"x"),s("mo",null,")"),s("mo",null,"+"),s("mi",null,"β")]),s("annotation",{encoding:"application/x-tex"},"\\gamma * Tanh(\\alpha * x) + \\beta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mbin"},"∗"),s("span",{class:"mord mathit",style:{"margin-right":"0.13889em"}},"T"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"n"),s("span",{class:"mord mathit"},"h"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mbin"},"∗"),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathit",style:{"margin-right":"0.05278em"}},"β")])])])]),s("td",{style:{"text-align":"center"}},"暂定（2025最新论文）")]),s("tr",null,[s("td",{style:{"text-align":"center"}},"……"),s("td",{style:{"text-align":"center"}},"……"),s("td",{style:{"text-align":"center"}},"……")])])],-1),i(`<h3 id="_2-1-batch-norm" tabindex="-1">2.1 Batch Norm <a class="header-anchor" href="#_2-1-batch-norm" aria-label="Permalink to &quot;2.1 Batch Norm&quot;">​</a></h3><p>中英文对比论文：<a href="https://yiyibooks.cn/arxiv/1502.03167v3/index.html" target="_blank" rel="noreferrer">Batch Norm</a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mrow><mi mathvariant="normal">E</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo></mrow><mrow><msqrt><mrow><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow></mfrac><mo>∗</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.427em;"></span><span class="strut bottom" style="height:2.55701em;vertical-align:-1.13001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.825005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.04500500000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm" style="margin-right:0.01389em;">V</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span><span class="mbin">+</span><span class="mord mathit">ϵ</span></span></span><span style="top:-0.855005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathit">x</span><span class="mbin">−</span><span class="mord textstyle uncramped"><span class="mord mathrm">E</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p><ul><li><p>关键四步</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502170625783.png" alt="image-20250502170625783"></p></li><li><p>训练和推理</p><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p></p><p>但是这里有一个点注意一下，在训练的时候有Batch的训练，但是推理的时候可以是任意的（比如单一的数据输入），这时候其实是没有Batch的mean（均值）和var（方差）这个概念的，所以，训练和推理的中Norm的计算方式是不一样的（PyTorch框架中的running属性进行控制），其实主要是两点（笔者个人理解）：</p><blockquote><ol><li><p>训练中的mean和var用于推理中（想想该如何设计呢）</p></li><li><p>训练的mean计算采用<strong>移动指数平均</strong>的方式（代码里面有个momentum参数，这里的跟优化器里的动量不一样哈）</p><p>running_{mean}=(1−momentum)⋅running_{mean}+momentum⋅mean</p><p>var同理</p></li></ol></blockquote></div></li><li><p>pytorch相关关键代码</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    exponential_average_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    exponential_average_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.training </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.track_running_stats:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">TODO</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">: if statement only here to tell the jit to skip emitting this when it is None</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.num_batches_tracked </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># type: ignore[has-type]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.num_batches_tracked.add_(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># type: ignore[has-type]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># use cumulative moving average</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            exponential_average_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> /</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.num_batches_tracked)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># use exponential moving average</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            exponential_average_factor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Decide whether the mini-batch stats should be used for normalization rather than the buffers.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Mini-batch stats are used in training mode, and in eval mode when buffers are None.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.training:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    bn_training </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    bn_training </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div></li></ul><h3 id="_2-2-layer-norm" tabindex="-1">2.2 Layer Norm <a class="header-anchor" href="#_2-2-layer-norm" aria-label="Permalink to &quot;2.2 Layer Norm&quot;">​</a></h3><p>中英文对照论文：<a href="https://yiyibooks.cn/arxiv/1607.06450v1/index.html" target="_blank" rel="noreferrer">Layer Norm</a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mrow><mi mathvariant="normal">E</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo></mrow><mrow><msqrt><mrow><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo>[</mo><mi>x</mi><mo>]</mo><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow></mfrac><mo>∗</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.427em;"></span><span class="strut bottom" style="height:2.55701em;vertical-align:-1.13001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.825005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.04500500000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm" style="margin-right:0.01389em;">V</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span><span class="mbin">+</span><span class="mord mathit">ϵ</span></span></span><span style="top:-0.855005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathit">x</span><span class="mbin">−</span><span class="mord textstyle uncramped"><span class="mord mathrm">E</span></span><span class="mopen">[</span><span class="mord mathit">x</span><span class="mclose">]</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p><ul><li><p>数据不变性：</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502164559327.png" alt="image-20250502164559327"></p></li><li><p>这里引用一下PyTorch官网的<code>[!Note]</code>:</p><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p></p><p>Unlike Batch Normalization and Instance Normalization, which applies scalar scale and bias for each entire channel/plane with the <code>affine</code> option, Layer Normalization applies per-element scale and bias with <code>elementwise_affine</code>.</p></div></li></ul><p>​ 这里的<code>affine</code>就是最后那一步放射变化，简单说就是进行缩放和平移（偏执）那一步</p><ul><li>DeepSeek帮我稍微整理的：</li></ul><table tabindex="0"><thead><tr><th style="text-align:center;">归一化类型</th><th style="text-align:center;"><code>affine</code> 的作用范围</th><th style="text-align:center;">参数形状（<code>γ</code> 和 <code>β</code>）</th><th style="text-align:center;">适用场景</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>BatchNorm</strong></td><td style="text-align:center;"><strong>整个通道/平面</strong>（per-channel）</td><td style="text-align:center;"><code>(C,)</code></td><td style="text-align:center;">固定长度的批次数据</td></tr><tr><td style="text-align:center;"><strong>InstanceNorm</strong></td><td style="text-align:center;"><strong>整个通道/平面</strong>（per-channel）</td><td style="text-align:center;"><code>(C,)</code></td><td style="text-align:center;">图像生成/风格迁移</td></tr><tr><td style="text-align:center;"><strong>LayerNorm</strong></td><td style="text-align:center;"><strong>每个元素</strong>（per-element）</td><td style="text-align:center;">输入张量的<strong>最后一维</strong></td><td style="text-align:center;">变长序列（如NLP/RNN）</td></tr></tbody></table><h3 id="_2-3-rms-norm" tabindex="-1">2.3 RMS Norm <a class="header-anchor" href="#_2-3-rms-norm" aria-label="Permalink to &quot;2.3 RMS Norm&quot;">​</a></h3><p>中英文对照论文：<a href="https://yiyibooks.cn/arxiv/1910.07467v1/index.html" target="_blank" rel="noreferrer">RMS Norm</a></p>`,13),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("mrow",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"R"),s("mi",{mathvariant:"normal"},"M"),s("mi",{mathvariant:"normal"},"S")]),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")")])]),s("mo",null,"∗"),s("msub",null,[s("mi",null,"γ"),s("mi",null,"i")]),s("mo",{separator:"true"},","),s("mspace",{width:"1em"}),s("mtext",null,[s("mi",{mathvariant:"normal"},"w"),s("mi",{mathvariant:"normal"},"h"),s("mi",{mathvariant:"normal"},"e"),s("mi",{mathvariant:"normal"},"r"),s("mi",{mathvariant:"normal"},"e")]),s("mspace",{width:"1em"}),s("mtext",null,[s("mi",{mathvariant:"normal"},"R"),s("mi",{mathvariant:"normal"},"M"),s("mi",{mathvariant:"normal"},"S")]),s("mo",null,"("),s("mi",null,"x"),s("mo",null,")"),s("mo",null,"="),s("msqrt",null,[s("mrow",null,[s("mi",null,"ϵ"),s("mo",null,"+"),s("mfrac",null,[s("mrow",null,[s("mn",null,"1")]),s("mrow",null,[s("mi",null,"n")])]),s("msubsup",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mrow",null,[s("mi",null,"n")])]),s("msubsup",null,[s("mi",null,"x"),s("mi",null,"i"),s("mn",null,"2")])])])]),s("annotation",{encoding:"application/x-tex"},"y_i = \\frac{x_i}{\\mathrm{RMS}(x)} * \\gamma_i, \\quad \\text{where} \\quad \\text{RMS}(x) = \\sqrt{\\epsilon + \\frac{1}{n} \\sum_{i=1}^{n} x_i^2} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"2.128249em"}}),s("span",{class:"strut bottom",style:{height:"3.6550199999999995em","vertical-align":"-1.5267709999999999em"}}),s("span",{class:"base displaystyle textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.03588em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mrel"},"="),s("span",{class:"mord reset-textstyle displaystyle textstyle uncramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.686em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle cramped"},[s("span",{class:"mord textstyle cramped"},[s("span",{class:"mord textstyle cramped"},[s("span",{class:"mord mathrm"},"R"),s("span",{class:"mord mathrm"},"M"),s("span",{class:"mord mathrm"},"S")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{style:{top:"-0.2300000000000001em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.677em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped"},[s("span",{class:"mord textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])])])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mbin"},"∗"),s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.05556em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mpunct"},","),s("span",{class:"mord mspace quad"}),s("span",{class:"text mord displaystyle textstyle uncramped"},[s("span",{class:"mord mathrm",style:{"margin-right":"0.01389em"}},"w"),s("span",{class:"mord mathrm"},"h"),s("span",{class:"mord mathrm"},"e"),s("span",{class:"mord mathrm"},"r"),s("span",{class:"mord mathrm"},"e")]),s("span",{class:"mord mspace quad"}),s("span",{class:"text mord displaystyle textstyle uncramped"},[s("span",{class:"mord mathrm"},"R"),s("span",{class:"mord mathrm"},"M"),s("span",{class:"mord mathrm"},"S")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mrel"},"="),s("span",{class:"sqrt mord"},[s("span",{class:"sqrt-sign",style:{top:"-0.023254000000000108em"}},[s("span",{class:"style-wrap reset-textstyle textstyle uncramped"},[s("span",{class:"delimsizing mult"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.665005em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"delimsizinginner delim-size4"},[s("span",null,"⎷")])]),s("span",{style:{top:"-0.24999499999999997em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"delimsizinginner delim-size4"},[s("span",null,"")])]),s("span",{style:{top:"-0.854995em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"delimsizinginner delim-size4"},[s("span",null,"")])]),s("span",{style:{top:"-1.459995em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"delimsizinginner delim-size4"},[s("span",null,"")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])])])]),s("span",{class:"vlist"},[s("span",{style:{top:"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"mord displaystyle textstyle cramped"},[s("span",{class:"mord mathit"},"ϵ"),s("span",{class:"mbin"},"+"),s("span",{class:"mord reset-textstyle displaystyle textstyle cramped"},[s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist"},[s("span",{style:{top:"0.686em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle cramped"},[s("span",{class:"mord textstyle cramped"},[s("span",{class:"mord mathit"},"n")])])]),s("span",{style:{top:"-0.22999999999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),s("span",{style:{top:"-0.677em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle textstyle cramped"},[s("span",{class:"mord textstyle cramped"},[s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),s("span",{class:"mop op-limits"},[s("span",{class:"vlist"},[s("span",{style:{top:"1.1776689999999999em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"i"),s("span",{class:"mrel"},"="),s("span",{class:"mord mathrm"},"1")])])]),s("span",{style:{top:"-0.000005000000000143778em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",null,[s("span",{class:"op-symbol large-op mop"},"∑")])]),s("span",{style:{top:"-1.2500050000000003em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit"},"n")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.27686399999999994em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit"},"i")])]),s("span",{style:{top:"-0.34480000000000005em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathrm"},"2")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])])])]),s("span",{style:{top:"-2.0482489999999998em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),s("span",{class:"reset-textstyle textstyle uncramped sqrt-line"})]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"1em"}},"​")]),a("​")])])])])])])])],-1),i('<ul><li><p><strong>这种归一化是大模型常用的归一化层方式，原因很简单，高效！！！</strong></p></li><li><p>核心思想（笔者理解）：去掉Layer Norm中的平移操作（平移不会影响相对分布），分母采用均方根代替。</p></li><li><p><strong>原始论文作者是假设了重新计算的居中不变性（re-centering invariance）是可有可无的</strong>：</p></li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502175716114.png" alt="image-20250502175716114"></p><ul><li><p>数据不变性：</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502181729268.png" alt="image-20250502181729268"></p></li></ul><p><strong>思考</strong>：</p><ul><li><p>为啥偏偏就选中MSE作为规范化标准？</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502182035888.png" alt="image-20250502182035888"></p></li></ul><h3 id="_2-4-dyt" tabindex="-1">2.4 DyT <a class="header-anchor" href="#_2-4-dyt" aria-label="Permalink to &quot;2.4 DyT&quot;">​</a></h3><p>中英文对照论文：<a href="https://yiyibooks.cn/arxiv/2503.10622v1/index.html" target="_blank" rel="noreferrer">Transformers without normlization</a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi><mo>∗</mo><mi>T</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo>(</mo><mi>α</mi><mo>∗</mo><mi>x</mi><mo>)</mo><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\\gamma * Tanh(\\alpha * x) + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">h</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mbin">∗</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span></span></p><ul><li>灵感来源</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502182553412.png" alt="image-20250502182553412"></p><ul><li><p>就很随意</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502183000775.png" alt="image-20250502183000775"></p></li><li><p>实验尝试（不同模型不同层数的Norm层前后分布对比）：</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502183447574.png" alt="image-20250502183447574"></p><p>浅层的时候往往输入输出分布偏向线性</p></li><li><p>论文所给伪代码</p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502183926711.png" alt="image-20250502183926711" style="zoom:33%;"></li><li><p>具体尝试我暂时还未进行，就先不试了</p></li></ul><h2 id="_3-其他相关内容" tabindex="-1">3. 其他相关内容 <a class="header-anchor" href="#_3-其他相关内容" aria-label="Permalink to &quot;3. 其他相关内容&quot;">​</a></h2><h3 id="_3-1-post-norm-pre-norm" tabindex="-1">3.1 Post-Norm &amp; Pre-Norm <a class="header-anchor" href="#_3-1-post-norm-pre-norm" aria-label="Permalink to &quot;3.1 Post-Norm &amp; Pre-Norm&quot;">​</a></h3><blockquote><p>Pre-Norm大模型中常用</p><p>这部分内容是大模型帮我整理的（哈哈哈哈，原谅我不太想整理这块）</p></blockquote><ul><li>结构</li></ul><p>结合Transformer那块知识，一个是在残差前，一个在残差后</p> Output_{post}=LayerNorm(x+SubLayer(x)) \\\\ Output_{pre}=x+SubLayer(LayerNorm(x)) 公式1:PostNorm(x)=x+LayerNorm(FeedForward(x+LayerNorm(Attention(x)))) \\\\\\\\ 公式2:PreNorm(x)=x+FeedForward(LayerNorm(x))+Attention(LayerNorm(x)) <table tabindex="0"><thead><tr><th>特性</th><th style="text-align:center;">Post-Norm</th><th style="text-align:center;">Pre-Norm</th></tr></thead><tbody><tr><td>公式</td><td style="text-align:center;">公式1</td><td style="text-align:center;">公式2</td></tr><tr><td>位置</td><td style="text-align:center;">残差后</td><td style="text-align:center;">残差前</td></tr><tr><td>出现时间</td><td style="text-align:center;">原始 Transformer（Vaswani et al., 2017）</td><td style="text-align:center;">之后发展（如 GPT-2 等）</td></tr><tr><td>优点</td><td style="text-align:center;">收敛后表现略好（某些任务）</td><td style="text-align:center;">更稳定，训练深层模型不易梯度消失</td></tr><tr><td>缺点</td><td style="text-align:center;">深层模型中容易梯度消失/爆炸</td><td style="text-align:center;">可能最终性能略低，但更容易训练</td></tr><tr><td>应用情况</td><td style="text-align:center;">BERT、初版Transformer</td><td style="text-align:center;">GPT系列、T5、LLama等大模型</td></tr></tbody></table><table tabindex="0"><thead><tr><th style="text-align:center;">模型</th><th style="text-align:center;">归一化类型</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>DeepSeek</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>GPT-2/3/4</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>BERT</strong></td><td style="text-align:center;">Post-Norm</td></tr><tr><td style="text-align:center;"><strong>T5</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>LLaMA</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>Transformer XL</strong></td><td style="text-align:center;">Pre-Norm</td></tr><tr><td style="text-align:center;"><strong>原始 Transformer</strong></td><td style="text-align:center;">Post-Norm</td></tr></tbody></table><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502185123075.png" alt="image-20250502185123075" style="zoom:50%;"><ul><li>选择 任务复杂度: 简单任务用 PostNorm，复杂任务用 PreNorm。 模型深度: 深层模型优先选择 PreNorm。</li></ul><h3 id="_3-2-deep-norm" tabindex="-1">3.2 Deep Norm <a class="header-anchor" href="#_3-2-deep-norm" aria-label="Permalink to &quot;3.2 Deep Norm&quot;">​</a></h3><ul><li><p>关键成果</p><blockquote><p>DeepNorm 是微软在 2022 年提出的改进方法（论文 <em>&quot;<a href="https://arxiv.org/abs/2203.00555" target="_blank" rel="noreferrer">DeepNet: Scaling Transformers to 1,000 Layers</a>&quot;</em>），<strong>基于 Post-Norm 但大幅提升了深层训练的稳定性</strong>，可支持超深层（如 1000 层）Transformer 的训练。</p></blockquote><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164334392.png" alt="image-20250409164334392"></p></li><li><p>基本结构</p></li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409162034019.png" alt="image-20250409162034019"></p><p>原始残差结构:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo>(</mo><msub><mi>x</mi><mi>l</mi></msub><mo>+</mo><mi>F</mi><mo>(</mo><msub><mi>x</mi><mi>l</mi></msub><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">x_{l+1} = LayerNorm(x_l + F(x_l)) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit">L</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">m</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>DeepNorm:</p>',27),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"l"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("mtext",null,[s("mi",{mathvariant:"normal"},"L"),s("mi",{mathvariant:"normal"},"N")]),s("mo",null,"("),s("mi",null,"α"),s("mo",null,"⋅"),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",null,"+"),s("msub",null,[s("mi",null,"G"),s("mi",null,"l")]),s("mo",null,"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"l")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"θ"),s("mi",null,"l")]),s("mo",null,")"),s("mo",null,")")]),s("annotation",{encoding:"application/x-tex"},"x_{l+1} = \\text{LN}(\\alpha \\cdot x_l + G_l(x_l, \\theta_l)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.75em"}}),s("span",{class:"strut bottom",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"base displaystyle textstyle uncramped"},[s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mbin"},"+"),s("span",{class:"mord mathrm"},"1")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mrel"},"="),s("span",{class:"text mord displaystyle textstyle uncramped"},[s("span",{class:"mord mathrm"},"L"),s("span",{class:"mord mathrm"},"N")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathit",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mbin"},"⋅"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"+"),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"G"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathit"},"x"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mpunct"},","),s("span",{class:"mord"},[s("span",{class:"mord mathit",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"vlist"},[s("span",{style:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.02778em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle cramped"},[s("span",{class:"mord mathit",style:{"margin-right":"0.01968em"}},"l")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},")")])])])])],-1),i(`<p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164837814.png" alt="image-20250409164837814"></p><ul><li>暂时不想细读这篇论文啦（后续补充）</li></ul><p><strong>思考：</strong></p><ul><li>DeepNorm中的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span>是哪里的参数？</li></ul><h3 id="_3-3-group-norm" tabindex="-1">3.3 Group Norm <a class="header-anchor" href="#_3-3-group-norm" aria-label="Permalink to &quot;3.3 Group Norm&quot;">​</a></h3><blockquote><p>笔者理解：是对BN进行改进，将channel进行分组，然后组内Norm</p></blockquote><p>论文链接：<a href="https://arxiv.org/abs/1803.08494" target="_blank" rel="noreferrer">Group Norm</a></p><ul><li><p>效果</p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250502190717337.png" alt="image-20250502190717337" style="zoom:50%;"></li></ul><h3 id="_3-4-instance-norm" tabindex="-1">3.4 Instance Norm <a class="header-anchor" href="#_3-4-instance-norm" aria-label="Permalink to &quot;3.4 Instance Norm&quot;">​</a></h3><blockquote><p>没咋看，看论文是在CV领域用的</p></blockquote><p>论文链接：<a href="https://arxiv.org/abs/1607.08022" target="_blank" rel="noreferrer">Instance Norm</a></p><h2 id="_4-代码实现" tabindex="-1">4. 代码实现 <a class="header-anchor" href="#_4-代码实现" aria-label="Permalink to &quot;4. 代码实现&quot;">​</a></h2><h3 id="_4-1-batch-norm" tabindex="-1">4.1 Batch Norm <a class="header-anchor" href="#_4-1-batch-norm" aria-label="Permalink to &quot;4.1 Batch Norm&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> BatchNorm</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, num_features, eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, momentum</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(BatchNorm, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.num_features </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_features</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> eps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.ones(num_features))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这俩是可学习参数</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.zeros(num_features))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> momentum</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这里不使用buffer注册，用属性简单实现</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.ones(num_features)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.zeros(num_features)  </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x, training</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> training:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.mean(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.var(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">unbiased</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算时候无偏，存储时候有偏</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;batch_mean shape, batch_var shape:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, batch_mean.shape, batch_var.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_mean</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.momentum </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_var</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;self.running_mean, self.running_var:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            batch_mean, batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_mean) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (torch.sqrt(batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_norm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BatchNorm(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ipt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ipt[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].shape)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    res </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_norm(ipt)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(res)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(res.min(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), res.max(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><h3 id="_4-2-layer-norm" tabindex="-1">4.2 Layer Norm <a class="header-anchor" href="#_4-2-layer-norm" aria-label="Permalink to &quot;4.2 Layer Norm&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这里我只实现NLP的样式</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LayerNormImpl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, normalized_shape: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> eps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.ones(normalized_shape))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.zeros(normalized_shape))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [batch_szie, seq_len, embedding_dim]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        emb_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.mean(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        emb_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x.var(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">unbiased</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        norm_x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> emb_mean) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (torch.sqrt(emb_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> norm_x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size, seq_length, embedding_dim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    embedding_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [batch_size, seq_length, embedding_dim]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ipt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(batch_size, seq_length, embedding_dim)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    layer_norm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LayerNormImpl(embedding_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer_norm(ipt)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out.max(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), out.min(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><h3 id="_4-3-rms-norm" tabindex="-1">4.3 RMS Norm <a class="header-anchor" href="#_4-3-rms-norm" aria-label="Permalink to &quot;4.3 RMS Norm&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对Layer Norm的优化，采用均方根，并假设重新计算的中心化无关（去掉平移）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> RMSNorm</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, normlized_shape: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, eps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.normlized_shape </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> normlized_shape</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> eps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.ones(normlized_shape))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # print(tuple(x.shape) == self.normlized_shape)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        assert</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.shape) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.normlized_shape, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;归一化形状与输入形状不一致&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        rms </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.sqrt(x.pow(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).mean(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.eps)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">   </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size, seq_length, embedding_dim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    embedding_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (batch_size, seq_length, embedding_dim)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ipt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(embedding_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rms_norm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RMSNorm(embedding_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rms_norm(ipt)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out.max(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), out.min(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p></p><p>在工程中，RMSNorm会和输入之前的Linear操作放在一起执行，也就是分母直接换成上层的Linear操作</p></div><h3 id="_4-4-dyt" tabindex="-1">4.4 DyT <a class="header-anchor" href="#_4-4-dyt" aria-label="Permalink to &quot;4.4 DyT&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.functional </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tanh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> DyT</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, normlizated_shape: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, init_alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.normlizated_shape </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> normlizated_shape</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> init_alpha)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.ones(normlizated_shape))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Parameter(torch.zeros(normlizated_shape))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        assert</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.shape) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.normlizated_shape, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;输入形状与归一化形状不匹配&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tanh(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.beta </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size, seq_length, embedding_dim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    embedding_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (batch_size, seq_length, embedding_dim)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ipt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(embedding_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    dyt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DyT(embedding_size)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    res </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dyt(ipt)</span></span></code></pre></div><h2 id="n-面试问题" tabindex="-1">n. 面试问题 <a class="header-anchor" href="#n-面试问题" aria-label="Permalink to &quot;n. 面试问题&quot;">​</a></h2><ul><li><p>BN和LN有什么区别？</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># PyTorch源码里面的说法值得借鉴一下</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.. note::</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Unlike Batch Normalization </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Instance Normalization, which applies</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    scalar scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> each entire channel</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plane </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> the</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    :attr:</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">\`affine\`</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> option, Layer Normalization applies per</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">element scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> :attr:</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">\`elementwise_affine\`</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 当然，除了最后的\`affine\`的性质不同外，针对的归一化维度也不同</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 一个是在batch/channel维度，一个是在embedding维度(当然也可以在channel维度进行)，对应的应用场景不同</span></span></code></pre></div></li><li><p>为啥不用BN来做NLP？</p></li><li><p>BN的训练和推理有什么不同？</p></li><li><p>讲讲Pre-Norm和Post-Norm。</p></li></ul>`,23)]))}const g=t(p,[["render",r]]);export{y as __pageData,g as default};
