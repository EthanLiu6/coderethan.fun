const t='{"documentCount":976,"nextId":976,"documentIds":{"0":"/AI/deep_learning_theory/01-feedforward_network.html#前馈神经网络-feedforward-neural-network","1":"/AI/deep_learning_theory/01-feedforward_network.html#_1-相关概念","2":"/AI/deep_learning_theory/01-feedforward_network.html#_1-1-人工智能是什么","3":"/AI/deep_learning_theory/01-feedforward_network.html#_1-2-深度学习与人工智能的关系","4":"/AI/deep_learning_theory/01-feedforward_network.html#_1-3-深度学习的概念","5":"/AI/deep_learning_theory/01-feedforward_network.html#_1-4-什么是人工神经网络","6":"/AI/deep_learning_theory/01-feedforward_network.html#_1-5-前馈神经网络的概念","7":"/AI/deep_learning_theory/01-feedforward_network.html#_2-神经元模型","8":"/AI/deep_learning_theory/01-feedforward_network.html#_2-1-m-p-神经元","9":"/AI/deep_learning_theory/01-feedforward_network.html#_2-2-经典激活函数","10":"/AI/deep_learning_theory/01-feedforward_network.html#_3-从神经元到感知机","11":"/AI/deep_learning_theory/01-feedforward_network.html#_3-1-使用感知机解决线性可分问题","12":"/AI/deep_learning_theory/01-feedforward_network.html#_3-2-如何解决异或问题","13":"/AI/deep_learning_theory/01-feedforward_network.html#_4-从感知机到深度神经网络","14":"/AI/deep_learning_theory/01-feedforward_network.html#_4-1-为何要用深度神经网络","15":"/AI/deep_learning_theory/01-feedforward_network.html#_4-2-深度神经网络解决问题案例","16":"/AI/deep_learning_theory/01-feedforward_network.html#_5-前馈神经网络计算流程","17":"/AI/deep_learning_theory/01-feedforward_network.html#_6-深度学习与传统机器学习","18":"/AI/deep_learning_theory/01-feedforward_network.html#_6-1-相同点","19":"/AI/deep_learning_theory/01-feedforward_network.html#_6-2-不同点","20":"/AI/deep_learning_theory/01-feedforward_network.html#_7-深度学习的特点","21":"/AI/deep_learning_theory/01-feedforward_network.html#_8-深度学习的典型算法","22":"/AI/deep_learning_theory/01-feedforward_network.html#_9-参考文献","23":"/AI/deep_learning_theory/02-back_propagation.html#_1-概念理解","24":"/AI/deep_learning_theory/02-back_propagation.html#_1-1-神经网络训练流程概述","25":"/AI/deep_learning_theory/02-back_propagation.html#_1-2-反向传播的定义","26":"/AI/deep_learning_theory/02-back_propagation.html#_2-梯度下降算法简述","27":"/AI/deep_learning_theory/02-back_propagation.html#_3-bp-或-深度神经网络训练需要明确的几个概念","28":"/AI/deep_learning_theory/02-back_propagation.html#_4-链式求导法则","29":"/AI/deep_learning_theory/02-back_propagation.html#_5-bp-流程图示","30":"/AI/deep_learning_theory/02-back_propagation.html#_6-反向传播数学推导","31":"/AI/deep_learning_theory/02-back_propagation.html#_6-1-反向传播目的确认","32":"/AI/deep_learning_theory/02-back_propagation.html#_6-2-线性连接层-weight-的梯度","33":"/AI/deep_learning_theory/02-back_propagation.html#_6-3-激活函数-input-的梯度","34":"/AI/deep_learning_theory/02-back_propagation.html#_6-4-激活函数-output-的梯度","35":"/AI/deep_learning_theory/02-back_propagation.html#_6-5-下层激活-input-z-and-z-梯度求解","36":"/AI/deep_learning_theory/02-back_propagation.html#_7-反向传播总结","37":"/AI/deep_learning_theory/03-bp_example_demo.html#神经网络案例展示","38":"/AI/deep_learning_theory/03-bp_example_demo.html#_1-题目","39":"/AI/deep_learning_theory/03-bp_example_demo.html#_2-前向传播过程-feedforward","40":"/AI/deep_learning_theory/03-bp_example_demo.html#_2-1-第一层求解","41":"/AI/deep_learning_theory/03-bp_example_demo.html#_2-2-第二层计算","42":"/AI/deep_learning_theory/03-bp_example_demo.html#_3-反向传播过程-back-propagation","43":"/AI/deep_learning_theory/03-bp_example_demo.html#_3-1-末层权重梯度计算","44":"/AI/deep_learning_theory/03-bp_example_demo.html#_3-1-1-计算流程概述","45":"/AI/deep_learning_theory/03-bp_example_demo.html#_3-1-2-具体计算过程","46":"/AI/deep_learning_theory/03-bp_example_demo.html#_3-2-前一层权重梯度计算-以-梯度计算为例","47":"/AI/deep_learning_theory/03-bp_example_demo.html#_4-权重更新","48":"/AI/deep_learning_theory/03-bp_example_demo.html#_5-迭代训练","49":"/AI/deep_learning_theory/03-bp_example_demo.html#_6-将前馈网络写成矩阵形式","50":"/AI/deep_learning_theory/03-bp_example_demo.html#_7-代码展示","51":"/AI/deep_learning_theory/04-convolution_neural_network.html#_1-概念","52":"/AI/deep_learning_theory/04-convolution_neural_network.html#_2-卷积运算","53":"/AI/deep_learning_theory/04-convolution_neural_network.html#_3-体会卷积的作用","54":"/AI/deep_learning_theory/04-convolution_neural_network.html#_4-卷积-和-前馈神经网络的关系","55":"/AI/deep_learning_theory/04-convolution_neural_network.html#_5-工程上标准的卷积","56":"/AI/deep_learning_theory/04-convolution_neural_network.html#_6-1x1-卷积","57":"/AI/deep_learning_theory/04-convolution_neural_network.html#_7-分组卷积-group-convolution","58":"/AI/deep_learning_theory/04-convolution_neural_network.html#_8-深度可分离卷积-deepwise-convolution","59":"/AI/deep_learning_theory/04-convolution_neural_network.html#_9-空间可分离卷积-spatially-separable-convolutions","60":"/AI/deep_learning_theory/04-convolution_neural_network.html#_10-空洞卷积-膨胀卷积-dilated-convolution-atrous-convolution","61":"/AI/deep_learning_theory/04-convolution_neural_network.html#_11-反卷积-转置卷积-deconvolution-transposed-convolution","62":"/AI/deep_learning_theory/04-convolution_neural_network.html#_12-可变形卷积-deformable-convolution","63":"/AI/deep_learning_theory/04-convolution_neural_network.html#_12-1-原理","64":"/AI/deep_learning_theory/04-convolution_neural_network.html#_12-2-过程","65":"/AI/deep_learning_theory/04-convolution_neural_network.html#_13-3d-卷积","66":"/AI/deep_learning_theory/04-convolution_neural_network.html#_14-参考链接","67":"/AI/deep_learning_theory/06-pytorch_install.html#_1-pytorch-官网","68":"/AI/deep_learning_theory/06-pytorch_install.html#_2-pytorch-简介","69":"/AI/deep_learning_theory/06-pytorch_install.html#_2-1-认识pytorch","70":"/AI/deep_learning_theory/06-pytorch_install.html#_2-2-pytorch-软件栈","71":"/AI/deep_learning_theory/06-pytorch_install.html#_3-pytorch-install","72":"/AI/deep_learning_theory/06-pytorch_install.html#_4-nvidia-相关软件库","73":"/AI/deep_learning_theory/06-pytorch_install.html#_4-1-显卡驱动","74":"/AI/deep_learning_theory/06-pytorch_install.html#_4-2-cuda","75":"/AI/deep_learning_theory/06-pytorch_install.html#_4-3-cudnn","76":"/AI/deep_learning_theory/06-pytorch_install.html#_5-gpu","77":"/AI/deep_learning_theory/06-pytorch_install.html#_5-1-gpu-加速原理","78":"/AI/deep_learning_theory/06-pytorch_install.html#_5-2-最先进的gpu","79":"/AI/deep_learning_theory/07-operators.html#_1-convolution","80":"/AI/deep_learning_theory/07-operators.html#_1-1-conv2d","81":"/AI/deep_learning_theory/07-operators.html#_1-2-convtranspose2d","82":"/AI/deep_learning_theory/07-operators.html#_2-线性变换层","83":"/AI/deep_learning_theory/07-operators.html#_2-1-linear-gemm","84":"/AI/deep_learning_theory/07-operators.html#_2-2-matmul-相关","85":"/AI/deep_learning_theory/07-operators.html#_3-normalization","86":"/AI/deep_learning_theory/07-operators.html#_3-1-batchnorm2d","87":"/AI/deep_learning_theory/07-operators.html#_3-2-layernorm","88":"/AI/deep_learning_theory/07-operators.html#_3-3-instance-normalization","89":"/AI/deep_learning_theory/07-operators.html#_3-4-group-normalization","90":"/AI/deep_learning_theory/07-operators.html#_3-5-switch-norm","91":"/AI/deep_learning_theory/07-operators.html#_3-6-rms-norm","92":"/AI/deep_learning_theory/07-operators.html#_4-pooling","93":"/AI/deep_learning_theory/07-operators.html#_4-1-max-pooling","94":"/AI/deep_learning_theory/07-operators.html#_4-2-averagepooling","95":"/AI/deep_learning_theory/07-operators.html#_4-3-global-average-pooling","96":"/AI/deep_learning_theory/07-operators.html#_5-activation-functions","97":"/AI/deep_learning_theory/07-operators.html#_6-reshape、-view、-permute、transpose","98":"/AI/deep_learning_theory/07-operators.html#_6-1-reshape","99":"/AI/deep_learning_theory/07-operators.html#_6-2-view","100":"/AI/deep_learning_theory/07-operators.html#_6-3-transpose","101":"/AI/deep_learning_theory/07-operators.html#_6-4-permute","102":"/AI/deep_learning_theory/07-operators.html#_7-sequenze-和-unequenze","103":"/AI/deep_learning_theory/07-operators.html#_8-concat、stack、expand-和-flatten","104":"/AI/deep_learning_theory/07-operators.html#_8-1-concat","105":"/AI/deep_learning_theory/07-operators.html#_8-2-stack","106":"/AI/deep_learning_theory/07-operators.html#_8-3-expand","107":"/AI/deep_learning_theory/07-operators.html#_8-4-flatten","108":"/AI/deep_learning_theory/07-operators.html#_9-pointwise","109":"/AI/deep_learning_theory/07-operators.html#_10-split-和-slice","110":"/AI/deep_learning_theory/07-operators.html#_10-1-split","111":"/AI/deep_learning_theory/07-operators.html#_10-2-slice","112":"/AI/deep_learning_theory/07-operators.html#_11-reduce-规约类算子","113":"/AI/deep_learning_theory/07-operators.html#_12-embedding","114":"/AI/deep_learning_theory/07-operators.html#_13-dropout","115":"/AI/deep_learning_theory/07-operators.html#_14-附录","116":"/AI/deep_learning_theory/07-operators.html#_15-参考链接","117":"/AI/deep_learning_theory/05-deep_learning_model.html#_1-什么是深度学习模型","118":"/AI/deep_learning_theory/05-deep_learning_model.html#_2-下载一个预训练好的深度学习模型","119":"/AI/deep_learning_theory/05-deep_learning_model.html#_3-可视化这个深度学习模型","120":"/AI/deep_learning_theory/08-activation_functions.html#_0-activation-整体介绍","121":"/AI/deep_learning_theory/08-activation_functions.html#_1-s-型激活函数","122":"/AI/deep_learning_theory/08-activation_functions.html#_2-relu-激活函数","123":"/AI/deep_learning_theory/08-activation_functions.html#_3-relu6","124":"/AI/deep_learning_theory/08-activation_functions.html#_4-其它relu-相关-激活函数","125":"/AI/deep_learning_theory/08-activation_functions.html#_5-elu-exponential-linear-units-和-selu-scaled-elu","126":"/AI/deep_learning_theory/08-activation_functions.html#_6-gelu-gaussian-error-linear-unit","127":"/AI/deep_learning_theory/08-activation_functions.html#_7-swish-与-hardswish","128":"/AI/deep_learning_theory/08-activation_functions.html#_8-mish","129":"/AI/deep_learning_theory/08-activation_functions.html#_9-softmax","130":"/AI/deep_learning_theory/08-activation_functions.html#_10-总结-好的激活函数应有的性质","131":"/AI/deep_learning_theory/08-activation_functions.html#_11-参考链接","132":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_0-循环神经网络-recurrent-neural-network-rnn","133":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_2-典型的rnn网络","134":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-rnn-结构详解","135":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-1-rnn-循环过程如下图所示","136":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-2-按时间步展开如下","137":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-3-经典rnn的计算图如下","138":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-4-rnn具体计算公式为","139":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-5-rnn-工程图展示","140":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-6-rnn可扩展到双向的情况-其结构如下","141":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_3-7-rnn扩展到多层构成循环神经网络-结构如下","142":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_4-rnn-应用案例-意图识别","143":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_5-经典rnn-存在的问题","144":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-lstm-long-short-term-memory-长短期记忆网络","145":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-1-lstm-整体结构","146":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-lstm-cell-详解","147":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-1-遗忘门","148":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-2-输入门","149":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-3-cell-state","150":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-4-输出门","151":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-2-5-总结","152":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-3-lstm-cell-具体计算","153":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_6-4-与rnn-类似-lstm-也有双向的","154":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_7-gru-门控循环单元-gated-recurrent-unit","155":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_7-1-lstm-和-gru-对比","156":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_7-2-原理","157":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_7-3-计算过程","158":"/AI/deep_learning_theory/09-recurrent_neural_network.html#_8-参考链接","159":"/AI/deep_learning_theory/10-seq2seq.html#_1-从rnn-到-seq2seq","160":"/AI/deep_learning_theory/10-seq2seq.html#_1-1-rnn-简述","161":"/AI/deep_learning_theory/10-seq2seq.html#_1-2-rnn-应用场景","162":"/AI/deep_learning_theory/10-seq2seq.html#_1-2-1-rnn-解决-n-vs-n-问题","163":"/AI/deep_learning_theory/10-seq2seq.html#_1-2-2-rnn-解决-n-versus-1-问题","164":"/AI/deep_learning_theory/10-seq2seq.html#_1-2-3-rnn-解决-1-vs-n-问题","165":"/AI/deep_learning_theory/10-seq2seq.html#_1-3-n-vs-m-型任务","166":"/AI/deep_learning_theory/10-seq2seq.html#_2-seq2seq-模型","167":"/AI/deep_learning_theory/10-seq2seq.html#_2-1-seq2seq-定义","168":"/AI/deep_learning_theory/10-seq2seq.html#_2-2-seq2seq-模型结构","169":"/AI/deep_learning_theory/10-seq2seq.html#_2-2-1-encoder-decoder-架构","170":"/AI/deep_learning_theory/10-seq2seq.html#_2-2-2-encoder-部分","171":"/AI/deep_learning_theory/10-seq2seq.html#_2-2-3-decoder-部分","172":"/AI/deep_learning_theory/10-seq2seq.html#_2-3-seq2seq-实现举例","173":"/AI/deep_learning_theory/10-seq2seq.html#_3-seq2seq-中的-attention-机制","174":"/AI/deep_learning_theory/10-seq2seq.html#_3-1-seq2seq-中的-attention-机制","175":"/AI/deep_learning_theory/10-seq2seq.html#_4-seq2seq-的工作流程","176":"/AI/deep_learning_theory/10-seq2seq.html#_4-1-预测时流程","177":"/AI/deep_learning_theory/10-seq2seq.html#_4-2-训练时流程","178":"/AI/deep_learning_theory/10-seq2seq.html#_4-2-1-teacher-forcing","179":"/AI/deep_learning_theory/10-seq2seq.html#_4-2-2-scheduled-sampling","180":"/AI/deep_learning_theory/10-seq2seq.html#_4-3-decoder的预训练","181":"/AI/deep_learning_theory/10-seq2seq.html#_5-seq2seq-的损失函数","182":"/AI/deep_learning_theory/10-seq2seq.html#_6-decoding-中的-beam-search","183":"/AI/deep_learning_theory/10-seq2seq.html#_6-1-贪心decoding","184":"/AI/deep_learning_theory/10-seq2seq.html#_6-2-beam-search-原理","185":"/AI/deep_learning_theory/10-seq2seq.html#_6-3-公式分析","186":"/AI/deep_learning_theory/10-seq2seq.html#_6-4-beam-search-分析","187":"/AI/deep_learning_theory/10-seq2seq.html#_7-nlp-从机器学习到深度学习","188":"/AI/deep_learning_theory/10-seq2seq.html#_7-1-nlp-中常见任务","189":"/AI/deep_learning_theory/10-seq2seq.html#_7-2-机器翻译的发展历程","190":"/AI/deep_learning_theory/10-seq2seq.html#_7-3-smt-方法简介","191":"/AI/deep_learning_theory/10-seq2seq.html#_7-4-nmt","192":"/AI/deep_learning_theory/10-seq2seq.html#_8-参考文献","193":"/AI/deep_learning_theory/11-1attentions.html#_1-attention-is-all-you-need","194":"/AI/deep_learning_theory/11-1attentions.html#_2-transformer-model-architecture","195":"/AI/deep_learning_theory/11-1attentions.html#_3-编码器和解码器堆栈","196":"/AI/deep_learning_theory/11-1attentions.html#_3-1-编码器","197":"/AI/deep_learning_theory/11-1attentions.html#_3-2-解码器","198":"/AI/deep_learning_theory/11-1attentions.html#_4-scaled-dot-product-attention-缩放版本的点积注意力","199":"/AI/deep_learning_theory/11-1attentions.html#_4-1-模型结构图","200":"/AI/deep_learning_theory/11-1attentions.html#_4-2-数学公式为","201":"/AI/deep_learning_theory/11-1attentions.html#_4-3-推导过程详解","202":"/AI/deep_learning_theory/11-1attentions.html#_4-2-1-self-attention-的思想","203":"/AI/deep_learning_theory/11-1attentions.html#_4-2-2-自注意的思想","204":"/AI/deep_learning_theory/11-1attentions.html#_4-2-3-自注意机制运算过程","205":"/AI/deep_learning_theory/11-1attentions.html#_4-2-4-写成矩阵的形式","206":"/AI/deep_learning_theory/11-1attentions.html#_4-4-为什么要进行缩放","207":"/AI/deep_learning_theory/11-1attentions.html#_5-multi-head-self-attention","208":"/AI/deep_learning_theory/11-1attentions.html#_5-1-原理简介","209":"/AI/deep_learning_theory/11-1attentions.html#_5-2-公式表达","210":"/AI/deep_learning_theory/11-1attentions.html#_5-3-底层原理","211":"/AI/deep_learning_theory/11-1attentions.html#_5-4-多头的实现细节展示","212":"/AI/deep_learning_theory/11-1attentions.html#_6-实际工程上的-multi-head-attention-详解","213":"/AI/deep_learning_theory/11-1attentions.html#_7-cross-multi-head-attention","214":"/AI/deep_learning_theory/11-1attentions.html#_8-mask-multi-head-attention","215":"/AI/deep_learning_theory/11-1attentions.html#_8-1-padding-mask","216":"/AI/deep_learning_theory/11-1attentions.html#_8-2-sequence-mask","217":"/AI/deep_learning_theory/11-1attentions.html#_9-mqa-multi-query-attention","218":"/AI/deep_learning_theory/11-1attentions.html#_10-大模型神器-gqa-grouped-query-attention","219":"/AI/deep_learning_theory/11-1attentions.html#_10-1-gqa-structure","220":"/AI/deep_learning_theory/11-1attentions.html#_10-2-精度改进-converting-the-checkpoint-and-uptraining","221":"/AI/deep_learning_theory/11-1attentions.html#_11-大模型加速利器-flashattention","222":"/AI/deep_learning_theory/11-1attentions.html#_11-1-原理介绍","223":"/AI/deep_learning_theory/11-1attentions.html#_11-2-标准attention机制的算法实现","224":"/AI/deep_learning_theory/11-1attentions.html#_11-3-flash-attention-算法思想","225":"/AI/deep_learning_theory/11-1attentions.html#_11-4-准备-切片的方式计算softmax","226":"/AI/deep_learning_theory/11-1attentions.html#_11-5-具体flashattention的算法","227":"/AI/deep_learning_theory/11-1attentions.html#flash-attention-效果","228":"/AI/deep_learning_theory/11-1attentions.html#_11-6-重计算-recompute","229":"/AI/deep_learning_theory/11-1attentions.html#_12-flash-attention-2","230":"/AI/deep_learning_theory/11-1attentions.html#_13-大模型推理加速利器-kv-cache","231":"/AI/deep_learning_theory/11-1attentions.html#_14-大模型推理加速利器-page-attention","232":"/AI/deep_learning_theory/11-1attentions.html#_15-参考链接","233":"/AI/deep_learning_theory/12-weight-initialization.html#_1-参数初始化概念-parameters-initialization","234":"/AI/deep_learning_theory/12-weight-initialization.html#_2-参数初始化的重要性","235":"/AI/deep_learning_theory/12-weight-initialization.html#_2-1-为什么参数初始化很重要","236":"/AI/deep_learning_theory/12-weight-initialization.html#_2-1-不合理初始化的问题","237":"/AI/deep_learning_theory/12-weight-initialization.html#_3-全0或常量初始化","238":"/AI/deep_learning_theory/12-weight-initialization.html#_4-随机初始化","239":"/AI/deep_learning_theory/12-weight-initialization.html#_4-1-较小随机值时","240":"/AI/deep_learning_theory/12-weight-initialization.html#_4-2-较大随机初始值时","241":"/AI/deep_learning_theory/12-weight-initialization.html#_4-3-结论","242":"/AI/deep_learning_theory/12-weight-initialization.html#_5-理想的参数初始化","243":"/AI/deep_learning_theory/12-weight-initialization.html#_5-1-参数初始化的必要条件","244":"/AI/deep_learning_theory/12-weight-initialization.html#_5-2-glorot-条件","245":"/AI/deep_learning_theory/12-weight-initialization.html#_6-塞维尔初始化-xavier-initialization","246":"/AI/deep_learning_theory/12-weight-initialization.html#_7-kaiming-initialization","247":"/AI/deep_learning_theory/12-weight-initialization.html#_7-1-方差计算数学基础","248":"/AI/deep_learning_theory/12-weight-initialization.html#_7-2-前向推导过程","249":"/AI/deep_learning_theory/12-weight-initialization.html#_7-3-反向推导过程","250":"/AI/deep_learning_theory/12-weight-initialization.html#_7-4-凯明初始化总结","251":"/AI/deep_learning_theory/12-weight-initialization.html#_7-4-1-服从正态分布时","252":"/AI/deep_learning_theory/12-weight-initialization.html#_7-4-2-服从均匀分布时","253":"/AI/deep_learning_theory/12-weight-initialization.html#_8-初始化策略选择","254":"/AI/deep_learning_theory/12-weight-initialization.html#_9-使用预训练的weight","255":"/AI/deep_learning_theory/12-weight-initialization.html#_10-参考文献","256":"/AI/deep_learning_theory/13-optimizers.html#optimizer-概述","257":"/AI/deep_learning_theory/13-optimizers.html#_1-gradient-descend","258":"/AI/deep_learning_theory/13-optimizers.html#_1-1-梯度下降法概念","259":"/AI/deep_learning_theory/13-optimizers.html#_1-2-梯度下降法三个变种","260":"/AI/deep_learning_theory/13-optimizers.html#_1-2-1-bgd-batch-gradient-descend","261":"/AI/deep_learning_theory/13-optimizers.html#_1-2-2-sgd-stochastic-gradient-descend","262":"/AI/deep_learning_theory/13-optimizers.html#_1-2-3-mini-bgd","263":"/AI/deep_learning_theory/13-optimizers.html#_2-sgd-with-momentum","264":"/AI/deep_learning_theory/13-optimizers.html#_2-1-算法过程","265":"/AI/deep_learning_theory/13-optimizers.html#_2-2-算法图示","266":"/AI/deep_learning_theory/13-optimizers.html#_2-2-特点","267":"/AI/deep_learning_theory/13-optimizers.html#_2-3-作用","268":"/AI/deep_learning_theory/13-optimizers.html#_3-nag-nesterov-accelerated-gradient","269":"/AI/deep_learning_theory/13-optimizers.html#_3-1-算法原理","270":"/AI/deep_learning_theory/13-optimizers.html#_3-2-算法原理图","271":"/AI/deep_learning_theory/13-optimizers.html#_3-3-算法详述","272":"/AI/deep_learning_theory/13-optimizers.html#_4-pytorch-中实现-sgd","273":"/AI/deep_learning_theory/13-optimizers.html#_4-1-算法过程","274":"/AI/deep_learning_theory/13-optimizers.html#_4-2-代码实现","275":"/AI/deep_learning_theory/13-optimizers.html#_5-adagrad-优化算法","276":"/AI/deep_learning_theory/13-optimizers.html#_5-1-自适应学习率的概念","277":"/AI/deep_learning_theory/13-optimizers.html#_5-2-adagrad-算法原理","278":"/AI/deep_learning_theory/13-optimizers.html#_5-3-adagrad-算法","279":"/AI/deep_learning_theory/13-optimizers.html#_5-4-特点","280":"/AI/deep_learning_theory/13-optimizers.html#_5-5-缺点","281":"/AI/deep_learning_theory/13-optimizers.html#_5-6-pytorch-实现","282":"/AI/deep_learning_theory/13-optimizers.html#_6-rmsprop-优化算法","283":"/AI/deep_learning_theory/13-optimizers.html#_6-1-理论基础","284":"/AI/deep_learning_theory/13-optimizers.html#_6-2-算法流程","285":"/AI/deep_learning_theory/13-optimizers.html#_6-3-pytorch-实现","286":"/AI/deep_learning_theory/13-optimizers.html#_7-adadelta","287":"/AI/deep_learning_theory/13-optimizers.html#_7-1-概述","288":"/AI/deep_learning_theory/13-optimizers.html#_7-2-算法流程","289":"/AI/deep_learning_theory/13-optimizers.html#_7-3-pytorch-实现","290":"/AI/deep_learning_theory/13-optimizers.html#_8-不同优化算法效果对比","291":"/AI/deep_learning_theory/13-optimizers.html#_8-1-loss-对比图","292":"/AI/deep_learning_theory/13-optimizers.html#_8-2-收敛过程对比","293":"/AI/deep_learning_theory/13-optimizers.html#_9-adam-优化器","294":"/AI/deep_learning_theory/13-optimizers.html#_9-1-原理概述","295":"/AI/deep_learning_theory/13-optimizers.html#_9-2-算法实现流程","296":"/AI/deep_learning_theory/13-optimizers.html#_9-3-pytorch-实现","297":"/AI/deep_learning_theory/13-optimizers.html#_9-4-效果展示","298":"/AI/deep_learning_theory/13-optimizers.html#_10-adamw","299":"/AI/deep_learning_theory/13-optimizers.html#_10-1-算法原理","300":"/AI/deep_learning_theory/13-optimizers.html#_10-2-pytorch实现","301":"/AI/deep_learning_theory/13-optimizers.html#_11-optimizer-收敛趋势对比图","302":"/AI/deep_learning_theory/13-optimizers.html#_12-参考文献","303":"/AI/deep_learning_theory/11-2attention-extension.html#_1-mqa-multi-query-attention","304":"/AI/deep_learning_theory/11-2attention-extension.html#_2-大模型神器-gqa-grouped-query-attention","305":"/AI/deep_learning_theory/11-2attention-extension.html#_2-1-gqa-structure","306":"/AI/deep_learning_theory/11-2attention-extension.html#_2-2-精度改进-converting-the-checkpoint-and-uptraining","307":"/AI/deep_learning_theory/11-2attention-extension.html#_3-mla-multi-head-latent-attention-boosting-inference-efficiency","308":"/AI/deep_learning_theory/11-2attention-extension.html#_3-1-mla-原理","309":"/AI/deep_learning_theory/11-2attention-extension.html#_3-2-mla-实现逻辑","310":"/AI/deep_learning_theory/11-2attention-extension.html#_4-大模型加速利器-flashattention","311":"/AI/deep_learning_theory/11-2attention-extension.html#_4-1-原理及思想介绍","312":"/AI/deep_learning_theory/11-2attention-extension.html#_4-2-标准attention机制的算法实现","313":"/AI/deep_learning_theory/11-2attention-extension.html#_4-3-准备-切片的方式计算softmax","314":"/AI/deep_learning_theory/11-2attention-extension.html#_4-4-flash-attention-1-算法图解","315":"/AI/deep_learning_theory/11-2attention-extension.html#_4-5-flashattention1-forward-伪代码","316":"/AI/deep_learning_theory/11-2attention-extension.html#_4-6-flashattention1-backward-伪代码","317":"/AI/deep_learning_theory/11-2attention-extension.html#_4-7-flash-attention-效果","318":"/AI/deep_learning_theory/11-2attention-extension.html#_4-8-重计算-recompute","319":"/AI/deep_learning_theory/11-2attention-extension.html#_4-9-flashattention1-的不足之处","320":"/AI/deep_learning_theory/11-2attention-extension.html#_5-flashattention-2-faster-attention-with-better-parallelism-and-work-partitioning","321":"/AI/deep_learning_theory/11-2attention-extension.html#_5-1-softmax-trick-v1-vs-v2","322":"/AI/deep_learning_theory/11-2attention-extension.html#_5-2-forward-pass","323":"/AI/deep_learning_theory/11-2attention-extension.html#_5-3-backward-pass","324":"/AI/deep_learning_theory/11-2attention-extension.html#_5-4-v2-相对于-v1-的改进","325":"/AI/deep_learning_theory/11-2attention-extension.html#_6-flashattention3-fast-and-accurate-attention-with-asynchrony-and-low-precision","326":"/AI/deep_learning_theory/11-2attention-extension.html#_7-ringattention","327":"/AI/deep_learning_theory/11-2attention-extension.html#_7-1-具体实现原理","328":"/AI/deep_learning_theory/11-2attention-extension.html#_8-从ring-attention-到-context-parallel","329":"/AI/deep_learning_theory/11-2attention-extension.html#_9-从context-parallel-到-chunked-pipeline-parallelism","330":"/AI/deep_learning_theory/11-2attention-extension.html#_10-大模型推理加速利器-kv-cache","331":"/AI/deep_learning_theory/11-2attention-extension.html#_11-大模型推理加速利器-page-attention-and-vllm","332":"/AI/deep_learning_theory/11-2attention-extension.html#_11-1-vllm-简介","333":"/AI/deep_learning_theory/11-2attention-extension.html#_11-2-秘密武器-pagedattention","334":"/AI/deep_learning_theory/11-2attention-extension.html#_11-3-优势1-block-无需连续","335":"/AI/deep_learning_theory/11-2attention-extension.html#_11-4-优势2-内存共享","336":"/AI/deep_learning_theory/11-2attention-extension.html#_12-radixattention","337":"/AI/deep_learning_theory/11-2attention-extension.html#_12-1-当前kv-cache","338":"/AI/deep_learning_theory/11-2attention-extension.html#_12-2-redisattention-strategy","339":"/AI/deep_learning_theory/11-2attention-extension.html#_13-参考链接","340":"/AI/deep_learning_theory/14-regularization.html#_1-正则化概念","341":"/AI/deep_learning_theory/14-regularization.html#_2-什么情况下容易出现过拟合","342":"/AI/deep_learning_theory/14-regularization.html#_3-常见的正则化方法","343":"/AI/deep_learning_theory/14-regularization.html#_3-1-参数范数惩罚","344":"/AI/deep_learning_theory/14-regularization.html#_3-2-数据集增强","345":"/AI/deep_learning_theory/14-regularization.html#_3-3-标签平滑-label-smoothing","346":"/AI/deep_learning_theory/14-regularization.html#_3-4-droupout","347":"/AI/deep_learning_theory/14-regularization.html#_3-5-dropconnet","348":"/AI/deep_learning_theory/14-regularization.html#_3-6-dropblock","349":"/AI/deep_learning_theory/14-regularization.html#_3-7-其它正则化方法","350":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#深度学习调优指南中文版","351":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#目录","352":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#这份手册是为谁准备的","353":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#为什么需要这份调优手册","354":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#开始新项目的指南","355":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择模型架构","356":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择优化器","357":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择batchsize","358":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#确定可行的batch-size并估计训练吞吐量","359":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择合适的batch-size以最小化训练时间","360":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择合适的batch-size以最小化资源消耗","361":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#更改batch-size需要重新调整大多数超参数","362":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#batch-norm会对batch-size的选择造成什么影响","363":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择初始配置","364":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#提高模型性能的科学方法","365":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#增量调整策略","366":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#探索与利用","367":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择下一轮实验的目标","368":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#设计下一轮实验","369":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#识别目标超参数、冗余超参数和固定超参数","370":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#创建一组研究","371":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#平衡实验的信息量和成本","372":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#从实验结果中获取经验","373":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#识别错误的搜索空间边界","374":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#没有在搜索空间中采样足够的点","375":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#检查训练曲线","376":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#使用isolation图检测更改是否有用","377":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#自动化常用的绘图","378":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#确定是否采用此训练工作流更改或超参数配置","379":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#探索结束后","380":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#确定每次训练运行的步数","381":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#当训练不受计算限制时如何决定该训练多久","382":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#使用学习率搜索算法来确定-max-train-steps-的初始值","383":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#当训练受计算限制时如何决定该训练多久","384":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#第一轮","385":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#第二轮","386":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#关于训练管道的额外补充","387":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#优化输入管道","388":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#评估模型性能","389":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#评估设置","390":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#设置定期评估","391":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#选择样本进行定期评估","392":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#保存检查点并追溯选择最佳检查点","393":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#设置实验跟踪","394":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#batchnorm的实现细节","395":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#多主机管道的考虑因素","396":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#常见问题的回答","397":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#最好的学习率衰减方案是什么","398":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#我应该使用哪种学习率衰减方案作为默认值","399":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#为什么有些论文有复杂的学习率衰减方案","400":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#adam-的超参数应该如何调整","401":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#为什么在优化的探索阶段使用quasi-random-search而不是更复杂的黑盒优化算法","402":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#在哪里可以找到quasi-random-search的实现","403":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#需要多少次试验才能通过quasi-random-search获得较好的结果","404":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#如何调试和缓解优化失败","405":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#识别不稳定的训练任务","406":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#常见不稳定模式的潜在修复方式","407":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#学习率预热","408":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#何时对学习率进行预热","409":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#如何对学习率进行预热","410":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#梯度截断","411":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#为什么将学习率和其他优化参数称为超参数-它们不是任何先验分布的参数。","412":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#为什么不应该调整batch-size来直接提高验证集性能","413":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#所有流行的优化算法的更新规则是什么","414":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#stochastic-gradient-descent-sgd","415":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#momentum","416":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#nesterov","417":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#rmsprop","418":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#adam","419":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#nadam","420":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#致谢","421":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#引用","422":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#关于贡献","423":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#贡献者许可协议","424":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#代码审核","425":"/AI/deep_learning_theory/15-deep-learning-tuning-guide.html#社区指南","426":"/AI/deep_learning_theory/20-pytorch-tensor.html#_1-创建pytorch-tensor","427":"/AI/deep_learning_theory/20-pytorch-tensor.html#_1-1-用torch-tensor-创建","428":"/AI/deep_learning_theory/20-pytorch-tensor.html#_1-2-直接生成特殊的tensor","429":"/AI/deep_learning_theory/20-pytorch-tensor.html#_1-3-仿照其它tensor生成","430":"/AI/deep_learning_theory/20-pytorch-tensor.html#_1-4-从numpy生成","431":"/AI/deep_learning_theory/20-pytorch-tensor.html#_2-工程实践","432":"/AI/deep_learning_theory/20-pytorch-tensor.html#_3-tensor-中的-to-方法","433":"/AI/deep_learning_theory/20-pytorch-tensor.html#_3-1-数据类型转化","434":"/AI/deep_learning_theory/20-pytorch-tensor.html#_3-2-device-转化","435":"/AI/deep_learning_theory/20-pytorch-tensor.html#_4-tensor-讲解","436":"/AI/deep_learning_theory/20-pytorch-tensor.html#_4-1-两个角度认识-tensor","437":"/AI/deep_learning_theory/20-pytorch-tensor.html#_4-2-代码实践之-视图到底是什么","438":"/AI/deep_learning_theory/20-pytorch-tensor.html#_4-3-代码实践之-tensor-中数据的连续性","439":"/AI/deep_learning_theory/20-pytorch-tensor.html#_5-tensor-运算的几种主要类型","440":"/AI/deep_learning_theory/20-pytorch-tensor.html#_6-tensor-的属性全解","441":"/AI/deep_learning_theory/20-pytorch-tensor.html#_7-外层-tensor-方法汇总","442":"/AI/deep_learning_theory/20-pytorch-tensor.html#_8-tensorbase-方法汇总","443":"/AI/deep_learning_theory/20-pytorch-tensor.html#_8-1-魔术方法-基本运算符-构造函数-索引","444":"/AI/deep_learning_theory/20-pytorch-tensor.html#_8-2-私有方法","445":"/AI/deep_learning_theory/20-pytorch-tensor.html#_8-3-tensor-的-对外api接口","446":"/AI/deep_learning_theory/21-pytorch-autograd.html#_1-pytorch-autograd-原理概述","447":"/AI/deep_learning_theory/21-pytorch-autograd.html#_1-1-原理概述","448":"/AI/deep_learning_theory/21-pytorch-autograd.html#_1-2-实现细节","449":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-pytorch-代码实现","450":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-1-pytorch-autograd-展示","451":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-2-require-grad-的自动推理机制","452":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-3-detach-隔离功能","453":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-4-控制梯度计算","454":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-5-梯度累加和清0","455":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-6-小心-inplace-op","456":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-7-pytorch-autograd-解方程","457":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-8-保存中间-activation-tensor-的梯度","458":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-9-customer-自定义自己的反向传播函数","459":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-10-多维tensor-如何backward","460":"/AI/deep_learning_theory/21-pytorch-autograd.html#_2-11-example-train-a-model-with-two-mlp-layers","461":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-要点总结","462":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-1-自动微分机制-auto-grad-重点","463":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-2-反向传播算法","464":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-3-tensor-的梯度","465":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-4-反向求导原理","466":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-5-动态图机制","467":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-6-auto-grad-机制不足","468":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-7-autograd是什么","469":"/AI/deep_learning_theory/21-pytorch-autograd.html#_3-8-grad-fun","470":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-pytorch-autograd-自动微分机制-extension-了解即可-不需要掌握","471":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-1-自动微分如何编码历史记录","472":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-2-saved-tensors","473":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-3-对于不可微分的函数的梯度计算","474":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-4-局部禁用梯度计算","475":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-5-设置-requires-grad","476":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-6-梯度模式","477":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-6-1-默认模式-grad-mode","478":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-6-2-无梯度模式","479":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-6-3-推断模式-inference-mode","480":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-6-4-评估模式-nn-module-eval","481":"/AI/deep_learning_theory/21-pytorch-autograd.html#_4-7-in-place-operations-with-autograd","482":"/AI/deep_learning_theory/22-pytorch-module.html#torch-nn-module","483":"/AI/deep_learning_theory/22-pytorch-module.html#_1-pytorch-自带的-torch-nn-layer","484":"/AI/deep_learning_theory/22-pytorch-module.html#_1-1-用-torch-nn-解决之前的问题","485":"/AI/deep_learning_theory/22-pytorch-module.html#_1-2-tensor-和-parameter-的区别","486":"/AI/deep_learning_theory/22-pytorch-module.html#_2-定义我们自己的module","487":"/AI/deep_learning_theory/22-pytorch-module.html#_2-1-代码案例","488":"/AI/deep_learning_theory/22-pytorch-module.html#_2-2-customer-layer-要点","489":"/AI/deep_learning_theory/22-pytorch-module.html#_3-nn-module-中的容器","490":"/AI/deep_learning_theory/22-pytorch-module.html#_4-nn-module-属性详解","491":"/AI/deep_learning_theory/22-pytorch-module.html#_5-torch-nn-module-常用功能","492":"/AI/deep_learning_theory/22-pytorch-module.html#_5-1-parameters-设置机制","493":"/AI/deep_learning_theory/22-pytorch-module.html#_5-2-buffers-功能展示","494":"/AI/deep_learning_theory/22-pytorch-module.html#_5-3-前向钩子函数展示","495":"/AI/deep_learning_theory/22-pytorch-module.html#_5-4-反向钩子函数展示","496":"/AI/deep_learning_theory/22-pytorch-module.html#_6-nn-module-方法全解","497":"/AI/deep_learning_theory/23-1training-example-1.html#_1-端到端训练一个深度学习模型","498":"/AI/deep_learning_theory/23-2decoder.html#decoder","499":"/AI/deep_learning_theory/23-3encoder.html#encoder-layer","500":"/AI/deep_learning_theory/23-4transformer.html#transformer-demo","501":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_0-torch-optim","502":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_1-如何使用torch-optim","503":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_1-1-创建一个优化器对象","504":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_1-2-逐参数选项-per-parameter-options","505":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_1-3-进行优化步骤","506":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_2-torch-optim-base-class-introduce","507":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_2-1-torch-optim-optimizer-的输入参数","508":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_2-2-torch-optim-optimizer-属性","509":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_2-3-torch-optim-optimizer-方法","510":"/AI/deep_learning_theory/24-pytorch-optimizer.html#_3-不同实现与性能优化","511":"/AI/deep_learning_theory/27-pytorch-model-save.html#_1-tensor-的保存和加载","512":"/AI/deep_learning_theory/27-pytorch-model-save.html#_2-模型状态的保存","513":"/AI/deep_learning_theory/27-pytorch-model-save.html#_2-1-定义一个模型","514":"/AI/deep_learning_theory/27-pytorch-model-save.html#_2-2-保存模型的状态","515":"/AI/deep_learning_theory/27-pytorch-model-save.html#_2-3-加载模型的状态","516":"/AI/deep_learning_theory/27-pytorch-model-save.html#_2-4-思考与尝试","517":"/AI/deep_learning_theory/27-pytorch-model-save.html#_3-保存与加载模型","518":"/AI/deep_learning_theory/27-pytorch-model-save.html#_3-1-保存模型","519":"/AI/deep_learning_theory/27-pytorch-model-save.html#_3-2-加载模型","520":"/AI/deep_learning_theory/27-pytorch-model-save.html#_3-3-思考与尝试","521":"/AI/deep_learning_theory/27-pytorch-model-save.html#_4-训练中的保存和加载","522":"/AI/deep_learning_theory/27-pytorch-model-save.html#_4-1-保存训练中的状态","523":"/AI/deep_learning_theory/27-pytorch-model-save.html#_4-2-加载训练中的状态","524":"/AI/deep_learning_theory/27-pytorch-model-save.html#_5-保存和加载模型的静态图","525":"/AI/deep_learning_theory/27-pytorch-model-save.html#_5-1-保存模型静态图","526":"/AI/deep_learning_theory/27-pytorch-model-save.html#_5-2-加载模型静态图","527":"/AI/deep_learning_theory/27-pytorch-model-save.html#_6-通用格式onnx的保存","528":"/AI/deep_learning_theory/27-pytorch-model-save.html#_6-1-保存onnx-静态图模型","529":"/AI/deep_learning_theory/27-pytorch-model-save.html#_6-2-运行onnx-模型","530":"/AI/deep_learning_theory/27-pytorch-model-save.html#_6-3-shape-infer","531":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#learning-rate-调整方案","532":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_2-pytorch中-torch-optim-lr-scheduler-使用方法","533":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_2-1-使用方法","534":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-学习率调度器-策略全解-learning-rate-scheduler","535":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-1-lr-scheduler-lambdalr","536":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-2-lr-scheduler-multiplicativelr","537":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-3-lr-scheduler-steplr","538":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-4-lr-scheduler-multisteplr","539":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-5-lr-scheduler-constantlr","540":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-6-lr-scheduler-linearlr","541":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-7-lr-scheduler-exponentiallr","542":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-8-lr-scheduler-polynomiallr","543":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-9-lr-scheduler-cycliclr","544":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-10-lr-scheduler-onecyclelr","545":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-11-lr-scheduler-cosineannealinglr","546":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-12-lr-scheduler-cosineannealingwarmrestarts","547":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-13-reducelronplateau","548":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-14-lr-scheduler-chainedscheduler","549":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_3-15-lr-scheduler-sequentiallr","550":"/AI/deep_learning_theory/25-pytorch-lr-scheduler.html#_4-探索源码","551":"/AI/deep_learning_theory/26-pytorch-dataloader.html#_1-dataset","552":"/AI/deep_learning_theory/26-pytorch-dataloader.html#_2-定义自己的数据集","553":"/AI/deep_learning_theory/26-pytorch-dataloader.html#_3-torch-中的-dataloader","554":"/AI/deep_learning_theory/26-pytorch-dataloader.html#_4-torchvision","555":"/AI/deep_learning_theory/26-pytorch-dataloader.html#_4-1-torchvision-中的dataset","556":"/AI/deep_learning_theory/26-pytorch-dataloader.html#torchvision-中的-transforms","557":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_1-pytorch-几种模式概览","558":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_1-1-pytorch-不仅仅是动态图","559":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_1-2-理解动态图和静态图","560":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_1-3-静态图的优势","561":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_2-几种模式简介","562":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_2-1-fx-图","563":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_2-2-torch-jit-script","564":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_2-3-torch-jit-trace","565":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_2-4-torch-compile","566":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_3-案例","567":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_3-1-模型准备","568":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_3-2-jit-script-代码展示","569":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_3-3-jit-traced-代码展示","570":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_4-export-to-onnx","571":"/AI/deep_learning_theory/29-pytorch-graph-mode.html#_5-compile-to-graph-dynamo","572":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_1-tensorboard-介绍","573":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_2-安装方式","574":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_3-抓取log","575":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_3-1-import-summarywriter","576":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_3-2-plot-scalar","577":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_3-3-plot-loss-and-accuracy","578":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_4-执行方式","579":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_5-查看graph","580":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_6-查看特征图","581":"/AI/deep_learning_theory/28-pytorch-tensorboard.html#_7-性能分析profiler","582":"/AI/deep_learning_theory/30-training-example-2.html#_1-imagenet-training-in-pytorch","583":"/AI/deep_learning_theory/30-training-example-2.html#_2-requirements","584":"/AI/deep_learning_theory/30-training-example-2.html#_3-数据集下载","585":"/AI/deep_learning_theory/30-training-example-2.html#_4-training","586":"/AI/deep_learning_theory/30-training-example-2.html#use-dummy-data","587":"/AI/deep_learning_theory/30-training-example-2.html#multi-processing-distributed-data-parallel-training","588":"/AI/deep_learning_theory/30-training-example-2.html#single-node-multiple-gpus","589":"/AI/deep_learning_theory/30-training-example-2.html#multiple-nodes","590":"/AI/deep_learning_theory/30-training-example-2.html#usage","591":"/AI/deep_learning_theory/42-1stable-diffusion.html#_1-代码介绍","592":"/AI/deep_learning_theory/42-1stable-diffusion.html#_2-代码复现步骤","593":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-stable-diffusion-整体结构","594":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-1-整体流程图","595":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-2-sd-训练流程图","596":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-3-sd-推理流程图","597":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-4-clip-原理图","598":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-5-latent-space","599":"/AI/deep_learning_theory/42-1stable-diffusion.html#_3-6-noiser-and-denoiser","600":"/AI/deep_learning_theory/42-1stable-diffusion.html#_4-stable-diffusion-具体模型结构","601":"/AI/deep_learning_theory/42-1stable-diffusion.html#_4-1-clip-结构","602":"/AI/deep_learning_theory/42-1stable-diffusion.html#_4-2-vae-模型结构","603":"/AI/deep_learning_theory/42-1stable-diffusion.html#_4-2-unet-base-模型结构图","604":"/AI/deep_learning_theory/42-1stable-diffusion.html#_5-评价指标","605":"/AI/deep_learning_theory/42-1stable-diffusion.html#_5-1-clip-score","606":"/AI/deep_learning_theory/42-1stable-diffusion.html#_5-2-fid","607":"/AI/deep_learning_theory/42-1stable-diffusion.html#_6-sd-进阶","608":"/AI/deep_learning_theory/42-1stable-diffusion.html#_6-1-sd2-之前版本异同","609":"/AI/deep_learning_theory/42-1stable-diffusion.html#_6-2-从-sd-到-sdxl","610":"/AI/deep_learning_theory/42-1stable-diffusion.html#_6-参考链接","611":"/AI/deep_learning_theory/42-2SDXL.html#sdxl","612":"/AI/deep_learning_theory/42-2SDXL.html#参考链接","613":"/AI/deep_learning_theory/40-ner.html#_1-模型跑通","614":"/AI/deep_learning_theory/40-ner.html#_2-bert-介绍","615":"/AI/deep_learning_theory/40-ner.html#_3-transformer-发展脉络","616":"/AI/deep_learning_theory/40-ner.html#_3-1-transformer-概述","617":"/AI/deep_learning_theory/40-ner.html#_3-2-迁移学习","618":"/AI/deep_learning_theory/40-ner.html#_3-3-transformer-家族","619":"/AI/deep_learning_theory/40-ner.html#_3-4-encoder-分支","620":"/AI/deep_learning_theory/40-ner.html#_3-5-decoder-分支","621":"/AI/deep_learning_theory/40-ner.html#_3-6-encoder-decoder-分支","622":"/AI/deep_learning_theory/40-ner.html#_3-7-大模型的爆发","623":"/AI/deep_learning_theory/40-ner.html#_4-bert-crf-conditional-random-field-实现命名实体识别-ner-任务","624":"/AI/deep_learning_theory/40-ner.html#_4-1-任务概述","625":"/AI/deep_learning_theory/40-ner.html#_4-2-crf-原理详解","626":"/AI/deep_learning_theory/40-ner.html#_4-2-1-线性crf的定义","627":"/AI/deep_learning_theory/40-ner.html#_4-2-2-发射分数","628":"/AI/deep_learning_theory/40-ner.html#_4-2-3-转移分数","629":"/AI/deep_learning_theory/40-ner.html#_4-2-4-crf-的损失函数计算","630":"/AI/deep_learning_theory/40-ner.html#_4-2-5-crf的viterbi解码","631":"/AI/deep_learning_theory/40-ner.html#_5-代码详解","632":"/AI/deep_learning_theory/40-ner.html#_5-1-真实路径得分计算","633":"/AI/deep_learning_theory/40-ner.html#_5-2-总路径得分计算","634":"/AI/deep_learning_theory/40-ner.html#_5-3-viterbi-解码过程","635":"/AI/deep_learning_theory/40-ner.html#_5-4-f1-score-的计算","636":"/AI/deep_learning_theory/41-question-answering.html#_1-模型跑通","637":"/AI/deep_learning_theory/41-question-answering.html#_2-t5-介绍","638":"/AI/deep_learning_theory/41-question-answering.html#_3-position-embedding-总结","639":"/AI/deep_learning_theory/41-question-answering.html#_3-1-绝对位置编码","640":"/AI/deep_learning_theory/41-question-answering.html#_3-1-1-三角函数式-sinusoidal-位置编码","641":"/AI/deep_learning_theory/41-question-answering.html#_3-1-2-可学习-learnable-的位置编码","642":"/AI/deep_learning_theory/41-question-answering.html#_3-2-相对位置编码","643":"/AI/deep_learning_theory/41-question-answering.html#_3-2-1-经典的相对位置编码","644":"/AI/deep_learning_theory/41-question-answering.html#_3-2-2-t5-中的相对位置编码","645":"/AI/deep_learning_theory/41-question-answering.html#_3-3-旋转位置编码","646":"/AI/deep_learning_theory/41-question-answering.html#_3-3-1-rope-原理","647":"/AI/deep_learning_theory/41-question-answering.html#_3-3-2-2-维扩展到多维","648":"/AI/deep_learning_theory/41-question-answering.html#_3-3-3-rope-的高效计算","649":"/AI/deep_learning_theory/41-question-answering.html#_3-3-4-llama-中的rope-代码实现","650":"/AI/deep_learning_theory/42-3VAE.html#vae","651":"/AI/deep_learning_theory/42-3VAE.html#_1-vae-的作用-数据压缩和数据生成","652":"/AI/deep_learning_theory/42-3VAE.html#_1-1-数据压缩","653":"/AI/deep_learning_theory/42-3VAE.html#_1-2-数据生成","654":"/AI/deep_learning_theory/42-3VAE.html#_1-3-数据压缩与数据生成的关系","655":"/AI/deep_learning_theory/42-3VAE.html#_1-4-example","656":"/AI/deep_learning_theory/42-3VAE.html#_1-5-可能出现的问题","657":"/AI/deep_learning_theory/42-3VAE.html#_1-6-vae-要点总结","658":"/AI/deep_learning_theory/42-3VAE.html#_2-理论推导vae","659":"/AI/deep_learning_theory/42-3VAE.html#_2-1-引入变分","660":"/AI/deep_learning_theory/42-3VAE.html#_4-参考文献","661":"/AI/deep_learning_theory/44-scaling-law.html#scaling-laws-for-neural-language-models","662":"/AI/deep_learning_theory/45-distribute-training.html#how-to-training-realy-large-model","663":"/AI/deep_learning_theory/46-nlp-llama.html#_1-llama-v1","664":"/AI/deep_learning_theory/46-nlp-llama.html#_2-llama-v2","665":"/AI/deep_learning_theory/46-nlp-llama.html#_3-llama-v3","666":"/AI/deep_learning_theory/46-nlp-llama.html#_4-llama-code-implement","667":"/AI/deep_learning_theory/47-nlp-deepseek.html#deepseek-v2","668":"/AI/deep_learning_theory/47-nlp-deepseek.html#deepseek-moe","669":"/AI/deep_learning_theory/47-nlp-deepseek.html#deepseek-v3","670":"/AI/deep_learning_theory/47-nlp-deepseek.html#deepseek-r1","671":"/AI/deep_learning_theory/#deep-learning-theroy","672":"/AI/#ai时代的算法学习","673":"/IT-learning/408知识/#_408知识","674":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_4-1-进程同步","675":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-基本概念","676":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-1为什么要提出","677":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-2-同步是什么","678":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-3-什么又是互斥","679":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-4-临界资源是啥","680":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-4-1-系统资源","681":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-4-2-临界资源-共享资源","682":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_1-4-3-临界区","683":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-同步如何实现","684":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-1-访问原则","685":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-2-软件实现-后续补充","686":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-2-1-单标志法","687":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-2-2-双标志先检查法","688":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-2-3-双标志后检查法","689":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-3-硬件实现-后续补充","690":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-3-1-中断屏蔽方法","691":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-3-2-test-and-set-ts指令-tsl指令","692":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-3-3-swap指令-exchange-xchg指令","693":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_2-3-4-信号量机制-重点-下一节详细讲解","694":"/IT-learning/408知识/操作系统/4.1 进程同步.html#_3-参考资料","695":"/IT-learning/408知识/操作系统/4.4 信号量机制pv操作之“可见”.html#_4-4-信号量机制pv操作之-可见","696":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#书籍推荐-——程序是怎样跑起来的","697":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_1-推荐原因1","698":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_2-推荐原因2","699":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_3-推荐原因3","700":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_4-推荐原因4","701":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_5-本书大概内容","702":"/IT-learning/408知识/碎片知识/01.程序是怎样跑起来的.html#_6-如何阅读该书","703":"/IT-learning/Java/01.java-se.html#javase-简介","704":"/IT-learning/Java/01.java-se.html#javase-核心概念","705":"/IT-learning/Java/01.java-se.html#_1-jdk、jre、jvm","706":"/IT-learning/Java/01.java-se.html#_2-java-基础语法","707":"/IT-learning/Java/#java-后端学习框架","708":"/IT-learning/Java/#_1-java-基础","709":"/IT-learning/Java/#_2-数据库基础","710":"/IT-learning/Java/#_3-java-web-开发","711":"/IT-learning/Java/#_4-mybatis","712":"/IT-learning/Java/#_5-spring","713":"/IT-learning/Java/#_6-spring-mvc","714":"/IT-learning/Java/#_7-sprintboot","715":"/IT-learning/Java/#_8-消息中间件","716":"/IT-learning/Java/#_9-部署与监控","717":"/IT-learning/Java/#_10-进阶主题","718":"/IT-learning/Java/#参考资料","719":"/IT-learning/Java/05.MyBatis.html#mybatis框架","720":"/IT-learning/Java/05.MyBatis.html#_01、mybatis简介","721":"/IT-learning/Java/05.MyBatis.html#_1-1、什么是mybatis","722":"/IT-learning/Java/05.MyBatis.html#_1-2、持久化","723":"/IT-learning/Java/05.MyBatis.html#_1-3、持久层","724":"/IT-learning/Java/05.MyBatis.html#_1-4、为什么需要mybatis","725":"/IT-learning/Java/05.MyBatis.html#_02、mybatis第一个程序","726":"/IT-learning/Java/05.MyBatis.html#_2-1、代码演示","727":"/IT-learning/Java/05.MyBatis.html#_2-2、问题说明","728":"/IT-learning/Java/05.MyBatis.html#_03、crud操作","729":"/IT-learning/Java/05.MyBatis.html#_3-1、namespace","730":"/IT-learning/Java/05.MyBatis.html#_3-2、select","731":"/IT-learning/Java/05.MyBatis.html#_3-3、insert","732":"/IT-learning/Java/05.MyBatis.html#_3-4、update","733":"/IT-learning/Java/05.MyBatis.html#_3-5、delete","734":"/IT-learning/Java/05.MyBatis.html#_3-6、思考题","735":"/IT-learning/Linux/01.Linux基础.html#linux基础部分","736":"/IT-learning/Linux/01.Linux基础.html#一、基本命令使用","737":"/IT-learning/Linux/01.Linux基础.html#_1-linux-文件系统结构","738":"/IT-learning/Linux/01.Linux基础.html#简介","739":"/IT-learning/Linux/01.Linux基础.html#常用目录","740":"/IT-learning/Linux/01.Linux基础.html#示例","741":"/IT-learning/Linux/01.Linux基础.html#_2-基本命令操作","742":"/IT-learning/Linux/01.Linux基础.html#文件和目录管理","743":"/IT-learning/Linux/01.Linux基础.html#文件操作","744":"/IT-learning/Linux/01.Linux基础.html#_3-文件权限管理","745":"/IT-learning/Linux/01.Linux基础.html#权限表示","746":"/IT-learning/Linux/01.Linux基础.html#查看和修改权限","747":"/IT-learning/Linux/01.Linux基础.html#_4-文本查看","748":"/IT-learning/Linux/01.Linux基础.html#查看文本文件","749":"/IT-learning/Linux/01.Linux基础.html#查找内容","750":"/IT-learning/Linux/01.Linux基础.html#_5-vim-编辑器基础","751":"/IT-learning/Linux/01.Linux基础.html#_5-1-进入退出","752":"/IT-learning/Linux/01.Linux基础.html#_5-2-模式","753":"/IT-learning/Linux/01.Linux基础.html#_5-3-基本操作","754":"/IT-learning/Linux/01.Linux基础.html#_6-进程管理","755":"/IT-learning/Linux/01.Linux基础.html#查看进程","756":"/IT-learning/Linux/01.Linux基础.html#管理进程","757":"/IT-learning/Linux/01.Linux基础.html#示例-1","758":"/IT-learning/Linux/01.Linux基础.html#_7-网络管理","759":"/IT-learning/Linux/01.Linux基础.html#查看网络配置","760":"/IT-learning/Linux/01.Linux基础.html#查看网络端口","761":"/IT-learning/Linux/01.Linux基础.html#抓取网页内容","762":"/IT-learning/Linux/01.Linux基础.html#_8-用户和组管理","763":"/IT-learning/Linux/01.Linux基础.html#用户管理","764":"/IT-learning/Linux/01.Linux基础.html#_9-文件查找","765":"/IT-learning/Linux/01.Linux基础.html#查找文件","766":"/IT-learning/Linux/01.Linux基础.html#查找可执行文件","767":"/IT-learning/Linux/01.Linux基础.html#_10-归档与压缩","768":"/IT-learning/Linux/01.Linux基础.html#打包和解压","769":"/IT-learning/Linux/01.Linux基础.html#_11-系统更新与软件管理","770":"/IT-learning/Linux/01.Linux基础.html#更新系统和安装软件包","771":"/IT-learning/Linux/01.Linux基础.html#_12-日志管理","772":"/IT-learning/Linux/01.Linux基础.html#查看日志","773":"/IT-learning/Linux/01.Linux基础.html#二、vim操作命令","774":"/IT-learning/Linux/01.Linux基础.html#_1-vim-模式简介","775":"/IT-learning/Linux/01.Linux基础.html#_2-启动和退出-vim","776":"/IT-learning/Linux/01.Linux基础.html#启动","777":"/IT-learning/Linux/01.Linux基础.html#退出","778":"/IT-learning/Linux/01.Linux基础.html#_3-插入模式操作","779":"/IT-learning/Linux/01.Linux基础.html#_4-普通模式基础操作","780":"/IT-learning/Linux/01.Linux基础.html#光标移动","781":"/IT-learning/Linux/01.Linux基础.html#删除操作","782":"/IT-learning/Linux/01.Linux基础.html#复制和粘贴","783":"/IT-learning/Linux/01.Linux基础.html#撤销与重做","784":"/IT-learning/Linux/01.Linux基础.html#_5-可视模式-选择操作","785":"/IT-learning/Linux/01.Linux基础.html#_6-查找与替换","786":"/IT-learning/Linux/01.Linux基础.html#查找","787":"/IT-learning/Linux/01.Linux基础.html#替换","788":"/IT-learning/Linux/01.Linux基础.html#_7-多文件和多窗口操作","789":"/IT-learning/Linux/01.Linux基础.html#打开多个文件","790":"/IT-learning/Linux/01.Linux基础.html#分屏操作","791":"/IT-learning/Linux/01.Linux基础.html#_8-文本缩进和格式调整","792":"/IT-learning/Linux/01.Linux基础.html#自动缩进","793":"/IT-learning/Linux/01.Linux基础.html#格式化代码","794":"/IT-learning/Linux/03.MPI并行计算.html#mpi并行计算","795":"/IT-learning/Linux/03.MPI并行计算.html#一、并行的引入","796":"/IT-learning/Linux/03.MPI并行计算.html#_1-1-基本概念","797":"/IT-learning/Linux/03.MPI并行计算.html#_1-2-什么是并行","798":"/IT-learning/Linux/03.MPI并行计算.html#_1-3-并行有啥用","799":"/IT-learning/Linux/03.MPI并行计算.html#_1-4-并行的实际案例","800":"/IT-learning/Linux/03.MPI并行计算.html#二、并行的类型","801":"/IT-learning/Linux/03.MPI并行计算.html#_2-1-按照处理机划分","802":"/IT-learning/Linux/03.MPI并行计算.html#_2-2-按照实现方式划分","803":"/IT-learning/Linux/03.MPI并行计算.html#三、mpi的基本原理","804":"/IT-learning/Linux/03.MPI并行计算.html#_3-1-基本原理","805":"/IT-learning/Linux/03.MPI并行计算.html#_1-mpi的架构","806":"/IT-learning/Linux/03.MPI并行计算.html#_2-进程和通信","807":"/IT-learning/Linux/03.MPI并行计算.html#_3-mpi的通信模式","808":"/IT-learning/Linux/03.MPI并行计算.html#_4-mpi的基本函数","809":"/IT-learning/Linux/03.MPI并行计算.html#_5-mpi的数据类型和消息标签","810":"/IT-learning/Linux/03.MPI并行计算.html#_6-通信域-communicator","811":"/IT-learning/Linux/03.MPI并行计算.html#_7-mpi中的常见通信模式","812":"/IT-learning/Linux/03.MPI并行计算.html#_8-mpi的优势和劣势","813":"/IT-learning/Linux/03.MPI并行计算.html#_3-2-模型演示","814":"/IT-learning/Linux/03.MPI并行计算.html#四、基本环境配置-简略","815":"/IT-learning/Linux/03.MPI并行计算.html#_4-1-linux环境","816":"/IT-learning/Linux/03.MPI并行计算.html#_4-2-ssh工具","817":"/IT-learning/Linux/03.MPI并行计算.html#_4-3-vim编辑器","818":"/IT-learning/Linux/03.MPI并行计算.html#_4-4-mpi环境","819":"/IT-learning/Linux/03.MPI并行计算.html#_4-4-1-安装","820":"/IT-learning/Linux/03.MPI并行计算.html#_4-4-2-编译","821":"/IT-learning/Linux/03.MPI并行计算.html#_4-4-3-配置","822":"/IT-learning/Linux/03.MPI并行计算.html#_4-4-4-了解","823":"/IT-learning/Linux/03.MPI并行计算.html#五、mpi的基本使用","824":"/IT-learning/Linux/03.MPI并行计算.html#_5-1-快速使用","825":"/IT-learning/Linux/03.MPI并行计算.html#_5-2-源码了解","826":"/IT-learning/Linux/03.MPI并行计算.html#_5-3-进阶","827":"/IT-learning/Linux/03.MPI并行计算.html#_5-3-1-分布式实现","828":"/IT-learning/Linux/03.MPI并行计算.html#六、学习策略与建议","829":"/IT-learning/Linux/03.MPI并行计算.html#_6-1-新东西学习","830":"/IT-learning/Linux/03.MPI并行计算.html#_6-2-遇事不决","831":"/IT-learning/Linux/03.MPI并行计算.html#_6-3-知识体系构建","832":"/IT-learning/Linux/#linux模块","833":"/IT-learning/#it学习指南","834":"/IT-learning/计算机图形学/02.直线光栅化.html#yi直线光栅化","835":"/IT-learning/计算机图形学/02.直线光栅化.html#_1-引入","836":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-实现","837":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-1-基本实现思路","838":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-2-数值微分法-dda算法","839":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-2-1-dda-算法概述","840":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-2-2-算法步骤","841":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-2-3-伪代码演示","842":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-2-4-优化方向","843":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-中心点画线法","844":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-1-算法思想","845":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-2-算法步骤","846":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-3-举例","847":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-4-伪代码演示","848":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-bresenham算法","849":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-1-基本思想","850":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-2-改进策略","851":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-3-伪代码实现","852":"/IT-learning/计算机图形学/02.直线光栅化.html#_2-3-4-举例","853":"/IT-learning/计算机图形学/02.直线光栅化.html#_3-思考","854":"/README.html#码医森","855":"/README.html#主页","856":"/README.html#站点大纲","857":"/IT-learning/计算机图形学/#计算机图形学的主要内容","858":"/IT-learning/计算机图形学/#为什么要学习计算机图形学","859":"/IT-learning/计算机图形学/#最新研究内容和成果","860":"/guide/博客结构.html#该站点的整体结构","861":"/guide/博客结构.html#主页","862":"/guide/博客结构.html#站点大纲","863":"/improve/#个人提升","864":"/guide/#整体该博客-站点-指南","865":"/update/更新日志.html#更新日志","866":"/update/更新日志.html#_2024-10","867":"/update/更新日志.html#大更新","868":"/update/更新日志.html#小更新","869":"/update/更新日志.html#_2024-11","870":"/update/更新日志.html#大更新-1","871":"/update/更新日志.html#小更新-1","872":"/update/更新日志.html#_2025-03","873":"/update/更新日志.html#大更新-2","874":"/update/更新日志.html#小更新-2","875":"/我的感悟/2024/不同商家的视野.html#不同商家之间的视野——带室友修电脑","876":"/我的感悟/2024/学而篇.html#论语之悟——学而篇","877":"/我的感悟/2024/学而篇.html#_1-学而时习之","878":"/我的感悟/2024/学而篇.html#_1-1-个人参悟","879":"/我的感悟/2024/学而篇.html#_1-2-不解之言","880":"/我的感悟/2024/重温士兵突击.html#士兵突击告诉让我明白的那些事","881":"/我的感悟/#站长随笔","882":"/我的感悟/#更新进度","883":"/技术问题清单/doccano账户管理.html#docker下的doccano添加普通用户","884":"/技术问题清单/doccano账户管理.html#_1-操作步骤","885":"/技术问题清单/doccano账户管理.html#_1-1-启动docker的doccano","886":"/技术问题清单/doccano账户管理.html#_1-2-进入doccano容器","887":"/技术问题清单/doccano账户管理.html#_1-3-配置-添加-超级管理员或者普通管理员账号","888":"/技术问题清单/doccano账户管理.html#_1-3-1-管理员账户","889":"/技术问题清单/doccano账户管理.html#_1-3-2-普通用户账户","890":"/技术问题清单/专英翻转课堂—PyTorch.html#introduction-to-pytorch","891":"/技术问题清单/专英翻转课堂—PyTorch.html#_1-what-is-pytorch","892":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-key-features-of-pytorch","893":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-1-dynamic-computation-graphs","894":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-2-autograd-automatic-gradient-calculation","895":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-3-tensors","896":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-4-easy-to-use-with-python","897":"/技术问题清单/专英翻转课堂—PyTorch.html#_2-5-rich-ecosystem-of-libraries","898":"/技术问题清单/专英翻转课堂—PyTorch.html#_3-the-application-domains-of-pytorch","899":"/技术问题清单/专英翻转课堂—PyTorch.html#_3-1-research","900":"/技术问题清单/专英翻转课堂—PyTorch.html#_3-2-industry","901":"/技术问题清单/专英翻转课堂—PyTorch.html#_3-3-education","902":"/技术问题清单/专英翻转课堂—PyTorch.html#_4-how-to-use-pytorch","903":"/技术问题清单/专英翻转课堂—PyTorch.html#_4-1-official-tutorials","904":"/技术问题清单/专英翻转课堂—PyTorch.html#_4-2-basic-framework","905":"/技术问题清单/专英翻转课堂—PyTorch.html#_5-conclusion","906":"/技术问题清单/#各类技术问题和踩坑","907":"/我的感悟/2024/#更新日志","908":"/技术问题清单/虚拟机网络问题.html#有关虚拟机创建的网络问题","909":"/技术问题清单/虚拟机网络问题.html#_1-基础环境","910":"/技术问题清单/虚拟机网络问题.html#_2-相关知识","911":"/技术问题清单/虚拟机网络问题.html#_3-常见网络问题","912":"/技术问题清单/虚拟机网络问题.html#_4-解决方案","913":"/技术问题清单/虚拟机网络问题.html#_4-1-法一-在物理主机开启nat和dhcp服务","914":"/技术问题清单/虚拟机网络问题.html#_4-2-法二-恢复默认网络配置","915":"/技术问题清单/虚拟机网络问题.html#_5-固定虚拟机网络ip-自动ip分配的可以不用操作","916":"/生活与算法/#生活与算法","917":"/生活与算法/#_1-什么是算法","918":"/生活与算法/#_2-生活中常常有算法","919":"/生活与算法/#_2-1-选择顺序-排队和优先处理","920":"/生活与算法/#_2-2-找东西-生活中的搜索","921":"/生活与算法/#_2-3-每次都选最佳-贪心法则","922":"/生活与算法/#_2-4-长远规划-逐步优化的过程","923":"/生活与算法/#_3-生活离不开算法思维","924":"/生活与算法/#_3-1-化繁为简-一步步来","925":"/生活与算法/#_3-2-避免错误-逻辑推理","926":"/生活与算法/#_3-3-时间管理-高效完成任务","927":"/生活与算法/#_4-算法交织于生活","928":"/生活与算法/#_5-简单总结一下","929":"/生活与算法/贪心算法/2.初步感受贪心.html#让我们简单步入-贪心-叭","930":"/生活与算法/贪心算法/2.初步感受贪心.html#_1-最大四位数的例子-从数字中选最大","931":"/生活与算法/贪心算法/2.初步感受贪心.html#_1-1-问题","932":"/生活与算法/贪心算法/2.初步感受贪心.html#_1-2-贪心思维","933":"/生活与算法/贪心算法/2.初步感受贪心.html#_1-3-数学过程","934":"/生活与算法/贪心算法/2.初步感受贪心.html#_1-4-结论","935":"/生活与算法/贪心算法/2.初步感受贪心.html#大家可能会觉得这不是显而易见的吗-但这只能帮你解决简单的问题-复杂的问题就需要我们认真去分析了。","936":"/生活与算法/贪心算法/2.初步感受贪心.html#_2-选择最便宜的出行方案","937":"/生活与算法/贪心算法/2.初步感受贪心.html#_2-1-问题","938":"/生活与算法/贪心算法/2.初步感受贪心.html#_2-2-贪心思维","939":"/生活与算法/贪心算法/2.初步感受贪心.html#_2-3-数学过程","940":"/生活与算法/贪心算法/2.初步感受贪心.html#_3-如何分配时间-优先完成最紧急的任务","941":"/生活与算法/贪心算法/2.初步感受贪心.html#_3-1-问题","942":"/生活与算法/贪心算法/2.初步感受贪心.html#_3-2-贪心思维","943":"/生活与算法/贪心算法/2.初步感受贪心.html#_3-3-数学过程","944":"/生活与算法/贪心算法/2.初步感受贪心.html#_4-找零问题-使用最少的硬币","945":"/生活与算法/贪心算法/2.初步感受贪心.html#_4-1-问题","946":"/生活与算法/贪心算法/2.初步感受贪心.html#_4-2-贪心思维","947":"/生活与算法/贪心算法/2.初步感受贪心.html#_4-3-数学过程","948":"/生活与算法/贪心算法/2.初步感受贪心.html#_5-我们已经步入-贪心算法-啦","949":"/面试求职/场景问题/#场景问题内容","950":"/生活与算法/贪心算法/3. 分发饼干问题.html#分发饼干问题","951":"/生活与算法/贪心算法/3. 分发饼干问题.html#_1-问题描述","952":"/生活与算法/贪心算法/3. 分发饼干问题.html#_2-目标","953":"/生活与算法/贪心算法/3. 分发饼干问题.html#_3-输入","954":"/生活与算法/贪心算法/3. 分发饼干问题.html#_4-输出","955":"/生活与算法/贪心算法/3. 分发饼干问题.html#_5-贪心算法的解法思路","956":"/生活与算法/贪心算法/3. 分发饼干问题.html#_6-解题步骤","957":"/生活与算法/贪心算法/3. 分发饼干问题.html#_7-代码实现-python","958":"/生活与算法/贪心算法/3. 分发饼干问题.html#_8-示例","959":"/生活与算法/贪心算法/3. 分发饼干问题.html#_9-时间复杂度","960":"/生活与算法/贪心算法/3. 分发饼干问题.html#_10-贪心策略的解释","961":"/生活与算法/贪心算法/3. 分发饼干问题.html#_11-思考","962":"/面试求职/Java面经/#这年代-不吃面经咋活","963":"/面试求职/算法岗/#前任铺路后人走","964":"/面试求职/算法岗/#nlp面经","965":"/面试求职/经验分享/#前任铺路后人走","966":"/生活与算法/贪心算法/1.人的本性——贪心！.html#人的本性——贪心","967":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_1-贪心与人生","968":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_2-贪心算法基本概念","969":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_2-1-概念","970":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_2-2-通俗讲解","971":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_3-贪心算法原理","972":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_3-1-我想说","973":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_3-2-贪心策略","974":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_3-3-基本原理","975":"/生活与算法/贪心算法/1.人的本性——贪心！.html#_4-总结"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[5,1,1],"1":[2,1,1],"2":[2,2,1],"3":[3,2,1],"4":[3,2,28],"5":[3,2,33],"6":[3,2,13],"7":[2,1,1],"8":[5,2,27],"9":[2,2,25],"10":[2,1,19],"11":[3,2,32],"12":[4,2,5],"13":[2,1,34],"14":[4,2,18],"15":[3,2,20],"16":[2,1,4],"17":[2,1,1],"18":[3,2,11],"19":[3,2,9],"20":[2,1,1],"21":[2,1,33],"22":[2,1,4],"23":[2,1,1],"24":[2,2,31],"25":[3,2,10],"26":[2,1,47],"27":[4,1,29],"28":[2,1,29],"29":[3,1,41],"30":[2,1,1],"31":[3,2,1],"32":[5,2,1],"33":[5,2,1],"34":[5,2,4],"35":[7,2,3],"36":[2,1,12],"37":[1,1,1],"38":[3,1,21],"39":[4,1,1],"40":[3,4,49],"41":[2,4,69],"42":[5,1,1],"43":[3,5,6],"44":[3,5,42],"45":[4,5,96],"46":[5,5,72],"47":[2,1,84],"48":[2,1,37],"49":[2,1,3],"50":[2,1,120],"51":[2,1,38],"52":[2,1,38],"53":[2,1,2],"54":[4,1,29],"55":[2,1,44],"56":[3,1,9],"57":[5,1,26],"58":[5,1,27],"59":[6,1,15],"60":[7,1,25],"61":[7,1,22],"62":[5,1,1],"63":[3,5,17],"64":[3,5,4],"65":[3,1,17],"66":[2,1,2],"67":[3,1,1],"68":[3,1,1],"69":[3,3,3],"70":[3,3,1],"71":[3,1,9],"72":[3,1,1],"73":[3,3,9],"74":[3,3,24],"75":[3,3,20],"76":[2,1,1],"77":[4,2,1],"78":[3,2,3],"79":[2,1,1],"80":[2,2,40],"81":[3,2,53],"82":[2,1,1],"83":[4,2,26],"84":[3,2,28],"85":[2,1,3],"86":[3,2,92],"87":[3,2,93],"88":[3,2,61],"89":[4,2,75],"90":[4,2,5],"91":[4,2,22],"92":[2,1,19],"93":[4,2,37],"94":[3,2,33],"95":[5,2,63],"96":[3,1,2],"97":[5,1,1],"98":[3,5,26],"99":[3,5,43],"100":[3,5,15],"101":[3,5,18],"102":[4,1,4],"103":[6,1,1],"104":[3,6,22],"105":[3,6,14],"106":[3,6,27],"107":[3,6,28],"108":[2,1,29],"109":[4,1,1],"110":[3,4,21],"111":[3,4,30],"112":[3,1,40],"113":[2,1,57],"114":[2,1,25],"115":[2,1,4],"116":[2,1,5],"117":[2,1,33],"118":[2,1,2],"119":[2,1,2],"120":[3,1,128],"121":[3,3,79],"122":[3,3,135],"123":[2,1,46],"124":[4,1,37],"125":[9,1,51],"126":[7,1,95],"127":[4,1,66],"128":[2,1,43],"129":[2,1,40],"130":[3,1,15],"131":[2,1,5],"132":[7,1,23],"133":[2,1,9],"134":[3,1,1],"135":[5,3,6],"136":[4,3,3],"137":[3,3,19],"138":[4,3,21],"139":[5,3,3],"140":[5,3,6],"141":[5,3,1],"142":[5,1,15],"143":[3,1,22],"144":[7,1,14],"145":[4,7,23],"146":[5,7,12],"147":[4,10,18],"148":[3,10,29],"149":[5,10,13],"150":[4,10,23],"151":[4,10,4],"152":[5,7,7],"153":[6,7,1],"154":[7,1,1],"155":[6,7,1],"156":[3,7,28],"157":[3,7,5],"158":[2,1,4],"159":[4,1,1],"160":[3,4,33],"161":[4,4,16],"162":[7,7,4],"163":[7,7,6],"164":[8,7,15],"165":[6,4,18],"166":[3,1,1],"167":[4,1,38],"168":[3,1,20],"169":[5,3,5],"170":[3,3,17],"171":[4,3,23],"172":[4,3,19],"173":[5,1,17],"174":[6,5,19],"175":[3,1,1],"176":[3,3,31],"177":[3,3,29],"178":[5,5,17],"179":[4,5,20],"180":[3,3,51],"181":[3,1,69],"182":[5,1,1],"183":[3,5,28],"184":[5,5,30],"185":[3,5,41],"186":[5,5,56],"187":[3,1,1],"188":[4,3,86],"189":[3,3,24],"190":[4,3,121],"191":[3,3,16],"192":[2,1,9],"193":[6,1,35],"194":[4,1,28],"195":[2,1,1],"196":[4,2,25],"197":[4,2,22],"198":[7,1,13],"199":[3,7,1],"200":[3,7,15],"201":[3,7,1],"202":[6,8,8],"203":[3,8,13],"204":[4,8,8],"205":[3,8,17],"206":[2,7,31],"207":[5,1,1],"208":[3,5,42],"209":[3,5,53],"210":[3,5,7],"211":[3,5,3],"212":[6,1,9],"213":[5,1,26],"214":[5,1,18],"215":[4,5,73],"216":[4,5,35],"217":[6,1,77],"218":[7,1,1],"219":[4,7,50],"220":[8,1,49],"221":[4,1,1],"222":[3,4,49],"223":[3,4,81],"224":[5,4,28],"225":[4,4,83],"226":[3,4,175],"227":[3,4,65],"228":[5,4,31],"229":[4,1,13],"230":[4,1,13],"231":[4,1,6],"232":[2,1,7],"233":[5,1,19],"234":[2,1,1],"235":[3,2,15],"236":[3,2,20],"237":[2,1,13],"238":[2,1,7],"239":[3,2,25],"240":[3,2,26],"241":[3,2,7],"242":[2,1,1],"243":[3,2,12],"244":[4,2,48],"245":[5,1,89],"246":[3,1,8],"247":[3,3,33],"248":[3,3,171],"249":[3,3,101],"250":[3,3,1],"251":[4,5,17],"252":[5,5,34],"253":[2,1,1],"254":[2,1,16],"255":[2,1,14],"256":[2,1,10],"257":[3,1,1],"258":[2,3,25],"259":[3,3,1],"260":[7,5,29],"261":[7,5,30],"262":[5,5,43],"263":[4,1,13],"264":[3,4,9],"265":[2,4,2],"266":[2,4,19],"267":[3,4,17],"268":[6,1,1],"269":[3,6,18],"270":[3,6,7],"271":[2,6,24],"272":[4,1,2],"273":[3,4,1],"274":[3,4,23],"275":[3,1,1],"276":[3,3,13],"277":[4,3,21],"278":[4,3,1],"279":[3,3,10],"280":[2,3,16],"281":[4,3,16],"282":[3,1,13],"283":[3,3,23],"284":[3,3,14],"285":[4,3,4],"286":[2,1,1],"287":[3,2,18],"288":[3,2,1],"289":[4,2,10],"290":[2,1,1],"291":[4,2,1],"292":[3,2,11],"293":[3,1,1],"294":[3,1,49],"295":[3,3,1],"296":[4,3,3],"297":[3,3,1],"298":[2,1,1],"299":[3,2,7],"300":[3,2,3],"301":[3,1,1],"302":[2,1,21],"303":[6,1,77],"304":[7,1,1],"305":[4,7,50],"306":[7,1,49],"307":[9,1,4],"308":[4,9,35],"309":[4,9,44],"310":[4,1,4],"311":[3,4,41],"312":[3,4,86],"313":[4,4,83],"314":[5,4,36],"315":[5,4,51],"316":[5,4,31],"317":[5,4,65],"318":[5,4,28],"319":[4,4,16],"320":[11,1,26],"321":[7,11,10],"322":[4,11,48],"323":[4,11,42],"324":[6,11,17],"325":[10,1,58],"326":[2,1,66],"327":[3,2,107],"328":[6,1,148],"329":[7,1,114],"330":[4,1,13],"331":[6,1,6],"332":[4,6,51],"333":[4,6,66],"334":[5,6,28],"335":[4,6,47],"336":[2,1,2],"337":[4,2,85],"338":[4,2,175],"339":[2,1,12],"340":[2,1,15],"341":[2,1,33],"342":[2,1,1],"343":[3,2,16],"344":[3,2,38],"345":[5,2,34],"346":[3,2,22],"347":[3,2,15],"348":[3,2,21],"349":[3,2,1],"350":[1,1,19],"351":[1,1,29],"352":[2,1,12],"353":[2,1,67],"354":[1,1,14],"355":[1,2,18],"356":[1,2,59],"357":[1,2,35],"358":[2,3,59],"359":[2,3,63],"360":[2,3,56],"361":[2,3,21],"362":[4,3,14],"363":[1,3,49],"364":[1,1,11],"365":[1,2,48],"366":[1,2,33],"367":[1,2,17],"368":[1,2,10],"369":[2,3,163],"370":[1,3,72],"371":[1,3,38],"372":[1,2,50],"373":[1,3,37],"374":[1,3,13],"375":[1,3,98],"376":[1,3,41],"377":[1,3,20],"378":[1,2,60],"379":[1,2,39],"380":[1,1,50],"381":[1,2,75],"382":[5,3,31],"383":[1,2,82],"384":[1,3,51],"385":[1,3,34],"386":[1,1,1],"387":[1,2,41],"388":[1,2,11],"389":[1,3,24],"390":[1,3,50],"391":[1,3,31],"392":[1,2,18],"393":[1,2,18],"394":[1,2,36],"395":[1,2,19],"396":[1,1,1],"397":[1,2,12],"398":[2,2,6],"399":[2,2,34],"400":[3,2,27],"401":[4,2,123],"402":[4,2,28],"403":[4,2,31],"404":[1,2,23],"405":[1,3,57],"406":[1,3,46],"407":[1,3,8],"408":[1,4,21],"409":[1,4,75],"410":[1,3,67],"411":[3,2,34],"412":[3,2,42],"413":[2,2,2],"414":[5,4,13],"415":[1,4,21],"416":[1,4,23],"417":[1,4,37],"418":[1,4,45],"419":[1,4,47],"420":[1,1,22],"421":[1,1,37],"422":[1,1,31],"423":[1,2,20],"424":[1,2,13],"425":[1,2,3],"426":[3,1,1],"427":[4,3,19],"428":[3,3,22],"429":[3,3,17],"430":[3,3,27],"431":[2,1,15],"432":[5,1,1],"433":[3,5,27],"434":[4,5,21],"435":[3,1,4],"436":[4,3,55],"437":[4,3,13],"438":[5,3,5],"439":[3,3,13],"440":[3,1,108],"441":[4,1,338],"442":[3,1,6],"443":[8,3,112],"444":[3,3,218],"445":[5,3,607],"446":[4,1,15],"447":[2,4,23],"448":[3,4,18],"449":[3,1,1],"450":[5,3,32],"451":[4,3,22],"452":[4,3,29],"453":[3,3,32],"454":[3,3,50],"455":[5,3,33],"456":[5,3,81],"457":[6,3,70],"458":[4,3,29],"459":[4,3,32],"460":[10,3,62],"461":[2,1,1],"462":[7,2,60],"463":[3,2,18],"464":[3,2,31],"465":[3,2,18],"466":[3,2,9],"467":[5,2,14],"468":[3,2,51],"469":[4,2,11],"470":[7,1,12],"471":[3,7,41],"472":[4,7,81],"473":[3,7,54],"474":[2,7,46],"475":[5,7,61],"476":[3,7,22],"477":[7,9,18],"478":[4,9,32],"479":[7,9,32],"480":[7,9,34],"481":[7,7,26],"482":[3,1,9],"483":[6,1,8],"484":[5,6,61],"485":[6,6,4],"486":[2,1,1],"487":[3,2,97],"488":[4,2,19],"489":[4,1,22],"490":[4,1,106],"491":[5,1,1],"492":[4,5,33],"493":[4,5,86],"494":[3,5,40],"495":[3,5,52],"496":[4,5,384],"497":[2,1,276],"498":[1,1,131],"499":[2,1,123],"500":[2,1,179],"501":[3,1,10],"502":[3,1,1],"503":[2,3,41],"504":[7,3,47],"505":[3,3,41],"506":[6,1,6],"507":[6,6,21],"508":[5,6,77],"509":[6,6,217],"510":[2,1,51],"511":[3,1,28],"512":[2,1,1],"513":[3,2,52],"514":[2,2,13],"515":[3,2,22],"516":[3,2,8],"517":[2,1,1],"518":[3,2,19],"519":[3,2,23],"520":[2,2,5],"521":[2,1,5],"522":[3,2,27],"523":[3,2,28],"524":[2,1,3],"525":[3,2,19],"526":[3,2,17],"527":[2,1,1],"528":[4,2,17],"529":[4,2,40],"530":[4,2,14],"531":[3,1,13],"532":[7,1,10],"533":[3,7,51],"534":[7,7,1],"535":[5,7,39],"536":[5,7,28],"537":[4,7,49],"538":[5,7,49],"539":[5,7,49],"540":[5,7,54],"541":[5,7,55],"542":[5,7,60],"543":[5,7,67],"544":[5,7,102],"545":[5,7,85],"546":[5,7,68],"547":[3,7,47],"548":[5,7,51],"549":[5,7,49],"550":[2,7,7],"551":[2,1,3],"552":[2,1,61],"553":[4,1,22],"554":[2,1,1],"555":[4,2,39],"556":[3,2,237],"557":[3,1,1],"558":[3,3,1],"559":[3,3,36],"560":[3,3,18],"561":[2,1,1],"562":[4,2,15],"563":[4,2,25],"564":[5,2,13],"565":[4,2,9],"566":[3,1,1],"567":[3,3,79],"568":[5,3,44],"569":[4,3,24],"570":[4,1,39],"571":[6,1,42],"572":[3,1,21],"573":[2,1,8],"574":[2,1,1],"575":[4,2,16],"576":[4,2,26],"577":[5,2,28],"578":[3,1,11],"579":[2,1,22],"580":[2,1,90],"581":[2,1,107],"582":[5,1,18],"583":[2,1,10],"584":[3,1,40],"585":[2,1,60],"586":[3,2,43],"587":[6,2,19],"588":[5,7,27],"589":[3,7,31],"590":[1,2,201],"591":[2,1,2],"592":[2,1,9],"593":[4,1,1],"594":[3,4,1],"595":[4,4,53],"596":[3,4,1],"597":[4,4,1],"598":[4,4,1],"599":[5,4,1],"600":[4,1,1],"601":[4,4,1],"602":[4,4,1],"603":[5,4,1],"604":[2,1,1],"605":[4,2,34],"606":[3,2,67],"607":[3,1,1],"608":[4,3,83],"609":[6,3,38],"610":[2,1,13],"611":[1,1,1],"612":[1,1,7],"613":[2,1,51],"614":[3,1,4],"615":[3,1,1],"616":[4,3,118],"617":[3,3,53],"618":[3,3,6],"619":[4,3,156],"620":[4,3,82],"621":[5,3,87],"622":[3,3,28],"623":[10,1,1],"624":[3,10,34],"625":[4,10,1],"626":[4,12,78],"627":[3,12,59],"628":[4,12,52],"629":[4,10,2],"630":[4,12,15],"631":[2,1,1],"632":[3,2,69],"633":[3,2,102],"634":[4,2,191],"635":[5,2,67],"636":[2,1,67],"637":[3,1,4],"638":[4,1,14],"639":[3,4,20],"640":[5,6,49],"641":[6,6,23],"642":[3,4,10],"643":[4,6,110],"644":[4,6,90],"645":[2,4,40],"646":[4,5,63],"647":[3,5,87],"648":[3,5,83],"649":[5,5,99],"650":[1,1,2],"651":[5,1,1],"652":[2,5,18],"653":[3,5,18],"654":[3,5,18],"655":[3,5,30],"656":[3,5,20],"657":[4,5,20],"658":[2,1,4],"659":[3,2,68],"660":[2,1,5],"661":[6,1,3],"662":[6,1,2],"663":[3,1,3],"664":[3,1,4],"665":[3,1,4],"666":[4,1,2],"667":[2,1,4],"668":[2,1,4],"669":[2,1,4],"670":[2,1,4],"671":[3,1,92],"672":[1,1,6],"673":[1,1,1],"674":[3,1,7],"675":[2,3,1],"676":[3,4,16],"677":[4,4,14],"678":[4,4,8],"679":[4,4,1],"680":[3,6,23],"681":[6,6,26],"682":[4,6,17],"683":[2,3,5],"684":[3,5,1],"685":[4,5,1],"686":[3,8,1],"687":[2,8,1],"688":[3,8,1],"689":[5,5,1],"690":[4,9,1],"691":[8,9,1],"692":[6,9,1],"693":[7,9,1],"694":[2,3,15],"695":[4,1,11],"696":[3,1,15],"697":[2,3,8],"698":[2,3,9],"699":[2,3,6],"700":[2,3,5],"701":[2,3,1],"702":[2,3,22],"703":[2,1,12],"704":[2,2,1],"705":[4,3,24],"706":[3,3,41],"707":[2,1,5],"708":[3,2,18],"709":[2,2,14],"710":[4,2,7],"711":[2,2,1],"712":[2,2,1],"713":[3,2,1],"714":[2,2,1],"715":[2,2,6],"716":[2,2,11],"717":[2,2,13],"718":[1,2,9],"719":[1,1,18],"720":[2,1,1],"721":[2,3,38],"722":[3,3,31],"723":[3,3,37],"724":[3,3,50],"725":[2,1,7],"726":[3,3,205],"727":[2,3,17],"728":[2,1,1],"729":[3,3,8],"730":[3,3,114],"731":[2,3,60],"732":[3,3,58],"733":[3,3,59],"734":[3,3,27],"735":[1,1,7],"736":[2,1,1],"737":[3,3,1],"738":[1,6,6],"739":[1,6,22],"740":[1,6,8],"741":[2,3,1],"742":[1,5,29],"743":[1,5,27],"744":[2,3,1],"745":[1,5,10],"746":[1,5,25],"747":[2,3,1],"748":[1,5,13],"749":[1,5,10],"750":[3,3,2],"751":[3,6,11],"752":[3,6,14],"753":[3,6,25],"754":[2,3,1],"755":[1,5,9],"756":[1,5,9],"757":[1,5,13],"758":[2,3,1],"759":[1,5,10],"760":[1,5,7],"761":[1,5,7],"762":[2,3,1],"763":[1,5,15],"764":[2,3,1],"765":[1,5,17],"766":[1,5,7],"767":[2,3,1],"768":[1,5,15],"769":[2,3,1],"770":[1,5,15],"771":[2,3,1],"772":[1,5,14],"773":[2,1,1],"774":[3,3,24],"775":[3,3,1],"776":[1,6,5],"777":[1,6,15],"778":[2,3,16],"779":[2,3,1],"780":[1,5,29],"781":[1,5,15],"782":[1,5,13],"783":[1,5,9],"784":[4,3,22],"785":[2,3,1],"786":[1,5,12],"787":[1,5,16],"788":[2,3,4],"789":[1,5,14],"790":[1,5,24],"791":[2,3,1],"792":[1,5,18],"793":[1,5,4],"794":[1,1,16],"795":[2,1,3],"796":[2,3,36],"797":[4,3,16],"798":[4,3,9],"799":[3,3,95],"800":[2,1,1],"801":[3,3,29],"802":[2,3,62],"803":[2,1,4],"804":[3,3,1],"805":[2,6,8],"806":[2,6,39],"807":[2,6,20],"808":[2,6,40],"809":[2,6,19],"810":[4,6,8],"811":[2,6,20],"812":[2,6,12],"813":[3,3,2],"814":[4,1,1],"815":[3,5,9],"816":[3,5,13],"817":[3,5,21],"818":[2,5,3],"819":[3,6,1],"820":[3,6,1],"821":[3,6,1],"822":[2,6,105],"823":[2,1,62],"824":[3,3,1],"825":[3,3,1],"826":[3,3,1],"827":[4,6,140],"828":[2,1,1],"829":[3,3,13],"830":[3,3,7],"831":[3,3,23],"832":[1,1,10],"833":[1,1,7],"834":[1,1,1],"835":[2,1,3],"836":[2,1,6],"837":[3,3,1],"838":[4,3,11],"839":[4,6,15],"840":[2,6,91],"841":[3,6,17],"842":[3,6,1],"843":[3,3,26],"844":[4,5,15],"845":[3,5,19],"846":[3,5,1],"847":[4,5,1],"848":[3,3,4],"849":[4,5,8],"850":[3,5,1],"851":[3,5,1],"852":[4,5,1],"853":[2,1,14],"854":[1,1,2],"855":[2,1,1],"856":[2,1,9],"857":[1,1,94],"858":[1,1,31],"859":[1,1,27],"860":[1,1,4],"861":[1,1,1],"862":[1,1,9],"863":[1,1,4],"864":[3,1,4],"865":[1,1,1],"866":[2,1,1],"867":[2,3,14],"868":[2,3,81],"869":[2,1,1],"870":[2,3,12],"871":[2,3,17],"872":[2,1,1],"873":[2,3,16],"874":[2,3,13],"875":[2,1,69],"876":[2,1,15],"877":[2,2,20],"878":[2,4,244],"879":[3,4,3],"880":[1,1,96],"881":[1,1,12],"882":[1,1,1],"883":[1,1,8],"884":[2,1,1],"885":[2,1,7],"886":[3,1,6],"887":[5,1,6],"888":[3,6,17],"889":[4,6,111],"890":[3,1,4],"891":[5,3,59],"892":[5,3,1],"893":[5,7,37],"894":[6,7,31],"895":[3,7,43],"896":[7,7,31],"897":[6,7,72],"898":[6,3,1],"899":[3,8,35],"900":[3,8,19],"901":[2,8,25],"902":[6,3,1],"903":[4,8,6],"904":[4,8,145],"905":[2,3,53],"906":[1,1,1],"907":[1,1,10],"908":[1,1,10],"909":[2,1,12],"910":[2,1,14],"911":[2,1,3],"912":[2,1,1],"913":[4,3,10],"914":[4,3,8],"915":[4,1,10],"916":[1,1,20],"917":[3,1,35],"918":[2,1,1],"919":[4,3,14],"920":[3,3,13],"921":[4,3,19],"922":[4,3,13],"923":[2,1,9],"924":[4,3,16],"925":[4,3,15],"926":[3,3,12],"927":[2,1,21],"928":[2,1,21],"929":[3,1,19],"930":[3,3,1],"931":[3,6,7],"932":[4,6,7],"933":[4,6,16],"934":[4,6,5],"935":[4,3,1],"936":[2,3,1],"937":[4,5,6],"938":[3,5,7],"939":[4,5,21],"940":[3,3,1],"941":[4,6,4],"942":[4,6,9],"943":[3,6,19],"944":[3,3,1],"945":[4,6,10],"946":[4,6,4],"947":[4,6,21],"948":[4,3,12],"949":[1,1,1],"950":[1,1,10],"951":[2,1,9],"952":[2,1,3],"953":[3,1,10],"954":[3,1,3],"955":[2,1,9],"956":[2,1,19],"957":[4,1,31],"958":[2,1,15],"959":[2,1,12],"960":[2,1,5],"961":[2,1,8],"962":[3,1,1],"963":[1,1,1],"964":[1,1,1],"965":[1,1,1],"966":[3,1,9],"967":[2,3,21],"968":[2,3,1],"969":[3,4,6],"970":[2,4,21],"971":[2,3,1],"972":[3,4,17],"973":[3,4,12],"974":[2,4,13],"975":[2,3,11]},"averageFieldLength":[3.130122950819672,3.0522540983606574,27.932377049180303],"storedFields":{"0":{"title":"前馈神经网络(feedforward neural network)","titles":[]},"1":{"title":"1 相关概念","titles":[]},"2":{"title":"1.1 人工智能是什么","titles":["1 相关概念"]},"3":{"title":"1.2 深度学习与人工智能的关系","titles":["1 相关概念"]},"4":{"title":"1.3 深度学习的概念","titles":["1 相关概念"]},"5":{"title":"1.4 什么是人工神经网络","titles":["1 相关概念"]},"6":{"title":"1.5 前馈神经网络的概念","titles":["1 相关概念"]},"7":{"title":"2 神经元模型","titles":[]},"8":{"title":"2.1 M-P 神经元","titles":["2 神经元模型"]},"9":{"title":"2.2 经典激活函数","titles":["2 神经元模型"]},"10":{"title":"3 从神经元到感知机","titles":[]},"11":{"title":"3.1 使用感知机解决线性可分问题","titles":["3 从神经元到感知机"]},"12":{"title":"3.2 如何解决异或问题 ？？？","titles":["3 从神经元到感知机"]},"13":{"title":"4 从感知机到深度神经网络","titles":[]},"14":{"title":"4.1 为何要用深度神经网络？","titles":["4 从感知机到深度神经网络"]},"15":{"title":"4.2 深度神经网络解决问题案例","titles":["4 从感知机到深度神经网络"]},"16":{"title":"5 前馈神经网络计算流程","titles":[]},"17":{"title":"6 深度学习与传统机器学习","titles":[]},"18":{"title":"6.1 相同点","titles":["6 深度学习与传统机器学习"]},"19":{"title":"6.2 不同点","titles":["6 深度学习与传统机器学习"]},"20":{"title":"7 深度学习的特点","titles":[]},"21":{"title":"8 深度学习的典型算法","titles":[]},"22":{"title":"9 参考文献","titles":[]},"23":{"title":"1 概念理解","titles":[]},"24":{"title":"1.1 神经网络训练流程概述","titles":["1 概念理解"]},"25":{"title":"1.2 反向传播的定义","titles":["1 概念理解"]},"26":{"title":"2 梯度下降算法简述","titles":[]},"27":{"title":"3 BP 或 深度神经网络训练需要明确的几个概念","titles":[]},"28":{"title":"4 链式求导法则","titles":[]},"29":{"title":"5 BP 流程图示","titles":[]},"30":{"title":"6 反向传播数学推导","titles":[]},"31":{"title":"6.1 反向传播目的确认","titles":["6 反向传播数学推导"]},"32":{"title":"6.2 线性连接层 weight 的梯度","titles":["6 反向传播数学推导"]},"33":{"title":"6.3 激活函数 input 的梯度","titles":["6 反向传播数学推导"]},"34":{"title":"6.4 激活函数 output 的梯度","titles":["6 反向传播数学推导"]},"35":{"title":"6.5 下层激活 input(z\' and z\'\') 梯度求解","titles":["6 反向传播数学推导"]},"36":{"title":"7 反向传播总结","titles":[]},"37":{"title":"神经网络案例展示","titles":[]},"38":{"title":"1 题目：","titles":[]},"39":{"title":"2 前向传播过程(feedforward)","titles":[]},"40":{"title":"2.1 第一层求解","titles":["2 前向传播过程(feedforward)"]},"41":{"title":"2.2 第二层计算","titles":["2 前向传播过程(feedforward)"]},"42":{"title":"3 反向传播过程(back propagation)","titles":[]},"43":{"title":"3.1 末层权重梯度计算","titles":["3 反向传播过程(back propagation)"]},"44":{"title":"3.1.1 计算流程概述","titles":["3 反向传播过程(back propagation)"]},"45":{"title":"3.1.2 具体计算过程","titles":["3 反向传播过程(back propagation)"]},"46":{"title":"3.2 前一层权重梯度计算（以 w1","titles":["3 反向传播过程(back propagation)"]},"47":{"title":"4 权重更新","titles":[]},"48":{"title":"5 迭代训练","titles":[]},"49":{"title":"6 将前馈网络写成矩阵形式","titles":[]},"50":{"title":"7 代码展示","titles":[]},"51":{"title":"1 概念","titles":[]},"52":{"title":"2 卷积运算","titles":[]},"53":{"title":"3 体会卷积的作用","titles":[]},"54":{"title":"4 卷积 和 前馈神经网络的关系","titles":[]},"55":{"title":"5 工程上标准的卷积","titles":[]},"56":{"title":"6 1x1 卷积","titles":[]},"57":{"title":"7 分组卷积(group convolution)","titles":[]},"58":{"title":"8 深度可分离卷积（deepwise convolution）","titles":[]},"59":{"title":"9 空间可分离卷积（Spatially Separable Convolutions）","titles":[]},"60":{"title":"10 空洞卷积（膨胀卷积）（Dilated Convolution / Atrous Convolution）","titles":[]},"61":{"title":"11 反卷积（转置卷积)(Deconvolution / Transposed Convolution）","titles":[]},"62":{"title":"12 可变形卷积（deformable convolution）","titles":[]},"63":{"title":"12.1 原理","titles":["12 可变形卷积（deformable convolution）"]},"64":{"title":"12.2 过程","titles":["12 可变形卷积（deformable convolution）"]},"65":{"title":"13 3D 卷积","titles":[]},"66":{"title":"14 参考链接","titles":[]},"67":{"title":"1 pytorch 官网","titles":[]},"68":{"title":"2 pytorch 简介","titles":[]},"69":{"title":"2.1 认识pytorch","titles":["2 pytorch 简介"]},"70":{"title":"2.2 pytorch 软件栈","titles":["2 pytorch 简介"]},"71":{"title":"3 pytorch install","titles":[]},"72":{"title":"4 nvidia 相关软件库","titles":[]},"73":{"title":"4.1 显卡驱动","titles":["4 nvidia 相关软件库"]},"74":{"title":"4.2 cuda","titles":["4 nvidia 相关软件库"]},"75":{"title":"4.3 cudnn","titles":["4 nvidia 相关软件库"]},"76":{"title":"5 GPU","titles":[]},"77":{"title":"5.1 GPU 加速原理","titles":["5 GPU"]},"78":{"title":"5.2 最先进的GPU","titles":["5 GPU"]},"79":{"title":"1 Convolution","titles":[]},"80":{"title":"1.1 Conv2D","titles":["1 Convolution"]},"81":{"title":"1.2 ConvTranspose2d","titles":["1 Convolution"]},"82":{"title":"2 线性变换层","titles":[]},"83":{"title":"2.1 Linear/Gemm","titles":["2 线性变换层"]},"84":{"title":"2.2 matmul 相关","titles":["2 线性变换层"]},"85":{"title":"3 Normalization","titles":[]},"86":{"title":"3.1 BatchNorm2d","titles":["3 Normalization"]},"87":{"title":"3.2 LayerNorm","titles":["3 Normalization"]},"88":{"title":"3.3 Instance Normalization","titles":["3 Normalization"]},"89":{"title":"3.4  Group Normalization","titles":["3 Normalization"]},"90":{"title":"3.5 Switch norm","titles":["3 Normalization"]},"91":{"title":"3.6 RMS Norm","titles":["3 Normalization"]},"92":{"title":"4 Pooling","titles":[]},"93":{"title":"4.1 Max Pooling","titles":["4 Pooling"]},"94":{"title":"4.2 AveragePooling","titles":["4 Pooling"]},"95":{"title":"4.3 Global Average Pooling","titles":["4 Pooling"]},"96":{"title":"5 activation functions","titles":[]},"97":{"title":"6 reshape、 view、 permute、transpose","titles":[]},"98":{"title":"6.1 reshape","titles":["6 reshape、 view、 permute、transpose"]},"99":{"title":"6.2 view","titles":["6 reshape、 view、 permute、transpose"]},"100":{"title":"6.3 transpose","titles":["6 reshape、 view、 permute、transpose"]},"101":{"title":"6.4 permute","titles":["6 reshape、 view、 permute、transpose"]},"102":{"title":"7 sequenze 和 unequenze","titles":[]},"103":{"title":"8 concat、stack、expand 和 flatten","titles":[]},"104":{"title":"8.1 concat","titles":["8 concat、stack、expand 和 flatten"]},"105":{"title":"8.2 stack","titles":["8 concat、stack、expand 和 flatten"]},"106":{"title":"8.3 expand","titles":["8 concat、stack、expand 和 flatten"]},"107":{"title":"8.4 flatten","titles":["8 concat、stack、expand 和 flatten"]},"108":{"title":"9 pointwise","titles":[]},"109":{"title":"10 split 和 slice","titles":[]},"110":{"title":"10.1 split","titles":["10 split 和 slice"]},"111":{"title":"10.2 slice","titles":["10 split 和 slice"]},"112":{"title":"11 reduce 规约类算子","titles":[]},"113":{"title":"12 embedding","titles":[]},"114":{"title":"13 dropout","titles":[]},"115":{"title":"14 附录","titles":[]},"116":{"title":"15 参考链接","titles":[]},"117":{"title":"1 什么是深度学习模型","titles":[]},"118":{"title":"2 下载一个预训练好的深度学习模型","titles":[]},"119":{"title":"3 可视化这个深度学习模型","titles":[]},"120":{"title":"0 Activation 整体介绍","titles":[]},"121":{"title":"1 S 型激活函数","titles":["0 Activation 整体介绍"]},"122":{"title":"2 Relu 激活函数","titles":["0 Activation 整体介绍"]},"123":{"title":"3 ReLU6","titles":[]},"124":{"title":"4 其它ReLU 相关 激活函数","titles":[]},"125":{"title":"5 ELU(Exponential Linear Units) 和 SELU(Scaled ELU)","titles":[]},"126":{"title":"6 GeLU（Gaussian Error Linear Unit）","titles":[]},"127":{"title":"7 Swish 与 Hardswish","titles":[]},"128":{"title":"8 mish","titles":[]},"129":{"title":"9 Softmax","titles":[]},"130":{"title":"10 总结：好的激活函数应有的性质","titles":[]},"131":{"title":"11 参考链接","titles":[]},"132":{"title":"0 循环神经网络(Recurrent neural network：RNN)","titles":[]},"133":{"title":"2 典型的RNN网络","titles":[]},"134":{"title":"3 RNN 结构详解","titles":[]},"135":{"title":"3.1 RNN 循环过程如下图所示：","titles":["3 RNN 结构详解"]},"136":{"title":"3.2 按时间步展开如下：","titles":["3 RNN 结构详解"]},"137":{"title":"3.3 经典RNN的计算图如下：","titles":["3 RNN 结构详解"]},"138":{"title":"3.4 RNN具体计算公式为：","titles":["3 RNN 结构详解"]},"139":{"title":"3.5 RNN 工程图展示：","titles":["3 RNN 结构详解"]},"140":{"title":"3.6 RNN可扩展到双向的情况，其结构如下：","titles":["3 RNN 结构详解"]},"141":{"title":"3.7 RNN扩展到多层构成循环神经网络，结构如下：","titles":["3 RNN 结构详解"]},"142":{"title":"4 RNN 应用案例(意图识别)","titles":[]},"143":{"title":"5 经典RNN 存在的问题","titles":[]},"144":{"title":"6 LSTM(Long Short-Term Memory) 长短期记忆网络","titles":[]},"145":{"title":"6.1 LSTM 整体结构","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络"]},"146":{"title":"6.2 LSTM cell 详解","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络"]},"147":{"title":"6.2.1 遗忘门","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络","6.2 LSTM cell 详解"]},"148":{"title":"6.2.2 输入门","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络","6.2 LSTM cell 详解"]},"149":{"title":"6.2.3 cell state","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络","6.2 LSTM cell 详解"]},"150":{"title":"6.2.4 输出门","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络","6.2 LSTM cell 详解"]},"151":{"title":"6.2.5 总结","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络","6.2 LSTM cell 详解"]},"152":{"title":"6.3 LSTM Cell 具体计算","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络"]},"153":{"title":"6.4 与RNN 类似 LSTM 也有双向的","titles":["6 LSTM(Long Short-Term Memory) 长短期记忆网络"]},"154":{"title":"7 GRU ：门控循环单元（Gated Recurrent Unit）","titles":[]},"155":{"title":"7.1 LSTM 和 GRU 对比","titles":["7 GRU ：门控循环单元（Gated Recurrent Unit）"]},"156":{"title":"7.2 原理","titles":["7 GRU ：门控循环单元（Gated Recurrent Unit）"]},"157":{"title":"7.3 计算过程","titles":["7 GRU ：门控循环单元（Gated Recurrent Unit）"]},"158":{"title":"8 参考链接","titles":[]},"159":{"title":"1 从RNN 到 Seq2Seq","titles":[]},"160":{"title":"1.1 RNN 简述","titles":["1 从RNN 到 Seq2Seq"]},"161":{"title":"1.2 RNN 应用场景","titles":["1 从RNN 到 Seq2Seq"]},"162":{"title":"1.2.1 RNN 解决 N VS N 问题","titles":["1 从RNN 到 Seq2Seq","1.2 RNN 应用场景"]},"163":{"title":"1.2.2 RNN 解决 N Versus 1 问题","titles":["1 从RNN 到 Seq2Seq","1.2 RNN 应用场景"]},"164":{"title":"1.2.3 RNN 解决 1 VS N 问题","titles":["1 从RNN 到 Seq2Seq","1.2 RNN 应用场景"]},"165":{"title":"1.3 N VS M 型任务","titles":["1 从RNN 到 Seq2Seq"]},"166":{"title":"2 Seq2Seq 模型","titles":[]},"167":{"title":"2.1 Seq2Seq 定义","titles":[]},"168":{"title":"2.2 seq2seq 模型结构","titles":[]},"169":{"title":"2.2.1 encoder-decoder 架构","titles":["2.2 seq2seq 模型结构"]},"170":{"title":"2.2.2 encoder 部分","titles":["2.2 seq2seq 模型结构"]},"171":{"title":"2.2.3 decoder 部分","titles":["2.2 seq2seq 模型结构"]},"172":{"title":"2.3 Seq2Seq 实现举例","titles":["2.2 seq2seq 模型结构"]},"173":{"title":"3 Seq2Seq 中的 Attention 机制","titles":[]},"174":{"title":"3.1 Seq2Seq 中的 Attention 机制","titles":["3 Seq2Seq 中的 Attention 机制"]},"175":{"title":"4 Seq2Seq 的工作流程","titles":[]},"176":{"title":"4.1 预测时流程","titles":["4 Seq2Seq 的工作流程"]},"177":{"title":"4.2 训练时流程","titles":["4 Seq2Seq 的工作流程"]},"178":{"title":"4.2.1 Teacher Forcing","titles":["4 Seq2Seq 的工作流程","4.2 训练时流程"]},"179":{"title":"4.2.2 Scheduled sampling","titles":["4 Seq2Seq 的工作流程","4.2 训练时流程"]},"180":{"title":"4.3 Decoder的预训练","titles":["4 Seq2Seq 的工作流程"]},"181":{"title":"5 Seq2Seq 的损失函数","titles":[]},"182":{"title":"6 Decoding 中的 Beam search","titles":[]},"183":{"title":"6.1 贪心decoding","titles":["6 Decoding 中的 Beam search"]},"184":{"title":"6.2 Beam search 原理","titles":["6 Decoding 中的 Beam search"]},"185":{"title":"6.3 公式分析","titles":["6 Decoding 中的 Beam search"]},"186":{"title":"6.4 Beam search 分析","titles":["6 Decoding 中的 Beam search"]},"187":{"title":"7 NLP 从机器学习到深度学习","titles":[]},"188":{"title":"7.1 NLP 中常见任务","titles":["7 NLP 从机器学习到深度学习"]},"189":{"title":"7.2 机器翻译的发展历程","titles":["7 NLP 从机器学习到深度学习"]},"190":{"title":"7.3 SMT 方法简介","titles":["7 NLP 从机器学习到深度学习"]},"191":{"title":"7.4 NMT","titles":["7 NLP 从机器学习到深度学习"]},"192":{"title":"8 参考文献","titles":[]},"193":{"title":"1 Attention Is All You Need","titles":[]},"194":{"title":"2 Transformer Model Architecture","titles":[]},"195":{"title":"3 编码器和解码器堆栈","titles":[]},"196":{"title":"3.1 编码器：","titles":["3 编码器和解码器堆栈"]},"197":{"title":"3.2 解码器：","titles":["3 编码器和解码器堆栈"]},"198":{"title":"4 Scaled Dot-Product Attention（缩放版本的点积注意力）","titles":[]},"199":{"title":"4.1 模型结构图","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）"]},"200":{"title":"4.2 数学公式为","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）"]},"201":{"title":"4.3 推导过程详解","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）"]},"202":{"title":"4.2.1 self attention 的思想","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）","4.3 推导过程详解"]},"203":{"title":"4.2.2 自注意的思想","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）","4.3 推导过程详解"]},"204":{"title":"4.2.3 自注意机制运算过程","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）","4.3 推导过程详解"]},"205":{"title":"4.2.4 写成矩阵的形式","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）","4.3 推导过程详解"]},"206":{"title":"4.4 为什么要进行缩放","titles":["4 Scaled Dot-Product Attention（缩放版本的点积注意力）"]},"207":{"title":"5 Multi-Head self Attention","titles":[]},"208":{"title":"5.1 原理简介","titles":["5 Multi-Head self Attention"]},"209":{"title":"5.2 公式表达","titles":["5 Multi-Head self Attention"]},"210":{"title":"5.3 底层原理","titles":["5 Multi-Head self Attention"]},"211":{"title":"5.4 多头的实现细节展示","titles":["5 Multi-Head self Attention"]},"212":{"title":"6 实际工程上的 Multi-Head Attention 详解","titles":[]},"213":{"title":"7 Cross Multi-Head Attention","titles":[]},"214":{"title":"8 Mask Multi-Head Attention","titles":[]},"215":{"title":"8.1 padding mask","titles":["8 Mask Multi-Head Attention"]},"216":{"title":"8.2 sequence mask","titles":["8 Mask Multi-Head Attention"]},"217":{"title":"9 MQA（Multi Query Attention）","titles":[]},"218":{"title":"10 大模型神器：GQA（Grouped Query Attention）","titles":[]},"219":{"title":"10.1 GQA Structure","titles":["10 大模型神器：GQA（Grouped Query Attention）"]},"220":{"title":"10.2 精度改进：converting the checkpoint and uptraining","titles":[]},"221":{"title":"11 大模型加速利器：FlashAttention:","titles":[]},"222":{"title":"11.1 原理介绍","titles":["11 大模型加速利器：FlashAttention:"]},"223":{"title":"11.2 标准attention机制的算法实现","titles":["11 大模型加速利器：FlashAttention:"]},"224":{"title":"11.3 flash attention 算法思想","titles":["11 大模型加速利器：FlashAttention:"]},"225":{"title":"11.4 准备：切片的方式计算softmax","titles":["11 大模型加速利器：FlashAttention:"]},"226":{"title":"11.5 具体flashattention的算法","titles":["11 大模型加速利器：FlashAttention:"]},"227":{"title":"Flash-Attention 效果","titles":["11 大模型加速利器：FlashAttention:"]},"228":{"title":"11.6 重计算(recompute)","titles":["11 大模型加速利器：FlashAttention:"]},"229":{"title":"12 # flash-attention 2","titles":[]},"230":{"title":"13 大模型推理加速利器：KV Cache","titles":[]},"231":{"title":"14 大模型推理加速利器：Page-Attention","titles":[]},"232":{"title":"15 参考链接","titles":[]},"233":{"title":"1 参数初始化概念(Parameters initialization)","titles":[]},"234":{"title":"2 参数初始化的重要性","titles":[]},"235":{"title":"2.1 为什么参数初始化很重要","titles":["2 参数初始化的重要性"]},"236":{"title":"2.1 不合理初始化的问题","titles":["2 参数初始化的重要性"]},"237":{"title":"3 全0或常量初始化","titles":[]},"238":{"title":"4 随机初始化","titles":[]},"239":{"title":"4.1 较小随机值时","titles":["4 随机初始化"]},"240":{"title":"4.2 较大随机初始值时","titles":["4 随机初始化"]},"241":{"title":"4.3 结论","titles":["4 随机初始化"]},"242":{"title":"5 理想的参数初始化","titles":[]},"243":{"title":"5.1 参数初始化的必要条件","titles":["5 理想的参数初始化"]},"244":{"title":"5.2 Glorot 条件","titles":["5 理想的参数初始化"]},"245":{"title":"6 塞维尔初始化(Xavier initialization)","titles":[]},"246":{"title":"7 kaiming initialization","titles":[]},"247":{"title":"7.1 方差计算数学基础","titles":["7 kaiming initialization"]},"248":{"title":"7.2 前向推导过程","titles":["7 kaiming initialization"]},"249":{"title":"7.3 反向推导过程","titles":["7 kaiming initialization"]},"250":{"title":"7.4 凯明初始化总结","titles":["7 kaiming initialization"]},"251":{"title":"7.4.1 服从正态分布时","titles":["7 kaiming initialization","7.4 凯明初始化总结"]},"252":{"title":"7.4.2 服从均匀分布时:","titles":["7 kaiming initialization","7.4 凯明初始化总结"]},"253":{"title":"8 初始化策略选择","titles":[]},"254":{"title":"9 使用预训练的weight","titles":[]},"255":{"title":"10 参考文献","titles":[]},"256":{"title":"optimizer 概述","titles":[]},"257":{"title":"1 Gradient Descend","titles":[]},"258":{"title":"1.1 梯度下降法概念","titles":["1 Gradient Descend"]},"259":{"title":"1.2 梯度下降法三个变种","titles":["1 Gradient Descend"]},"260":{"title":"1.2.1 BGD(Batch Gradient Descend)","titles":["1 Gradient Descend","1.2 梯度下降法三个变种"]},"261":{"title":"1.2.2 SGD(Stochastic Gradient Descend)","titles":["1 Gradient Descend","1.2 梯度下降法三个变种"]},"262":{"title":"1.2.3 Mini-BGD","titles":["1 Gradient Descend","1.2 梯度下降法三个变种"]},"263":{"title":"2 SGD with Momentum","titles":[]},"264":{"title":"2.1 算法过程","titles":["2 SGD with Momentum"]},"265":{"title":"2.2 算法图示","titles":["2 SGD with Momentum"]},"266":{"title":"2.2 特点","titles":["2 SGD with Momentum"]},"267":{"title":"2.3 作用","titles":["2 SGD with Momentum"]},"268":{"title":"3  NAG（Nesterov Accelerated Gradient）","titles":[]},"269":{"title":"3.1 算法原理","titles":["3  NAG（Nesterov Accelerated Gradient）"]},"270":{"title":"3.2 算法原理图","titles":["3  NAG（Nesterov Accelerated Gradient）"]},"271":{"title":"3.3 算法详述","titles":["3  NAG（Nesterov Accelerated Gradient）"]},"272":{"title":"4 Pytorch 中实现 SGD","titles":[]},"273":{"title":"4.1 算法过程","titles":["4 Pytorch 中实现 SGD"]},"274":{"title":"4.2 代码实现","titles":["4 Pytorch 中实现 SGD"]},"275":{"title":"5 AdaGrad 优化算法","titles":[]},"276":{"title":"5.1 自适应学习率的概念","titles":["5 AdaGrad 优化算法"]},"277":{"title":"5.2 AdaGrad 算法原理","titles":["5 AdaGrad 优化算法"]},"278":{"title":"5.3 AdaGrad 算法","titles":["5 AdaGrad 优化算法"]},"279":{"title":"5.4 特点","titles":["5 AdaGrad 优化算法"]},"280":{"title":"5.5 缺点","titles":["5 AdaGrad 优化算法"]},"281":{"title":"5.6 pytorch 实现","titles":["5 AdaGrad 优化算法"]},"282":{"title":"6 RMSProp 优化算法","titles":[]},"283":{"title":"6.1 理论基础","titles":["6 RMSProp 优化算法"]},"284":{"title":"6.2 算法流程","titles":["6 RMSProp 优化算法"]},"285":{"title":"6.3 pytorch 实现","titles":["6 RMSProp 优化算法"]},"286":{"title":"7 Adadelta","titles":[]},"287":{"title":"7.1 概述","titles":["7 Adadelta"]},"288":{"title":"7.2 算法流程","titles":["7 Adadelta"]},"289":{"title":"7.3 pytorch 实现","titles":["7 Adadelta"]},"290":{"title":"8  不同优化算法效果对比","titles":[]},"291":{"title":"8.1 loss 对比图","titles":["8  不同优化算法效果对比"]},"292":{"title":"8.2 收敛过程对比","titles":["8  不同优化算法效果对比"]},"293":{"title":"9 Adam 优化器","titles":[]},"294":{"title":"9.1 原理概述","titles":[]},"295":{"title":"9.2 算法实现流程","titles":["9.1 原理概述"]},"296":{"title":"9.3 pytorch 实现","titles":["9.1 原理概述"]},"297":{"title":"9.4 效果展示","titles":["9.1 原理概述"]},"298":{"title":"10 AdamW","titles":[]},"299":{"title":"10.1 算法原理","titles":["10 AdamW"]},"300":{"title":"10.2 pytorch实现","titles":["10 AdamW"]},"301":{"title":"11 Optimizer 收敛趋势对比图","titles":[]},"302":{"title":"12 参考文献","titles":[]},"303":{"title":"1 MQA（Multi Query Attention）","titles":[]},"304":{"title":"2 大模型神器：GQA（Grouped Query Attention）","titles":[]},"305":{"title":"2.1 GQA Structure","titles":["2 大模型神器：GQA（Grouped Query Attention）"]},"306":{"title":"2.2 精度改进：converting the checkpoint and uptraining","titles":[]},"307":{"title":"3 MLA(Multi-Head Latent Attention): Boosting Inference Efficiency","titles":[]},"308":{"title":"3.1 MLA 原理","titles":["3 MLA(Multi-Head Latent Attention): Boosting Inference Efficiency"]},"309":{"title":"3.2 MLA 实现逻辑","titles":["3 MLA(Multi-Head Latent Attention): Boosting Inference Efficiency"]},"310":{"title":"4 大模型加速利器：FlashAttention:","titles":[]},"311":{"title":"4.1 原理及思想介绍","titles":["4 大模型加速利器：FlashAttention:"]},"312":{"title":"4.2 标准attention机制的算法实现","titles":["4 大模型加速利器：FlashAttention:"]},"313":{"title":"4.3 准备：切片的方式计算softmax","titles":["4 大模型加速利器：FlashAttention:"]},"314":{"title":"4.4 flash-attention-1 算法图解","titles":["4 大模型加速利器：FlashAttention:"]},"315":{"title":"4.5 FlashAttention1 Forward 伪代码","titles":["4 大模型加速利器：FlashAttention:"]},"316":{"title":"4.6 FlashAttention1 Backward 伪代码","titles":["4 大模型加速利器：FlashAttention:"]},"317":{"title":"4.7 Flash-Attention 效果","titles":["4 大模型加速利器：FlashAttention:"]},"318":{"title":"4.8 重计算(recompute)","titles":["4 大模型加速利器：FlashAttention:"]},"319":{"title":"4.9 FlashAttention1 的不足之处","titles":["4 大模型加速利器：FlashAttention:"]},"320":{"title":"5 FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning","titles":[]},"321":{"title":"5.1 softmax-trick v1 vs v2","titles":["5 FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"]},"322":{"title":"5.2 forward pass","titles":["5 FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"]},"323":{"title":"5.3 backward pass","titles":["5 FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"]},"324":{"title":"5.4 v2 相对于 v1 的改进","titles":["5 FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"]},"325":{"title":"6 FlashAttention3 : Fast and Accurate Attention with Asynchrony and Low-precision","titles":[]},"326":{"title":"7 RingAttention","titles":[]},"327":{"title":"7.1 具体实现原理","titles":["7 RingAttention"]},"328":{"title":"8 从ring-attention 到 context parallel","titles":[]},"329":{"title":"9 从context parallel 到 chunked pipeline parallelism","titles":[]},"330":{"title":"10 大模型推理加速利器：KV Cache","titles":[]},"331":{"title":"11 大模型推理加速利器：Page-Attention and vLLM","titles":[]},"332":{"title":"11.1 vLLM 简介","titles":["11 大模型推理加速利器：Page-Attention and vLLM"]},"333":{"title":"11.2 秘密武器：PagedAttention","titles":["11 大模型推理加速利器：Page-Attention and vLLM"]},"334":{"title":"11.3 优势1 : block 无需连续","titles":["11 大模型推理加速利器：Page-Attention and vLLM"]},"335":{"title":"11.4 优势2 ：内存共享","titles":["11 大模型推理加速利器：Page-Attention and vLLM"]},"336":{"title":"12 RadixAttention","titles":[]},"337":{"title":"12.1 当前KV Cache","titles":["12 RadixAttention"]},"338":{"title":"12.2 RedisAttention strategy","titles":["12 RadixAttention"]},"339":{"title":"13 参考链接","titles":[]},"340":{"title":"1 正则化概念","titles":[]},"341":{"title":"2 什么情况下容易出现过拟合","titles":[]},"342":{"title":"3 常见的正则化方法","titles":[]},"343":{"title":"3.1 参数范数惩罚","titles":["3 常见的正则化方法"]},"344":{"title":"3.2 数据集增强","titles":["3 常见的正则化方法"]},"345":{"title":"3.3 标签平滑（label smoothing）","titles":["3 常见的正则化方法"]},"346":{"title":"3.4 droupout","titles":["3 常见的正则化方法"]},"347":{"title":"3.5 dropconnet","titles":["3 常见的正则化方法"]},"348":{"title":"3.6 dropblock","titles":["3 常见的正则化方法"]},"349":{"title":"3.7 其它正则化方法","titles":["3 常见的正则化方法"]},"350":{"title":"深度学习调优指南中文版","titles":[]},"351":{"title":"目录","titles":["深度学习调优指南中文版"]},"352":{"title":"这份手册是为谁准备的？","titles":["深度学习调优指南中文版"]},"353":{"title":"为什么需要这份调优手册？","titles":["深度学习调优指南中文版"]},"354":{"title":"开始新项目的指南","titles":["深度学习调优指南中文版"]},"355":{"title":"选择模型架构","titles":["深度学习调优指南中文版","开始新项目的指南"]},"356":{"title":"选择优化器","titles":["深度学习调优指南中文版","开始新项目的指南"]},"357":{"title":"选择BatchSize","titles":["深度学习调优指南中文版","开始新项目的指南"]},"358":{"title":"确定可行的Batch Size并估计训练吞吐量","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"359":{"title":"选择合适的Batch Size以最小化训练时间","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"360":{"title":"选择合适的Batch Size以最小化资源消耗","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"361":{"title":"更改Batch Size需要重新调整大多数超参数","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"362":{"title":"Batch Norm会对Batch Size的选择造成什么影响？","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"363":{"title":"选择初始配置","titles":["深度学习调优指南中文版","开始新项目的指南","选择BatchSize"]},"364":{"title":"提高模型性能的科学方法","titles":["深度学习调优指南中文版"]},"365":{"title":"增量调整策略","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"366":{"title":"探索与利用","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"367":{"title":"选择下一轮实验的目标","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"368":{"title":"设计下一轮实验","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"369":{"title":"识别目标超参数、冗余超参数和固定超参数","titles":["深度学习调优指南中文版","提高模型性能的科学方法","设计下一轮实验"]},"370":{"title":"创建一组研究","titles":["深度学习调优指南中文版","提高模型性能的科学方法","设计下一轮实验"]},"371":{"title":"平衡实验的信息量和成本","titles":["深度学习调优指南中文版","提高模型性能的科学方法","设计下一轮实验"]},"372":{"title":"从实验结果中获取经验","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"373":{"title":"识别错误的搜索空间边界","titles":["深度学习调优指南中文版","提高模型性能的科学方法","从实验结果中获取经验"]},"374":{"title":"没有在搜索空间中采样足够的点","titles":["深度学习调优指南中文版","提高模型性能的科学方法","从实验结果中获取经验"]},"375":{"title":"检查训练曲线","titles":["深度学习调优指南中文版","提高模型性能的科学方法","从实验结果中获取经验"]},"376":{"title":"使用isolation图检测更改是否有用","titles":["深度学习调优指南中文版","提高模型性能的科学方法","从实验结果中获取经验"]},"377":{"title":"自动化常用的绘图","titles":["深度学习调优指南中文版","提高模型性能的科学方法","从实验结果中获取经验"]},"378":{"title":"确定是否采用此训练工作流更改或超参数配置","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"379":{"title":"探索结束后","titles":["深度学习调优指南中文版","提高模型性能的科学方法"]},"380":{"title":"确定每次训练运行的步数","titles":["深度学习调优指南中文版"]},"381":{"title":"当训练不受计算限制时如何决定该训练多久","titles":["深度学习调优指南中文版","确定每次训练运行的步数"]},"382":{"title":"使用学习率搜索算法来确定 max_train_steps 的初始值","titles":["深度学习调优指南中文版","确定每次训练运行的步数","当训练不受计算限制时如何决定该训练多久"]},"383":{"title":"当训练受计算限制时如何决定该训练多久","titles":["深度学习调优指南中文版","确定每次训练运行的步数"]},"384":{"title":"第一轮","titles":["深度学习调优指南中文版","确定每次训练运行的步数","当训练受计算限制时如何决定该训练多久"]},"385":{"title":"第二轮","titles":["深度学习调优指南中文版","确定每次训练运行的步数","当训练受计算限制时如何决定该训练多久"]},"386":{"title":"关于训练管道的额外补充","titles":["深度学习调优指南中文版"]},"387":{"title":"优化输入管道","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"388":{"title":"评估模型性能","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"389":{"title":"评估设置","titles":["深度学习调优指南中文版","关于训练管道的额外补充","评估模型性能"]},"390":{"title":"设置定期评估","titles":["深度学习调优指南中文版","关于训练管道的额外补充","评估模型性能"]},"391":{"title":"选择样本进行定期评估","titles":["深度学习调优指南中文版","关于训练管道的额外补充","评估模型性能"]},"392":{"title":"保存检查点并追溯选择最佳检查点","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"393":{"title":"设置实验跟踪","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"394":{"title":"BatchNorm的实现细节","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"395":{"title":"多主机管道的考虑因素","titles":["深度学习调优指南中文版","关于训练管道的额外补充"]},"396":{"title":"常见问题的回答","titles":["深度学习调优指南中文版"]},"397":{"title":"最好的学习率衰减方案是什么","titles":["深度学习调优指南中文版","常见问题的回答"]},"398":{"title":"我应该使用哪种学习率衰减方案作为默认值？","titles":["深度学习调优指南中文版","常见问题的回答"]},"399":{"title":"为什么有些论文有复杂的学习率衰减方案？","titles":["深度学习调优指南中文版","常见问题的回答"]},"400":{"title":"Adam 的超参数应该如何调整？","titles":["深度学习调优指南中文版","常见问题的回答"]},"401":{"title":"为什么在优化的探索阶段使用Quasi-Random-Search而不是更复杂的黑盒优化算法？","titles":["深度学习调优指南中文版","常见问题的回答"]},"402":{"title":"在哪里可以找到Quasi-Random-Search的实现？","titles":["深度学习调优指南中文版","常见问题的回答"]},"403":{"title":"需要多少次试验才能通过Quasi-Random-Search获得较好的结果？","titles":["深度学习调优指南中文版","常见问题的回答"]},"404":{"title":"如何调试和缓解优化失败","titles":["深度学习调优指南中文版","常见问题的回答"]},"405":{"title":"识别不稳定的训练任务","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败"]},"406":{"title":"常见不稳定模式的潜在修复方式","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败"]},"407":{"title":"学习率预热","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败"]},"408":{"title":"何时对学习率进行预热","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败","学习率预热"]},"409":{"title":"如何对学习率进行预热","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败","学习率预热"]},"410":{"title":"梯度截断","titles":["深度学习调优指南中文版","常见问题的回答","如何调试和缓解优化失败"]},"411":{"title":"为什么将学习率和其他优化参数称为超参数？ 它们不是任何先验分布的参数。","titles":["深度学习调优指南中文版","常见问题的回答"]},"412":{"title":"为什么不应该调整Batch Size来直接提高验证集性能?","titles":["深度学习调优指南中文版","常见问题的回答"]},"413":{"title":"所有流行的优化算法的更新规则是什么？","titles":["深度学习调优指南中文版","常见问题的回答"]},"414":{"title":"Stochastic gradient descent (SGD)","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"415":{"title":"Momentum","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"416":{"title":"Nesterov","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"417":{"title":"RMSProp","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"418":{"title":"ADAM","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"419":{"title":"NADAM","titles":["深度学习调优指南中文版","常见问题的回答","所有流行的优化算法的更新规则是什么？"]},"420":{"title":"致谢","titles":["深度学习调优指南中文版"]},"421":{"title":"引用","titles":["深度学习调优指南中文版"]},"422":{"title":"关于贡献","titles":["深度学习调优指南中文版"]},"423":{"title":"贡献者许可协议","titles":["深度学习调优指南中文版","关于贡献"]},"424":{"title":"代码审核","titles":["深度学习调优指南中文版","关于贡献"]},"425":{"title":"社区指南","titles":["深度学习调优指南中文版","关于贡献"]},"426":{"title":"1 创建pytorch tensor","titles":[]},"427":{"title":"1.1 用torch.Tensor 创建","titles":["1 创建pytorch tensor"]},"428":{"title":"1.2 直接生成特殊的tensor","titles":["1 创建pytorch tensor"]},"429":{"title":"1.3 仿照其它tensor生成","titles":["1 创建pytorch tensor"]},"430":{"title":"1.4 从numpy生成","titles":["1 创建pytorch tensor"]},"431":{"title":"2 工程实践","titles":[]},"432":{"title":"3 Tensor 中的 to 方法","titles":[]},"433":{"title":"3.1 数据类型转化","titles":["3 Tensor 中的 to 方法"]},"434":{"title":"3.2 device 转化","titles":["3 Tensor 中的 to 方法"]},"435":{"title":"4 Tensor 讲解","titles":[]},"436":{"title":"4.1 两个角度认识 Tensor","titles":["4 Tensor 讲解"]},"437":{"title":"4.2 代码实践之：视图到底是什么","titles":["4 Tensor 讲解"]},"438":{"title":"4.3 代码实践之：Tensor 中数据的连续性","titles":["4 Tensor 讲解"]},"439":{"title":"5 Tensor 运算的几种主要类型","titles":["4 Tensor 讲解"]},"440":{"title":"6 Tensor 的属性全解","titles":[]},"441":{"title":"7 外层 Tensor 方法汇总","titles":[]},"442":{"title":"8 TensorBase 方法汇总","titles":[]},"443":{"title":"8.1 魔术方法（基本运算符 + 构造函数 + 索引）","titles":["8 TensorBase 方法汇总"]},"444":{"title":"8.2 私有方法","titles":["8 TensorBase 方法汇总"]},"445":{"title":"8.3 Tensor 的 对外API接口","titles":["8 TensorBase 方法汇总"]},"446":{"title":"1 pytorch autograd 原理概述","titles":[]},"447":{"title":"1.1 原理概述","titles":["1 pytorch autograd 原理概述"]},"448":{"title":"1.2 实现细节","titles":["1 pytorch autograd 原理概述"]},"449":{"title":"2 pytorch 代码实现","titles":[]},"450":{"title":"2.1 pytorch autograd 展示","titles":["2 pytorch 代码实现"]},"451":{"title":"2.2 require_grad 的自动推理机制","titles":["2 pytorch 代码实现"]},"452":{"title":"2.3 detach 隔离功能","titles":["2 pytorch 代码实现"]},"453":{"title":"2.4 控制梯度计算","titles":["2 pytorch 代码实现"]},"454":{"title":"2.5 梯度累加和清0","titles":["2 pytorch 代码实现"]},"455":{"title":"2.6 小心 inplace-op","titles":["2 pytorch 代码实现"]},"456":{"title":"2.7 pytorch autograd 解方程","titles":["2 pytorch 代码实现"]},"457":{"title":"2.8 保存中间 activation tensor 的梯度","titles":["2 pytorch 代码实现"]},"458":{"title":"2.9 customer 自定义自己的反向传播函数","titles":["2 pytorch 代码实现"]},"459":{"title":"2.10 多维Tensor 如何backward","titles":["2 pytorch 代码实现"]},"460":{"title":"2.11 example : train a model with two mlp layers","titles":["2 pytorch 代码实现"]},"461":{"title":"3 要点总结","titles":[]},"462":{"title":"3.1 自动微分机制(auto grad) 重点：","titles":["3 要点总结"]},"463":{"title":"3.2 反向传播算法","titles":["3 要点总结"]},"464":{"title":"3.3 tensor 的梯度","titles":["3 要点总结"]},"465":{"title":"3.4 反向求导原理","titles":["3 要点总结"]},"466":{"title":"3.5 动态图机制","titles":["3 要点总结"]},"467":{"title":"3.6 auto grad 机制不足","titles":["3 要点总结"]},"468":{"title":"3.7 autograd是什么","titles":["3 要点总结"]},"469":{"title":"3.8 grad_fun","titles":["3 要点总结"]},"470":{"title":"4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握","titles":[]},"471":{"title":"4.1 自动微分如何编码历史记录","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"472":{"title":"4.2 Saved Tensors","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"473":{"title":"4.3 对于不可微分的函数的梯度计算","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"474":{"title":"4.4 局部禁用梯度计算","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"475":{"title":"4.5 设置 requires_grad","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"476":{"title":"4.6 梯度模式","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"477":{"title":"4.6.1 默认模式（Grad mode）","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握","4.6 梯度模式"]},"478":{"title":"4.6.2 无梯度模式","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握","4.6 梯度模式"]},"479":{"title":"4.6.3 推断模式(inference mode)","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握","4.6 梯度模式"]},"480":{"title":"4.6.4 评估模式（nn.Module.eval()）","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握","4.6 梯度模式"]},"481":{"title":"4.7 In-place operations with autograd","titles":["4 pytorch autograd(自动微分机制) extension ： 了解即可，不需要掌握"]},"482":{"title":"torch.nn.Module","titles":[]},"483":{"title":"1 pytorch 自带的 torch.nn layer","titles":[]},"484":{"title":"1.1 用 torch.nn 解决之前的问题","titles":["1 pytorch 自带的 torch.nn layer"]},"485":{"title":"1.2 Tensor 和 Parameter 的区别","titles":["1 pytorch 自带的 torch.nn layer"]},"486":{"title":"2 定义我们自己的module","titles":[]},"487":{"title":"2.1 代码案例","titles":["2 定义我们自己的module"]},"488":{"title":"2.2 customer layer 要点","titles":["2 定义我们自己的module"]},"489":{"title":"3 nn.Module 中的容器","titles":[]},"490":{"title":"4 nn.Module 属性详解","titles":[]},"491":{"title":"5 torch.nn.Module 常用功能","titles":[]},"492":{"title":"5.1  _parameters 设置机制","titles":["5 torch.nn.Module 常用功能"]},"493":{"title":"5.2 _buffers 功能展示","titles":["5 torch.nn.Module 常用功能"]},"494":{"title":"5.3 前向钩子函数展示","titles":["5 torch.nn.Module 常用功能"]},"495":{"title":"5.4 反向钩子函数展示","titles":["5 torch.nn.Module 常用功能"]},"496":{"title":"6 nn.Module 方法全解","titles":["5 torch.nn.Module 常用功能"]},"497":{"title":"1 端到端训练一个深度学习模型","titles":[]},"498":{"title":"Decoder","titles":[]},"499":{"title":"Encoder layer","titles":[]},"500":{"title":"transformer demo","titles":[]},"501":{"title":"0 torch.optim","titles":[]},"502":{"title":"1 如何使用torch.optim","titles":[]},"503":{"title":"1.1 创建一个优化器对象","titles":["1 如何使用torch.optim"]},"504":{"title":"1.2 逐参数选项(Per-parameter options)","titles":["1 如何使用torch.optim"]},"505":{"title":"1.3 进行优化步骤","titles":["1 如何使用torch.optim"]},"506":{"title":"2 torch.optim base class introduce","titles":[]},"507":{"title":"2.1 torch.optim.Optimizer 的输入参数","titles":["2 torch.optim base class introduce"]},"508":{"title":"2.2 torch.optim.Optimizer 属性","titles":["2 torch.optim base class introduce"]},"509":{"title":"2.3 torch.optim.Optimizer 方法","titles":["2 torch.optim base class introduce"]},"510":{"title":"3 不同实现与性能优化","titles":[]},"511":{"title":"1 tensor 的保存和加载","titles":[]},"512":{"title":"2 模型状态的保存","titles":[]},"513":{"title":"2.1 定义一个模型","titles":["2 模型状态的保存"]},"514":{"title":"2.2 保存模型的状态","titles":["2 模型状态的保存"]},"515":{"title":"2.3 加载模型的状态","titles":["2 模型状态的保存"]},"516":{"title":"2.4 思考与尝试","titles":["2 模型状态的保存"]},"517":{"title":"3 保存与加载模型","titles":[]},"518":{"title":"3.1 保存模型","titles":["3 保存与加载模型"]},"519":{"title":"3.2 加载模型","titles":["3 保存与加载模型"]},"520":{"title":"3.3 思考与尝试","titles":["3 保存与加载模型"]},"521":{"title":"4 训练中的保存和加载","titles":[]},"522":{"title":"4.1 保存训练中的状态","titles":["4 训练中的保存和加载"]},"523":{"title":"4.2 加载训练中的状态","titles":["4 训练中的保存和加载"]},"524":{"title":"5 保存和加载模型的静态图","titles":[]},"525":{"title":"5.1 保存模型静态图","titles":["5 保存和加载模型的静态图"]},"526":{"title":"5.2 加载模型静态图","titles":["5 保存和加载模型的静态图"]},"527":{"title":"6 通用格式onnx的保存","titles":[]},"528":{"title":"6.1 保存onnx 静态图模型","titles":["6 通用格式onnx的保存"]},"529":{"title":"6.2 运行onnx 模型","titles":["6 通用格式onnx的保存"]},"530":{"title":"6.3 shape infer","titles":["6 通用格式onnx的保存"]},"531":{"title":"learning rate 调整方案","titles":[]},"532":{"title":"2 pytorch中 torch.optim.lr_scheduler 使用方法","titles":[]},"533":{"title":"2.1 使用方法","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"534":{"title":"3 学习率调度器 策略全解 (learning-rate scheduler)","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"535":{"title":"3.1 lr_scheduler.LambdaLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"536":{"title":"3.2 lr_scheduler.MultiplicativeLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"537":{"title":"3.3 lr_scheduler.StepLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"538":{"title":"3.4 lr_scheduler.MultiStepLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"539":{"title":"3.5 lr_scheduler.ConstantLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"540":{"title":"3.6 lr_scheduler.LinearLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"541":{"title":"3.7 lr_scheduler.ExponentialLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"542":{"title":"3.8 lr_scheduler.PolynomialLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"543":{"title":"3.9 lr_scheduler.CyclicLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"544":{"title":"3.10 lr_scheduler.OneCycleLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"545":{"title":"3.11 lr_scheduler.CosineAnnealingLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"546":{"title":"3.12 lr_scheduler.CosineAnnealingWarmRestarts","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"547":{"title":"3.13 ReduceLROnPlateau","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"548":{"title":"3.14 lr_scheduler.ChainedScheduler","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"549":{"title":"3.15 lr_scheduler.SequentialLR","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"550":{"title":"4 探索源码","titles":["2 pytorch中 torch.optim.lr_scheduler 使用方法"]},"551":{"title":"1 Dataset","titles":[]},"552":{"title":"2 定义自己的数据集","titles":[]},"553":{"title":"3 torch 中的 dataloader","titles":[]},"554":{"title":"4 torchvision","titles":[]},"555":{"title":"4.1 torchvision 中的dataset","titles":["4 torchvision"]},"556":{"title":"torchvision 中的 transforms","titles":["4 torchvision"]},"557":{"title":"1 pytorch 几种模式概览","titles":[]},"558":{"title":"1.1 pytorch 不仅仅是动态图","titles":["1 pytorch 几种模式概览"]},"559":{"title":"1.2 理解动态图和静态图","titles":["1 pytorch 几种模式概览"]},"560":{"title":"1.3 静态图的优势","titles":["1 pytorch 几种模式概览"]},"561":{"title":"2 几种模式简介","titles":[]},"562":{"title":"2.1 fx 图","titles":["2 几种模式简介"]},"563":{"title":"2.2 torch.jit.script","titles":["2 几种模式简介"]},"564":{"title":"2.3 torch.jit.trace","titles":["2 几种模式简介"]},"565":{"title":"2.4 torch.compile","titles":["2 几种模式简介"]},"566":{"title":"3 案例：","titles":[]},"567":{"title":"3.1 模型准备","titles":["3 案例："]},"568":{"title":"3.2 jit.script 代码展示","titles":["3 案例："]},"569":{"title":"3.3 jit.traced 代码展示","titles":["3 案例："]},"570":{"title":"4 export to onnx","titles":[]},"571":{"title":"5 compile to graph (dynamo)","titles":[]},"572":{"title":"1 tensorboard 介绍","titles":[]},"573":{"title":"2 安装方式","titles":[]},"574":{"title":"3 抓取log","titles":[]},"575":{"title":"3.1 import SummaryWriter","titles":["3 抓取log"]},"576":{"title":"3.2 plot scalar","titles":["3 抓取log"]},"577":{"title":"3.3 plot loss and accuracy","titles":["3 抓取log"]},"578":{"title":"4 执行方式：","titles":[]},"579":{"title":"5 查看graph","titles":[]},"580":{"title":"6 查看特征图","titles":[]},"581":{"title":"7 性能分析profiler","titles":[]},"582":{"title":"1 ImageNet training in PyTorch","titles":[]},"583":{"title":"2 Requirements","titles":[]},"584":{"title":"3 数据集下载：","titles":[]},"585":{"title":"4 Training","titles":[]},"586":{"title":"Use Dummy Data","titles":["4 Training"]},"587":{"title":"Multi-processing Distributed Data Parallel Training","titles":["4 Training"]},"588":{"title":"Single node, multiple GPUs:","titles":["4 Training","Multi-processing Distributed Data Parallel Training"]},"589":{"title":"Multiple nodes:","titles":["4 Training","Multi-processing Distributed Data Parallel Training"]},"590":{"title":"Usage","titles":["4 Training"]},"591":{"title":"1 代码介绍","titles":[]},"592":{"title":"2 代码复现步骤","titles":[]},"593":{"title":"3 stable diffusion 整体结构","titles":[]},"594":{"title":"3.1 整体流程图","titles":["3 stable diffusion 整体结构"]},"595":{"title":"3.2 sd 训练流程图","titles":["3 stable diffusion 整体结构"]},"596":{"title":"3.3 sd 推理流程图","titles":["3 stable diffusion 整体结构"]},"597":{"title":"3.4 clip 原理图","titles":["3 stable diffusion 整体结构"]},"598":{"title":"3.5 latent space","titles":["3 stable diffusion 整体结构"]},"599":{"title":"3.6 noiser and denoiser","titles":["3 stable diffusion 整体结构"]},"600":{"title":"4 stable diffusion 具体模型结构","titles":[]},"601":{"title":"4.1 clip 结构","titles":["4 stable diffusion 具体模型结构"]},"602":{"title":"4.2 vae 模型结构","titles":["4 stable diffusion 具体模型结构"]},"603":{"title":"4.2 unet-base 模型结构图","titles":["4 stable diffusion 具体模型结构"]},"604":{"title":"5 评价指标","titles":[]},"605":{"title":"5.1 clip score","titles":["5 评价指标"]},"606":{"title":"5.2 FID","titles":["5 评价指标"]},"607":{"title":"6 sd 进阶","titles":[]},"608":{"title":"6.1 sd2 之前版本异同","titles":["6 sd 进阶"]},"609":{"title":"6.2 从 SD 到 SDXL","titles":["6 sd 进阶"]},"610":{"title":"6 参考链接","titles":[]},"611":{"title":"SDXL","titles":[]},"612":{"title":"参考链接","titles":[]},"613":{"title":"1 模型跑通","titles":[]},"614":{"title":"2 bert 介绍","titles":[]},"615":{"title":"3 transformer 发展脉络","titles":[]},"616":{"title":"3.1 transformer 概述","titles":["3 transformer 发展脉络"]},"617":{"title":"3.2 迁移学习","titles":["3 transformer 发展脉络"]},"618":{"title":"3.3 transformer 家族","titles":["3 transformer 发展脉络"]},"619":{"title":"3.4 encoder 分支","titles":["3 transformer 发展脉络"]},"620":{"title":"3.5 Decoder 分支","titles":["3 transformer 发展脉络"]},"621":{"title":"3.6 Encoder-Decoder 分支","titles":["3 transformer 发展脉络"]},"622":{"title":"3.7 大模型的爆发","titles":["3 transformer 发展脉络"]},"623":{"title":"4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务","titles":[]},"624":{"title":"4.1 任务概述","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务"]},"625":{"title":"4.2 CRF 原理详解","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务"]},"626":{"title":"4.2.1 线性CRF的定义","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务","4.2 CRF 原理详解"]},"627":{"title":"4.2.2 发射分数","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务","4.2 CRF 原理详解"]},"628":{"title":"4.2.3 转移分数","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务","4.2 CRF 原理详解"]},"629":{"title":"4.2.4 CRF 的损失函数计算","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务"]},"630":{"title":"4.2.5 CRF的Viterbi解码","titles":["4 BERT + CRF(Conditional Random Field) 实现命名实体识别(NER) 任务","4.2.4 CRF 的损失函数计算"]},"631":{"title":"5 代码详解","titles":[]},"632":{"title":"5.1 真实路径得分计算","titles":["5 代码详解"]},"633":{"title":"5.2 总路径得分计算","titles":["5 代码详解"]},"634":{"title":"5.3 Viterbi 解码过程","titles":["5 代码详解"]},"635":{"title":"5.4 f1 score 的计算","titles":["5 代码详解"]},"636":{"title":"1 模型跑通","titles":[]},"637":{"title":"2 t5 介绍","titles":[]},"638":{"title":"3 position embedding 总结","titles":[]},"639":{"title":"3.1 绝对位置编码","titles":["3 position embedding 总结"]},"640":{"title":"3.1.1 三角函数式(Sinusoidal)位置编码","titles":["3 position embedding 总结","3.1 绝对位置编码"]},"641":{"title":"3.1.2 可学习(Learnable)的位置编码","titles":["3 position embedding 总结","3.1 绝对位置编码"]},"642":{"title":"3.2 相对位置编码","titles":["3 position embedding 总结"]},"643":{"title":"3.2.1 经典的相对位置编码","titles":["3 position embedding 总结","3.2 相对位置编码"]},"644":{"title":"3.2.2 T5 中的相对位置编码","titles":["3 position embedding 总结","3.2 相对位置编码"]},"645":{"title":"3.3 旋转位置编码","titles":["3 position embedding 总结"]},"646":{"title":"3.3.1 RoPE 原理","titles":["3 position embedding 总结","3.3 旋转位置编码"]},"647":{"title":"3.3.2 2 维扩展到多维","titles":["3 position embedding 总结","3.3 旋转位置编码"]},"648":{"title":"3.3.3 RoPE 的高效计算","titles":["3 position embedding 总结","3.3 旋转位置编码"]},"649":{"title":"3.3.4 llama 中的RoPE 代码实现","titles":["3 position embedding 总结","3.3 旋转位置编码"]},"650":{"title":"VAE","titles":[]},"651":{"title":"1 VAE 的作用 （数据压缩和数据生成）","titles":[]},"652":{"title":"1.1 数据压缩","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"653":{"title":"1.2 数据生成","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"654":{"title":"1.3 数据压缩与数据生成的关系","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"655":{"title":"1.4 example","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"656":{"title":"1.5 可能出现的问题","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"657":{"title":"1.6 VAE 要点总结","titles":["1 VAE 的作用 （数据压缩和数据生成）"]},"658":{"title":"2 理论推导VAE","titles":[]},"659":{"title":"2.1 引入变分","titles":["2 理论推导VAE"]},"660":{"title":"4 参考文献","titles":[]},"661":{"title":"Scaling Laws for Neural Language Models","titles":[]},"662":{"title":"How to training realy large model","titles":[]},"663":{"title":"1 llama-v1","titles":[]},"664":{"title":"2 llama-v2","titles":[]},"665":{"title":"3 llama-v3","titles":[]},"666":{"title":"4 llama code implement","titles":[]},"667":{"title":"DeepSeek-V2","titles":[]},"668":{"title":"DeepSeek-MOE","titles":[]},"669":{"title":"DeepSeek-V3","titles":[]},"670":{"title":"DeepSeek-R1","titles":[]},"671":{"title":"Deep Learning Theroy","titles":[]},"672":{"title":"AI时代的算法学习","titles":[]},"673":{"title":"408知识","titles":[]},"674":{"title":"4.1 进程同步","titles":[]},"675":{"title":"1. 基本概念","titles":["4.1 进程同步"]},"676":{"title":"1.1为什么要提出？","titles":["4.1 进程同步","1. 基本概念"]},"677":{"title":"1.2 同步是什么？","titles":["4.1 进程同步","1. 基本概念"]},"678":{"title":"1.3 什么又是互斥？","titles":["4.1 进程同步","1. 基本概念"]},"679":{"title":"1.4 临界资源是啥？","titles":["4.1 进程同步","1. 基本概念"]},"680":{"title":"1.4.1 系统资源","titles":["4.1 进程同步","1. 基本概念","1.4 临界资源是啥？"]},"681":{"title":"1.4.2 临界资源（共享资源）","titles":["4.1 进程同步","1. 基本概念","1.4 临界资源是啥？"]},"682":{"title":"1.4.3 临界区","titles":["4.1 进程同步","1. 基本概念","1.4 临界资源是啥？"]},"683":{"title":"2. 同步如何实现","titles":["4.1 进程同步"]},"684":{"title":"2.1 访问原则","titles":["4.1 进程同步","2. 同步如何实现"]},"685":{"title":"2.2 软件实现（后续补充）","titles":["4.1 进程同步","2. 同步如何实现"]},"686":{"title":"2.2.1 单标志法","titles":["4.1 进程同步","2. 同步如何实现","2.2 软件实现（后续补充）"]},"687":{"title":"2.2.2 双标志先检查法","titles":["4.1 进程同步","2. 同步如何实现","2.2 软件实现（后续补充）"]},"688":{"title":"2.2.3 双标志后检查法","titles":["4.1 进程同步","2. 同步如何实现","2.2 软件实现（后续补充）"]},"689":{"title":"2.3 硬件实现（后续补充）","titles":["4.1 进程同步","2. 同步如何实现"]},"690":{"title":"2.3.1 中断屏蔽方法","titles":["4.1 进程同步","2. 同步如何实现","2.3 硬件实现（后续补充）"]},"691":{"title":"2.3.2 Test-And-Set（TS指令/TSL指令）","titles":["4.1 进程同步","2. 同步如何实现","2.3 硬件实现（后续补充）"]},"692":{"title":"2.3.3 Swap指令（EXCHANGE，XCHG指令）","titles":["4.1 进程同步","2. 同步如何实现","2.3 硬件实现（后续补充）"]},"693":{"title":"2.3.4 信号量机制（重点，下一节详细讲解）","titles":["4.1 进程同步","2. 同步如何实现","2.3 硬件实现（后续补充）"]},"694":{"title":"3. 参考资料","titles":["4.1 进程同步"]},"695":{"title":"4.4 信号量机制pv操作之“可见”","titles":[]},"696":{"title":"[书籍推荐]——程序是怎样跑起来的","titles":[]},"697":{"title":"1. 推荐原因1","titles":["[书籍推荐]——程序是怎样跑起来的"]},"698":{"title":"2. 推荐原因2","titles":["[书籍推荐]——程序是怎样跑起来的"]},"699":{"title":"3. 推荐原因3","titles":["[书籍推荐]——程序是怎样跑起来的"]},"700":{"title":"4. 推荐原因4","titles":["[书籍推荐]——程序是怎样跑起来的"]},"701":{"title":"5. 本书大概内容","titles":["[书籍推荐]——程序是怎样跑起来的"]},"702":{"title":"6. 如何阅读该书","titles":["[书籍推荐]——程序是怎样跑起来的"]},"703":{"title":"JavaSE 简介","titles":[]},"704":{"title":"JavaSE 核心概念","titles":["JavaSE 简介"]},"705":{"title":"1. JDK、JRE、JVM","titles":["JavaSE 简介","JavaSE 核心概念"]},"706":{"title":"2. Java 基础语法","titles":["JavaSE 简介","JavaSE 核心概念"]},"707":{"title":"Java 后端学习框架","titles":[]},"708":{"title":"1. Java 基础","titles":["Java 后端学习框架"]},"709":{"title":"2. 数据库基础","titles":["Java 后端学习框架"]},"710":{"title":"3. Java Web 开发","titles":["Java 后端学习框架"]},"711":{"title":"4. Mybatis","titles":["Java 后端学习框架"]},"712":{"title":"5. Spring","titles":["Java 后端学习框架"]},"713":{"title":"6. Spring MVC","titles":["Java 后端学习框架"]},"714":{"title":"7. SprintBoot","titles":["Java 后端学习框架"]},"715":{"title":"8. 消息中间件","titles":["Java 后端学习框架"]},"716":{"title":"9. 部署与监控","titles":["Java 后端学习框架"]},"717":{"title":"10. 进阶主题","titles":["Java 后端学习框架"]},"718":{"title":"参考资料","titles":["Java 后端学习框架"]},"719":{"title":"MyBatis框架","titles":[]},"720":{"title":"01、Mybatis简介","titles":["MyBatis框架"]},"721":{"title":"1.1、什么是MyBatis","titles":["MyBatis框架","01、Mybatis简介"]},"722":{"title":"1.2、持久化","titles":["MyBatis框架","01、Mybatis简介"]},"723":{"title":"1.3、持久层","titles":["MyBatis框架","01、Mybatis简介"]},"724":{"title":"1.4、为什么需要Mybatis","titles":["MyBatis框架","01、Mybatis简介"]},"725":{"title":"02、MyBatis第一个程序","titles":["MyBatis框架"]},"726":{"title":"2.1、代码演示","titles":["MyBatis框架","02、MyBatis第一个程序"]},"727":{"title":"2.2、问题说明","titles":["MyBatis框架","02、MyBatis第一个程序"]},"728":{"title":"03、CRUD操作","titles":["MyBatis框架"]},"729":{"title":"3.1、namespace","titles":["MyBatis框架","03、CRUD操作"]},"730":{"title":"3.2、select","titles":["MyBatis框架","03、CRUD操作"]},"731":{"title":"3.3、insert","titles":["MyBatis框架","03、CRUD操作"]},"732":{"title":"3.4、update","titles":["MyBatis框架","03、CRUD操作"]},"733":{"title":"3.5、delete","titles":["MyBatis框架","03、CRUD操作"]},"734":{"title":"3.6、思考题","titles":["MyBatis框架","03、CRUD操作"]},"735":{"title":"Linux基础部分","titles":[]},"736":{"title":"一、基本命令使用","titles":["Linux基础部分"]},"737":{"title":"1. Linux 文件系统结构","titles":["Linux基础部分","一、基本命令使用"]},"738":{"title":"简介","titles":["Linux基础部分","一、基本命令使用","1. Linux 文件系统结构"]},"739":{"title":"常用目录","titles":["Linux基础部分","一、基本命令使用","1. Linux 文件系统结构"]},"740":{"title":"示例","titles":["Linux基础部分","一、基本命令使用","1. Linux 文件系统结构"]},"741":{"title":"2. 基本命令操作","titles":["Linux基础部分","一、基本命令使用"]},"742":{"title":"文件和目录管理","titles":["Linux基础部分","一、基本命令使用","2. 基本命令操作"]},"743":{"title":"文件操作","titles":["Linux基础部分","一、基本命令使用","2. 基本命令操作"]},"744":{"title":"3. 文件权限管理","titles":["Linux基础部分","一、基本命令使用"]},"745":{"title":"权限表示","titles":["Linux基础部分","一、基本命令使用","3. 文件权限管理"]},"746":{"title":"查看和修改权限","titles":["Linux基础部分","一、基本命令使用","3. 文件权限管理"]},"747":{"title":"4. 文本查看","titles":["Linux基础部分","一、基本命令使用"]},"748":{"title":"查看文本文件","titles":["Linux基础部分","一、基本命令使用","4. 文本查看"]},"749":{"title":"查找内容","titles":["Linux基础部分","一、基本命令使用","4. 文本查看"]},"750":{"title":"5. Vim 编辑器基础","titles":["Linux基础部分","一、基本命令使用"]},"751":{"title":"5.1 进入退出","titles":["Linux基础部分","一、基本命令使用","5. Vim 编辑器基础"]},"752":{"title":"5.2 模式","titles":["Linux基础部分","一、基本命令使用","5. Vim 编辑器基础"]},"753":{"title":"5.3 基本操作","titles":["Linux基础部分","一、基本命令使用","5. Vim 编辑器基础"]},"754":{"title":"6. 进程管理","titles":["Linux基础部分","一、基本命令使用"]},"755":{"title":"查看进程","titles":["Linux基础部分","一、基本命令使用","6. 进程管理"]},"756":{"title":"管理进程","titles":["Linux基础部分","一、基本命令使用","6. 进程管理"]},"757":{"title":"示例","titles":["Linux基础部分","一、基本命令使用","6. 进程管理"]},"758":{"title":"7. 网络管理","titles":["Linux基础部分","一、基本命令使用"]},"759":{"title":"查看网络配置","titles":["Linux基础部分","一、基本命令使用","7. 网络管理"]},"760":{"title":"查看网络端口","titles":["Linux基础部分","一、基本命令使用","7. 网络管理"]},"761":{"title":"抓取网页内容","titles":["Linux基础部分","一、基本命令使用","7. 网络管理"]},"762":{"title":"8. 用户和组管理","titles":["Linux基础部分","一、基本命令使用"]},"763":{"title":"用户管理","titles":["Linux基础部分","一、基本命令使用","8. 用户和组管理"]},"764":{"title":"9. 文件查找","titles":["Linux基础部分","一、基本命令使用"]},"765":{"title":"查找文件","titles":["Linux基础部分","一、基本命令使用","9. 文件查找"]},"766":{"title":"查找可执行文件","titles":["Linux基础部分","一、基本命令使用","9. 文件查找"]},"767":{"title":"10. 归档与压缩","titles":["Linux基础部分","一、基本命令使用"]},"768":{"title":"打包和解压","titles":["Linux基础部分","一、基本命令使用","10. 归档与压缩"]},"769":{"title":"11. 系统更新与软件管理","titles":["Linux基础部分","一、基本命令使用"]},"770":{"title":"更新系统和安装软件包","titles":["Linux基础部分","一、基本命令使用","11. 系统更新与软件管理"]},"771":{"title":"12. 日志管理","titles":["Linux基础部分","一、基本命令使用"]},"772":{"title":"查看日志","titles":["Linux基础部分","一、基本命令使用","12. 日志管理"]},"773":{"title":"二、VIM操作命令","titles":["Linux基础部分"]},"774":{"title":"1. Vim 模式简介","titles":["Linux基础部分","二、VIM操作命令"]},"775":{"title":"2. 启动和退出 Vim","titles":["Linux基础部分","二、VIM操作命令"]},"776":{"title":"启动","titles":["Linux基础部分","二、VIM操作命令","2. 启动和退出 Vim"]},"777":{"title":"退出","titles":["Linux基础部分","二、VIM操作命令","2. 启动和退出 Vim"]},"778":{"title":"3. 插入模式操作","titles":["Linux基础部分","二、VIM操作命令"]},"779":{"title":"4. 普通模式基础操作","titles":["Linux基础部分","二、VIM操作命令"]},"780":{"title":"光标移动","titles":["Linux基础部分","二、VIM操作命令","4. 普通模式基础操作"]},"781":{"title":"删除操作","titles":["Linux基础部分","二、VIM操作命令","4. 普通模式基础操作"]},"782":{"title":"复制和粘贴","titles":["Linux基础部分","二、VIM操作命令","4. 普通模式基础操作"]},"783":{"title":"撤销与重做","titles":["Linux基础部分","二、VIM操作命令","4. 普通模式基础操作"]},"784":{"title":"5. 可视模式（选择操作）","titles":["Linux基础部分","二、VIM操作命令"]},"785":{"title":"6. 查找与替换","titles":["Linux基础部分","二、VIM操作命令"]},"786":{"title":"查找","titles":["Linux基础部分","二、VIM操作命令","6. 查找与替换"]},"787":{"title":"替换","titles":["Linux基础部分","二、VIM操作命令","6. 查找与替换"]},"788":{"title":"7. 多文件和多窗口操作","titles":["Linux基础部分","二、VIM操作命令"]},"789":{"title":"打开多个文件","titles":["Linux基础部分","二、VIM操作命令","7. 多文件和多窗口操作"]},"790":{"title":"分屏操作","titles":["Linux基础部分","二、VIM操作命令","7. 多文件和多窗口操作"]},"791":{"title":"8. 文本缩进和格式调整","titles":["Linux基础部分","二、VIM操作命令"]},"792":{"title":"自动缩进","titles":["Linux基础部分","二、VIM操作命令","8. 文本缩进和格式调整"]},"793":{"title":"格式化代码","titles":["Linux基础部分","二、VIM操作命令","8. 文本缩进和格式调整"]},"794":{"title":"MPI并行计算","titles":[]},"795":{"title":"一、并行的引入","titles":["MPI并行计算"]},"796":{"title":"1.1 基本概念","titles":["MPI并行计算","一、并行的引入"]},"797":{"title":"1.2 什么是并行？","titles":["MPI并行计算","一、并行的引入"]},"798":{"title":"1.3 并行有啥用？","titles":["MPI并行计算","一、并行的引入"]},"799":{"title":"1.4 并行的实际案例","titles":["MPI并行计算","一、并行的引入"]},"800":{"title":"二、并行的类型","titles":["MPI并行计算"]},"801":{"title":"2.1 按照处理机划分","titles":["MPI并行计算","二、并行的类型"]},"802":{"title":"2.2 按照实现方式划分","titles":["MPI并行计算","二、并行的类型"]},"803":{"title":"三、MPI的基本原理","titles":["MPI并行计算"]},"804":{"title":"3.1 基本原理","titles":["MPI并行计算","三、MPI的基本原理"]},"805":{"title":"1. MPI的架构","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"806":{"title":"2. 进程和通信","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"807":{"title":"3. MPI的通信模式","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"808":{"title":"4. MPI的基本函数","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"809":{"title":"5. MPI的数据类型和消息标签","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"810":{"title":"6. 通信域（Communicator）","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"811":{"title":"7. MPI中的常见通信模式","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"812":{"title":"8. MPI的优势和劣势","titles":["MPI并行计算","三、MPI的基本原理","3.1 基本原理"]},"813":{"title":"3.2 模型演示","titles":["MPI并行计算","三、MPI的基本原理"]},"814":{"title":"四、基本环境配置（简略）","titles":["MPI并行计算"]},"815":{"title":"4.1 Linux环境","titles":["MPI并行计算","四、基本环境配置（简略）"]},"816":{"title":"4.2 ssh工具","titles":["MPI并行计算","四、基本环境配置（简略）"]},"817":{"title":"4.3 VIM编辑器","titles":["MPI并行计算","四、基本环境配置（简略）"]},"818":{"title":"4.4 MPI环境","titles":["MPI并行计算","四、基本环境配置（简略）"]},"819":{"title":"4.4.1 安装","titles":["MPI并行计算","四、基本环境配置（简略）","4.4 MPI环境"]},"820":{"title":"4.4.2 编译","titles":["MPI并行计算","四、基本环境配置（简略）","4.4 MPI环境"]},"821":{"title":"4.4.3 配置","titles":["MPI并行计算","四、基本环境配置（简略）","4.4 MPI环境"]},"822":{"title":"4.4.4 了解","titles":["MPI并行计算","四、基本环境配置（简略）","4.4 MPI环境"]},"823":{"title":"五、MPI的基本使用","titles":["MPI并行计算"]},"824":{"title":"5.1 快速使用","titles":["MPI并行计算","五、MPI的基本使用"]},"825":{"title":"5.2 源码了解","titles":["MPI并行计算","五、MPI的基本使用"]},"826":{"title":"5.3 进阶","titles":["MPI并行计算","五、MPI的基本使用"]},"827":{"title":"5.3.1 分布式实现","titles":["MPI并行计算","五、MPI的基本使用","5.3 进阶"]},"828":{"title":"六、学习策略与建议","titles":["MPI并行计算"]},"829":{"title":"6.1 新东西学习","titles":["MPI并行计算","六、学习策略与建议"]},"830":{"title":"6.2 遇事不决","titles":["MPI并行计算","六、学习策略与建议"]},"831":{"title":"6.3 知识体系构建","titles":["MPI并行计算","六、学习策略与建议"]},"832":{"title":"Linux模块","titles":[]},"833":{"title":"IT学习指南","titles":[]},"834":{"title":"yi直线光栅化","titles":[]},"835":{"title":"1. 引入","titles":["yi直线光栅化"]},"836":{"title":"2. 实现","titles":["yi直线光栅化"]},"837":{"title":"2.1 基本实现思路","titles":["yi直线光栅化","2. 实现"]},"838":{"title":"2.2 数值微分法（DDA算法）","titles":["yi直线光栅化","2. 实现"]},"839":{"title":"2.2.1 DDA 算法概述","titles":["yi直线光栅化","2. 实现","2.2 数值微分法（DDA算法）"]},"840":{"title":"2.2.2 算法步骤","titles":["yi直线光栅化","2. 实现","2.2 数值微分法（DDA算法）"]},"841":{"title":"2.2.3 伪代码演示","titles":["yi直线光栅化","2. 实现","2.2 数值微分法（DDA算法）"]},"842":{"title":"2.2.4 优化方向","titles":["yi直线光栅化","2. 实现","2.2 数值微分法（DDA算法）"]},"843":{"title":"2.3 中心点画线法","titles":["yi直线光栅化","2. 实现"]},"844":{"title":"2.3.1 算法思想","titles":["yi直线光栅化","2. 实现","2.3 中心点画线法"]},"845":{"title":"2.3.2 算法步骤","titles":["yi直线光栅化","2. 实现","2.3 中心点画线法"]},"846":{"title":"2.3.3 举例","titles":["yi直线光栅化","2. 实现","2.3 中心点画线法"]},"847":{"title":"2.3.4 伪代码演示","titles":["yi直线光栅化","2. 实现","2.3 中心点画线法"]},"848":{"title":"2.3 Bresenham算法","titles":["yi直线光栅化","2. 实现"]},"849":{"title":"2.3.1 基本思想","titles":["yi直线光栅化","2. 实现","2.3 Bresenham算法"]},"850":{"title":"2.3.2 改进策略","titles":["yi直线光栅化","2. 实现","2.3 Bresenham算法"]},"851":{"title":"2.3.3 伪代码实现","titles":["yi直线光栅化","2. 实现","2.3 Bresenham算法"]},"852":{"title":"2.3.4 举例","titles":["yi直线光栅化","2. 实现","2.3 Bresenham算法"]},"853":{"title":"3. 思考","titles":["yi直线光栅化"]},"854":{"title":"码医森","titles":[]},"855":{"title":"主页:","titles":["码医森"]},"856":{"title":"站点大纲:","titles":["码医森"]},"857":{"title":"计算机图形学的主要内容","titles":[]},"858":{"title":"为什么要学习计算机图形学","titles":[]},"859":{"title":"最新研究内容和成果","titles":[]},"860":{"title":"该站点的整体结构","titles":[]},"861":{"title":"主页🏠","titles":["该站点的整体结构"]},"862":{"title":"站点大纲👀","titles":["该站点的整体结构"]},"863":{"title":"个人提升","titles":[]},"864":{"title":"整体该博客(站点)指南","titles":[]},"865":{"title":"更新日志","titles":[]},"866":{"title":"2024-10","titles":["更新日志"]},"867":{"title":"大更新：","titles":["更新日志","2024-10"]},"868":{"title":"小更新：","titles":["更新日志","2024-10"]},"869":{"title":"2024-11","titles":["更新日志"]},"870":{"title":"大更新：","titles":["更新日志","2024-11"]},"871":{"title":"小更新：","titles":["更新日志","2024-11"]},"872":{"title":"2025-03","titles":["更新日志"]},"873":{"title":"大更新:","titles":["更新日志","2025-03"]},"874":{"title":"小更新:","titles":["更新日志","2025-03"]},"875":{"title":"不同商家之间的视野——带室友修电脑","titles":[]},"876":{"title":"论语之悟——学而篇","titles":[]},"877":{"title":"1. 学而时习之","titles":["论语之悟——学而篇"]},"878":{"title":"1.1 个人参悟","titles":["论语之悟——学而篇","1. 学而时习之"]},"879":{"title":"1.2 不解之言","titles":["论语之悟——学而篇","1. 学而时习之"]},"880":{"title":"士兵突击告诉让我明白的那些事","titles":[]},"881":{"title":"站长随笔","titles":[]},"882":{"title":"更新进度","titles":[]},"883":{"title":"Docker下的doccano添加普通用户","titles":[]},"884":{"title":"1. 操作步骤","titles":["Docker下的doccano添加普通用户"]},"885":{"title":"1.1 启动docker的doccano","titles":["Docker下的doccano添加普通用户"]},"886":{"title":"1.2 进入Doccano容器","titles":["Docker下的doccano添加普通用户"]},"887":{"title":"1.3 配置（添加）超级管理员或者普通管理员账号","titles":["Docker下的doccano添加普通用户"]},"888":{"title":"1.3.1 管理员账户","titles":["Docker下的doccano添加普通用户","1.3 配置（添加）超级管理员或者普通管理员账号"]},"889":{"title":"1.3.2 普通用户账户","titles":["Docker下的doccano添加普通用户","1.3 配置（添加）超级管理员或者普通管理员账号"]},"890":{"title":"Introduction to PyTorch","titles":[]},"891":{"title":"1. What is PyTorch?","titles":["Introduction to PyTorch"]},"892":{"title":"2. Key Features of PyTorch","titles":["Introduction to PyTorch"]},"893":{"title":"2.1. Dynamic Computation Graphs","titles":["Introduction to PyTorch","2. Key Features of PyTorch"]},"894":{"title":"2.2. Autograd (Automatic Gradient Calculation)","titles":["Introduction to PyTorch","2. Key Features of PyTorch"]},"895":{"title":"2.3. Tensors","titles":["Introduction to PyTorch","2. Key Features of PyTorch"]},"896":{"title":"2.4. Easy to Use with Python","titles":["Introduction to PyTorch","2. Key Features of PyTorch"]},"897":{"title":"2.5. Rich Ecosystem of Libraries","titles":["Introduction to PyTorch","2. Key Features of PyTorch"]},"898":{"title":"3. The Application Domains of PyTorch","titles":["Introduction to PyTorch"]},"899":{"title":"3.1. Research","titles":["Introduction to PyTorch","3. The Application Domains of PyTorch"]},"900":{"title":"3.2. Industry","titles":["Introduction to PyTorch","3. The Application Domains of PyTorch"]},"901":{"title":"3.3. Education","titles":["Introduction to PyTorch","3. The Application Domains of PyTorch"]},"902":{"title":"4. How To Use PyTorch？","titles":["Introduction to PyTorch"]},"903":{"title":"4.1 Official Tutorials","titles":["Introduction to PyTorch","4. How To Use PyTorch？"]},"904":{"title":"4.2 Basic Framework","titles":["Introduction to PyTorch","4. How To Use PyTorch？"]},"905":{"title":"5. Conclusion","titles":["Introduction to PyTorch"]},"906":{"title":"各类技术问题和踩坑","titles":[]},"907":{"title":"更新日志","titles":[]},"908":{"title":"有关虚拟机创建的网络问题","titles":[]},"909":{"title":"1. 基础环境","titles":["有关虚拟机创建的网络问题"]},"910":{"title":"2. 相关知识","titles":["有关虚拟机创建的网络问题"]},"911":{"title":"3. 常见网络问题","titles":["有关虚拟机创建的网络问题"]},"912":{"title":"4. 解决方案","titles":["有关虚拟机创建的网络问题"]},"913":{"title":"4.1 法一：在物理主机开启NAT和DHCP服务","titles":["有关虚拟机创建的网络问题","4. 解决方案"]},"914":{"title":"4.2 法二：恢复默认网络配置","titles":["有关虚拟机创建的网络问题","4. 解决方案"]},"915":{"title":"5. 固定虚拟机网络ip（自动ip分配的可以不用操作）","titles":["有关虚拟机创建的网络问题"]},"916":{"title":"生活与算法","titles":[]},"917":{"title":"1. 什么是算法？","titles":["生活与算法"]},"918":{"title":"2. 生活中常常有算法","titles":["生活与算法"]},"919":{"title":"2.1 选择顺序：排队和优先处理","titles":["生活与算法","2. 生活中常常有算法"]},"920":{"title":"2.2 找东西：生活中的搜索","titles":["生活与算法","2. 生活中常常有算法"]},"921":{"title":"2.3 每次都选最佳：贪心法则","titles":["生活与算法","2. 生活中常常有算法"]},"922":{"title":"2.4 长远规划：逐步优化的过程","titles":["生活与算法","2. 生活中常常有算法"]},"923":{"title":"3. 生活离不开算法思维","titles":["生活与算法"]},"924":{"title":"3.1 化繁为简：一步步来","titles":["生活与算法","3. 生活离不开算法思维"]},"925":{"title":"3.2 避免错误：逻辑推理","titles":["生活与算法","3. 生活离不开算法思维"]},"926":{"title":"3.3 时间管理：高效完成任务","titles":["生活与算法","3. 生活离不开算法思维"]},"927":{"title":"4. 算法交织于生活","titles":["生活与算法"]},"928":{"title":"5. 简单总结一下","titles":["生活与算法"]},"929":{"title":"让我们简单步入“贪心”叭","titles":[]},"930":{"title":"1. 最大四位数的例子：从数字中选最大","titles":["让我们简单步入“贪心”叭"]},"931":{"title":"1.1 问题：","titles":["让我们简单步入“贪心”叭","1. 最大四位数的例子：从数字中选最大"]},"932":{"title":"1.2 贪心思维：","titles":["让我们简单步入“贪心”叭","1. 最大四位数的例子：从数字中选最大"]},"933":{"title":"1.3 数学过程：","titles":["让我们简单步入“贪心”叭","1. 最大四位数的例子：从数字中选最大"]},"934":{"title":"1.4 结论：","titles":["让我们简单步入“贪心”叭","1. 最大四位数的例子：从数字中选最大"]},"935":{"title":"大家可能会觉得这不是显而易见的吗？但这只能帮你解决简单的问题，复杂的问题就需要我们认真去分析了。","titles":["让我们简单步入“贪心”叭"]},"936":{"title":"2. 选择最便宜的出行方案","titles":["让我们简单步入“贪心”叭"]},"937":{"title":"2.1 问题：","titles":["让我们简单步入“贪心”叭","2. 选择最便宜的出行方案"]},"938":{"title":"2.2 贪心思维：","titles":["让我们简单步入“贪心”叭","2. 选择最便宜的出行方案"]},"939":{"title":"2.3 数学过程：","titles":["让我们简单步入“贪心”叭","2. 选择最便宜的出行方案"]},"940":{"title":"3. 如何分配时间：优先完成最紧急的任务","titles":["让我们简单步入“贪心”叭"]},"941":{"title":"3.1 问题：","titles":["让我们简单步入“贪心”叭","3. 如何分配时间：优先完成最紧急的任务"]},"942":{"title":"3.2 贪心思维：","titles":["让我们简单步入“贪心”叭","3. 如何分配时间：优先完成最紧急的任务"]},"943":{"title":"3.3 数学过程：","titles":["让我们简单步入“贪心”叭","3. 如何分配时间：优先完成最紧急的任务"]},"944":{"title":"4. 找零问题：使用最少的硬币","titles":["让我们简单步入“贪心”叭"]},"945":{"title":"4.1 问题：","titles":["让我们简单步入“贪心”叭","4. 找零问题：使用最少的硬币"]},"946":{"title":"4.2 贪心思维：","titles":["让我们简单步入“贪心”叭","4. 找零问题：使用最少的硬币"]},"947":{"title":"4.3 数学过程：","titles":["让我们简单步入“贪心”叭","4. 找零问题：使用最少的硬币"]},"948":{"title":"5. 我们已经步入“贪心算法”啦","titles":["让我们简单步入“贪心”叭"]},"949":{"title":"场景问题内容","titles":[]},"950":{"title":"分发饼干问题","titles":[]},"951":{"title":"1. 问题描述","titles":["分发饼干问题"]},"952":{"title":"2. 目标","titles":["分发饼干问题"]},"953":{"title":"3. 输入：","titles":["分发饼干问题"]},"954":{"title":"4. 输出：","titles":["分发饼干问题"]},"955":{"title":"5. 贪心算法的解法思路","titles":["分发饼干问题"]},"956":{"title":"6. 解题步骤","titles":["分发饼干问题"]},"957":{"title":"7. 代码实现（Python）","titles":["分发饼干问题"]},"958":{"title":"8. 示例","titles":["分发饼干问题"]},"959":{"title":"9. 时间复杂度","titles":["分发饼干问题"]},"960":{"title":"10. 贪心策略的解释","titles":["分发饼干问题"]},"961":{"title":"11. 思考","titles":["分发饼干问题"]},"962":{"title":"这年代，不吃面经咋活？","titles":[]},"963":{"title":"前任铺路后人走","titles":[]},"964":{"title":"NLP面经","titles":["前任铺路后人走"]},"965":{"title":"前任铺路后人走","titles":[]},"966":{"title":"人的本性——贪心！！！","titles":[]},"967":{"title":"1. 贪心与人生","titles":["人的本性——贪心！！！"]},"968":{"title":"2. 贪心算法基本概念","titles":["人的本性——贪心！！！"]},"969":{"title":"2.1 概念","titles":["人的本性——贪心！！！","2. 贪心算法基本概念"]},"970":{"title":"2.2 通俗讲解","titles":["人的本性——贪心！！！","2. 贪心算法基本概念"]},"971":{"title":"3. 贪心算法原理","titles":["人的本性——贪心！！！"]},"972":{"title":"3.1 我想说","titles":["人的本性——贪心！！！","3. 贪心算法原理"]},"973":{"title":"3.2 贪心策略","titles":["人的本性——贪心！！！","3. 贪心算法原理"]},"974":{"title":"3.3 基本原理","titles":["人的本性——贪心！！！","3. 贪心算法原理"]},"975":{"title":"4. 总结","titles":["人的本性——贪心！！！"]}},"dirtCount":0,"index":[["证明全局最优",{"2":{"974":1}}],["局部最优解在全局最优解内",{"2":{"974":1}}],["局部最优",{"2":{"970":1}}],["局部禁用梯度计算",{"0":{"474":1}}],["采取对应的策略和方法",{"2":{"970":1}}],["采用的是普通的",{"2":{"609":1}}],["采用了更大的text",{"2":{"608":1}}],["采用这种方法时",{"2":{"370":1}}],["采用",{"2":{"338":1}}],["采用可分离卷积的计算量比标准卷积要少",{"2":{"59":1}}],["性价比",{"2":{"967":1}}],["性能优化",{"2":{"717":1}}],["性能优异",{"2":{"619":1}}],["性能分析profiler",{"0":{"581":1}}],["性能就越不会下降",{"2":{"381":1}}],["性能取决于问题",{"2":{"363":1}}],["往往追求",{"2":{"967":1}}],["往往得不出有效的结论",{"2":{"369":1}}],["孩子的胃口",{"2":{"958":1}}],["孩子得到满足",{"2":{"957":1}}],["孩子指针",{"2":{"957":1}}],["饼干的大小",{"2":{"958":1}}],["饼干指针",{"2":{"957":1}}],["饼干大小数组",{"2":{"956":1}}],["胃口",{"2":{"953":1}}],["场景问题内容",{"0":{"949":1}}],["啦",{"0":{"948":1}}],["枚硬币",{"2":{"947":1}}],["项任务",{"2":{"943":1}}],["剩下时间做截止时间是",{"2":{"943":1}}],["突然想起之前新闻上报道的一个高中小伙拿着小钱钱坐公交从xxx坐到了xxx",{"2":{"937":1}}],["哈哈哈",{"2":{"937":1,"967":1}}],["哈佛大学",{"2":{"350":1}}],["放在个位",{"2":{"933":1}}],["放在十位",{"2":{"933":1}}],["放在百位",{"2":{"933":1}}],["放一张大纲导图",{"2":{"735":1}}],["帮助大家理解",{"2":{"929":1}}],["帮助我们更好地应对每天的琐事与挑战",{"2":{"928":1}}],["帮助我们更有效率地处理生活中的琐事",{"2":{"923":1}}],["叭",{"0":{"929":1},"1":{"930":1,"931":1,"932":1,"933":1,"934":1,"935":1,"936":1,"937":1,"938":1,"939":1,"940":1,"941":1,"942":1,"943":1,"944":1,"945":1,"946":1,"947":1,"948":1}}],["灵感就来自于我们日常寻找最快捷路线的行为",{"2":{"927":1}}],["灵活",{"2":{"724":1}}],["安排时间",{"2":{"927":1}}],["安装程序会自动配置这些工具",{"2":{"822":1}}],["安装时的配置",{"2":{"822":1}}],["安装完",{"2":{"822":1}}],["安装验证",{"2":{"817":1}}],["安装",{"0":{"819":1},"2":{"817":1}}],["安装与基本使用",{"2":{"709":1}}],["安装方式",{"0":{"573":1}}],["安装指定版本",{"2":{"71":1}}],["安装最新版本",{"2":{"71":1}}],["节省时间",{"2":{"926":1}}],["节点它的",{"2":{"462":1}}],["节点",{"2":{"338":1,"796":1}}],["节点根据其状态进行颜色编码",{"2":{"338":1}}],["决策树",{"2":{"925":1}}],["决定之前cell",{"2":{"147":1}}],["决定哪些信息可以进入cell",{"2":{"145":1}}],["做出一个看似合理的决定",{"2":{"925":1}}],["做好关注选择的优化器的",{"2":{"356":1}}],["面向小白",{"2":{"929":1}}],["面向对象编程",{"2":{"708":1}}],["面对一项复杂的工作任务时",{"2":{"924":1}}],["化繁为简",{"0":{"924":1}}],["跟算法中的",{"2":{"922":1,"925":1}}],["跟随",{"2":{"619":1}}],["追求每一步的",{"2":{"921":1}}],["搜索信息",{"2":{"927":1}}],["搜索",{"2":{"920":1}}],["搜索空间和预算往往更为重要",{"2":{"401":1}}],["搜索空间够大吗",{"2":{"372":1}}],["搜索空间",{"2":{"370":1}}],["钱包的经历",{"2":{"920":1}}],["买菜和看剧",{"2":{"919":1}}],["吃早饭",{"2":{"917":1}}],["吃的时候再解冻的方法也是",{"2":{"722":1}}],["洗脸",{"2":{"917":1}}],["似乎是一种传统的",{"2":{"917":1}}],["慢慢发现学的东西往往来源于生活",{"2":{"917":1}}],["觉得这是计算机和程序员的专属领域",{"2":{"916":1}}],["恢复默认网络配置",{"0":{"914":1}}],["恢复它",{"2":{"399":1}}],["法二",{"0":{"914":1}}],["法一",{"0":{"913":1}}],["桥接模式",{"2":{"910":1}}],["域名解析",{"2":{"910":1}}],["域名备案成功并添加底部footer",{"2":{"868":1}}],["身边的一些同学遇到了一些网络问题",{"2":{"908":1}}],["侧边栏",{"2":{"889":1}}],["登录后发现创建成功了",{"2":{"889":1}}],["登录成功",{"2":{"888":1}}],["邮箱>",{"2":{"888":1}}],["希望你能喜欢",{"2":{"948":1}}],["希望大家能够静下心来跟我一块学习算法",{"2":{"928":1}}],["希望能给大家起到抛砖引玉的作用",{"2":{"917":1}}],["希望这些随笔能给我带来反思的同时带给你启发",{"2":{"881":1}}],["希望避免产生另一个混淆",{"2":{"411":1}}],["警醒自己",{"2":{"880":1}}],["迷茫的时候",{"2":{"880":1}}],["迷茫时的自己",{"2":{"880":1}}],["挫折时",{"2":{"880":1}}],["骄傲的时候",{"2":{"880":1}}],["焦虑的时候",{"2":{"880":1}}],["怕寂寞",{"2":{"880":1}}],["怕没得到",{"2":{"880":1}}],["顶得住和顶不住是个选择题",{"2":{"880":1}}],["艰巨在于漫长",{"2":{"880":1}}],["讨厌别人就是在讨厌自己",{"2":{"880":1}}],["事儿得一件一件办",{"2":{"880":1}}],["事件抽取等",{"2":{"188":1}}],["饭得一口一口吃",{"2":{"880":1}}],["偷奸耍滑不是机会",{"2":{"880":1}}],["鬼和你怕的东西不都是自己想出来的",{"2":{"880":1}}],["坚定不移",{"2":{"880":1}}],["淳朴善良",{"2":{"880":1}}],["心稳",{"2":{"880":1}}],["心机狡猾的自己",{"2":{"880":1}}],["心里自然而然的产生强烈的",{"2":{"878":1}}],["寂寞难耐的自己",{"2":{"880":1}}],["士兵突击",{"2":{"880":1}}],["士兵突击告诉让我明白的那些事",{"0":{"880":1}}],["沉得住气",{"2":{"880":1}}],["耐得住寂寞",{"2":{"880":1}}],["何为不愠",{"2":{"879":1}}],["何为君子",{"2":{"878":1,"879":1}}],["何况",{"2":{"878":1}}],["何时对学习率进行预热",{"0":{"408":1}}],["君子",{"2":{"878":2}}],["乐",{"2":{"878":2}}],["途中你看到一个小山峰",{"2":{"970":1}}],["途中",{"2":{"878":1}}],["啊",{"2":{"878":2}}],["知己",{"2":{"878":1}}],["知识体系构建",{"0":{"831":1}}],["知识弥补",{"2":{"696":1}}],["难道不是志同道合的人就不能是孔子所言的",{"2":{"878":1}}],["难以想象孔子之后的生活基本很少有",{"2":{"878":1}}],["道德绑架",{"2":{"878":1}}],["道",{"2":{"878":1}}],["志之",{"2":{"878":1}}],["志",{"2":{"878":1}}],["志同道合",{"2":{"878":2}}],["志同道合的人",{"2":{"878":1}}],["志于学",{"2":{"878":7}}],["远程机访问测试管理员账户",{"2":{"888":1}}],["远",{"2":{"878":3}}],["朋",{"2":{"878":7}}],["吾二十有一而志于学",{"2":{"878":1}}],["晚了至少两年半",{"2":{"878":1}}],["愠",{"2":{"878":1}}],["雪儿实习",{"2":{"878":1}}],["十五岁才上学",{"2":{"878":1}}],["十有五",{"2":{"878":1}}],["十分重要",{"2":{"726":1}}],["孔子说自己",{"2":{"878":1}}],["嘿嘿",{"2":{"878":1}}],["遇到过两次",{"2":{"878":1}}],["遇事不决",{"0":{"830":1}}],["广义的学",{"2":{"878":1}}],["广播",{"2":{"808":1}}],["习",{"2":{"878":1}}],["习惯上卷积运算常用",{"2":{"52":1}}],["习惯上",{"2":{"13":1}}],["老师这里说的学问基本就是狭义的知识",{"2":{"878":1}}],["老板直接说换了贵一点",{"2":{"875":1}}],["老板直接问啥问题",{"2":{"875":1}}],["老板一心想着我们不怎么懂这些",{"2":{"875":1}}],["老板当时大致是这样说的",{"2":{"875":1}}],["老板的话语让我选择带他去别的店看看",{"2":{"875":1}}],["圣人",{"2":{"878":3}}],["言不尽意",{"2":{"876":1,"878":1}}],["毕竟我连第一家老板的能力也没有",{"2":{"875":1}}],["价格合理",{"2":{"875":1}}],["民大的",{"2":{"875":1}}],["马上修",{"2":{"875":1}}],["陪室友去维修他的笔记本",{"2":{"875":1}}],["感兴趣的小伙伴可以自己查阅学习",{"2":{"974":1}}],["感悟总结",{"2":{"875":1}}],["感知机的结构如下",{"2":{"10":1}}],["感知机",{"2":{"10":1}}],["功过格",{"2":{"873":1}}],["功能展示",{"0":{"493":1}}],["论语",{"2":{"878":1}}],["论语之悟",{"0":{"876":1},"1":{"877":1,"878":1,"879":1},"2":{"868":1,"873":1,"907":1}}],["论文中还试过以",{"2":{"648":1}}],["论文中指出",{"2":{"646":1}}],["论文中最先提出来的概念",{"2":{"57":1}}],["论文译文",{"2":{"637":1}}],["论文原文",{"2":{"637":1}}],["论文地址",{"2":{"543":1,"661":2}}],["论文忽略了导致最终结果的过程",{"2":{"353":1}}],["论文只讨论了sigmoid",{"2":{"245":1}}],["论文采用了两种成熟的技术来解决这些挑战",{"2":{"222":1,"311":1}}],["论文认为主要目标是避免将注意力矩阵读取和写入到hbm",{"2":{"222":1,"311":1}}],["论文提出了一种名为flashattention的新型注意力算法",{"2":{"222":1,"311":1}}],["论文提出将query",{"2":{"208":1}}],["论文首次发表于1997年",{"2":{"144":1}}],["论文",{"2":{"124":1,"125":2,"127":2,"174":1,"217":1,"219":1,"220":1,"271":1,"281":1,"289":1,"294":1,"299":1,"302":1,"303":1,"305":1,"306":1,"385":1,"545":1,"546":1,"645":1}}],["论文链接",{"2":{"86":1,"87":1,"88":1,"90":1,"91":1,"95":1,"114":1,"122":1,"126":1,"128":1,"193":1,"220":1,"228":1,"229":1,"231":1,"245":1,"246":1,"306":1,"307":1,"310":1,"320":1,"325":1,"326":1,"331":1,"544":1,"605":1,"622":1,"644":1,"650":1,"663":1,"664":1,"665":1,"667":2,"668":2,"669":2,"670":2}}],["审核中",{"2":{"868":1}}],["美化主页和导航",{"2":{"868":1}}],["初步感受贪心",{"2":{"868":1}}],["初步建站并测试",{"2":{"867":1}}],["初始score",{"2":{"634":1}}],["初始分数",{"2":{"633":1}}],["初始学习率",{"2":{"545":1}}],["初始化mpi环境",{"2":{"808":1}}],["初始化和终止",{"2":{"808":1}}],["初始化父类",{"2":{"487":1}}],["初始化",{"2":{"405":1,"406":1,"632":1,"827":1}}],["初始化策略选择",{"0":{"253":1}}],["初始化的时候令权重的均值是0",{"2":{"248":1}}],["初始化输出矩阵",{"2":{"226":1}}],["初始权重直接影响模型的输出",{"2":{"235":1}}],["冥想锻炼",{"2":{"863":1}}],["影视",{"2":{"859":1}}],["影响力",{"2":{"126":1}}],["培养创造力",{"2":{"858":1}}],["医疗成像",{"2":{"858":1}}],["建筑设计",{"2":{"858":1}}],["建议根据自己的编程语言和变成习惯来实现",{"2":{"950":1}}],["建议看代码里的注释",{"2":{"950":1}}],["建议安装无gui的系统",{"2":{"815":1}}],["建议结合自己学习的408知识",{"2":{"702":1}}],["建议改用",{"2":{"496":1}}],["建议您在训练模型时始终使用",{"2":{"480":1}}],["建议您在不需要自动求导跟踪的代码部分",{"2":{"479":1}}],["建议设定",{"2":{"284":1}}],["游戏开发",{"2":{"858":1}}],["碰撞检测",{"2":{"857":1}}],["火焰",{"2":{"857":1}}],["粒子系统和烟雾",{"2":{"857":1}}],["刚体和流体仿真",{"2":{"857":1}}],["物理机",{"2":{"910":1}}],["物理学与图形学结合",{"2":{"857":1}}],["物理模拟",{"2":{"857":1}}],["物理块会根据需要进行分配",{"2":{"334":1}}],["着色器语言",{"2":{"857":1}}],["着就会导致loss的收敛很缓慢",{"2":{"236":1}}],["路径追踪",{"2":{"857":1}}],["阴影等复杂效果",{"2":{"857":1}}],["折射",{"2":{"857":1}}],["折中的更新速度",{"2":{"262":1}}],["纹理映射",{"2":{"857":1}}],["镜面反射等",{"2":{"857":1}}],["漫反射",{"2":{"857":1}}],["照明与着色",{"2":{"857":1}}],["投影和着色的基础",{"2":{"857":1}}],["投影与观察",{"2":{"857":1}}],["投影等操作",{"2":{"857":1}}],["投资理财",{"2":{"831":1}}],["曲面造型等非常重要",{"2":{"857":1}}],["曲面等",{"2":{"857":1}}],["曲线的变化",{"2":{"857":1}}],["曲线",{"2":{"857":1}}],["坐标系统",{"2":{"857":1}}],["坐标点绘制",{"2":{"840":1}}],["©",{"2":{"856":1}}],["版权所有",{"2":{"856":1}}],["版本号",{"2":{"490":1}}],["版本的对应关系",{"2":{"71":1}}],["站长随笔",{"0":{"881":1}}],["站点",{"0":{"864":1}}],["站点大纲👀",{"0":{"862":1}}],["站点大纲",{"0":{"856":1}}],["站在巨人的肩膀上",{"2":{"617":1}}],["码医森",{"0":{"854":1},"1":{"855":1,"856":1}}],["举例",{"0":{"846":1,"852":1}}],["举个例子",{"2":{"320":1,"367":1,"369":1,"375":1,"628":1,"921":1}}],["令起点坐标为",{"2":{"840":1}}],["截距",{"2":{"840":1}}],["横纵坐标定位一个点",{"2":{"838":1}}],["横向或纵向",{"2":{"829":1}}],["斜率",{"2":{"840":1,"841":1}}],["斜率具有衰减性",{"2":{"125":1}}],["斜截式",{"2":{"838":1}}],["涵盖内容",{"2":{"833":1}}],["涵盖了对自然语言进行理解和生成的各个方面",{"2":{"188":1}}],["怎么样去补齐这个差距",{"2":{"831":1}}],["怎么去求那么复杂的高斯分布也就是隐空间呢",{"2":{"658":1}}],["市面上重要的信息很多",{"2":{"831":1}}],["集中注意力很重要",{"2":{"831":1}}],["集体通信",{"2":{"806":1}}],["联系自已已有的其他知识体系",{"2":{"830":1}}],["看看成才",{"2":{"880":1}}],["看看许三多",{"2":{"880":1}}],["看看第一句",{"2":{"878":1}}],["看到别人做违反道德和法律的事",{"2":{"878":1}}],["看到这里会发现",{"2":{"646":1}}],["看宏观",{"2":{"830":1}}],["跳出狭隘",{"2":{"830":1}}],["跳出局部最小值",{"2":{"267":1}}],["宏观理解所属地位和作用",{"2":{"829":1}}],["六",{"0":{"828":1},"1":{"829":1,"830":1,"831":1}}],["六个接口",{"2":{"823":1}}],["连接",{"2":{"827":2}}],["连续的输入和具有兼容步幅的输入可以进行重塑而无需复制",{"2":{"98":1}}],["终端中输入",{"2":{"827":1}}],["终止mpi环境",{"2":{"808":1}}],["终止某个进程",{"2":{"757":1}}],["终止指定进程",{"2":{"756":1}}],["密钥将生成在",{"2":{"827":1}}],["密钥",{"2":{"827":1}}],["密码>",{"2":{"888":1}}],["密码",{"2":{"726":1,"730":1}}],["五",{"0":{"823":1},"1":{"824":1,"825":1,"826":1,"827":1}}],["扫一遍",{"2":{"817":1}}],["四",{"0":{"814":1},"1":{"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1}}],["四项注意力的组合",{"2":{"644":1}}],["尤其在图形算法的效率优化和资源管理上",{"2":{"858":1}}],["尤其在处理非同步通信时",{"2":{"812":1}}],["尤其是对于文科生来说",{"2":{"916":1}}],["尤其是变换",{"2":{"857":1}}],["尤其是多个参数时",{"2":{"733":1}}],["尤其是transformer类",{"2":{"409":1}}],["尤其是当许多试验需要并行运行时",{"2":{"401":1}}],["尤其是当验证集性能不会随时间持续增加而是围绕特定值波动时",{"2":{"392":1}}],["尤其是在培训可能受到训练作业抢占",{"2":{"390":1}}],["尤其是在开始新项目时",{"2":{"356":1}}],["尤其是学习率和正则化超参数",{"2":{"357":1}}],["劣势",{"2":{"812":1}}],["散播",{"2":{"806":1}}],["聚合",{"2":{"806":1,"808":1}}],["聚合所有步数的梯度范数直方图",{"2":{"410":1}}],["兼容mpi标准",{"2":{"802":1}}],["科学计算",{"2":{"802":1}}],["遵循mpi标准",{"2":{"802":1}}],["混合模型",{"2":{"801":1}}],["爬取url的函数",{"2":{"799":1}}],["典型案例包括",{"2":{"799":1}}],["典型的",{"2":{"410":1}}],["典型的rnn网络",{"0":{"133":1}}],["典型的sigmoid",{"2":{"9":1}}],["透过网络相互连接传递消息",{"2":{"796":1}}],["线段",{"2":{"857":1}}],["线程是进程中的更小执行单元",{"2":{"796":1}}],["线程",{"2":{"796":1}}],["线性代数",{"2":{"857":1}}],["线性体现在线性序列中的元素之间存在明确的顺序关系",{"2":{"626":1}}],["线性crf的定义",{"0":{"626":1}}],["线性回归或逻辑回归",{"2":{"343":1}}],["线性模型",{"2":{"340":1}}],["线性神经网络的问题",{"2":{"120":1}}],["线性相乘",{"2":{"50":1}}],["线性项导数计算",{"2":{"45":1}}],["线性连接",{"2":{"44":1}}],["线性连接层",{"0":{"32":1}}],["线性变换层",{"0":{"82":1},"1":{"83":1,"84":1}}],["线性变换",{"2":{"40":1,"41":1}}],["线性可分与线性不可分",{"2":{"11":1}}],["垂直分屏",{"2":{"790":1}}],["切换到第一个",{"2":{"789":1}}],["切换到上一个文件",{"2":{"789":1}}],["切换到下一个文件",{"2":{"789":1}}],["切片使我们能够在一个cuda核函数中实现我们的算法",{"2":{"226":1,"315":1}}],["切片的方式计算softmax",{"0":{"225":1,"313":1}}],["切片和重计算",{"2":{"224":1,"311":1}}],["适合流水线任务",{"2":{"811":1}}],["适合矩阵乘法",{"2":{"811":1}}],["适合需要在不同节点之间进行通信的任务",{"2":{"802":1}}],["适合大型集群内的多核节点",{"2":{"801":1}}],["适合大规模分布式系统",{"2":{"801":1}}],["适合多任务操作",{"2":{"788":1}}],["适用的条件是",{"2":{"510":1}}],["适用于很多场景",{"2":{"929":1}}],["适用于大规模计算",{"2":{"812":1}}],["适用于多核处理器的并行计算",{"2":{"802":1}}],["适用于windows",{"2":{"802":1}}],["适用于需要大规模并行计算的科学和工程应用",{"2":{"802":1}}],["适用于不同的计算需求和环境",{"2":{"802":1}}],["适用于不同维度的输入",{"2":{"84":1}}],["适用于具有动态特性和复杂逻辑的模型",{"2":{"559":1}}],["适用于ai算法的训练学习",{"2":{"75":1}}],["替换整个文件中的所有",{"2":{"787":1}}],["替换当前行所有",{"2":{"787":1}}],["替换当前行第一个匹配的",{"2":{"787":1}}],["替换",{"0":{"787":1},"2":{"827":1}}],["替换成",{"2":{"345":1}}],["光荣在于平淡",{"2":{"880":1}}],["光线追踪的延伸",{"2":{"857":1}}],["光线追踪",{"2":{"857":1}}],["光栅图形算法",{"2":{"857":1}}],["光栅图形与光栅化",{"2":{"857":1}}],["光栅化",{"2":{"857":1}}],["光标移动",{"0":{"780":1}}],["光盘等外存相比",{"2":{"722":1}}],["\\t\\t\\t\\t\\t",{"2":{"766":1}}],["抓取内容",{"2":{"761":1}}],["抓取网页内容",{"0":{"761":1}}],["抓取log",{"0":{"574":1},"1":{"575":1,"576":1,"577":1}}],["管理员账户",{"0":{"888":1}}],["管理进程",{"0":{"756":1}}],["管道模型并行",{"2":{"328":1}}],["撤销上一步操作",{"2":{"783":1}}],["撤销",{"2":{"753":1}}],["撤销与重做",{"0":{"783":1},"2":{"753":1}}],["粘贴到光标后",{"2":{"753":1}}],["退出",{"0":{"777":1},"2":{"751":1,"752":1,"777":1}}],["退火",{"2":{"544":1}}],["退火是一种通过加热和冷却金属来改变其晶体结构",{"2":{"544":1}}],["启动docker的doccano",{"0":{"885":1}}],["启动和退出",{"0":{"775":1},"1":{"776":1,"777":1}}],["启动",{"0":{"776":1},"2":{"751":1}}],["启发式搜索的方法来处理",{"2":{"190":1}}],["行业未来的方向是什么",{"2":{"831":1}}],["行业的自动化程度高么",{"2":{"831":1}}],["行业中占据主导地位",{"2":{"619":1}}],["行",{"2":{"748":2}}],["快速上手",{"2":{"829":1}}],["快速使用",{"0":{"824":1}}],["快速查找",{"2":{"765":2}}],["快速查看文件内容",{"2":{"748":1}}],["快捷键",{"2":{"778":1,"780":1,"781":1,"782":1,"783":1,"784":1}}],["快很多",{"2":{"217":1,"303":1}}],["权限表示",{"0":{"745":1}}],["权重初始化",{"2":{"484":1}}],["权重进行缩放",{"2":{"444":2}}],["权重衰减",{"2":{"375":1,"503":1}}],["权重衰减强度的最佳值通常取决于模型大小",{"2":{"369":1}}],["权重系数的计算",{"2":{"204":1}}],["权重共享",{"2":{"54":1}}],["权重的梯度什么时候计算的",{"2":{"29":1}}],["权重的梯度吗",{"2":{"27":1}}],["权重的梯度",{"2":{"27":1}}],["权重更新",{"0":{"47":1},"2":{"27":1,"497":1}}],["权重",{"2":{"27":1}}],["列出文件和目录",{"2":{"742":1}}],["临时文件目录",{"2":{"739":1}}],["临界区指的是一个访问共用资源",{"2":{"682":1}}],["临界区",{"0":{"682":1},"2":{"694":1}}],["临界区外的进程阻塞其他的进程",{"2":{"681":1}}],["临界资源",{"0":{"681":1},"2":{"681":1,"694":1}}],["临界资源是啥",{"0":{"679":1},"1":{"680":1,"681":1,"682":1}}],["日志管理",{"0":{"771":1},"1":{"772":1}}],["日志",{"2":{"739":1}}],["删",{"2":{"731":1}}],["删除选择内容",{"2":{"784":1}}],["删除一个单词",{"2":{"781":1}}],["删除至行尾",{"2":{"781":2}}],["删除至行首",{"2":{"781":1}}],["删除整行",{"2":{"781":1}}],["删除光标所在字符",{"2":{"781":1}}],["删除操作",{"0":{"781":1}}],["删除当前行",{"2":{"753":1}}],["删除和复制",{"2":{"753":1}}],["删除空目录",{"2":{"742":1}}],["删除词语",{"2":{"621":1}}],["删除",{"2":{"496":1,"709":1}}],["王五",{"2":{"731":1}}],["名字",{"2":{"730":1}}],["名为torch",{"2":{"463":1}}],["课堂练习",{"2":{"730":1}}],["课件链接",{"2":{"230":1,"330":1,"662":1}}],["查阅",{"2":{"829":1}}],["查找上一个匹配",{"2":{"786":1}}],["查找下一个匹配",{"2":{"786":1}}],["查找可执行文件",{"0":{"766":1}}],["查找大于",{"2":{"765":1}}],["查找文件",{"0":{"765":1},"2":{"765":1}}],["查找",{"0":{"786":1},"2":{"753":1}}],["查找与替换",{"0":{"785":1},"1":{"786":1,"787":1},"2":{"753":1}}],["查找替换等操作",{"2":{"752":1}}],["查找指定字符串",{"2":{"749":1}}],["查找内容",{"0":{"749":1}}],["查询用户",{"2":{"730":1}}],["查询全部用户",{"2":{"730":1}}],["查看日志",{"0":{"772":1}}],["查看监听的端口和服务",{"2":{"760":1}}],["查看监听端口",{"2":{"760":1}}],["查看网络端口",{"0":{"760":1}}],["查看网络接口信息",{"2":{"759":1}}],["查看网络配置",{"0":{"759":1}}],["查看所有进程",{"2":{"757":1}}],["查看系统所有进程",{"2":{"755":1}}],["查看系统配置文件目录",{"2":{"740":1}}],["查看当前终端的进程",{"2":{"755":1}}],["查看当前用户进程",{"2":{"755":1}}],["查看进程",{"0":{"755":1}}],["查看后",{"2":{"748":1}}],["查看前",{"2":{"748":1}}],["查看文本文件",{"0":{"748":1}}],["查看文件内容",{"2":{"743":1}}],["查看权限",{"2":{"746":1}}],["查看和修改权限",{"0":{"746":1}}],["查看整个文件内容",{"2":{"743":1}}],["查看基本命令目录",{"2":{"740":1}}],["查看根目录内容",{"2":{"740":1}}],["查看帮助文档",{"2":{"726":2}}],["查看特征图",{"0":{"580":1}}],["查看graph",{"0":{"579":1}}],["查看您当前存档的协议或签署新协议",{"2":{"423":1}}],["查看自己电脑的driver",{"2":{"71":1}}],["万能的map",{"2":{"730":1}}],["姓名",{"2":{"726":1}}],["李四",{"2":{"726":1}}],["张三",{"2":{"726":1}}],["张量的钩子",{"2":{"472":1}}],["张量的数组视图描述",{"2":{"441":1}}],["张量是否会被打包为不同的张量对象取决于它是否是其自身",{"2":{"472":1}}],["张量会根据需要自动保存",{"2":{"472":1}}],["张量相乘",{"2":{"444":1}}],["张量模型并行",{"2":{"328":1}}],["张量存储器加速器",{"2":{"325":1}}],["张量核心",{"2":{"325":1}}],["张量",{"2":{"55":2,"440":1,"441":1}}],["搭建实验数据库",{"2":{"726":1}}],["搭建环境",{"2":{"725":1}}],["搭建模型也不方便",{"2":{"467":1}}],["公司需要",{"2":{"724":1}}],["公式表达",{"0":{"209":1}}],["公式分析",{"0":{"185":1}}],["公式如下",{"2":{"125":1,"245":1}}],["公式",{"2":{"123":1,"126":1,"127":1,"128":1,"129":1,"545":1,"546":1}}],["公式化简",{"2":{"34":1}}],["易于使用",{"2":{"724":1}}],["易于学习",{"2":{"724":1}}],["持久单元",{"2":{"723":1}}],["持久模块",{"2":{"723":1}}],["持久层",{"0":{"723":1},"2":{"723":2}}],["持久化的主要应用是将内存中的对象存储在数据库中",{"2":{"722":1}}],["持久化是将程序数据在持久状态和瞬时状态间转换的机制",{"2":{"722":1}}],["持久化",{"0":{"722":1}}],["持久性缓冲区和非持久性缓冲区之间唯一的区别是后者不会成为该模块的",{"2":{"493":1}}],["环境查询",{"2":{"808":1}}],["环境说明",{"2":{"719":1}}],["环境之外使用它",{"2":{"473":1}}],["观察者等",{"2":{"717":1}}],["微分几何",{"2":{"857":1}}],["微服务架构",{"2":{"717":1}}],["微调训练的约束更少",{"2":{"617":1}}],["微调模型所需的时间",{"2":{"617":1}}],["微调时只需要很少的数据量就可以达到不错的性能",{"2":{"617":1}}],["微调的方式可以在任务特定的数据上进行更好的参数优化",{"2":{"180":1}}],["监控工具",{"2":{"716":1}}],["云服务",{"2":{"716":1}}],["容器化应用",{"2":{"716":1}}],["部署",{"2":{"716":1}}],["部署与监控",{"0":{"716":1}}],["部分的作用就是接受encoder",{"2":{"171":1}}],["部分",{"0":{"170":1,"171":1},"2":{"170":1}}],["订阅模式",{"2":{"715":1}}],["框架",{"2":{"709":1}}],["封装",{"2":{"708":1}}],["继承",{"2":{"708":1}}],["继续用下一块大饼干尝试满足同一个小孩",{"2":{"956":1}}],["继续finetune",{"2":{"608":1}}],["继续训练",{"2":{"399":1}}],["继续通过多个独立同分布变量求一个变量",{"2":{"249":1}}],["欢迎来到ethan的的随笔天地",{"2":{"881":1}}],["欢迎来到",{"2":{"707":1}}],["欢迎在github的讨论区提出相关问题",{"2":{"422":1}}],["乘法",{"2":{"706":1}}],["乘以nbest",{"2":{"634":1}}],["开发",{"0":{"710":1},"2":{"705":1}}],["开发工具包",{"2":{"705":1}}],["开始值",{"2":{"827":1}}],["开始遍历",{"2":{"634":1}}],["开始run",{"2":{"570":1}}],["开始执行单次训练",{"2":{"399":1}}],["开始新项目的指南",{"0":{"354":1},"1":{"355":1,"356":1,"357":1,"358":1,"359":1,"360":1,"361":1,"362":1,"363":1},"2":{"351":1}}],["俄顷书籍内容有一些让人耳目一新的感觉",{"2":{"699":1}}],["担心这些的想必就是对计算机不太了解",{"2":{"697":1}}],["程序=数据结构+算法",{"2":{"917":1}}],["程序",{"2":{"822":2,"827":1}}],["程序的工具",{"2":{"822":1}}],["程序的运行工具",{"2":{"822":1}}],["程序的性能",{"2":{"337":2}}],["程序而专门设计的",{"2":{"822":1}}],["程序运行的实例",{"2":{"796":1}}],["程序运行的核心",{"2":{"705":1}}],["程序所需的类库",{"2":{"705":1}}],["程序是怎样跑起来的",{"0":{"696":1},"1":{"697":1,"698":1,"699":1,"700":1,"701":1,"702":1},"2":{"868":1}}],["百度百科",{"2":{"694":2}}],["软件实现",{"0":{"685":1},"1":{"686":1,"687":1,"688":1}}],["软件栈",{"0":{"70":1}}],["才能顺利开始一天的工作",{"2":{"917":1}}],["才能继续执行",{"2":{"807":1}}],["才能防止出现以下情况",{"2":{"681":1}}],["才是一个好的解决方案",{"2":{"681":1}}],["才需要重新考虑",{"2":{"354":1}}],["电脑系统中的软件虚拟元件",{"2":{"680":1}}],["电脑系统内部的任何元件都是资源",{"2":{"680":1}}],["电力",{"2":{"360":1}}],["萤幕等",{"2":{"680":1}}],["资源",{"2":{"694":1}}],["资源浪费等",{"2":{"676":1}}],["资源消耗相对较低的配置",{"2":{"363":1}}],["资源消耗是增加还是减少",{"2":{"360":1}}],["资源消耗",{"2":{"360":2}}],["资源消耗和batch",{"2":{"357":1}}],["死锁",{"2":{"676":1}}],["死代码消除",{"2":{"560":1}}],["硬件实现",{"0":{"689":1},"1":{"690":1,"691":1,"692":1,"693":1}}],["硬件设备等",{"2":{"676":1}}],["硬件加速的低精度gemm",{"2":{"325":1}}],["掌握图形学有助于在这些新兴领域占据优势",{"2":{"858":1}}],["掌握二维和三维空间中的坐标系",{"2":{"857":1}}],["掌握c++高性能推理部署",{"2":{"672":1}}],["掌握pytorch原理和应用",{"2":{"672":1}}],["紧跟时代",{"2":{"672":1}}],["距离",{"2":{"659":1}}],["距离越远",{"2":{"50":2,"644":1}}],["答案",{"2":{"656":1}}],["答案是不必要",{"2":{"383":1}}],["椭圆之间完全没有交集",{"2":{"656":1}}],["椭圆",{"2":{"655":1}}],["手机",{"2":{"920":1}}],["手也就稳了",{"2":{"880":1}}],["手写数字0",{"2":{"655":1}}],["手动实现",{"2":{"86":1,"87":1,"88":1,"89":1}}],["近年来最火的生成模型莫过于gan和vae",{"2":{"653":1}}],["近似随机搜索",{"2":{"376":1}}],["⊗",{"2":{"648":1}}],["视为可训练参数",{"2":{"648":1}}],["视为",{"2":{"644":1}}],["视图层展示",{"2":{"710":1}}],["视图",{"2":{"437":1}}],["视图到底是什么",{"0":{"437":1}}],["别混日子了",{"2":{"880":1}}],["别致",{"2":{"644":1}}],["别忘了公式里还有一个argmax",{"2":{"190":1}}],["里边用到了一种更简单的相对位置编码",{"2":{"644":1}}],["里面的人生道理是我们平常很难得到的",{"2":{"880":1}}],["里面的道理了",{"2":{"878":1}}],["里面有一些内容会让我眼前一亮的感觉",{"2":{"696":1}}],["里面还有一个叫",{"2":{"572":1}}],["里面涉及到大量的特征工程",{"2":{"190":1}}],["换个方式或者换个材料",{"2":{"830":1}}],["换成",{"2":{"643":1}}],["换句话说",{"2":{"337":1,"369":1,"375":1,"376":1,"380":2,"478":1,"617":1,"928":1}}],["换句话说就是效果有所下降",{"2":{"217":1,"303":1}}],["⊤",{"2":{"643":1,"647":1}}],["天马行空",{"2":{"642":1}}],["风极一时的",{"2":{"641":1}}],["风光无限",{"2":{"190":1}}],["猜测可能是为了能让周期是一个很大的数",{"2":{"640":1}}],["周老师推导",{"2":{"695":1}}],["周期会明显变长",{"2":{"640":1}}],["周围的词语",{"2":{"616":1}}],["示例代码",{"2":{"799":1}}],["示例",{"0":{"740":1,"757":1,"958":1},"2":{"640":1}}],["示意图",{"2":{"80":1}}],["三",{"0":{"803":1},"1":{"804":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"813":1}}],["三角函数式",{"0":{"640":1},"2":{"640":1}}],["三个矩阵的形状均为",{"2":{"226":1,"315":1}}],["绝对位置编码的一个最朴素方案是不特意去设计什么",{"2":{"641":1}}],["绝对位置编码公式表达如下",{"2":{"639":1}}],["绝对位置编码会加到输入中",{"2":{"639":1}}],["绝对位置编码",{"0":{"639":1},"1":{"640":1,"641":1}}],["想当然的",{"2":{"972":1}}],["想象你在一座山上爬山",{"2":{"970":1}}],["想想日常生活",{"2":{"967":1}}],["想想铁打的钢七连",{"2":{"880":1}}],["想要和得到",{"2":{"880":1}}],["想办法微调一下attention结构",{"2":{"638":1}}],["想办法将位置信息融入到输入中",{"2":{"638":1}}],["想知道是怎么训练的就很容易了",{"2":{"181":1}}],["真心希望大家都能够好好静下心来问问自己",{"2":{"880":1}}],["真正可怕的或者说真正可贵的",{"2":{"880":1}}],["真正能够参悟孔子的大部分思想",{"2":{"878":1}}],["真正例个数",{"2":{"635":1}}],["真正例",{"2":{"635":1}}],["真诚待客",{"2":{"875":1}}],["真诚靠谱",{"2":{"875":1}}],["真诚",{"2":{"875":1}}],["真实的实体个数",{"2":{"635":1}}],["真实路径得分计算",{"0":{"632":1}}],["真实数据举例",{"2":{"204":1}}],["排序的时间复杂度是",{"2":{"959":1}}],["排序算法",{"2":{"919":1}}],["排序后的",{"2":{"445":1}}],["排队和优先处理",{"0":{"919":1}}],["排除被mask",{"2":{"634":1}}],["插入模式操作",{"0":{"778":1}}],["插入模式",{"2":{"752":1,"774":1}}],["插入",{"2":{"709":1}}],["插入最佳标签",{"2":{"634":1}}],["插入和淘汰变得高效",{"2":{"337":1}}],["防置到最后一个维度",{"2":{"634":1}}],["防止生成不属于任何分类的图片",{"2":{"656":1}}],["防止因固定超参数的设置漏掉可能的优解",{"2":{"375":1}}],["防止因输入数据分布变化对结果产生影响",{"2":{"86":1}}],["防止在相对较慢的gpu高带宽存储器",{"2":{"222":1,"314":1}}],["防止网络过拟合",{"2":{"92":1}}],["防止梯度消失",{"2":{"86":1}}],["融合",{"2":{"634":1}}],["住的tag",{"2":{"634":1}}],["轴",{"2":{"840":2}}],["轴上",{"2":{"633":1}}],["轴变换",{"2":{"439":1}}],["掩模",{"2":{"632":1}}],["掩码和dropout见附录b",{"2":{"226":1,"315":1}}],["若在给定随机变量序列的",{"2":{"626":1}}],["书本上是远远无法理解的",{"2":{"876":1}}],["书不尽言",{"2":{"876":1,"878":1}}],["书中的定义",{"2":{"626":1}}],["书籍封面",{"2":{"696":1}}],["书籍推荐",{"0":{"696":1},"1":{"697":1,"698":1,"699":1,"700":1,"701":1,"702":1},"2":{"718":1,"868":1}}],["书籍",{"2":{"232":1,"255":1,"339":1}}],["找零问题",{"0":{"944":1},"1":{"945":1,"946":1,"947":1}}],["找东西",{"0":{"920":1},"2":{"928":1}}],["找出得出概率最大",{"2":{"624":1}}],["找到vmware的nat和dhcp服务并开启",{"2":{"913":1}}],["找到专业中需要解决的问题",{"2":{"831":1}}],["找到进程",{"2":{"757":1}}],["找到本机pytorch",{"2":{"482":1}}],["找到",{"2":{"431":3}}],["找到这个值作为max",{"2":{"382":1}}],["铺平了道路",{"2":{"622":1}}],["种语言之间进行翻译的模型",{"2":{"621":1}}],["亿参数的大版本",{"2":{"621":1}}],["亿个参数",{"2":{"620":2}}],["及将所有",{"2":{"621":1}}],["翻译",{"2":{"621":1}}],["翻译模型通过大量的平行语料",{"2":{"190":1}}],["续写文本",{"2":{"620":1}}],["鉴别器也参与微调",{"2":{"619":1}}],["鉴别器",{"2":{"619":1}}],["拓展到多语言输入",{"2":{"619":1}}],["界",{"2":{"619":1}}],["抽取式问答",{"2":{"619":1}}],["抽象成计算机上可执行的算子如conv2d",{"2":{"117":1}}],["双标志后检查法",{"0":{"688":1}}],["双标志先检查法",{"0":{"687":1}}],["双向",{"2":{"619":1}}],["双隐层感知器就足以解决任何复杂的分类问题",{"2":{"14":1}}],["家族",{"0":{"618":1}}],["二",{"0":{"773":1,"800":1},"1":{"774":1,"775":1,"776":1,"777":1,"778":1,"779":1,"780":1,"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1,"788":1,"789":1,"790":1,"791":1,"792":1,"793":1,"801":1,"802":1}}],["二进制文件",{"2":{"739":1}}],["二字",{"2":{"695":1,"967":1}}],["二维平面的中心就是图片的二维高斯分布的",{"2":{"655":1}}],["二次训练",{"2":{"617":1}}],["二阶矩估计可能在训练初期有很高的偏置",{"2":{"294":1}}],["二阶矩估计",{"2":{"294":1}}],["二阶矩的估计",{"2":{"294":1}}],["纯",{"2":{"616":2,"619":3,"620":4}}],["精细面部表情模拟",{"2":{"859":1}}],["精讲",{"2":{"610":1}}],["精度改进",{"0":{"220":1,"306":1}}],["σ​2​​",{"2":{"606":1}}],["σ​1​​",{"2":{"606":1}}],["σ2",{"2":{"606":1}}],["σ1",{"2":{"606":1}}],["μ",{"2":{"655":2}}],["μ2",{"2":{"606":1}}],["μ1",{"2":{"606":1}}],["μ​2​​",{"2":{"606":1}}],["μ​1​​",{"2":{"606":1}}],["μ​q​​",{"2":{"606":1}}],["μ​p​​",{"2":{"606":1}}],["μq",{"2":{"606":1}}],["μp",{"2":{"606":1}}],["专业",{"2":{"875":1}}],["专著于数据持久化逻辑的实现",{"2":{"723":1}}],["专门用于评估模型生成图片的性能",{"2":{"606":1}}],["专家和新手用着表面上类似的方法",{"2":{"353":1}}],["评价指标",{"0":{"604":1},"1":{"605":1,"606":1}}],["评估越高",{"2":{"605":1}}],["评估模式不是一种局部禁用梯度计算的机制",{"2":{"480":1}}],["评估模式",{"0":{"480":1}}],["评估模型性能",{"0":{"388":1},"1":{"389":1,"390":1,"391":1},"2":{"351":1}}],["评估",{"2":{"395":1}}],["评估设置",{"0":{"389":1}}],["评估改变是否有用",{"2":{"372":1}}],["太大",{"2":{"584":1}}],["拿到",{"2":{"580":1}}],["拿到这个梯度值",{"2":{"457":1}}],["展望",{"2":{"612":1}}],["展板",{"2":{"572":1}}],["展示",{"0":{"450":1}}],["展示的是一个超参数轴图",{"2":{"408":1}}],["捕获模型的执行轨迹",{"2":{"564":1}}],["编辑",{"2":{"914":1}}],["编辑器基础",{"0":{"750":1},"1":{"751":1,"752":1,"753":1}}],["编程时忽略",{"2":{"823":1}}],["编程复杂度较高",{"2":{"812":1}}],["编译器和运行工具是",{"2":{"822":1}}],["编译器",{"2":{"822":1}}],["编译器包装器",{"2":{"822":1}}],["编译",{"0":{"820":1}}],["编译优化",{"2":{"560":1}}],["编写部分文章",{"2":{"868":1}}],["编写学而篇的",{"2":{"868":1}}],["编写对应的配置文件sql",{"2":{"732":1,"733":1}}],["编写接口方法",{"2":{"732":1,"733":1}}],["编写sql语句的时候",{"2":{"730":1}}],["编写测试类",{"2":{"726":1}}],["编写mapper",{"2":{"726":1}}],["编写mapper接口类",{"2":{"726":1}}],["编写mybatis工具类",{"2":{"726":1}}],["编写mybatis核心配置文件",{"2":{"726":1}}],["编写代码",{"2":{"725":1}}],["编码维度为768",{"2":{"641":1}}],["编码",{"2":{"621":1}}],["编码器表示是并行计算的",{"2":{"219":1,"305":1}}],["编码器由n",{"2":{"196":1}}],["编码器和解码器堆栈",{"0":{"195":1},"1":{"196":1,"197":1}}],["编码器和解码器都使用self",{"2":{"194":1}}],["编码器映射一个用符号表示的输入序列",{"2":{"194":1}}],["编码器",{"0":{"196":1},"2":{"168":1}}],["编码器将输入转换为一个隐藏状态向量",{"2":{"167":1}}],["读权限",{"2":{"745":1}}],["读一部分的时候边看边回顾整体框架结构",{"2":{"702":1}}],["读起来比较容易",{"2":{"698":1}}],["读者自行看源码就好",{"2":{"644":1}}],["读者常常想知道作者是如何得出如此复杂的研究结果的",{"2":{"399":1}}],["读取图片对应的label",{"2":{"552":1}}],["冷却",{"2":{"544":1}}],["打开多个文件",{"0":{"789":1}}],["打开或创建名为",{"2":{"776":1}}],["打开图像",{"2":{"555":1}}],["打包目录",{"2":{"768":1}}],["打包文件",{"2":{"768":1}}],["打包和解压",{"0":{"768":1}}],["打乱句子顺序",{"2":{"621":1}}],["打乱的网格搜索",{"2":{"401":1}}],["打印每个进程的计算状态",{"2":{"827":1}}],["打印状态信息",{"2":{"799":1}}],["打印机",{"2":{"682":1}}],["打印训练信息",{"2":{"567":1}}],["打印当前学习率",{"2":{"541":1}}],["合并+通信",{"2":{"803":1}}],["合适的学习率调整策略可以帮助模型更快地收敛或避免陷入局部最优点",{"2":{"531":1}}],["合理",{"2":{"363":2}}],["他不光学",{"2":{"878":1}}],["他人本地没有这个模型",{"2":{"516":1,"520":1}}],["他们都很重要",{"2":{"356":1}}],["他们都可能对数据进行一些操作",{"2":{"18":1}}],["他们又进入了饱和区",{"2":{"241":1}}],["规模模型的研究人员组成了",{"2":{"620":1}}],["规则进行",{"2":{"509":1}}],["规约类算子",{"0":{"112":1}}],["状态是按参数保存的",{"2":{"509":1}}],["状态字典的重载",{"2":{"496":1}}],["阶段发生",{"2":{"509":1}}],["阶跃函数具有不连续",{"2":{"9":1}}],["闭包应该清除梯度",{"2":{"505":1}}],["忽略大小写查找",{"2":{"749":1}}],["忽略填充索引",{"2":{"500":1}}],["忽略这些警告",{"2":{"456":1}}],["命令在当前行替换",{"2":{"787":1}}],["命令",{"2":{"777":1,"789":1}}],["命令行模式",{"2":{"752":1}}],["命令行参数解析",{"2":{"497":1}}],["命名空间中唯一的标识符",{"2":{"730":1}}],["命名实体识别等",{"2":{"188":1}}],["命名实体识别",{"2":{"188":1,"619":1}}],["端到端训练一个深度学习模型",{"0":{"497":1}}],["副本引用原始module",{"2":{"496":1}}],["副本本身不具有参数",{"2":{"496":1}}],["遍历过程中",{"2":{"961":1}}],["遍历两个数组的时间复杂度是",{"2":{"959":1}}],["遍历饼干数组",{"2":{"956":1}}],["遍历",{"2":{"497":1}}],["遍历模块的buffers",{"2":{"496":1}}],["遍历模块的参数",{"2":{"496":1}}],["遍历所有可能的y",{"2":{"190":1}}],["键进入普通模式",{"2":{"774":1}}],["键进入",{"2":{"752":2}}],["键是相应的参数和缓冲区名称",{"2":{"496":1}}],["键值缓存共享示例",{"2":{"337":1}}],["键值缓存",{"2":{"337":1}}],["未来发展等因素",{"2":{"925":1}}],["未来随着算法和计算能力的进一步提升",{"2":{"859":1}}],["未来版本中可能会对非完整钩子的行为进行更改",{"2":{"496":1}}],["未发表的研究结果显示",{"2":{"544":1}}],["未经记录的实验可能不会得到重视",{"2":{"393":1}}],["递归删除目录及其内容",{"2":{"742":1}}],["递归的将所有子模块应用",{"2":{"496":1}}],["递归的将所有子模块的",{"2":{"496":1}}],["递归神经网络",{"2":{"132":1,"167":1}}],["额外的状态应该是可",{"2":{"496":1}}],["子问题的最优解可以组合成原问题的最优解",{"2":{"974":1}}],["子网掩码",{"2":{"910":1}}],["子网",{"2":{"910":1}}],["子曰",{"2":{"877":1}}],["子类可以使用local",{"2":{"496":1}}],["子类可以通过覆盖此方法并添加自定义逻辑来实现特定于类的行为",{"2":{"496":1}}],["子类实现此函数",{"2":{"496":1}}],["子module",{"2":{"496":1}}],["子模块还可以有子模块",{"2":{"490":1}}],["子模块为当前模块的普通属性",{"2":{"488":1}}],["移动饼干指针",{"2":{"957":1}}],["移动孩子指针",{"2":{"957":1}}],["移动到文件末尾",{"2":{"780":1}}],["移动到文件开头",{"2":{"780":1}}],["移动到前一个单词的开头",{"2":{"780":1}}],["移动到下一个单词的开头",{"2":{"780":1}}],["移动到行尾",{"2":{"780":1}}],["移动到行首",{"2":{"780":1}}],["移动位数有other",{"2":{"443":1}}],["移除钩子函数",{"2":{"494":1,"495":1}}],["检测到是list类型",{"2":{"492":1}}],["检查一个tensor",{"2":{"444":1}}],["检查张量是否是视图",{"2":{"444":1}}],["检查张量是否位于共享内存中",{"2":{"441":1}}],["检查点和数据分片方面",{"2":{"395":1}}],["检查点选择使用得当",{"2":{"381":1}}],["检查训练曲线是识别常见故障的一种简单方法",{"2":{"375":1}}],["检查训练曲线",{"0":{"375":1}}],["派生于哪些类型",{"2":{"492":1}}],["给我们一种感觉",{"2":{"875":1}}],["给室友基本说了一下",{"2":{"875":1}}],["给定四个数字",{"2":{"931":1}}],["给定直线的两个端点p0",{"2":{"840":1}}],["给定输入的",{"2":{"224":1,"311":1}}],["给定输入序列",{"2":{"188":1,"223":1,"312":1}}],["给文件所有者增加执行权限",{"2":{"746":1}}],["给数据库增加一个用户",{"2":{"731":1}}],["给到父类",{"2":{"490":1}}],["补丁列表记录了模块中所有可导操作的详细信息",{"2":{"490":1}}],["库和头文件",{"2":{"822":1}}],["库和头文件的路径和链接选项",{"2":{"822":1}}],["库",{"2":{"482":1}}],["外推性是指大模型在训练时和预测时的输入长度不一致",{"2":{"645":1}}],["外部使用",{"2":{"496":1}}],["外",{"2":{"476":1}}],["外层",{"0":{"441":1}}],["外层循环遍历k和v",{"2":{"226":1}}],["禁用",{"2":{"474":1}}],["禁止用",{"2":{"456":1}}],["字符",{"2":{"796":1}}],["字典形式",{"2":{"508":1}}],["字典",{"2":{"507":1}}],["字段也不会被更新",{"2":{"475":1}}],["字段中",{"2":{"475":1}}],["字段",{"2":{"474":1}}],["字节数",{"2":{"445":1}}],["↦",{"2":{"472":1}}],["属性",{"0":{"508":1},"2":{"496":1}}],["属性设置为",{"2":{"493":1}}],["属性详解",{"0":{"490":1}}],["属性是进入这个图的入口",{"2":{"471":1}}],["属性还包含",{"2":{"469":1}}],["冻结权重",{"2":{"465":1}}],["触发反向求导操作",{"2":{"465":1}}],["告诉torch",{"2":{"464":1}}],["隐空间对应相同标签的点离得比较近",{"2":{"657":1}}],["隐空间中对应不同标签的点不会离得很远",{"2":{"657":1}}],["隐空间随便拿个点解码之后",{"2":{"657":1}}],["隐空间",{"2":{"657":1}}],["隐式创建",{"2":{"462":1}}],["隐藏层数",{"2":{"375":1}}],["隐藏层中有一半是黑色的",{"2":{"142":1}}],["隐藏状态还用于进行预测",{"2":{"150":1}}],["隐藏状态包含了先前输入的信息",{"2":{"150":1}}],["隐藏状态按照下图传递",{"2":{"135":1}}],["覆盖了原来的值",{"2":{"462":1}}],["叶子节点的梯度会自动保存下来的",{"2":{"462":1}}],["叶子节点",{"2":{"456":2,"462":1}}],["底层会有一个新tensor的创建过程的",{"2":{"455":1}}],["底层的实现机制",{"2":{"455":1}}],["底层原理",{"0":{"210":1}}],["隔离功能",{"0":{"452":1}}],["向史班长学习为人",{"2":{"880":1}}],["向三多学习精神",{"2":{"880":1}}],["向左",{"2":{"790":1}}],["向下滚动半屏",{"2":{"780":1}}],["向下一个位置的标签",{"2":{"628":1}}],["向上滚动半屏",{"2":{"780":1}}],["向上取整",{"2":{"445":1}}],["向",{"2":{"628":1}}],["向module",{"2":{"496":1}}],["向量和矩阵运算",{"2":{"857":1}}],["向量的元素按照两两一组应用旋转变换",{"2":{"648":1}}],["向量相关性2",{"2":{"203":1}}],["向量相关性1",{"2":{"203":1}}],["向量",{"2":{"50":1,"225":1,"313":1,"646":2,"648":1}}],["拉平后",{"2":{"445":1}}],["∣δy∣",{"2":{"840":2}}],["∣δy∣|",{"2":{"840":1}}],["∣δx∣|",{"2":{"840":1}}],["∣δx∣",{"2":{"840":2}}],["∣∣​2​​",{"2":{"606":1}}],["∣∣2||",{"2":{"606":1}}],["∣∣⋅",{"2":{"606":2}}],["∣other∣",{"2":{"445":1}}],["∣input−other∣",{"2":{"445":1}}],["∣g∣",{"2":{"410":1}}],["逆双曲余弦",{"2":{"445":1}}],["绕过padding",{"2":{"444":1}}],["介绍",{"0":{"572":1,"614":1,"637":1},"2":{"444":1}}],["嵌套tensor",{"2":{"444":2}}],["嵌套张量",{"2":{"444":2}}],["元硬币",{"2":{"947":1}}],["元的硬币",{"2":{"945":1,"947":2}}],["元",{"2":{"939":9,"945":3,"947":5}}],["元预算",{"2":{"939":1}}],["元素是否含有true",{"2":{"444":1}}],["元素是否全是true",{"2":{"444":1}}],["元参数",{"2":{"411":2}}],["私有方法",{"0":{"444":1}}],["魔术方法",{"0":{"443":1},"2":{"496":1}}],["格式化代码",{"0":{"793":1}}],["格式的数据",{"2":{"570":1}}],["格式的稀疏",{"2":{"441":1}}],["格式",{"2":{"441":1}}],["描述",{"2":{"739":1}}],["描述了",{"2":{"441":1}}],["描述句子中的事件和参与者",{"2":{"188":1}}],["`pwd`",{"2":{"726":2}}],["`pad`",{"2":{"113":1}}],["`id`",{"2":{"726":3}}],["`user`",{"2":{"726":3}}],["`mybatis`",{"2":{"726":2}}],["`torch",{"2":{"556":1}}],["`dataloader`",{"2":{"556":1}}],["`name`",{"2":{"726":2}}],["`nbest`",{"2":{"634":1}}],["`np",{"2":{"556":1}}],["`numpy",{"2":{"441":1}}],["`randomcrop`",{"2":{"556":1}}],["``torchvision",{"2":{"556":1}}],["``totensor``",{"2":{"556":1}}],["``",{"2":{"556":4}}],["``randomcrop``",{"2":{"556":2}}],["``rescale``",{"2":{"556":2}}],["`b`",{"2":{"451":1}}],["`a`",{"2":{"451":1}}],["支持latex渲染",{"2":{"870":1}}],["支持https协议",{"2":{"867":1}}],["支持分布式数据处理和mapreduce并行计算模式",{"2":{"802":1}}],["支持高性能计算",{"2":{"802":1}}],["支持多种网络协议和多种平台",{"2":{"802":1}}],["支持同时编辑多个文件和窗口",{"2":{"788":1}}],["支持编写动态sql",{"2":{"724":1}}],["支持原地操作",{"2":{"481":1}}],["支持将",{"2":{"441":1}}],["支持",{"2":{"441":1}}],["支持各种高性能模型",{"2":{"335":1}}],["成员",{"2":{"889":2}}],["成员密码>",{"2":{"889":1}}],["成员名>",{"2":{"889":1}}],["成tensorboard支持的格式就行",{"2":{"572":1}}],["成为",{"2":{"496":1}}],["成多个tensor",{"2":{"441":1}}],["成功训练需要4万次的预热",{"2":{"407":1}}],["~~~~~~~~~~~~~~~~~~",{"2":{"556":1}}],["~",{"2":{"441":1,"443":1,"742":1,"827":2}}],["~10",{"2":{"383":1}}],["短时傅里叶逆变换",{"2":{"441":1}}],["短时傅里叶变换",{"2":{"441":1}}],["短期的记忆影响较大",{"2":{"143":1}}],["钩子将以",{"2":{"509":2}}],["钩子函数的自定义操作",{"2":{"494":1}}],["钩子函数",{"2":{"490":2,"496":2,"509":1}}],["钩子注册函数",{"2":{"457":1}}],["钩子",{"2":{"441":1,"457":1,"496":2}}],["共用设备或是共用存储器",{"2":{"682":1}}],["共用的范围就可以越大",{"2":{"644":1}}],["共约600m样本",{"2":{"608":1}}],["共170m样本",{"2":{"608":1}}],["共轭转置将矩阵的每个元素取复共轭",{"2":{"440":1}}],["共轭转置操作将实部保持不变",{"2":{"440":1}}],["共享内存模型",{"2":{"801":1}}],["共享进程资源",{"2":{"796":1}}],["共享资源",{"0":{"681":1}}],["共享",{"2":{"217":1,"303":1}}],["$pythonpath",{"2":{"613":1,"636":1}}],["$",{"2":{"440":1,"780":1}}],["$$var",{"2":{"248":1}}],["$$",{"2":{"190":1,"248":1}}],["$$argmax",{"2":{"190":1}}],["讲解",{"0":{"435":1},"1":{"436":1,"437":1,"438":1,"439":1}}],["尾数",{"2":{"433":2}}],["符号位",{"2":{"433":2}}],["符合或近似符合0",{"2":{"130":1}}],["源码了解",{"0":{"825":1}}],["源码一样吗",{"2":{"431":1}}],["源码",{"2":{"431":1,"829":1}}],["源语言和目标语言的句子往往并没有相同的长度",{"2":{"165":1}}],["仿佛是个难以理解的复杂系统",{"2":{"916":1}}],["仿照其它tensor生成",{"0":{"429":1}}],["仿射变换",{"2":{"120":1}}],["社区指南",{"0":{"425":1}}],["社区需要更多涵盖有用方法的资源",{"2":{"353":1}}],["获取进程总数",{"2":{"827":1}}],["获取当前进程的编号",{"2":{"827":1}}],["获取当前进程的id",{"2":{"808":1}}],["获取当前学习率",{"2":{"545":1}}],["获取总的进程数",{"2":{"808":1}}],["获取网页内容",{"2":{"761":1}}],["获取sqlsession连接",{"2":{"726":1,"730":1}}],["获取实际的实体",{"2":{"635":1}}],["获取预测出来的实体",{"2":{"635":1}}],["获取每条句子长度",{"2":{"634":1}}],["获取",{"2":{"509":1}}],["获取额外状态",{"2":{"496":1}}],["获取经过掩模后的矩阵",{"2":{"444":1}}],["获取稀疏矩阵中非0元素的",{"2":{"444":1}}],["获取稀疏矩阵的索引矩阵",{"2":{"444":1}}],["获取更多信息",{"2":{"424":1}}],["获得各个位置的标签向量之后",{"2":{"624":1}}],["获得",{"2":{"379":1}}],["出行方案的费用分别是",{"2":{"939":1}}],["出于教育或调试目的",{"2":{"472":1}}],["出于这个目的",{"2":{"424":1}}],["出现了",{"2":{"21":1}}],["贡献者许可协议",{"0":{"423":1}}],["留一颗小星星",{"2":{"422":1}}],["阅读本手稿并提出宝贵的意见来改进我们的内容",{"2":{"420":1}}],["∇l",{"2":{"417":2,"418":4,"419":6}}],["∇j",{"2":{"258":1}}],["受简单且可扩展的预训练方法的启发",{"2":{"620":1}}],["受batch",{"2":{"412":1}}],["受计算限制的和不受计算限制的",{"2":{"380":1}}],["极其激进",{"2":{"410":1}}],["极端激进的梯度截断本质上是一种降低学习率的奇怪方式",{"2":{"410":1}}],["极有可能转移",{"2":{"384":1}}],["阈值更小",{"2":{"410":1}}],["阈值逻辑单元",{"2":{"10":1}}],["某种适应性策略会怎么样呢",{"2":{"410":1}}],["某些函数将使用其他值",{"2":{"473":1}}],["某些模型会在非常早期的阶段显示出不稳定的情况",{"2":{"405":1}}],["某些神经元可能永远不会被激活",{"2":{"122":1}}],["λ",{"2":{"410":1}}],["λ≈1",{"2":{"125":1}}],["表明这个variable是node",{"2":{"468":1}}],["表明是",{"2":{"468":1}}],["表明此variable实例是否是个view",{"2":{"468":1}}],["表明此variable实例是否需要grad",{"2":{"468":1}}],["表现出训练不稳定性的模型的超参数轴图示例",{"2":{"408":1}}],["表示可以满足的小孩的最大数量",{"2":{"954":1}}],["表示他们至少需要多大的饼干才能满足",{"2":{"951":1}}],["表示所有进程组成的通信域",{"2":{"810":1}}],["表示椭圆的中心",{"2":{"655":1}}],["表示成下面的式子",{"2":{"646":1}}],["表示复数的实部",{"2":{"646":1}}],["表示",{"2":{"646":1,"745":1,"807":1}}],["表示欧几里得范数",{"2":{"606":1}}],["表示矩阵的迹运算",{"2":{"606":1}}],["表示生成图像的分布",{"2":{"606":1}}],["表示真实图像的分布",{"2":{"606":1}}],["表示执行浮点数除法",{"2":{"441":1}}],["表示执行整数除法或向下取整除法",{"2":{"441":1}}],["表示非常低的训练损失",{"2":{"381":1}}],["表示一个子字符串或令牌序列",{"2":{"338":1}}],["表示kv压缩维度",{"2":{"309":1}}],["表示d个通道",{"2":{"249":1}}],["表示损失函数对其求导",{"2":{"249":1}}],["表示网络下一层的输入通道数等于上一层的输出通道数",{"2":{"248":1}}],["表示前一层的输出经过激活函数变成下一层的输入",{"2":{"248":1}}],["表示激活函数relu",{"2":{"248":1}}],["表示第j个饼干的大小",{"2":{"953":1}}],["表示第i个小孩的需求",{"2":{"953":1}}],["表示第几层",{"2":{"248":1}}],["表示第t",{"2":{"137":1}}],["表示被卷积的输入",{"2":{"248":1}}],["表示某个位置的输出值",{"2":{"248":1}}],["表示将右侧的值赋给左侧的变量或表达式",{"2":{"225":1,"313":1}}],["表示掩码",{"2":{"214":1}}],["表示重要",{"2":{"148":1}}],["表示不重要",{"2":{"148":1}}],["表示能力",{"2":{"120":1}}],["表示要扩大内核的范围",{"2":{"60":1}}],["众所周知",{"2":{"406":1}}],["范数异常值非常大",{"2":{"405":1}}],["范数是指在深度学习中",{"2":{"405":1}}],["范数的变化",{"2":{"405":1}}],["范围内",{"2":{"380":1}}],["诊断和纠正训练失败是一个活跃的研究领域",{"2":{"404":1}}],["运算符",{"2":{"706":1}}],["运算",{"2":{"648":1}}],["运算融合",{"2":{"560":1}}],["运算的几种主要类型",{"0":{"439":1}}],["运气特别好和运气特别差的研究之间的差异也可能大于使用固定超参数在不同随机种子上重新训练该模型之间的典型差异",{"2":{"403":1}}],["运行测试",{"2":{"726":1}}],["运行环境",{"2":{"705":1}}],["运行onnx",{"0":{"529":1}}],["运行案例",{"2":{"498":1}}],["运行速度会降低",{"2":{"496":1}}],["运行",{"2":{"456":1}}],["运行请求的操作来计算结果张量",{"2":{"447":1}}],["运行次数",{"2":{"393":1}}],["运行固定步长的训练",{"2":{"392":1}}],["运行第一轮中最佳的超参数配置",{"2":{"385":1}}],["运行更多的试验当然更好",{"2":{"374":1}}],["运行设定步数的试验",{"2":{"359":1}}],["运行所有实验",{"2":{"359":1}}],["运行少量的训练实验",{"2":{"358":1}}],["运行时协同设计的好处",{"2":{"338":1}}],["运行时可以自动识别和利用这些重用模式",{"2":{"337":1}}],["运行前缀匹配和重用",{"2":{"338":1}}],["运行cp需要megatron",{"2":{"328":1}}],["运行的",{"2":{"328":1}}],["模糊查询like语句该怎么写",{"2":{"734":1}}],["模拟每个批次的输入数据",{"2":{"493":1}}],["模拟训练过程",{"2":{"493":1}}],["模拟了不同数量的调整预算",{"2":{"403":1}}],["模块文章",{"2":{"871":2}}],["模块结构",{"2":{"868":1}}],["模块并调整导航栏",{"2":{"867":1}}],["模块实现并发任务",{"2":{"799":1}}],["模块",{"2":{"619":1,"620":1,"868":3,"870":1}}],["模块还可以包含其他模块",{"2":{"488":1}}],["模块呢",{"2":{"483":1}}],["模式简介",{"0":{"774":1}}],["模式",{"0":{"752":1},"2":{"476":1,"477":2,"496":2,"497":1,"811":2}}],["模式和推断模式这样的上下文管理器",{"2":{"474":1}}],["模型演示",{"0":{"813":1}}],["模型可能无法正确处理",{"2":{"645":1}}],["模型可以使用",{"2":{"621":1}}],["模型可以从预训练模型中继承这些有用的语言特征和知识",{"2":{"180":1}}],["模型也是采用该位置编码方式",{"2":{"645":1}}],["模型也容易过拟合",{"2":{"341":1}}],["模型中",{"2":{"630":1}}],["模型中的",{"2":{"619":1,"620":1}}],["模型中的所有子层以及嵌入层产生的输出维度都为dmodel",{"2":{"196":1}}],["模型大小的发展趋势",{"2":{"622":1}}],["模型大了约3倍",{"2":{"608":1}}],["模型只能处理一定长度内的文本",{"2":{"621":1}}],["模型只使用",{"2":{"619":1,"620":1}}],["模型适合处理那些需要根据给定输入来生成新文本的任务",{"2":{"621":1}}],["模型适合处理那些只涉及文本生成的任务",{"2":{"620":1}}],["模型在分类等下游任务上取得了很好的效果",{"2":{"620":1}}],["模型引入了两处架构变化",{"2":{"619":1}}],["模型相比",{"2":{"619":1}}],["模型及它的常见变体如下",{"2":{"619":1}}],["模型依然在",{"2":{"619":1}}],["模型通常通过破坏给定的句子",{"2":{"619":1}}],["模型通常会受益",{"2":{"547":1}}],["模型完全不需要人工标注数据",{"2":{"616":1}}],["模型本质上都是预训练语言模型",{"2":{"616":1}}],["模型层出不穷",{"2":{"616":1,"618":1}}],["模型迁移用于文本分类",{"2":{"616":1}}],["模型跑通",{"0":{"613":1,"636":1}}],["模型后分别转换为特征向量",{"2":{"605":1}}],["模型准备",{"0":{"567":1}}],["模型状态中都保存了什么内容呢",{"2":{"516":1}}],["模型状态的保存",{"0":{"512":1},"1":{"513":1,"514":1,"515":1,"516":1}}],["模型搭建",{"2":{"497":2}}],["模型真正执行之处",{"2":{"496":1}}],["模型权重",{"2":{"463":1}}],["模型训练损失中不稳定的学习率",{"2":{"408":1}}],["模型训练的时间复杂度较高",{"2":{"121":1}}],["模型选择就是选择训练期间看到的最佳检查点",{"2":{"392":1}}],["模型架构上的显著胜利通常会转移",{"2":{"384":1}}],["模型架构",{"2":{"384":1}}],["模型架构通常具有各种超参数",{"2":{"355":1}}],["模型参数初始值",{"2":{"384":1}}],["模型的目标来完成预训练",{"2":{"621":1}}],["模型的性能也在不断提高",{"2":{"620":1}}],["模型的探索在在很大程度上是由",{"2":{"620":1}}],["模型的预训练通常围绕着预测句子中下一个单词展开",{"2":{"620":1}}],["模型的出现",{"2":{"616":1}}],["模型的计算图是根据实际输入数据动态构建的",{"2":{"559":1}}],["模型的计算图在执行前需要显式地进行编译和优化",{"2":{"559":1}}],["模型的",{"2":{"490":1}}],["模型的当前类的",{"2":{"490":1}}],["模型的当前状态会定期保存在磁盘上",{"2":{"392":1}}],["模型的收敛速度会变慢",{"2":{"383":1}}],["模型的表征能力也会增加",{"2":{"14":1}}],["模型就会越来越接近其最佳性能",{"2":{"383":1}}],["模型会对训练集的预测变得越来越自信",{"2":{"381":1}}],["模型是否存在优化问题",{"2":{"372":1}}],["模型将不断改进",{"2":{"365":1}}],["模型类型等",{"2":{"364":1}}],["模型配置",{"2":{"363":1}}],["模型和优化器",{"2":{"359":1}}],["模型复杂度较高",{"2":{"341":1}}],["模型容易过拟合",{"2":{"341":1}}],["模型遇到山谷不会自动减弱更新的幅度",{"2":{"271":1}}],["模型规模小还好",{"2":{"230":1,"330":1}}],["模型里面涉及两种",{"2":{"214":1}}],["模型下载",{"2":{"212":1}}],["模型都是自回归的",{"2":{"194":1}}],["模型都使用了这种激活函数",{"2":{"126":1}}],["模型一经推出便取得",{"2":{"193":1}}],["模型结构超参数通常是目标或固定超参数",{"2":{"369":1}}],["模型结构图",{"0":{"199":1,"603":1}}],["模型结构",{"0":{"168":1,"602":1},"1":{"169":1,"170":1,"171":1,"172":1}}],["模型",{"0":{"166":1,"529":1},"2":{"21":1,"167":1,"220":1,"306":1,"381":1,"544":1,"608":1,"616":6,"619":2,"620":2,"621":3,"806":1}}],["抖动的",{"2":{"401":1}}],["贝叶斯优化就会显得更具吸引力",{"2":{"401":1}}],["贝叶斯优化和与其类似的工具更适合开发阶段",{"2":{"401":1}}],["贝叶斯优化工具就是一个值得考虑的选择",{"2":{"379":1}}],["发现没了",{"2":{"889":1}}],["发现有知己之时",{"2":{"878":1}}],["发现寝室没人",{"2":{"878":1}}],["发现潜在的新方向",{"2":{"366":1}}],["发微信",{"2":{"813":1}}],["发送端和接收端采用同一个变量命名",{"2":{"823":1}}],["发送方会等待接收方收到消息后",{"2":{"807":1}}],["发送消息",{"2":{"796":2}}],["发布",{"2":{"715":1}}],["发布截止日期",{"2":{"399":1}}],["发射分数的生成过程如下",{"2":{"627":1}}],["发射分数",{"0":{"627":1},"2":{"632":1}}],["发射这个概念是从crf里面带出来的",{"2":{"624":1}}],["发展脉络",{"0":{"615":1},"1":{"616":1,"617":1,"618":1,"619":1,"620":1,"621":1,"622":1}}],["衰减",{"2":{"399":1}}],["衰减方案",{"2":{"399":1}}],["衰减方案是根据验证集性能以临时方式调整衰减方案的结果",{"2":{"399":1}}],["衰减方案是什么",{"2":{"397":1}}],["衰减方案的论文并不少见",{"2":{"399":1}}],["批处理规范统计信息在主机之间同步",{"2":{"395":1}}],["虚拟网络编辑器",{"2":{"914":1}}],["虚拟化",{"2":{"910":1}}],["虚拟化管理工具",{"2":{"909":1}}],["虚拟现实等领域的逼真化和互动性提供了强大的支持",{"2":{"859":1}}],["虚拟现实等",{"2":{"858":1}}],["虚拟现实",{"2":{"858":1}}],["虚拟机搭建过程不再赘述",{"2":{"908":1}}],["虚拟机",{"2":{"705":1,"910":1}}],["虚拟批次大小的情况",{"2":{"394":1}}],["虚线框",{"2":{"222":1,"314":1}}],["据说",{"2":{"394":1}}],["据不完全统计",{"2":{"126":1}}],["样本量",{"2":{"391":1}}],["测试中",{"2":{"868":1}}],["测试网络连通性",{"2":{"759":2}}],["测试类中测试",{"2":{"730":1}}],["测试",{"2":{"480":1,"725":1,"731":2,"732":1,"733":1,"827":1}}],["测试分割时",{"2":{"390":1}}],["测试度量中的周期性",{"2":{"390":1}}],["测试集上运行时",{"2":{"389":1}}],["定期评估作业的运行速度可能不够快",{"2":{"391":1}}],["定期评估应在固定步长间隔进行",{"2":{"390":1}}],["定期评估是最实际和最经济的选择",{"2":{"389":1}}],["定期评估",{"2":{"389":1}}],["定义优化器和损失函数",{"2":{"568":1}}],["定义训练函数",{"2":{"567":1}}],["定义数据集",{"2":{"552":1,"567":1}}],["定义自己的数据集",{"0":{"552":1}}],["定义参数",{"2":{"545":1}}],["定义学习率调度器",{"2":{"541":1}}],["定义一个模型",{"0":{"513":1}}],["定义输入数据和目标标签",{"2":{"495":1}}],["定义模型和优化器",{"2":{"541":1}}],["定义模型参数",{"2":{"498":1}}],["定义模型",{"2":{"495":1,"567":1}}],["定义我们自己的module",{"0":{"486":1},"1":{"487":1,"488":1}}],["定义的操作",{"2":{"472":1}}],["定义右侧取幂运算符",{"2":{"441":1}}],["定义右侧取模运算符",{"2":{"441":1}}],["定义tensor",{"2":{"441":2}}],["定义对象的字符串表示形式",{"2":{"441":1,"496":1}}],["定义",{"0":{"167":1},"2":{"51":1,"167":1,"827":1}}],["验证",{"2":{"389":1,"480":1}}],["验证数据和测试数据的任何一种随机分割所产生的方差",{"2":{"378":1}}],["离自己的生活太遥远",{"2":{"916":1}}],["离线评估可能会相当复杂",{"2":{"389":1}}],["离线评估中使用的数据的子集",{"2":{"389":1}}],["离线评估",{"2":{"389":1}}],["离散的卷积公式如下",{"2":{"52":1}}],["昂贵的在线数据预处理",{"2":{"387":1}}],["足够好",{"2":{"384":1}}],["松散",{"2":{"384":1}}],["遗传算法",{"2":{"401":1}}],["遗憾的是",{"2":{"384":1,"722":1}}],["遗忘门决定了从之前的步骤中保留哪些信息是相关的",{"2":{"151":1}}],["遗忘门",{"0":{"147":1},"2":{"146":1,"147":1}}],["轮是最实用的",{"2":{"383":1}}],["错误的搜索空间可能会导致自欺欺人",{"2":{"382":1}}],["地址",{"2":{"584":1,"827":1}}],["地设置参数的requires",{"2":{"496":1}}],["地拟合训练集",{"2":{"382":1}}],["地名",{"2":{"188":1}}],["译注",{"2":{"381":1,"401":1,"406":1}}],["绘制不同n下的position",{"2":{"640":1}}],["绘制学习率略高于",{"2":{"405":1}}],["绘制回顾检查点选择发现的训练steps",{"2":{"381":1}}],["绘制的训练误差和验证误差与训练期间训练步数的关系图",{"2":{"375":1}}],["吝啬的训练时间预算可能需要将学习率衰减计划调整到完美",{"2":{"380":1}}],["慷慨的训练时间预算可以使调整更容易",{"2":{"380":1}}],["竞赛",{"2":{"379":1}}],["归档与压缩",{"0":{"767":1},"1":{"768":1}}],["归根结底",{"2":{"378":1,"387":1}}],["归一化有助于降低不稳定性",{"2":{"406":1}}],["归一化应该是残差之前的最后一个操作",{"2":{"406":1}}],["归一化",{"2":{"18":1}}],["估计试验方差的成本太高",{"2":{"378":1}}],["您仍然可以将选项作为关键字参数传递",{"2":{"504":1}}],["您需要提供一个可迭代的对象",{"2":{"503":1}}],["您需要构建一个优化器对象",{"2":{"503":1}}],["您还打算在下一次前向传播中使用更新后的参数进行梯度模式的计算",{"2":{"478":1}}],["您希望原地更新参数",{"2":{"478":1}}],["您可以随时尝试它们",{"2":{"510":1}}],["您可以随时切换回无梯度模式",{"2":{"479":1}}],["您可以指定优化器特定的选项",{"2":{"503":1}}],["您可以确保模型的子模块被正确地注册和命名",{"2":{"496":1}}],["您可以探索",{"2":{"472":1}}],["您可以使用",{"2":{"472":2}}],["您可以使用链式法则自动计算梯度",{"2":{"471":1}}],["您运行的就是您要求微分的内容",{"2":{"471":1}}],["您不必编码所有可能的路径",{"2":{"471":1}}],["您只需要签署一次cla协议即可",{"2":{"423":1}}],["您都会学到新事物",{"2":{"377":1}}],["您查看这类图表的频率就越低",{"2":{"377":1}}],["辛顿",{"2":{"377":1}}],["制度中",{"2":{"375":2}}],["幸运",{"2":{"375":2}}],["坏",{"2":{"375":1}}],["区域",{"2":{"374":1}}],["好好活就是做有意义的事",{"2":{"880":1}}],["好好做人",{"2":{"880":1}}],["好",{"2":{"374":1,"379":1}}],["好的",{"2":{"371":1}}],["好的激活函数应有的性质",{"0":{"130":1}}],["冗余参数",{"2":{"371":1}}],["冗余超参数后模型的性能",{"2":{"376":1}}],["冗余超参数上最佳试验的性能",{"2":{"376":1}}],["冗余超参数",{"2":{"370":1}}],["冗余超参数越多",{"2":{"369":1}}],["冗余超参数还是固定超参数是根据实验目标来决定的",{"2":{"369":1}}],["冗余超参数是指",{"2":{"369":1}}],["冗余超参数或固定超参数",{"2":{"369":1}}],["冗余超参数和固定超参数",{"0":{"369":1},"2":{"368":1}}],["试验被定义为产生",{"2":{"408":1}}],["试验是否会以有利于某些目标或冗余超参数像",{"2":{"375":1}}],["试验都没有表现出有过拟合",{"2":{"375":1}}],["试验",{"2":{"370":1}}],["延迟和内存需求",{"2":{"369":1}}],["延续了2017年pascal的fp16和2020年ampere的bf16的趋势",{"2":{"325":1}}],["率先采用个",{"2":{"572":1}}],["率将是一个冗余超参数",{"2":{"369":1}}],["率作为一个冗余超参数",{"2":{"369":1}}],["构建云服务并备案",{"2":{"868":1}}],["构建概念体系很重要",{"2":{"831":1}}],["构建一个大型的双语对照表",{"2":{"189":1}}],["构造",{"2":{"726":1}}],["构造函数",{"0":{"443":1},"2":{"496":1,"509":1}}],["构成条件随机场",{"2":{"626":1}}],["构成的网络",{"2":{"369":1}}],["固定虚拟机网络ip",{"0":{"915":1}}],["固定维度d为500",{"2":{"640":1}}],["固定为",{"2":{"634":1}}],["固定这个参数所带来的限制就越多",{"2":{"369":1}}],["固定的超参数对我们的实验结论做了限定",{"2":{"369":1}}],["固定超参数",{"2":{"369":2}}],["固定超参数的值不需要",{"2":{"369":1}}],["固定超参数是指",{"2":{"369":1}}],["固定训练样本的数量达到设定的效果所花的时间",{"2":{"359":1}}],["必须在所有mpi函数之前调用",{"2":{"808":1}}],["必须写上",{"2":{"733":1}}],["必须一致",{"2":{"729":1}}],["必须先调用父类的",{"2":{"488":1}}],["必须是",{"2":{"445":1}}],["必须优化才能公平比较不同目标超参数值的参数",{"2":{"369":1}}],["必须被淘汰",{"2":{"338":1}}],["尝试把while循环改写成for循环",{"2":{"961":1}}],["尝试用饼干去满足孩子",{"2":{"957":1}}],["尝试用每块饼干去满足胃口最小的孩子",{"2":{"956":1}}],["尝试修改代码",{"2":{"889":1}}],["尝试将残差调控因子初始化为",{"2":{"406":1}}],["尝试使用新的优化器",{"2":{"406":1}}],["尝试对训练流程进行改进",{"2":{"367":1}}],["尝试太小的值",{"2":{"241":1}}],["围绕最佳值缩小我们的搜索空间",{"2":{"366":1}}],["判断中点与直线位置关系",{"2":{"845":1}}],["判断与0的关系即可知道下一个点的位置具体怎么确定",{"2":{"844":1}}],["判断",{"2":{"635":1}}],["判断句子顺序是否被交换",{"2":{"619":1}}],["判断前向钩子函数是否带参数",{"2":{"490":1}}],["判断反向传播钩子函数是否完全覆盖了模块的所有梯度输出",{"2":{"490":1}}],["判断超参数的优化空间是否已经饱和",{"2":{"366":1}}],["判断文本是正面的",{"2":{"188":1}}],["深入了解一个专业",{"2":{"831":1}}],["深入浅出完整解析stable",{"2":{"610":2}}],["深入理解问题是至关重要的",{"2":{"366":1}}],["深度卷积和",{"2":{"58":1}}],["深度可分离卷积由两步组成",{"2":{"58":1}}],["深度可分离卷积",{"0":{"58":1}}],["深度神经网络训练需要明确的几个概念",{"0":{"27":1}}],["深度神经网络识别汉字",{"2":{"15":1}}],["深度神经网络解决问题案例",{"0":{"15":1}}],["深度前馈网络",{"2":{"6":1}}],["深度学习调优指南中文版",{"0":{"350":1},"1":{"351":1,"352":1,"353":1,"354":1,"355":1,"356":1,"357":1,"358":1,"359":1,"360":1,"361":1,"362":1,"363":1,"364":1,"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"377":1,"378":1,"379":1,"380":1,"381":1,"382":1,"383":1,"384":1,"385":1,"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1,"396":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1,"414":1,"415":1,"416":1,"417":1,"418":1,"419":1,"420":1,"421":1,"422":1,"423":1,"424":1,"425":1}}],["深度学习优化器是用于训练神经网络模型的算法或工具",{"2":{"256":1}}],["深度学习预训练模型下载",{"2":{"118":1}}],["深度学习网络图中的算子有很多种类",{"2":{"117":1}}],["深度学习模型训练过程的本质是对",{"2":{"233":1}}],["深度学习模型可视化",{"2":{"119":1}}],["深度学习模型通过学习大量数据来提取和学习数据的高级特征表示",{"2":{"117":1}}],["深度学习模型是一种机器学习模型",{"2":{"117":1}}],["深度学习的",{"2":{"191":1}}],["深度学习的众多项任务都开始应用",{"2":{"21":1}}],["深度学习的典型算法",{"0":{"21":1}}],["深度学习的特点",{"0":{"20":1}}],["深度学习的特征提取并不依靠人工",{"2":{"19":1}}],["深度学习的概念",{"0":{"4":1}}],["深度学习与传统机器学习",{"0":{"17":1},"1":{"18":1,"19":1}}],["深度学习与人工智能的关系",{"0":{"3":1}}],["深度学习旨在通过构建和训练多层神经网络来实现人工智能任务",{"2":{"4":1}}],["深度学习",{"2":{"4":1}}],["本段整理日志",{"2":{"877":1}}],["本身就很小且简单",{"2":{"724":1}}],["本身也是一个variable",{"2":{"468":1}}],["本是apache的一个开源项目ibatis",{"2":{"721":1}}],["本书大概内容",{"0":{"701":1}}],["本篇前置内容",{"2":{"695":1}}],["本篇内容课前定位",{"2":{"674":1}}],["本文将概述自动微分",{"2":{"470":1}}],["本文档源于我们自己训练神经网络",{"2":{"353":1}}],["本文档中描述的技术也可能适用于其他类型的问题",{"2":{"352":1}}],["本文档适用于对最大化深度学习的性能感兴趣的工程师和研究人员",{"2":{"352":1}}],["本项目遵循",{"2":{"425":1}}],["本质上",{"2":{"409":1}}],["本节的其余部分将更详细地讲解增量调优策略",{"2":{"365":1}}],["朝着这个目标取得进展",{"2":{"365":1}}],["逐一解决",{"2":{"924":1}}],["逐步去实现",{"2":{"922":1}}],["逐步优化的过程",{"0":{"922":1}}],["逐步计算出直线上其他点的坐标",{"2":{"839":1}}],["逐步添加功能并进行改进",{"2":{"365":1}}],["逐位对应相乘",{"2":{"648":1}}],["逐参数选项",{"0":{"504":1}}],["逐层完全连通的水流系统",{"2":{"15":1}}],["配置",{"0":{"821":1,"887":1},"1":{"888":1,"889":1},"2":{"827":1}}],["配置部分不在该讲解范围内",{"2":{"735":1}}],["配置文件中namespace中的名称为对应mapper接口或者dao接口的完整包名",{"2":{"729":1}}],["配置空间可能非常大",{"2":{"365":1}}],["配备pagedattention的vllm重新定义了llm",{"2":{"332":1}}],["循序渐进",{"2":{"365":1}}],["循环中的总步数可以通过以下两种方式之一进行确定",{"2":{"544":1}}],["循环学习率策略在每个批次之后改变学习率",{"2":{"543":1}}],["循环",{"2":{"510":5,"706":1}}],["循环顺序更改",{"2":{"322":1}}],["循环一次q才完成output的一次累计",{"2":{"319":1}}],["循环解码",{"2":{"168":1}}],["循环过程如下图所示",{"0":{"135":1}}],["循环神经网络",{"0":{"132":1},"2":{"132":1}}],["应调用",{"2":{"543":1,"544":1}}],["应该考虑拿孩子遍历还是饼干",{"2":{"961":1}}],["应该有一个相对独立的逻辑层面",{"2":{"723":1}}],["应该对应什么样的标签",{"2":{"627":1}}],["应该是控制模型中哪些部分参与梯度计算的主要方法",{"2":{"475":1}}],["应该以几个不同的数量级进行扫描",{"2":{"409":1}}],["应该使用与计算梯度不同的",{"2":{"362":1}}],["应当从训练集中随机抽取样本",{"2":{"375":1}}],["应用广泛",{"2":{"858":1}}],["应用最广",{"2":{"848":1}}],["应用所需",{"2":{"705":1}}],["应用旋转位置编码",{"2":{"649":1}}],["应用旋转操作",{"2":{"649":1}}],["应用到前面公式",{"2":{"647":1}}],["应用用户指定的函数",{"2":{"496":1}}],["应用于不希望更新的参数",{"2":{"475":1}}],["应用dropout之后",{"2":{"346":1}}],["应用场景",{"0":{"161":1},"1":{"162":1,"163":1,"164":1}}],["应用案例",{"0":{"142":1}}],["耗时且成本高昂",{"2":{"361":1}}],["永远不会增加",{"2":{"359":1}}],["达到某一性能目标所需的步数通常会减少",{"2":{"359":1}}],["故在应用工作中通常应避免使用它",{"2":{"358":1}}],["点对点通信",{"2":{"806":1}}],["点击展开",{"2":{"358":1,"359":1,"360":1,"361":1,"362":1,"369":1,"370":1,"371":1,"373":1,"374":1,"375":1,"376":1,"377":1,"382":1,"384":1,"385":1,"389":1,"390":1,"391":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"411":1,"412":1,"413":1}}],["点积大幅度增长",{"2":{"206":1}}],["详见bergstra",{"2":{"402":1}}],["详见",{"2":{"357":1}}],["详解",{"0":{"146":1,"212":1},"1":{"147":1,"148":1,"149":1,"150":1,"151":1}}],["🤖使用额外的步骤来延长高学习率的训练时间",{"2":{"385":1}}],["🤖",{"2":{"356":1,"359":1,"374":1,"410":2}}],["花时间在模型架构和训练配置上是有意义的",{"2":{"354":1}}],["花书定义",{"2":{"51":1}}],["任何连结到电脑系统中的装置",{"2":{"680":1}}],["任何训练任务都会变得不稳定",{"2":{"405":1}}],["任何让训练变得更糟的事情都可以作为正则化器",{"2":{"375":1}}],["任何标有🤖表情符号的地方是我们要进一步调查的地方",{"2":{"353":1}}],["任务的开始结束时间都不同",{"2":{"973":1}}],["任务间通过网络通信",{"2":{"801":1}}],["任务间通过共享内存交换数据",{"2":{"801":1}}],["任务概述",{"0":{"624":1}}],["任务及其涉及的数据",{"2":{"622":1}}],["任务来进行预训练",{"2":{"621":1}}],["任务转换为",{"2":{"621":1}}],["任务都转换为",{"2":{"621":1}}],["任务上取得了优异的性能",{"2":{"619":1}}],["任务上都远远超过先前的最强基准",{"2":{"616":1}}],["任务替换为句子排序预测",{"2":{"619":1}}],["任务",{"0":{"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"193":1,"619":1,"621":1,"622":1}}],["教育",{"2":{"917":1}}],["教育和生产环境中的高性能计算",{"2":{"802":1}}],["教授学生以及为我们的同事提供实践建议的经验",{"2":{"353":1}}],["教科书也往往回避实用指南",{"2":{"353":1}}],["致谢",{"0":{"420":1},"2":{"351":1}}],["关闭当前分屏",{"2":{"790":1}}],["关系型数据库",{"2":{"709":1}}],["关系总结如下",{"2":{"55":1}}],["关于时间复杂度的详细计算",{"2":{"959":1}}],["关于随笔",{"2":{"881":1}}],["关于",{"2":{"878":1}}],["关于ethan博客介绍",{"2":{"854":1,"860":1}}],["关于默认模式最重要的是",{"2":{"477":1}}],["关于如何使用pull",{"2":{"424":1}}],["关于训练管道的额外补充",{"0":{"386":1},"1":{"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1,"395":1}}],["关于训练工作流的额外补充",{"2":{"351":1}}],["关于贡献",{"0":{"422":1},"1":{"423":1,"424":1,"425":1},"2":{"351":1}}],["探索了构建多语言模型的多个预训练目标",{"2":{"619":1}}],["探索源码",{"0":{"550":1}}],["探索阶段",{"2":{"401":1}}],["探索",{"2":{"366":1}}],["探索结束后",{"0":{"379":1},"2":{"351":1}}],["探索与利用",{"0":{"366":1},"2":{"351":1}}],["增量公式",{"2":{"840":1}}],["增量调整策略",{"0":{"365":1},"2":{"351":1}}],["增",{"2":{"731":1}}],["增大时",{"2":{"381":1}}],["增大网络感受野",{"2":{"92":1}}],["增加了代码的复杂性",{"2":{"369":1}}],["增加",{"2":{"360":4,"889":1,"907":1}}],["增加batch",{"2":{"357":2,"359":2}}],["目的进程编号",{"2":{"823":1}}],["目标进程id",{"2":{"806":1}}],["目标",{"0":{"952":1},"2":{"619":1}}],["目标超参数的每个设置的",{"2":{"375":1}}],["目标超参数是",{"2":{"369":1}}],["目标超参数是指",{"2":{"369":1}}],["目标超参数",{"2":{"368":1}}],["目标可以包括",{"2":{"367":1}}],["目录",{"0":{"351":1},"2":{"739":1}}],["目前是大模型相对位置编码中应用最广的方式之一",{"2":{"645":1}}],["目前已被",{"2":{"441":1}}],["目前已经有很多更好的激活函数",{"2":{"9":1}}],["目前还没有任何能够令人信服的证据表明batch",{"2":{"412":1}}],["目前还没有任何算法可以在没有人工指导的情况下有效地搜索这个空间",{"2":{"365":1}}],["目前尚不清楚如何构建一组严格的实验来自信地回答最佳的lr",{"2":{"397":1}}],["目前batch",{"2":{"394":1}}],["目前很少有人记录下那些深度学习中获得良好结果的实际方法",{"2":{"353":1}}],["目前",{"2":{"282":1,"353":1,"619":1}}],["目前并没有明确的胜出者",{"2":{"156":1}}],["目前的想法是",{"2":{"128":1}}],["谷歌开源社区指南",{"2":{"425":1}}],["谷歌大脑团队",{"2":{"350":1}}],["谷歌研究",{"2":{"350":1}}],["产品",{"2":{"350":1}}],["产生的超参数的不同值时",{"2":{"376":1}}],["产生梯度消失问题",{"2":{"239":1}}],["产生一个上三角矩阵",{"2":{"216":1}}],["产生最终值",{"2":{"208":1}}],["产生",{"2":{"208":1}}],["产生不同的结果",{"2":{"180":1}}],["丢掉整块的有效特征",{"2":{"348":1}}],["丢弃哪些神经元是随机决定",{"2":{"346":1}}],["丢了西瓜",{"2":{"183":1}}],["世纪80",{"2":{"345":1}}],["ϵ",{"2":{"345":3,"356":1,"400":1}}],["色彩抖动",{"2":{"344":1}}],["白平衡",{"2":{"344":1}}],["锐化",{"2":{"344":1}}],["旋转",{"2":{"857":1}}],["旋转位置编码计算",{"2":{"649":1}}],["旋转位置编码",{"0":{"645":1},"1":{"646":1,"647":1,"648":1,"649":1},"2":{"645":1}}],["旋转和平移等等",{"2":{"344":1}}],["旋转180度",{"2":{"61":1}}],["裁剪",{"2":{"344":1}}],["创建的项目",{"2":{"889":1}}],["创建和启动线程",{"2":{"799":1}}],["创建和删除目录",{"2":{"742":1}}],["创建消息",{"2":{"796":2}}],["创建空文件",{"2":{"743":1}}],["创建文件",{"2":{"743":1}}],["创建实体类",{"2":{"726":1}}],["创建了一个",{"2":{"619":1}}],["创建优化器和学习率调度器",{"2":{"545":1}}],["创建掩码",{"2":{"498":1}}],["创建输入数据",{"2":{"498":1}}],["创建模型",{"2":{"498":1,"500":1}}],["创建模型实例",{"2":{"493":1}}],["创建者的第几个输出",{"2":{"440":1}}],["创建",{"0":{"427":1}}],["创建pytorch",{"0":{"426":1},"1":{"427":1,"428":1,"429":1,"430":1}}],["创建研究通常涉及几个方面",{"2":{"370":1}}],["创建一个名为",{"2":{"742":1}}],["创建一个优化器对象",{"0":{"503":1}}],["创建一个需要梯度的张量",{"2":{"452":1}}],["创建一个现有",{"2":{"445":1}}],["创建一个示例张量",{"2":{"111":1}}],["创建一组研究",{"0":{"370":1}}],["创建一系列研究以比较目标超参数的不同值",{"2":{"368":1}}],["创建新的假数据相当简单",{"2":{"344":1}}],["添加不同商家之间的视野",{"2":{"907":1}}],["添加虚拟机网络问题",{"2":{"871":1}}],["添加重温士兵突击",{"2":{"871":1,"907":1}}],["添加专英翻转课堂内容",{"2":{"868":1}}],["添加文章",{"2":{"868":3}}],["添加用户到组",{"2":{"763":1}}],["添加用户",{"2":{"763":1}}],["添加",{"0":{"887":1},"1":{"888":1,"889":1},"2":{"496":1,"868":2,"870":1,"871":2,"877":1}}],["添加一个用户",{"2":{"731":1}}],["添加一个参数组",{"2":{"509":1}}],["添加一个参数范数惩罚ω",{"2":{"343":1}}],["添加一个buffer",{"2":{"496":1}}],["添加了一些类型的正则化",{"2":{"380":1}}],["添加到",{"2":{"508":1}}],["添加到我们的训练流程中",{"2":{"369":1}}],["添加到训练集中",{"2":{"344":1}}],["限制其运算能力的任何实体或是虚拟的组成元件",{"2":{"680":1}}],["限制因素通常是加速器",{"2":{"358":1}}],["限制模型",{"2":{"343":1}}],["限制了网络几何变换建模的能力",{"2":{"63":1}}],["复杂的问题就需要我们认真去分析了",{"0":{"935":1}}],["复杂模型具有较强的表达能力",{"2":{"341":1}}],["复习考试",{"2":{"919":1}}],["复制选择内容",{"2":{"784":1}}],["复制当前单词",{"2":{"782":1}}],["复制当前行",{"2":{"753":1,"782":1}}],["复制和粘贴",{"0":{"782":1}}],["复制和移动文件",{"2":{"743":1}}],["复制文件",{"2":{"743":1}}],["复制给",{"2":{"226":1}}],["复数可以设置",{"2":{"464":1}}],["什么又是互斥",{"0":{"678":1}}],["什么情况下容易出现过拟合",{"0":{"341":1}}],["什么是算法",{"0":{"917":1}}],["什么是并行",{"0":{"797":1}}],["什么是持久层",{"2":{"723":1}}],["什么是mybatis",{"0":{"721":1}}],["什么是大模型外推性",{"2":{"645":1}}],["什么是ring",{"2":{"326":1}}],["什么是",{"2":{"215":1}}],["什么是深度学习模型",{"0":{"117":1}}],["什么是人工神经网络",{"0":{"5":1}}],["博客迁移至新mac",{"2":{"873":1}}],["博客指南",{"2":{"868":1}}],["博客结构",{"2":{"864":1,"868":1}}],["博客",{"2":{"339":1}}],["链接1",{"2":{"610":1}}],["链接",{"2":{"442":1,"572":1,"584":1}}],["链接到一个新节点",{"2":{"338":1}}],["链式求导",{"2":{"45":1}}],["链式求导有两种情况需要考虑",{"2":{"28":1}}],["链式求导法则",{"0":{"28":1}}],["被mask",{"2":{"634":2}}],["被提出之后",{"2":{"616":1}}],["被load",{"2":{"496":1}}],["被state",{"2":{"496":1}}],["被调用",{"2":{"490":1,"496":1}}],["被",{"2":{"441":1,"509":2}}],["被拆分为两个节点",{"2":{"338":1}}],["被合并到树中作为一个单独的边",{"2":{"338":1}}],["被称为",{"2":{"878":1}}],["被称为条件语言模型",{"2":{"176":1}}],["被称为输出层神经元的误差信号",{"2":{"29":1}}],["服务周到",{"2":{"875":1}}],["服务",{"2":{"875":1,"913":1}}],["服务拆分与",{"2":{"717":1}}],["服务端应用和基础库的标准",{"2":{"703":1}}],["服务器更新",{"2":{"867":1}}],["服务器",{"2":{"796":1}}],["服务器接收来自第一个聊天会话的新消息",{"2":{"338":1}}],["服务器接收一个请求",{"2":{"338":1}}],["服务器接收一个少样本学习查询",{"2":{"338":1}}],["服务器接收一批额外的少样本学习查询",{"2":{"338":1}}],["服务器在基数树中找到提示的前缀",{"2":{"338":1}}],["服务器处理一个传入的用户消息",{"2":{"338":1}}],["服从均匀分布时",{"0":{"252":1}}],["服从正态分布时",{"0":{"251":1}}],["基础环境",{"0":{"909":1}}],["基础大纲",{"2":{"735":1}}],["基础",{"0":{"708":1},"2":{"719":1}}],["基础语法",{"0":{"706":1}}],["基准上击败人类的模型",{"2":{"619":1}}],["基准上超过了当时所有的最强模型",{"2":{"619":1}}],["基准和翻译任务上都取得了最好的性能",{"2":{"619":1}}],["基于vmware",{"2":{"815":1}}],["基于发射分数使用crf解码最优的标签路径",{"2":{"624":1}}],["基于预训练模型进行微调会是一个更好的选择",{"2":{"617":1}}],["基于上下文",{"2":{"616":1}}],["基于句子的前",{"2":{"616":1}}],["基于openclip在laion",{"2":{"608":1}}],["基于base的variable",{"2":{"468":1}}],["基于随机移动的低差异序列的quasi",{"2":{"401":1}}],["基于低差异序列",{"2":{"401":1}}],["基于时间间隔进行评估可能会使解释训练曲线变得更加困难",{"2":{"390":1}}],["基于每个映射版本",{"2":{"208":1}}],["基本每看一两集都会有我的泪点",{"2":{"880":1}}],["基本博客结构和装修完成",{"2":{"867":1}}],["基本思想",{"0":{"849":1}}],["基本实现思路",{"0":{"837":1}}],["基本环境配置",{"0":{"814":1},"1":{"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1}}],["基本环境要求如下",{"2":{"794":1}}],["基本原理",{"0":{"804":1,"974":1},"1":{"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1}}],["基本操作",{"0":{"753":1},"2":{"817":1}}],["基本查看",{"2":{"748":1}}],["基本查询",{"2":{"709":1}}],["基本命令操作",{"0":{"741":1},"1":{"742":1,"743":1}}],["基本命令使用",{"0":{"736":1},"1":{"737":1,"738":1,"739":1,"740":1,"741":1,"742":1,"743":1,"744":1,"745":1,"746":1,"747":1,"748":1,"749":1,"750":1,"751":1,"752":1,"753":1,"754":1,"755":1,"756":1,"757":1,"758":1,"759":1,"760":1,"761":1,"762":1,"763":1,"764":1,"765":1,"766":1,"767":1,"768":1,"769":1,"770":1,"771":1,"772":1}}],["基本用户命令存放目录",{"2":{"739":1}}],["基本概念",{"0":{"675":1,"796":1},"1":{"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1}}],["基本的三角循环",{"2":{"543":2}}],["基本运算符",{"0":{"443":1}}],["基本超参数轴图",{"2":{"382":1}}],["基本步骤和原则都是相似的",{"2":{"364":1}}],["基数树最初为空",{"2":{"338":1}}],["体现了前端",{"2":{"338":1}}],["体会卷积的作用",{"0":{"53":1}}],["树结构存储在",{"2":{"338":1}}],["系统消息日志",{"2":{"772":1}}],["系统事件日志",{"2":{"772":1}}],["系统日志文件",{"2":{"772":1}}],["系统",{"2":{"770":2,"772":2}}],["系统更新与软件管理",{"0":{"769":1},"1":{"770":1}}],["系统管理员",{"2":{"739":1}}],["系统配置文件",{"2":{"739":1}}],["系统资源",{"0":{"680":1},"2":{"680":1}}],["系统提示",{"2":{"338":1}}],["系统将淘汰所有缓存的token",{"2":{"338":1}}],["系统动态地分配内存用于缓存和运行请求",{"2":{"338":1}}],["策略全解",{"0":{"534":1}}],["策略",{"2":{"338":1,"973":1}}],["淘汰",{"2":{"338":1}}],["淘汰策略可以有效地管理缓存空间",{"2":{"338":1}}],["淘汰策略",{"2":{"337":1,"338":1}}],["取的数据不在任何椭圆里",{"2":{"656":1}}],["取出结果",{"2":{"570":1}}],["取绝对值",{"2":{"443":1}}],["取余运算符",{"2":{"441":1}}],["取代了传统的",{"2":{"338":1}}],["取得成功重要的是缩放不变性",{"2":{"91":1}}],["取得了重大成功",{"2":{"21":1}}],["少样本学习示例",{"2":{"337":1}}],["绿色表示新添加的节点",{"2":{"338":1}}],["绿色框表示不可共享的部分",{"2":{"337":1}}],["绿点是rnn单元",{"2":{"172":1}}],["工具",{"2":{"830":1}}],["工厂",{"2":{"717":1}}],["工作环境",{"2":{"925":1}}],["工作",{"2":{"619":1}}],["工作负载中很常见",{"2":{"337":1}}],["工程模拟",{"2":{"802":1}}],["工程实践",{"0":{"431":1}}],["工程图展示",{"0":{"139":1}}],["工程上的计算图",{"2":{"157":1}}],["工程上计算图",{"2":{"152":1}}],["工程上3d卷积",{"2":{"65":1}}],["工程上",{"2":{"55":1,"117":1}}],["工程上标准的卷积",{"0":{"55":1}}],["工程上大多数据都是多维度的",{"2":{"52":1}}],["工程中处理的数据大都是离散的",{"2":{"52":1}}],["调整方案",{"0":{"531":1}}],["调整",{"2":{"441":1}}],["调用训练函数",{"2":{"568":1}}],["调用之前执行预处理操作",{"2":{"509":1}}],["调用以上三种to",{"2":{"496":1}}],["调用",{"2":{"441":2,"443":1,"496":1,"509":2}}],["调用的复杂程序中",{"2":{"337":1}}],["调节阀的总数可以成千上万甚至更多",{"2":{"15":1}}],["高效完成任务",{"0":{"926":1}}],["高效的内存共享",{"2":{"335":1}}],["高中的恩师田老师曾经告诉我们",{"2":{"878":1}}],["高级渲染技术",{"2":{"857":1}}],["高扩展性",{"2":{"812":1}}],["高学习率不再能很好地进行训练",{"2":{"404":1}}],["高梯度方差可能是由以下原因造成的",{"2":{"380":1}}],["高维特征空间中的线性模型往往有很大的参数空间",{"2":{"341":1}}],["高度",{"2":{"65":1}}],["至于具体原理和证明",{"2":{"975":1}}],["至于",{"2":{"878":1}}],["至于稍远的位置",{"2":{"644":1}}],["至于注意力",{"2":{"328":1}}],["至少目前我很多时候还是会做不到",{"2":{"878":1}}],["至少需要一直供电吧",{"2":{"722":1}}],["至少得有一定的规律性才能让神经网络进行学习",{"2":{"654":1}}],["至少在局部上",{"2":{"473":2}}],["至少",{"2":{"377":1,"382":1}}],["至少有一些是冗余超参数",{"2":{"369":1}}],["至少能够并行发起数个训练流程",{"2":{"364":1}}],["至80",{"2":{"333":1}}],["占用高达1",{"2":{"333":1}}],["秘密武器",{"0":{"333":1}}],["今天完成一部分",{"2":{"924":1}}],["今天",{"2":{"332":1}}],["许多复杂的",{"2":{"399":1}}],["许多正则化方法通过对目标函数j",{"2":{"343":1}}],["许多策略显式地被设计来减少测试误差",{"2":{"340":1}}],["许多研究提出了序列并行性",{"2":{"329":1}}],["许多机器学习的库实现的是互相关函数但是称之为卷积",{"2":{"52":1}}],["甚至为通用人工智能",{"2":{"622":1}}],["甚至会导致过拟合",{"2":{"380":1}}],["甚至会导致梯度弥散或爆炸",{"2":{"235":1}}],["甚至1m",{"2":{"329":1}}],["跨语言语言模型",{"2":{"619":1}}],["跨batch",{"2":{"380":1}}],["跨九个时间点进行演示",{"2":{"338":1}}],["跨多个节点扩展张量并行性",{"2":{"329":1}}],["跨多个节点进行处理",{"2":{"329":1}}],["跨过山谷后梯度方向会发生变化",{"2":{"269":1}}],["默认模式是在没有启用其他模式",{"2":{"477":1}}],["默认模式",{"0":{"477":1},"2":{"476":1,"477":1}}],["默认情况下",{"2":{"475":1}}],["默认情况下会生成",{"2":{"410":1}}],["默认为",{"2":{"444":1,"475":1}}],["默认设置是尝试使用",{"2":{"409":1}}],["默认的context",{"2":{"328":1}}],["默认是vgg类似的网络",{"2":{"246":1}}],["扩展性强",{"2":{"801":1}}],["扩展到",{"2":{"621":1}}],["扩展到更多gpu并增加tp都可能会遇到重叠问题",{"2":{"328":1}}],["扩展",{"2":{"472":1}}],["扩大张量模型并行性",{"2":{"328":1}}],["长远规划",{"0":{"922":1}}],["长的像的图片离得近",{"2":{"657":1}}],["长度",{"2":{"633":1}}],["长序列长度",{"2":{"328":1}}],["长短期记忆",{"2":{"144":1}}],["长短期记忆网络",{"0":{"144":1},"1":{"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1}}],["旁边的通信是为了",{"2":{"328":1}}],["层之前添加了绝对位置嵌入",{"2":{"619":1}}],["层可以更好地建模邻近词语对的依赖关系",{"2":{"619":1}}],["层面上是经过多层的函数调用",{"2":{"455":1}}],["层模型",{"2":{"369":1}}],["层模型是否优于最好的",{"2":{"369":1}}],["层宽度",{"2":{"355":1}}],["层",{"2":{"328":1,"723":1}}],["青色框",{"2":{"327":1}}],["黄色框表示不可共享的模型输出",{"2":{"337":1}}],["黄色框",{"2":{"327":1}}],["先做截止时间是",{"2":{"943":1}}],["先做人",{"2":{"878":1}}],["先选择",{"2":{"939":1}}],["先刷牙",{"2":{"917":1}}],["先完成",{"2":{"829":1}}],["先上手",{"2":{"829":1}}],["先前的实验表明最好的优化器和当前的目标超参数无关",{"2":{"369":1}}],["先前的工作还提出利用环拓扑来计算自注意力",{"2":{"327":1}}],["先用",{"2":{"59":1}}],["交换数据",{"2":{"801":1}}],["交换kv还可以利用mqa",{"2":{"328":1}}],["交换tensor的两个轴并返回",{"2":{"100":1}}],["交互的内部循环中出现了挑战",{"2":{"327":1}}],["了吗",{"2":{"878":1}}],["了一份数据",{"2":{"430":1}}],["了解如何模拟光照和材质效果",{"2":{"857":1}}],["了解平移",{"2":{"857":1}}],["了解",{"0":{"822":1}}],["了解即可",{"0":{"470":1},"1":{"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1}}],["了解随机元优化中的短期偏差描述了选择学习率的短视危险",{"2":{"384":1}}],["了解特定模型超参数",{"2":{"367":1}}],["了",{"2":{"326":1,"383":1,"648":1,"878":1}}],["卡越多",{"2":{"326":1}}],["术语一点地说",{"2":{"326":1}}],["网关",{"2":{"910":1}}],["网易伏羲采用最新的3d面部重建技术",{"2":{"859":1}}],["网易伏羲团队开发的雅可比预处理非线性共轭梯度方法在处理复杂的自碰撞场景时表现卓越",{"2":{"859":1}}],["网格搜索也是可以接受的",{"2":{"402":1}}],["网站链接",{"2":{"326":1}}],["网络管理",{"0":{"758":1},"1":{"759":1,"760":1,"761":1}}],["网络连线与记忆体区块等",{"2":{"680":1}}],["网络结构的搭建",{"2":{"484":1}}],["网络延迟问题等影响的情况下",{"2":{"390":1}}],["网络层数通常是一个目标或固定的超参数",{"2":{"369":1}}],["网络会对前面的信息进行记忆并应用于当前输出的计算中",{"2":{"133":1}}],["网络架构和数据特征进行评估和实验",{"2":{"120":1}}],["网络的最终性能与收敛得到的最优解直接相关",{"2":{"235":1}}],["网络的输出信号",{"2":{"29":1}}],["网络的出口也是若干管道开口",{"2":{"15":1}}],["网络的入口是若干管道开口",{"2":{"15":1}}],["消息通讯的匹配",{"2":{"823":1}}],["消息标志",{"2":{"823":1}}],["消息标签",{"2":{"809":1}}],["消息数据",{"2":{"806":1}}],["消息传递接口",{"2":{"802":1}}],["消息传递",{"2":{"796":1}}],["消息是数据和控制信息的封装",{"2":{"796":1}}],["消息",{"2":{"796":1}}],["消息中间件",{"0":{"715":1}}],["消除每个连续数据中除第一个元素之外的所有元素",{"2":{"441":1}}],["消除由低三角形因果蒙版导致的不必要计算",{"2":{"328":1}}],["消除个别设备施加的内存限制",{"2":{"327":1}}],["消除梯度消失和爆炸",{"2":{"125":1}}],["消费者异步性",{"2":{"325":1}}],["技术心得",{"2":{"881":1}}],["技术没有高低之分",{"2":{"724":1}}],["技术",{"2":{"619":1}}],["技术挑战在于重新设计flashattention",{"2":{"325":1}}],["技术寻找更好的激活函数",{"2":{"127":1}}],["低精度要求小心处理以最小化量化误差",{"2":{"325":1}}],["低精度",{"2":{"325":1}}],["低效性",{"2":{"260":1}}],["执行一系列步骤来解决问题的过程",{"2":{"923":1}}],["执行一次优化步骤",{"2":{"509":1}}],["执行计算任务",{"2":{"811":1}}],["执行相应操作",{"2":{"796":1}}],["执行权限",{"2":{"745":1}}],["执行方式",{"0":{"578":1}}],["执行训练步骤",{"2":{"545":1}}],["执行训练和参数更新",{"2":{"541":1}}],["执行前向传播",{"2":{"494":1}}],["执行",{"2":{"441":1}}],["执行矩阵乘法操作",{"2":{"444":1}}],["执行矩阵乘法和加法操作",{"2":{"444":1}}],["执行矩阵乘法",{"2":{"325":1}}],["执行所有的计算步骤",{"2":{"226":1,"315":1}}],["异步发送和接收消息",{"2":{"808":1}}],["异步通信允许发送方在消息尚未接收完毕时继续执行",{"2":{"807":1}}],["异步通信",{"2":{"807":1}}],["异步消息处理",{"2":{"715":1}}],["异步性要求在matmul和softmax之间重叠计算",{"2":{"325":1}}],["异步性是硬件专门化的结果",{"2":{"325":1}}],["异常处理",{"2":{"708":1}}],["异或问题如下图所示",{"2":{"12":1}}],["略有改动",{"2":{"966":1}}],["略",{"2":{"324":2}}],["新增java",{"2":{"868":1}}],["新增内容",{"2":{"868":1}}],["新增贪心算法模块的几篇文章",{"2":{"868":1}}],["新增算法模块的一些内容",{"2":{"868":1}}],["新增ssl证书",{"2":{"867":1}}],["新增seq",{"2":{"324":1}}],["新增",{"2":{"867":1,"868":1,"873":1,"874":1}}],["新东西学习",{"0":{"829":1}}],["新的y",{"2":{"456":1}}],["新的训练过程总共应当进行了11000次",{"2":{"409":1}}],["新的想法经过一个完整的工作",{"2":{"385":1}}],["新的正则化器",{"2":{"367":1}}],["新的轮次被追加到",{"2":{"338":1}}],["新的轮次被追加到树中作为一个新节点",{"2":{"338":1}}],["新的细胞状态和新的隐藏状态随后传递到下一个时间步",{"2":{"150":1}}],["置换内外循环位置",{"2":{"324":1}}],["避免错误",{"0":{"925":1}}],["避免冲突",{"2":{"676":1}}],["避免一些耗时的检查",{"2":{"509":1}}],["避免在多轮评估中对验证集过度适应",{"2":{"391":1}}],["避免仅因历史原因而表现良好的不必要更改",{"2":{"366":1}}],["避免了几乎所有的",{"2":{"721":1}}],["避免了重复的图构建和优化过程",{"2":{"564":1}}],["避免了对每个block用",{"2":{"322":1}}],["避免了多次读写",{"2":{"322":1}}],["避免梯度在传播过程中出现过大或过小的变化",{"2":{"120":1}}],["超级管理员或者普通管理员账号",{"0":{"887":1},"1":{"888":1,"889":1}}],["超详细的vmware虚拟机安装linux图文教程保姆级",{"2":{"815":1}}],["超过句子长度则",{"2":{"634":2}}],["超过该临界总步数的减少效果将会下降",{"2":{"359":1}}],["超过最大理论tflops",{"2":{"320":1}}],["超参数",{"2":{"411":3,"500":1}}],["超参数搜索方差或学习方差",{"2":{"378":1}}],["超参数的准备",{"2":{"356":1}}],["超参",{"2":{"27":1}}],["没有其他点可以更高",{"2":{"970":1}}],["没有具体的模板",{"2":{"970":1}}],["没有追赶的",{"2":{"942":1}}],["没有顺序要求",{"2":{"730":1}}],["没有任何第三方依赖",{"2":{"724":1}}],["没有太多传统教条模式",{"2":{"696":1}}],["没有开源",{"2":{"620":1}}],["没有",{"2":{"475":1}}],["没有实际存储",{"2":{"468":1}}],["没有发现一致的优势",{"2":{"378":1}}],["没有在搜索空间中采样足够的点",{"0":{"374":1}}],["没有一个优化器是适用于所有类型的机器学习问题和模型架构的",{"2":{"356":1}}],["没有softmax重新缩放",{"2":{"316":1}}],["没有残差",{"2":{"246":1}}],["普通用户账户",{"0":{"889":1}}],["普通用户的主目录",{"2":{"739":1}}],["普通模式基础操作",{"0":{"779":1},"1":{"780":1,"781":1,"782":1,"783":1}}],["普通模式",{"2":{"752":1,"774":1}}],["普通的",{"2":{"721":1}}],["普通attention",{"2":{"316":1}}],["普通卷积网络kernel大小固定",{"2":{"63":1}}],["官方文档",{"2":{"440":1,"718":1,"829":1}}],["官方逻辑图",{"2":{"315":1}}],["官网链接",{"2":{"272":1}}],["官网",{"0":{"67":1}}],["逻辑推理",{"0":{"925":1}}],["逻辑运算简图",{"2":{"315":1}}],["逻辑回归",{"2":{"10":1}}],["伪代码实现",{"0":{"851":1}}],["伪代码演示",{"0":{"841":1,"847":1}}],["伪代码展示",{"2":{"535":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":2,"547":1,"548":1,"549":1}}],["伪代码",{"0":{"315":1,"316":1}}],["压缩",{"2":{"309":2,"768":1}}],["压缩维度与解压维度",{"2":{"102":1}}],["称为",{"2":{"360":1}}],["称为多维潜隐注意力",{"2":{"308":1}}],["称作为cross",{"2":{"213":1}}],["缓冲区",{"2":{"823":1}}],["缓冲区默认是持久的",{"2":{"493":1}}],["缓冲区等",{"2":{"490":1}}],["缓存等",{"2":{"739":1}}],["缓存",{"2":{"338":1}}],["缓存的流式传输可以重叠延迟",{"2":{"329":1}}],["缓存将成为限制推理效率的瓶颈",{"2":{"308":1}}],["缓解数据稀疏性问题",{"2":{"180":2}}],["缓解了过拟合问题的发生",{"2":{"122":1}}],["修复主页底部页脚的版权信息未居中问题",{"2":{"868":1}}],["修改用户组",{"2":{"763":1}}],["修改用户的信息",{"2":{"732":1}}],["修改权限",{"2":{"746":1}}],["修改一个用户",{"2":{"732":1}}],["修改",{"2":{"441":1}}],["修改或细化",{"2":{"441":1}}],["修改batch",{"2":{"412":1}}],["修改adagrad",{"2":{"283":1}}],["修正从原点初始化的一阶矩",{"2":{"294":1}}],["包测试",{"2":{"726":1}}],["包",{"2":{"726":1}}],["包含内容",{"2":{"863":1,"864":1}}],["包含内容如下",{"2":{"832":1}}],["包含了消息传递接口的支持库",{"2":{"822":1}}],["包含了整个输入序列的信息",{"2":{"170":1}}],["包含编译器",{"2":{"705":1}}],["包含",{"2":{"609":1,"705":1}}],["包含所有参数组的列表",{"2":{"509":1}}],["包括我这里所写的这些",{"2":{"876":1}}],["包括光线反射",{"2":{"857":1}}],["包括phong模型",{"2":{"857":1}}],["包括编译器和运行程序",{"2":{"822":1}}],["包括点对点通信",{"2":{"806":1}}],["包括单核单处理器",{"2":{"799":1}}],["包括档案",{"2":{"680":1}}],["包括来自",{"2":{"619":1}}],["包括来自项目成员的提交",{"2":{"424":1}}],["包括参数和持久性缓冲区",{"2":{"496":1}}],["包括输入张量",{"2":{"490":1}}],["包括新的超参数配置",{"2":{"378":1}}],["包括尽可能多的有冗余超参数",{"2":{"371":1}}],["包括贝叶斯优化或进化算法等方法",{"2":{"370":1}}],["包括",{"2":{"369":1}}],["包括对于获得良好结果至关重要的所有实用细节",{"2":{"353":1}}],["包括个人和团队",{"2":{"352":1}}],["包括mha",{"2":{"328":1}}],["包括偏置修正",{"2":{"294":1}}],["早期较大的梯度范数",{"2":{"410":1}}],["早期算法背景下",{"2":{"294":1}}],["早期的",{"2":{"189":1}}],["收集",{"2":{"806":1}}],["收集指标",{"2":{"389":1}}],["收单词转移分数",{"2":{"632":1}}],["收敛趋势对比图",{"0":{"301":1}}],["收敛速度也相当快",{"2":{"292":1}}],["收敛过程对比",{"0":{"292":1}}],["收到这两个函数的影响",{"2":{"126":1}}],["γv​t+1​​+∇l",{"2":{"416":1}}],["γvt+1+∇l",{"2":{"416":1}}],["γ",{"2":{"284":1}}],["已不使用",{"2":{"907":1}}],["已删",{"2":{"868":1}}],["已在siggraph",{"2":{"859":1}}],["已知条件",{"2":{"840":1}}],["已有能运行且得到不错结果的训练工作流",{"2":{"364":1}}],["已选择并实现适当的评估指标",{"2":{"354":1}}],["已被证明是一种有效且实用的深度神经网络优化算法",{"2":{"282":1}}],["已经很不错了",{"2":{"878":1}}],["已经天然的具备了",{"2":{"723":1}}],["已经从事计算机行业的管理人士或者技术人员",{"2":{"696":1}}],["已经具有一些计算机知识和技能非计算机专业人士",{"2":{"696":1}}],["已经完成了梯度清0",{"2":{"456":1}}],["已经将学习率针对该步数进行了调整",{"2":{"363":1}}],["已经有一个工作流设置用来进行训练和评估",{"2":{"354":1}}],["已经有很多尝试将多个逐元素操作融合在一起",{"2":{"223":1,"312":1}}],["已经被很多目前最为领先的模型所采用",{"2":{"126":1}}],["η​max​​−η​min​​",{"2":{"545":1,"546":1}}],["η​t​​=η​min​​+​2​​1​​",{"2":{"545":1,"546":1}}],["ηmax−ηmin",{"2":{"545":1,"546":1}}],["ηt=ηmin+12",{"2":{"545":1,"546":1}}],["η",{"2":{"280":1,"284":1}}],["起始梯度",{"2":{"280":1}}],["仍依赖于人工设置一个全局学习率",{"2":{"280":1}}],["净效果是在参数空间中更为平缓的倾斜方向会取得更大的进步",{"2":{"277":1}}],["独立地适应所有模型参数的学习率",{"2":{"277":1}}],["独立同分布",{"2":{"245":2}}],["利用",{"2":{"329":1,"366":1}}],["利用最新的oss和cudnn快闪注意力内核",{"2":{"328":1}}],["利用数据移动和张量核心的异步执行",{"2":{"325":1}}],["利用低秩kv联合压缩来消除推理时kvcache的瓶颈",{"2":{"308":1}}],["利用当前位置处先前的梯度值先做一个参数更新",{"2":{"269":1}}],["利用encoder所有隐藏层状态",{"2":{"174":1}}],["旨在通过逐步做出局部最优选择来寻找全局最优解",{"2":{"969":1}}],["旨在按照https",{"2":{"402":1}}],["旨在最大限度地洞察调优问题",{"2":{"401":1}}],["旨在降低通信成本",{"2":{"327":1}}],["旨在应用于凸问题时快速收敛",{"2":{"283":1}}],["旨在加速学习",{"2":{"263":1}}],["旨在希望可以找到一个最优的激活函数",{"2":{"127":1}}],["小孩胃口数组",{"2":{"956":1}}],["小时的任务",{"2":{"943":3}}],["小时可用",{"2":{"943":1}}],["小时",{"2":{"943":4}}],["小角处有点磕碰",{"2":{"875":1}}],["小更新",{"0":{"868":1,"871":1,"874":1}}],["小结",{"2":{"733":1}}],["小明",{"2":{"730":1}}],["小心让日子把你们给混了",{"2":{"880":1}}],["小心将来日子混了你",{"2":{"880":1}}],["小心",{"0":{"455":1}}],["小但一致的梯度",{"2":{"263":1}}],["小批量梯度下降",{"2":{"262":1}}],["小于16时",{"2":{"86":1}}],["稳定性",{"2":{"260":1}}],["控制流",{"2":{"708":1}}],["控制流语句的原因",{"2":{"471":1}}],["控制符",{"2":{"620":1}}],["控制forward的调度",{"2":{"496":1}}],["控制梯度计算",{"0":{"453":1}}],["控制参数更新的步长",{"2":{"258":1}}],["控制了候选结果的数量",{"2":{"186":1}}],["α是学习率",{"2":{"258":1}}],["α",{"2":{"258":1,"264":1}}],["α≈1",{"2":{"125":2}}],["优先考虑胃口最小的小孩",{"2":{"955":1}}],["优先完成最紧急的任务",{"0":{"940":1},"1":{"941":1,"942":1,"943":1}}],["优化时间",{"2":{"928":1}}],["优化较好",{"2":{"848":1}}],["优化dda算法",{"2":{"843":1}}],["优化方向",{"0":{"842":1}}],["优化用于intel架构",{"2":{"802":1}}],["优化目标不再是noise",{"2":{"608":1}}],["优化",{"2":{"370":1}}],["优化掉",{"2":{"370":1,"376":1}}],["优化输入管道",{"0":{"387":1},"2":{"351":1}}],["优化thread",{"2":{"324":1}}],["优化attention部分thread",{"2":{"324":1}}],["优化算法",{"0":{"275":1,"282":1},"1":{"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"283":1,"284":1,"285":1},"2":{"384":1}}],["优化器还支持指定每个参数的选项",{"2":{"504":1}}],["优化器及学习率配置",{"2":{"497":1}}],["优化器选择",{"2":{"484":1}}],["优化器的状态",{"2":{"508":1}}],["优化器的选择通常是一个目标超参数或固定超参数",{"2":{"369":1}}],["优化器的目标是通过调整模型的参数",{"2":{"256":1}}],["优化器超参数",{"2":{"363":1,"384":1}}],["优化器",{"0":{"293":1},"2":{"356":1}}],["优化器使用梯度下降等迭代方法来更新模型的参数",{"2":{"256":1}}],["优势2",{"0":{"335":1}}],["优势1",{"0":{"334":1}}],["优势",{"2":{"122":1,"812":1}}],["概率和统计",{"2":{"857":1}}],["概率响应曲面模型拥有它自己的真实超参数",{"2":{"411":1}}],["概率",{"2":{"345":1}}],["概率或1",{"2":{"345":1}}],["概述",{"0":{"256":1,"287":1,"616":1}}],["概念",{"0":{"51":1,"969":1},"2":{"122":1,"123":1,"220":1,"306":1,"723":1}}],["概念理解",{"0":{"23":1},"1":{"24":1,"25":1}}],["迁移重构",{"2":{"862":1}}],["迁移到了google",{"2":{"721":1}}],["迁移到其他的神经网络中",{"2":{"254":1}}],["迁移",{"2":{"254":1,"617":1}}],["迁移学习",{"0":{"617":1},"2":{"254":1}}],["考虑局部",{"2":{"974":1}}],["考虑单边即可",{"2":{"626":1}}],["考虑",{"2":{"473":1}}],["考虑batch",{"2":{"445":1}}],["考虑进行一次性离线预处理并保存",{"2":{"387":1}}],["考虑运行最佳试验n次",{"2":{"378":1}}],["考虑是否上线新的最佳配置",{"2":{"365":1}}],["考虑反向传方差相等时公式",{"2":{"251":1,"252":1}}],["考虑前向传播方差相等时公式",{"2":{"251":1,"252":1}}],["考虑两种语言之间的各种对齐方式",{"2":{"190":1}}],["凯明初始化总结",{"0":{"250":1},"1":{"251":1,"252":1}}],["附近是对称的",{"2":{"249":1}}],["附录",{"0":{"115":1}}],["涉及到反向传播",{"2":{"249":1}}],["偏移",{"2":{"444":1}}],["偏移通过输入特征卷积得到",{"2":{"63":1}}],["偏置初始化为",{"2":{"248":1}}],["≠0",{"2":{"248":1}}],["≠0e",{"2":{"248":1}}],["求泛函极值的方法称为变分法",{"2":{"659":1}}],["求导操作针对整个反向图来进行",{"2":{"465":1}}],["求梯度",{"2":{"454":1}}],["求解线性最小二乘问题",{"2":{"441":1}}],["求解过程",{"2":{"34":1}}],["求得的",{"2":{"249":1}}],["求方差的时候用到",{"2":{"248":1}}],["√​​​n​i​​​^​​​​6​​​​​",{"2":{"252":1}}],["√​​n​i​​​​6​​​​​",{"2":{"252":1}}],["√​​n​in​​+n​out​​​​2​​​​​",{"2":{"245":1}}],["√​​π​​2​​​​​",{"2":{"126":1}}],["均对应着一个标签",{"2":{"627":1}}],["均为线性链表示的随机变量序列",{"2":{"626":1}}],["均为独立同分布的",{"2":{"245":1}}],["均匀分布",{"2":{"252":1}}],["均值都是0",{"2":{"249":1}}],["均值分布",{"2":{"130":1}}],["均值的问题",{"2":{"121":1}}],["均值",{"2":{"121":1}}],["均值为零",{"2":{"120":1}}],["塞维尔初始化",{"0":{"245":1}}],["∀i",{"2":{"245":4}}],["∀",{"2":{"244":4}}],["说",{"2":{"878":1}}],["说到这里",{"2":{"878":1}}],["说实话",{"2":{"878":2}}],["说白了就是用来操作数据库存在的",{"2":{"723":1}}],["说的更通俗点就算",{"2":{"244":1}}],["说明是",{"2":{"508":1}}],["说明当前状态下的模型参数需要更大的更新量才能更好的逼近最优解",{"2":{"405":1}}],["说明我们最佳的学习率比较临界",{"2":{"405":1}}],["说明",{"2":{"217":1,"303":1,"840":2}}],["条件语句",{"2":{"706":1}}],["条件语言模型意味着decoder",{"2":{"180":1}}],["条件语言模型可以使用一些预训练好的语言模型来对decoder的参数进行初始化",{"2":{"176":1}}],["条件分支和循环等情况",{"2":{"559":1}}],["条件超参数可能会是一个问题",{"2":{"370":1}}],["条件推导如下",{"2":{"245":1}}],["条件论文链接",{"2":{"244":1}}],["条件",{"0":{"244":1},"2":{"620":1}}],["处的变分或函数的变分被定义为它们之差",{"2":{"659":1}}],["处",{"2":{"240":1,"473":1}}],["处理请求异常",{"2":{"799":1}}],["处理请求与响应",{"2":{"710":1}}],["处理消息",{"2":{"796":2}}],["处理同一任务的不同部分",{"2":{"796":1}}],["处理",{"2":{"644":1}}],["处理商业问题的机器学习工程师很少有时间回顾并概括他们的调参过程",{"2":{"353":1}}],["处理它",{"2":{"338":1}}],["处理人机对话",{"2":{"188":1}}],["处理以产生神经元的输出",{"2":{"8":1}}],["±1",{"2":{"240":1}}],["几何图元",{"2":{"857":1}}],["几种模式简介",{"0":{"561":1},"1":{"562":1,"563":1,"564":1,"565":1}}],["几种模式概览",{"0":{"557":1},"1":{"558":1,"559":1,"560":1}}],["几种normalization",{"2":{"85":1}}],["几乎将测得的tflops",{"2":{"325":1}}],["几乎很快就找到了正确的方向并前进",{"2":{"292":1}}],["几乎所有的值集中在",{"2":{"240":1}}],["几乎所有的输出激活值都很接近0",{"2":{"239":1}}],["较小的batch",{"2":{"412":1}}],["较小随机值时",{"0":{"239":1}}],["较长的预热时间可以纠正梯度截断无法纠正的不稳定性",{"2":{"410":1}}],["较大的batch",{"2":{"412":1}}],["较大的模型相对较少受到注意力的内存带宽开销的影响",{"2":{"219":1,"305":1}}],["较大随机初始值时",{"0":{"240":1}}],["过日子就是问题叠着问题",{"2":{"880":1}}],["过了几年我又是另一种理解",{"2":{"878":1}}],["过小的验证集",{"2":{"375":1}}],["过小的权值初始值",{"2":{"236":1}}],["过短",{"2":{"328":1}}],["过程中发生了什么",{"2":{"437":1}}],["过程才结束吗",{"2":{"186":1}}],["过程如下图所示",{"2":{"178":1}}],["过程为",{"2":{"172":1}}],["过程",{"0":{"64":1}}],["糟糕的初始化方案不仅会影响网络收敛",{"2":{"235":1}}],["理所应当的算法",{"2":{"972":1}}],["理解算法本身或许会对当下的我们有一定的启发",{"2":{"927":1}}],["理解完这三句之后",{"2":{"878":1}}],["理解这里的",{"2":{"878":1}}],["理解和掌握图形学技术可以打开许多职业发展的机会",{"2":{"858":1}}],["理解gpu如何进行图形加速",{"2":{"857":1}}],["理解动态图和静态图",{"0":{"559":1}}],["理想情况下",{"2":{"356":1,"390":1}}],["理想的截断阈值要刚好高于",{"2":{"410":1}}],["理想的训练的step数也会发生变化",{"2":{"381":1}}],["理想的部署将预填节点组织成两组",{"2":{"329":1}}],["理想的参数初始化",{"0":{"242":1},"1":{"243":1,"244":1}}],["理想的网络参数初始化使模型训练事半功倍",{"2":{"235":1}}],["理论与实践的结合",{"2":{"858":1}}],["理论推导vae",{"0":{"658":1},"1":{"659":1}}],["理论基础",{"0":{"283":1}}],["理论上任意的batch",{"2":{"357":1}}],["理论上",{"2":{"145":1}}],["理论和实践都反复证明",{"2":{"14":1}}],["恰当的权重初始化是非常重要的",{"2":{"235":1}}],["根目录",{"2":{"738":1}}],["根本不知道生成模型生成了什么东西",{"2":{"656":1}}],["根本就存不进缓存",{"2":{"230":1,"330":1}}],["根节点被拆分",{"2":{"338":1}}],["根据不同情况",{"2":{"970":1}}],["根据不同任务的需要",{"2":{"15":1}}],["根据我们的正常思维",{"2":{"932":1}}],["根据我们的经验",{"2":{"401":1}}],["根据更改修正主页index内容",{"2":{"873":1}}],["根据公式迭代得到的",{"2":{"840":1}}],["根据已知的起点坐标",{"2":{"839":1}}],["根据id删除用户",{"2":{"733":1}}],["根据id删除一个用户",{"2":{"733":1}}],["根据id查询用户",{"2":{"730":2}}],["根据贝叶斯公式",{"2":{"659":1}}],["根据分析和推断的结果",{"2":{"563":1}}],["根据输入和操作的语义来确定操作的数据类型",{"2":{"563":1}}],["根据",{"2":{"544":1,"730":1}}],["根据循环学习率策略",{"2":{"543":1}}],["根据param",{"2":{"509":1}}],["根据这个定义",{"2":{"475":1}}],["根据loss相对于给定参数的梯度来调整parameters",{"2":{"463":1}}],["根据lm和tm寻找最佳y的过程",{"2":{"190":1}}],["根据需要重新分配内存",{"2":{"441":1}}],["根据梯度范数的第90百分位数选择梯度截断阈值",{"2":{"410":1}}],["根据问题的不同",{"2":{"389":1}}],["根据上述问题的答案",{"2":{"372":1}}],["根据实验目标",{"2":{"368":1}}],["根据团队的资源预算计费",{"2":{"360":1}}],["根据以上的猜测",{"2":{"348":1}}],["根据平方梯度的整个历史收缩学习率",{"2":{"283":1}}],["根据两个随机变量积的方差公式可得",{"2":{"248":1}}],["根据过个随机变量和的方差推导公式为",{"2":{"248":1}}],["根据链式法则",{"2":{"239":1}}],["根据z",{"2":{"194":1}}],["根据调整后的结果来选择best",{"2":{"186":1}}],["根据总分还是平均分",{"2":{"186":1}}],["写权限",{"2":{"745":1}}],["写入内容",{"2":{"743":1}}],["写时复制机制",{"2":{"335":1}}],["写出到",{"2":{"226":1}}],["写成矩阵形式参考dot",{"2":{"211":1}}],["写成矩阵形式",{"2":{"205":1}}],["写成矩阵的形式",{"0":{"205":1}}],["内积结果有衰减趋势的出现",{"2":{"648":1}}],["内积满足线性叠加性",{"2":{"647":1}}],["内部使用",{"2":{"496":1}}],["内外层循环和flashattention1",{"2":{"323":1}}],["内存的价格要高2~3个数量级",{"2":{"722":1}}],["内存过于昂贵",{"2":{"722":1}}],["内存断电后数据会丢失",{"2":{"722":1}}],["内存消耗和数据传输",{"2":{"560":1}}],["内存优化等",{"2":{"560":1}}],["内存很快就会被kv",{"2":{"338":1}}],["内存共享",{"0":{"335":1}}],["内存浪费仅发生在序列的最后一个块中",{"2":{"334":1}}],["内存需求与序列长度𝑁成线性关系",{"2":{"316":1}}],["内存效率",{"2":{"262":1}}],["内存占用和序列长度呈线性关系",{"2":{"227":1,"317":1}}],["内存开销",{"2":{"227":1,"317":1}}],["内存循环遍历q",{"2":{"226":1}}],["内核",{"2":{"60":1}}],["≤",{"2":{"226":4,"445":1}}],["设当前点为",{"2":{"840":1}}],["设",{"2":{"626":1}}],["设备上",{"2":{"496":1}}],["设定为warmup",{"2":{"409":1}}],["设计模式",{"2":{"717":1}}],["设计",{"2":{"717":1}}],["设计并展开实验",{"2":{"365":1}}],["设计下一轮实验",{"0":{"368":1},"1":{"369":1,"370":1,"371":1},"2":{"351":1}}],["设计了mla",{"2":{"308":1}}],["设计训练模型即可",{"2":{"191":1}}],["设置tab为4个空格",{"2":{"792":1}}],["设置缩进宽度为4",{"2":{"792":1}}],["设置自动缩进",{"2":{"792":1}}],["设置密码",{"2":{"763":1}}],["设置我们input",{"2":{"570":1}}],["设置我们是否需要求这个tensor的梯度",{"2":{"464":1}}],["设置每个参数组的学习率",{"2":{"543":1}}],["设置成train",{"2":{"497":1}}],["设置为0",{"2":{"634":1}}],["设置为",{"2":{"496":2,"544":1}}],["设置为none的参数和缓冲区不包括在内",{"2":{"496":1}}],["设置额外状态",{"2":{"496":1}}],["设置机制",{"0":{"492":1}}],["设置管道以跟踪到目前为止在训练期间看到的",{"2":{"392":1}}],["设置定期评估",{"0":{"390":1}}],["设置实验跟踪",{"0":{"393":1},"2":{"351":1}}],["设置中",{"2":{"338":1}}],["设置过大的话",{"2":{"280":1}}],["设置",{"0":{"475":1},"2":{"226":1,"475":1,"497":1}}],["尺寸为大小为",{"2":{"226":1,"315":1}}],["芯片上",{"2":{"226":1,"315":1}}],["𝑁^2",{"2":{"228":1,"318":1}}],["𝑂",{"2":{"228":1,"318":1}}],["𝑑2",{"2":{"227":1,"317":1}}],["𝑀",{"2":{"227":1,"317":1}}],["𝑚",{"2":{"226":1,"228":1,"315":1,"318":1}}],["𝑥",{"2":{"225":1,"226":2,"313":1,"315":2}}],["𝑥^",{"2":{"225":4,"313":4}}],["𝑥∈",{"2":{"225":1,"313":1}}],["ℓ",{"2":{"225":8,"226":9,"228":1,"313":8,"315":1,"318":1}}],["准备",{"0":{"225":1,"313":1}}],["划分为块",{"2":{"224":1,"311":1}}],["访问原则",{"0":{"684":1}}],["访问量",{"2":{"224":1,"311":1}}],["访问的二次方增长",{"2":{"223":1,"312":1}}],["存钱买房",{"2":{"922":1}}],["存储线程的列表",{"2":{"799":1}}],["存储完整的爬取内容",{"2":{"799":1}}],["存储不同group",{"2":{"508":1}}],["存储",{"2":{"508":7}}],["存储优化器的全局超参数",{"2":{"508":1}}],["存储子模块",{"2":{"490":1}}],["存储模块中的非持久性缓冲区",{"2":{"490":1}}],["存储当前variable实例的梯度",{"2":{"468":1}}],["存储我们反向函数的地方",{"2":{"462":1}}],["存储的数据类型",{"2":{"441":1}}],["存储在",{"2":{"224":1,"311":1}}],["存在着临界资源",{"2":{"681":1}}],["存在两个主要原因限制了in",{"2":{"481":1}}],["存在",{"2":{"371":1}}],["存在的短期记忆问题",{"2":{"143":1}}],["存在的问题",{"0":{"143":1}}],["存在一定的稀疏性",{"2":{"130":1}}],["存在有限个点处不可微",{"2":{"120":1}}],["存在分支",{"2":{"28":1}}],["方向的差值更大",{"2":{"840":2}}],["方便地在一段代码或函数中禁用梯度",{"2":{"478":1}}],["方式二",{"2":{"571":1}}],["方式一",{"2":{"571":1}}],["方式2",{"2":{"457":1,"505":1,"529":1}}],["方式1",{"2":{"457":1,"505":1,"529":1}}],["方案很重要并且调整它很重要",{"2":{"397":1}}],["方差计算数学基础",{"0":{"247":1}}],["方面进行",{"2":{"223":1,"312":1}}],["方法二",{"2":{"726":1}}],["方法一",{"2":{"726":1}}],["方法中的后置钩子函数",{"2":{"508":1}}],["方法中的前置钩子函数",{"2":{"508":1}}],["方法中的",{"2":{"508":1}}],["方法中只会保留一个单独的key",{"2":{"220":1,"306":1}}],["方法会被编译",{"2":{"496":1}}],["方法与几种类似机制之间的比较",{"2":{"496":1}}],["方法内部调用",{"2":{"496":1}}],["方法全解",{"0":{"496":1}}],["方法是查找以",{"2":{"472":1}}],["方法应用这些函数对象来计算图的求值结果",{"2":{"471":1}}],["方法来获取其字符串表示",{"2":{"509":1}}],["方法来获取对象的字符串表示",{"2":{"441":1}}],["方法来访问",{"2":{"468":1}}],["方法调用",{"2":{"443":1,"509":1}}],["方法汇总",{"0":{"441":1,"442":1},"1":{"443":1,"444":1,"445":1}}],["方法",{"0":{"432":1,"509":1},"1":{"433":1,"434":1},"2":{"496":1,"505":1,"508":3,"543":1,"544":1,"616":1,"708":1}}],["方法简介",{"0":{"190":1}}],["∈rbr×bc",{"2":{"226":1}}],["∈rbrm",{"2":{"226":1}}],["∈r​b​r​​×b​c​​​​",{"2":{"226":1}}],["∈r​b​r​​​​",{"2":{"226":1}}],["∈r​n×n​​",{"2":{"223":1,"312":1}}],["∈rn×n",{"2":{"223":1,"312":1}}],["∈",{"2":{"223":2,"224":2,"225":2,"228":1,"309":3,"311":2,"312":2,"313":2,"318":1}}],["蓝色表示在当前时间点访问的缓存节点",{"2":{"338":1}}],["蓝色框表示可共享的提示部分",{"2":{"337":1}}],["蓝色箭头",{"2":{"222":1,"314":1}}],["蓝点是某一时刻的输出向量",{"2":{"172":1}}],["红色表示已被淘汰的节点",{"2":{"338":1}}],["红色箭头",{"2":{"222":1,"314":1}}],["红点是embdding",{"2":{"172":1}}],["尽可能早地在管道中删除不必要的特征和元数据",{"2":{"387":1}}],["尽可能考虑新点和baseline的再训练方差",{"2":{"378":1}}],["尽可能密集地对冗余超参数采样",{"2":{"371":1}}],["尽可能多地比较目标超参数的值可以拓宽我们从实验中获得的经验的范围",{"2":{"371":1}}],["尽量都写上",{"2":{"733":1}}],["尽量去近似",{"2":{"659":1}}],["尽量重用有效的模型",{"2":{"355":1}}],["尽量减少warp间的通讯和读取shared",{"2":{"324":1}}],["尽量保持梯度的大小和方向保持一致",{"2":{"120":1}}],["尽管",{"2":{"619":1}}],["尽管如此",{"2":{"480":1,"878":2}}],["尽管每个张量都有这个标志",{"2":{"475":1}}],["尽管可能会造成混淆",{"2":{"411":1}}],["尽管在更高的维度中不行",{"2":{"402":1}}],["尽管在人为判断生成的衰减方案时这几乎不可能",{"2":{"399":1}}],["尽管这会让我们更难解释我们的调优结果",{"2":{"401":1}}],["尽管这是可能的",{"2":{"329":1}}],["尽管它包含相同优秀的点",{"2":{"401":1}}],["尽管它可能很糟糕",{"2":{"363":1}}],["尽管上面的例子的是一个很好的起点",{"2":{"377":1}}],["尽管不完全相同",{"2":{"369":1}}],["尽管不同应用场景的开发流程有所不同",{"2":{"364":1}}],["尽管当资源有限或有强力的证据表明它们不影响目标超参数时",{"2":{"369":1}}],["尽管超参数的类型取决于实验目标",{"2":{"369":1}}],["尽管有些人认为我们会花大部分时间来提升验证集的指标",{"2":{"366":1}}],["尽管从概念上讲",{"2":{"316":1}}],["尽管学习率有时需要从建议的默认修改",{"2":{"294":1}}],["尽管bgd可能收敛到全局最优解",{"2":{"260":1}}],["尽管由于重新计算而增加了浮点运算量",{"2":{"222":1,"314":1}}],["针对性能",{"2":{"510":1}}],["针对大型模型的标准分片将单个键头和值头复制了模型分区的数量",{"2":{"219":1,"305":1}}],["针对特定简单任务的时候人工提取特征会简单有效",{"2":{"19":1}}],["越来越焦虑😥",{"2":{"942":1}}],["越来越长时间的实验逐渐降低了它不可用的风险",{"2":{"385":1}}],["越往上走你越会发现搞那些底层和顶层的人是多门的伟大",{"2":{"700":1}}],["越低越好",{"2":{"373":1}}],["越长",{"2":{"326":1}}],["越大越好",{"2":{"217":1,"303":1}}],["越小越好",{"2":{"217":1,"303":1}}],["越高越好",{"2":{"185":1}}],["推荐使用parallels",{"2":{"909":1}}],["推荐原因4",{"0":{"700":1}}],["推荐原因3",{"0":{"699":1}}],["推荐原因2",{"0":{"698":1}}],["推荐原因1",{"0":{"697":1}}],["推荐须知",{"2":{"696":1}}],["推荐通过下述方式来实现",{"2":{"648":1}}],["推理流程图",{"0":{"596":1}}],["推理速度上生成一个",{"2":{"217":1,"303":1}}],["推断出来",{"2":{"544":1}}],["推断模式下的计算不会被记录在反向图中",{"2":{"479":1}}],["推断模式是无梯度模式的极端版本",{"2":{"479":1}}],["推断模式",{"0":{"479":1}}],["推测",{"2":{"385":1}}],["推迟其的增加可能更好",{"2":{"360":1}}],["推导过程详解",{"0":{"201":1},"1":{"202":1,"203":1,"204":1,"205":1}}],["推导过程非常复杂",{"2":{"190":1}}],["吗",{"2":{"216":1}}],["指南",{"0":{"864":1}}],["指定环境变量",{"2":{"613":1}}],["指定应该进行优化的张量",{"2":{"507":1}}],["指的是什么",{"2":{"503":1}}],["指的主要的是",{"2":{"117":1}}],["指示是否应该将键分配给其在state",{"2":{"496":1}}],["指示有多少个正在运行的请求正在使用它",{"2":{"338":1}}],["指数位",{"2":{"433":2}}],["指数加权",{"2":{"294":1}}],["指出",{"2":{"401":1}}],["指模型在生产环境中运行的时间",{"2":{"383":1}}],["指哪些位置呢",{"2":{"215":1}}],["仅主机模式",{"2":{"910":1}}],["仅使用于个人的专英课堂翻转",{"2":{"890":1}}],["仅使用两个阶段可以获得更好的结果",{"2":{"544":1}}],["仅使用约",{"2":{"394":1}}],["仅仅是训练统计数据的线性组合",{"2":{"394":1}}],["仅仅是近似计算对应的平均值",{"2":{"287":1}}],["仅针对目标超参数的某些值存在的超参数称为条件超参数",{"2":{"369":1}}],["仅浪费不到4",{"2":{"334":1}}],["仅在必要时将请求分发到sp组",{"2":{"329":1}}],["仅与source",{"2":{"213":1}}],["仅基于attention机制并完全避免循环",{"2":{"193":1}}],["位置的",{"2":{"648":1}}],["位置都计算对应的旋转位置编码",{"2":{"648":1}}],["位置编码的方案",{"2":{"648":1}}],["位置编码的加入是必不可少的",{"2":{"638":1}}],["位置编码是加性的",{"2":{"648":1}}],["位置编码是在原",{"2":{"640":1}}],["位置编码有点相似",{"2":{"648":1}}],["位置编码",{"0":{"640":1}}],["位置",{"2":{"212":1,"644":7}}],["位置完全连接的前馈网络",{"2":{"196":1}}],["维基百科",{"2":{"694":2,"797":1}}],["维的图片编码为2维的高斯分布",{"2":{"655":1}}],["维的query",{"2":{"208":1}}],["维扩展到多维",{"0":{"647":1}}],["维度",{"2":{"647":1}}],["维度平面上的向量的几何性质",{"2":{"646":1}}],["维度扩展",{"2":{"634":1}}],["维度上的",{"2":{"319":1}}],["维中",{"2":{"402":1}}],["维护成本",{"2":{"360":1}}],["维护开销可以忽略不计",{"2":{"338":1}}],["维输出值",{"2":{"208":1}}],["维效果更好",{"2":{"208":1}}],["倍预算的随机搜索变得更加困难",{"2":{"401":1}}],["倍",{"2":{"206":1,"208":1,"541":1,"619":1,"620":1}}],["自己想想自己的生活哈哈哈",{"2":{"948":1}}],["自己吓唬自己吗",{"2":{"880":1}}],["自己提前查阅相关环境安装资料进行环境配置",{"2":{"794":1}}],["自变量是q的密度函数",{"2":{"659":1}}],["自带的",{"0":{"483":1},"1":{"484":1,"485":1}}],["自动ip分配的可以不用操作",{"0":{"915":1}}],["自动生成侧边栏",{"2":{"868":1}}],["自动生成这些标准化的工具",{"2":{"822":1}}],["自动格式化选中的代码块",{"2":{"793":1}}],["自动缩进",{"0":{"792":1},"2":{"792":1}}],["自动求导的缓冲区释放和重用使其非常高效",{"2":{"481":1}}],["自动微分同时执行请求的计算",{"2":{"471":1}}],["自动微分将这个图表示为一组函数对象",{"2":{"471":1}}],["自动微分在执行操作",{"2":{"471":1}}],["自动微分是一种反向自动微分系统",{"2":{"471":1}}],["自动微分如何编码历史记录",{"0":{"471":1}}],["自动微分机制",{"0":{"462":1,"470":1},"1":{"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1}}],["自动推导的",{"2":{"462":1}}],["自动转换到全精度",{"2":{"444":1}}],["自动化常用的绘图",{"0":{"377":1}}],["自定义异常",{"2":{"708":1}}],["自定义操作",{"2":{"495":1}}],["自定义的模型应该继承自基类",{"2":{"488":1}}],["自定义自己的反向传播函数",{"0":{"458":1}}],["自定义函数都可以",{"2":{"457":1}}],["自定义在反序列化过程中恢复对象状态的行为",{"2":{"441":1}}],["自定义对象在序列化和反序列化过程中的行为",{"2":{"441":1}}],["自定义对象在深拷贝",{"2":{"441":1}}],["自适应算法很难击败预算是其两倍的quasi",{"2":{"401":1}}],["自适应黑盒优化算法可能会因为一些不幸的早期试验而忽略了搜索空间的中间部分",{"2":{"401":1}}],["自适应学习率的概念",{"0":{"276":1}}],["自一致性中的问题",{"2":{"337":1}}],["自然会明了其中的真正用意",{"2":{"878":1}}],["自然会问有没有其他方法",{"2":{"276":1}}],["自然语言处理",{"2":{"160":1,"188":1}}],["自注意机制运算过程",{"0":{"204":1}}],["自注意的思想",{"0":{"203":1}}],["qm⊤kn=",{"2":{"647":1}}],["qmq",{"2":{"646":1}}],["qa",{"2":{"636":1}}],["qscheme",{"2":{"445":2}}],["qr",{"2":{"445":2}}],["qikj⊤=xiwqwk⊤xj⊤+xiwqwk⊤pj⊤+piwqwk⊤xj⊤+piwqwk⊤pj⊤q",{"2":{"644":1}}],["qikj⊤q",{"2":{"643":1,"644":1}}],["qi",{"2":{"326":1}}],["qk​t​​−l",{"2":{"323":1}}],["qk^",{"2":{"323":1}}],["qkt−l",{"2":{"323":1}}],["qktdk",{"2":{"200":1}}],["q​m​⊤​​k​n​​=",{"2":{"647":1}}],["q​m​​",{"2":{"646":1}}],["q​i​​k​j​⊤​​=x​i​​w​q​​w​k​⊤​​x​j​⊤​​+x​i​​w​q​​w​k​⊤​​p​j​⊤​​+p​i​​w​q​​w​k​⊤​​x​j​⊤​​+p​i​​w​q​​w​k​⊤​​p​j​⊤​​",{"2":{"644":1}}],["q​i​​k​j​⊤​​",{"2":{"643":1,"644":1}}],["q​i​​",{"2":{"326":1}}],["q​t​r​​​​",{"2":{"226":1}}],["q​1​​",{"2":{"226":1}}],["qtrq",{"2":{"226":1}}],["q1",{"2":{"226":1}}],["qw​i​q​​",{"2":{"209":1}}],["qwiq",{"2":{"209":1}}],["q",{"2":{"200":4,"205":1,"208":1,"209":6,"223":2,"224":2,"226":5,"309":1,"311":2,"312":2,"315":2,"327":1,"328":1,"445":9,"498":4,"500":4,"606":9,"643":1,"644":6,"646":1,"647":4,"659":6,"751":1,"777":2,"790":1}}],["quickly",{"2":{"497":1,"586":1,"896":1}}],["quantile",{"2":{"445":2}}],["quantized",{"2":{"445":1}}],["quasi",{"2":{"379":1,"401":4}}],["quad",{"2":{"223":2,"225":4,"312":2,"313":4}}],["queries",{"2":{"499":7}}],["query",{"0":{"217":1,"218":1,"303":1,"304":1},"1":{"219":1,"305":1},"2":{"215":3,"217":3,"220":1,"303":3,"306":1,"327":1,"498":3,"499":14,"500":3,"646":1,"648":3}}],["questions",{"2":{"337":1}}],["question",{"2":{"188":1,"636":3}}],["quot",{"2":{"9":6,"52":2,"122":2,"215":2,"225":2,"313":2,"338":28,"360":2,"369":12,"370":4,"375":6,"376":2,"380":4,"383":2,"384":2,"504":2,"544":4,"586":2,"628":8,"807":4,"870":2,"913":2}}],["缩进选定文本",{"2":{"792":1}}],["缩进",{"2":{"784":1}}],["缩放等基本变换",{"2":{"857":1}}],["缩放每个参数反比于其所有梯度历史平方值总和的平方根",{"2":{"277":1}}],["缩放版本的点积注意力",{"0":{"198":1},"1":{"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":1,"206":1}}],["缩写",{"2":{"51":1}}],["缩写为bp",{"2":{"25":1}}],["确实能带来一定的远程衰减性",{"2":{"648":1}}],["确实",{"2":{"411":1}}],["确实可以",{"2":{"186":1}}],["确认",{"2":{"390":1}}],["确定最大位移方向",{"2":{"845":1}}],["确定",{"2":{"443":1}}],["确定了目标和冗余超参数之后",{"2":{"370":1}}],["确定哪个优化器在给定的步数中产生最低的验证错误",{"2":{"369":1}}],["确定更深的模型是否会减少验证集错误",{"2":{"369":1}}],["确定无效的方向并将其删除",{"2":{"366":1}}],["确定验证集效果对哪些超参数最敏感",{"2":{"366":1}}],["确定此初始配置将需要一些手动配置的训练运行和反复试验",{"2":{"363":1}}],["确定可行的batch",{"0":{"358":1}}],["确定每次训练运行的步数",{"0":{"380":1},"1":{"381":1,"382":1,"383":1,"384":1,"385":1},"2":{"351":1}}],["确定是否采用此训练工作流更改或超参数配置",{"0":{"378":1},"2":{"351":1}}],["确保可以无密码登录",{"2":{"827":1}}],["确保使用最佳实践",{"2":{"406":1}}],["确保在运行评估或检查点之前",{"2":{"395":1}}],["确保采样集与完整数据集之间没有偏差",{"2":{"391":1}}],["确保定期作业使用的采样数据集的性能与整个离线评估集的性能相似",{"2":{"391":1}}],["确保填充的数据被正确地加权",{"2":{"390":1}}],["确保我们能从实验中获得足够多的经验",{"2":{"371":1}}],["确保任何改进都有据可循",{"2":{"365":1}}],["确保前缀正确插入树中",{"2":{"338":1}}],["确保对位置的预测",{"2":{"197":1}}],["完整的类名或者别名",{"2":{"730":1}}],["完成进程间的数据传输",{"2":{"822":1}}],["完成持久化工作的代码块",{"2":{"723":1}}],["完成前向传播后",{"2":{"471":1}}],["完美",{"2":{"382":1}}],["完美拟合训练集",{"2":{"381":1}}],["完美缩放适用于batch",{"2":{"359":1}}],["完全可以跳过代码部分",{"2":{"950":1}}],["完全可以跳跃",{"2":{"702":1}}],["完全两种不同的感受",{"2":{"875":1}}],["完全展开得到",{"2":{"644":1}}],["完全拟合",{"2":{"381":2}}],["完全重新计算时约为30",{"2":{"328":1}}],["完全连接的层",{"2":{"194":1}}],["完形填空问题等",{"2":{"162":1}}],["呈现一发不可收的迹象",{"2":{"193":1}}],["领域的",{"2":{"621":1}}],["领域出现了越来越多基于",{"2":{"616":1}}],["领域等其他领域",{"2":{"193":1}}],["领域有许多常见的任务",{"2":{"188":1}}],["各种证明和推导一定是必要的吗",{"2":{"972":1}}],["各类技术问题和踩坑",{"0":{"906":1}}],["各类计算机知识体系",{"2":{"833":1}}],["各行各业的分析等",{"2":{"863":1}}],["各个进程依次执行不同的步骤",{"2":{"811":1}}],["各个层对状态z的梯度的方差要保持一致",{"2":{"244":1}}],["各个层的激活的方差要保持一致",{"2":{"244":1}}],["各层激活值不为0",{"2":{"243":1}}],["各层激活值不会出现饱和现象",{"2":{"243":1}}],["各层输出近似正态分布",{"2":{"125":1}}],["各项nlp",{"2":{"193":1}}],["我的建议",{"2":{"950":1}}],["我的感悟",{"2":{"867":1,"868":1}}],["我可不想让你走开我的算法生活课",{"2":{"948":1}}],["我可以给自己基本定位为",{"2":{"878":1}}],["我尝试创建",{"2":{"889":1}}],["我使用createuser",{"2":{"889":1}}],["我都乐于分享",{"2":{"881":1}}],["我喜欢不焦虑的人",{"2":{"880":1}}],["我要回去找自己的枝枝蔓蔓了",{"2":{"880":1}}],["我要承担风险",{"2":{"875":1}}],["我依旧找到了我宝贵的东西",{"2":{"880":1}}],["我会在其中看到我自己的影子",{"2":{"880":1}}],["我希望如此",{"2":{"878":1}}],["我才能够慢慢理解吧",{"2":{"878":1}}],["我才慢慢觉知到其中的奥秘",{"2":{"878":1}}],["我自己暂时的确还没参悟出孔子这里的思想",{"2":{"878":1}}],["我自然明白老板用意",{"2":{"875":1}}],["我先说说目前的大概理解",{"2":{"878":1}}],["我还不能够完全理解清楚",{"2":{"878":1}}],["我还给我们计租老师推荐了",{"2":{"696":1}}],["我想说",{"0":{"972":1}}],["我想大家想到的并不是什么算法",{"2":{"967":1}}],["我想也并不是不生气",{"2":{"878":1}}],["我想表达的是教材解释成",{"2":{"878":1}}],["我想起一件事",{"2":{"878":1}}],["我这里不再详细赘述",{"2":{"959":1}}],["我这里更不能去解读",{"2":{"878":1}}],["我这里的这两点不是为了反驳教学上的理解",{"2":{"878":1}}],["我这个tensor",{"2":{"464":1}}],["我懂得",{"2":{"878":1}}],["我三四岁就开始上学了呢",{"2":{"878":1}}],["我以前看到这句话的时候心里想",{"2":{"878":1}}],["我并没有带太多情绪的地回复到",{"2":{"878":1}}],["我是否也是这样",{"2":{"878":1}}],["我认为一定要结合自己的日常真实生活",{"2":{"878":1}}],["我领悟这段话用了很久的时间",{"2":{"878":1}}],["我也不是什么君子",{"2":{"878":1}}],["我也不是很想说什么了",{"2":{"875":1}}],["我也无法真正书写出我的感悟",{"2":{"876":1}}],["我仅仅是根据个人认知和生活习得整理的",{"2":{"876":1}}],["我说还不如我们自己弄",{"2":{"875":1}}],["我能做什么准备",{"2":{"831":1}}],["我个人而言",{"2":{"878":1}}],["我个人的路径",{"2":{"831":1}}],["我个人觉得受众群体",{"2":{"696":1}}],["我觉得这是一种很高的境界",{"2":{"878":1}}],["我觉得没必要",{"2":{"878":1}}],["我觉得已经用言语精炼的表达了",{"2":{"878":1}}],["我觉得想理解孔子及其弟子想传达的思想",{"2":{"876":1}}],["我觉得主要就是",{"2":{"798":1}}],["我觉得学习计算机不能只会编程",{"2":{"700":1}}],["我应该使用哪种学习率衰减方案作为默认值",{"0":{"398":1}}],["我画了一个形象生动的图来示意smt和nmt的区别",{"2":{"191":1}}],["我们解决问题的时候会觉得这是本该如此的",{"2":{"975":1}}],["我们简单理解一下这个东西",{"2":{"973":1}}],["我们绘不自觉地优先选择价格最低或折扣最大的商品",{"2":{"967":1}}],["我们绘制了在",{"2":{"376":1}}],["我们每次都选最大的数字放在高位",{"2":{"934":1}}],["我们每次降低这个距离",{"2":{"659":1}}],["我们先从",{"2":{"933":1}}],["我们先去了小镇的的一家店",{"2":{"875":1}}],["我们渐渐步入到新的纪元",{"2":{"927":1}}],["我们经常需要想办法提高效率",{"2":{"926":1}}],["我们经过公式变换",{"2":{"190":1}}],["我们人生一旦领悟到要学",{"2":{"878":1}}],["我们学习的书本知识或许只是学习的很小很小的一部分",{"2":{"878":1}}],["我们一句一句来看",{"2":{"878":1}}],["我们一般使用delete标签进行删除操作",{"2":{"733":1}}],["我们一般使用update标签进行更新操作",{"2":{"732":1}}],["我们一般使用insert标签进行插入操作",{"2":{"731":1}}],["我们一般使用动态规划",{"2":{"190":1}}],["我们提问如果更换新的怎样",{"2":{"875":1}}],["我们提出对blockwise",{"2":{"327":1}}],["我们自己买来修",{"2":{"875":1}}],["我们自然会找到越来越好的配置",{"2":{"365":1}}],["我们尽量将parameter参数和resulttype都写上",{"2":{"733":1}}],["我们把这些程序的片段称作临界区或临界段",{"2":{"681":1}}],["我们把总的使用成本",{"2":{"360":1}}],["我们知道有一种距离可以量化两种分布的差异kullback",{"2":{"659":1}}],["我们称这种现象为过拟合",{"2":{"656":1}}],["我们称之为",{"2":{"401":1}}],["我们称之为上线",{"2":{"365":1}}],["我们初步展开",{"2":{"643":1}}],["我们再回忆下一般的带绝对位置编码的attention",{"2":{"643":1}}],["我们用一些简单的",{"2":{"929":1}}],["我们用转移分数表示一个标签向另一个标签转移的分数",{"2":{"628":1}}],["我们用tiny",{"2":{"584":1}}],["我们用tensorboard就行",{"2":{"572":1}}],["我们来看下李航老师在",{"2":{"626":1}}],["我们相当于将预训练模型已经获得的知识",{"2":{"617":1}}],["我们安装好了",{"2":{"573":1}}],["我们具体的实现过程",{"2":{"488":1}}],["我们拿不到input的梯度",{"2":{"487":1}}],["我们按照以下规则定义基本操作的梯度计算顺序",{"2":{"473":1}}],["我们按块计算注意力",{"2":{"225":1,"313":1}}],["我们欢迎听到来自您的反馈",{"2":{"422":1}}],["我们复用了最初由naman",{"2":{"420":1}}],["我们推荐其他人使用",{"2":{"411":1}}],["我们决定为该领域的一个混乱来源做出贡献",{"2":{"411":1}}],["我们认为这将",{"2":{"384":1}}],["我们期望在短运行中找到的哪些超参数值会转移到更长的训练运行中",{"2":{"384":1}}],["我们建议进行两轮调整",{"2":{"383":1}}],["我们建议坚持使用成熟",{"2":{"356":1}}],["我们能完成的实验就会越少",{"2":{"383":1}}],["我们并没有以精确或数学定义良好的方式使用短语",{"2":{"381":1}}],["我们并行执行attention函数",{"2":{"208":1}}],["我们愿意等待的时间",{"2":{"380":1}}],["我们甚至可以将验证集折叠到训练集中",{"2":{"379":1}}],["我们最关心的是学习方差",{"2":{"378":1}}],["我们最终获得了数据压缩的分布规律",{"2":{"654":1}}],["我们最终保存的是这个新的model",{"2":{"525":1}}],["我们最终得到了正确的结果",{"2":{"224":1,"311":1}}],["我们最终工程上使用的就是上式",{"2":{"52":1}}],["我们对模型的理解就会越深入",{"2":{"383":1}}],["我们对目标超参数的不同设置选取最佳试验效果的试验",{"2":{"375":1}}],["我们对以下问题感兴趣",{"2":{"375":1}}],["我们对每个子层再采用一个残差连接",{"2":{"196":1}}],["我们总是查看至少是最好的几项试验的训练曲线",{"2":{"375":1}}],["我们实际上需要在每个设备上对批次进行二次抽样",{"2":{"394":1}}],["我们实验的主要目标只需要考虑每次试验的验证误差",{"2":{"375":1}}],["我们实现了一个最近最少使用",{"2":{"337":1}}],["我们喜欢在被我们称之为基本超参数轴图的图表绘制已完成的试验",{"2":{"373":1}}],["我们是否应该在我们能接受的情况下一直训练",{"2":{"383":1}}],["我们是否从搜索空间中采样了足够多的点",{"2":{"372":1}}],["我们是一个由五名研究人员和工程师组成的团队",{"2":{"353":1}}],["我们只需对",{"2":{"975":1}}],["我们只需要选择一个值并将其用于所有试验",{"2":{"381":1}}],["我们只需要把",{"2":{"326":1}}],["我们只需要将因果掩码应用到1个块",{"2":{"322":1}}],["我们只需要通过求",{"2":{"190":1}}],["我们只是把最较大概率的部分框出来",{"2":{"655":1}}],["我们只能从其他要求中想办法节约资源",{"2":{"371":1}}],["我们都在运用",{"2":{"928":1}}],["我们都有过找钥匙",{"2":{"920":1}}],["我们都可以表示为二维情形的拼接",{"2":{"647":1}}],["我们都应该尝试找到一个尽可能接近我们任务的预训练模型",{"2":{"617":1}}],["我们都不会从头训练模型",{"2":{"617":1}}],["我们都系统地确保我们的选择仍然是正确的",{"2":{"385":1}}],["我们都会总结该研究是否将冗余超参数调整得足够好",{"2":{"371":1}}],["我们都会去对所有的可能输出",{"2":{"184":1}}],["我们都需要确保它均匀搜索目标超参数",{"2":{"370":1}}],["我们更愿意使用",{"2":{"411":1}}],["我们更加偏好使用quasi",{"2":{"370":1}}],["我们更偏向使用准随机算法",{"2":{"370":1}}],["我们想要通过样本x来估计关于z的分布",{"2":{"659":1}}],["我们想要获得数据经过压缩后满足什么规律",{"2":{"654":1}}],["我们想要评估实验为该目标提供的证据",{"2":{"372":1}}],["我们想要比较大量目标超参数的值",{"2":{"370":1}}],["我们想要计算注意力输出",{"2":{"223":1,"312":1}}],["我们没有选择顶不住的权利",{"2":{"880":1}}],["我们没有优化器超参数值的先验倾向",{"2":{"369":1}}],["我们没能充分针对每个目标超参数调优冗余超参数的风险就越高",{"2":{"369":1}}],["我们会优先完成那些耗时短",{"2":{"926":1}}],["我们会优先选择最先进的贝叶斯优化方法",{"2":{"370":1}}],["我们会把大目标分成多个小目标",{"2":{"922":1}}],["我们会慢慢领悟其中的道理的",{"2":{"878":1}}],["我们会默认选择",{"2":{"510":1}}],["我们会尝试默认选择当前设备上通常最快的实现方式",{"2":{"510":1}}],["我们会使用github提供的pull",{"2":{"424":1}}],["我们会定期进行大大小小的修改",{"2":{"422":1}}],["我们会根据之前实验的结果来动态调整采样策略这导致我们不能随意的更换目标",{"2":{"401":1}}],["我们会考虑以下因素",{"2":{"391":1}}],["我们会自动为所有试验生成训练曲线",{"2":{"377":1}}],["我们会为我们在实验中变化的所有超参数自动生成基本超参数轴图",{"2":{"377":1}}],["我们会设计一个",{"2":{"370":1}}],["我们会将",{"2":{"369":1}}],["我们会将所有非目标超参数保留为冗余超参数",{"2":{"369":1}}],["我们会有一个较大的幅度越过山谷",{"2":{"271":1}}],["我们根据实验目的确定目标超参数",{"2":{"369":1}}],["我们必须要让这些个椭圆尽可能的推叠在一起",{"2":{"656":1}}],["我们必须意识到",{"2":{"375":1}}],["我们必须分别调整学习率",{"2":{"369":1}}],["我们必须确保更改是有据可循的",{"2":{"365":1}}],["我们必须确定起点",{"2":{"363":1}}],["我们可能采取了一种不同的说法",{"2":{"411":1}}],["我们可能无法获得它们理论上能够提供的优势",{"2":{"401":1}}],["我们可能无法理清各自的影响",{"2":{"367":1}}],["我们可能能够回答很多问题",{"2":{"383":1}}],["我们可能能够减少训练步数",{"2":{"375":1}}],["我们可能可以在增加训练时间和重新调整学习率衰减策略中受益",{"2":{"381":1}}],["我们可能需要使用更新鲜的估计",{"2":{"378":1}}],["我们可能想要确定导致最佳验证误差的权重衰减值",{"2":{"376":1}}],["我们可能会觉得有些搞笑",{"2":{"878":1}}],["我们可能会运行少量的长时间",{"2":{"383":1}}],["我们可能会错误地得出结论",{"2":{"382":1}}],["我们可能会说",{"2":{"381":1}}],["我们可能会看到训练损失会一直在缓慢减小",{"2":{"381":1}}],["我们可能会在特定搜索空间运行相同的实验",{"2":{"378":1}}],["我们可能会观察到",{"2":{"378":1}}],["我们可能会受益于增加训练步数或更改学习率计划",{"2":{"375":1}}],["我们可能会找到更优秀的点",{"2":{"373":1}}],["我们可能会得出不正确的结论",{"2":{"372":1}}],["我们可能对不同目标超参数值进行了不公平的比较",{"2":{"371":1}}],["我们可能因为没有搜索某些冗余超参数空间",{"2":{"371":1}}],["我们可能出于各种原因将其设为固定超参数",{"2":{"369":1}}],["我们可能固定其中一些参数",{"2":{"369":1}}],["我们可能通过过去的实验发现最优激活函数和模型深度无关",{"2":{"369":1}}],["我们可以更有条理",{"2":{"928":1}}],["我们可以更快地找到最佳的模型和优化器超参数",{"2":{"383":1}}],["我们可以称这种思维方式为",{"2":{"923":1}}],["我们可以考虑直接使用map实现",{"2":{"730":1}}],["我们可以直接将它作为参数训练出来",{"2":{"644":1}}],["我们可以直接使用相应的结构和权重",{"2":{"254":1}}],["我们可以选择一个在大规模英文语料上预训练好的模型",{"2":{"617":1}}],["我们可以采用系统的方法来找出训练任务中存在的稳定性问题",{"2":{"405":1}}],["我们可以想做多少轮就做多少轮",{"2":{"383":1}}],["我们可以负担得起训练的时间",{"2":{"380":1}}],["我们可以只在工作流发生重大变化后重新对试验方差进行估计",{"2":{"378":1}}],["我们可以只在序列开始进行输入计算",{"2":{"164":1}}],["我们可以把它分解成几个小任务",{"2":{"924":1}}],["我们可以把可能导致这种不一致结果的最重要的变化来源分为以下几大类",{"2":{"378":1}}],["我们可以把前l−1层看作表示",{"2":{"13":1}}],["我们可以也添加许多其他有用的潜在图表和可视化",{"2":{"377":1}}],["我们可以从最佳试验的训练曲线中学到什么",{"2":{"372":1}}],["我们可以使用",{"2":{"405":1}}],["我们可以使用这个实现",{"2":{"402":1}}],["我们可以使用这些超参数来构建搜索空间",{"2":{"379":1}}],["我们可以使用任何无梯度优化算法",{"2":{"370":1}}],["我们可以使用算法自动搜索整个配置空间来最大化性能",{"2":{"365":1}}],["我们可以创建一个研究",{"2":{"370":1}}],["我们可以进行这种转换",{"2":{"369":1}}],["我们可以通过多种方式来评估模型的性能",{"2":{"389":1}}],["我们可以通过对基本超参数轴图的x轴值进行分桶",{"2":{"376":1}}],["我们可以通过手动指定一组超参数配置来创建研究",{"2":{"370":1}}],["我们可以通过增加计算资源来应对这种风险",{"2":{"369":1}}],["我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制",{"2":{"13":1}}],["我们可以集中提升验证集效果",{"2":{"366":1}}],["我们可以估计每步时间",{"2":{"358":1}}],["我们可以在项目开始时一次性做出决定",{"2":{"354":1}}],["我们可以在反向传播过程中从sram中的q",{"2":{"228":1,"318":1}}],["我们可以重用它们的共同祖先",{"2":{"338":1}}],["我们可以自动识别和利用键值缓存重用机会",{"2":{"337":1}}],["我们可以像操作系统的虚拟内存一样以更加灵活的方式管理键和值",{"2":{"334":1}}],["我们可以跳过对该块的计算",{"2":{"322":1}}],["我们可以一次处理一个块计算",{"2":{"226":1,"315":1}}],["我们可以将",{"2":{"510":1}}],["我们可以将目标超参数与冗余超参数放在相同的搜索空间中",{"2":{"370":1}}],["我们可以将目标转变为",{"2":{"190":1}}],["我们可以将资源消耗分解为以下几个部分",{"2":{"360":1}}],["我们可以将拼接后的向量",{"2":{"225":1,"313":1}}],["我们大部分时间都花在了",{"2":{"366":1}}],["我们才完全清楚在深度学习从业者的工作流程中可以找到多少有趣及被忽视的研究问题",{"2":{"353":1}}],["我们也可能引发错误",{"2":{"473":1}}],["我们也希望看到可能有不同建议的替代指南和方式",{"2":{"353":1}}],["我们也对查询执行低秩压缩",{"2":{"309":1}}],["我们鼓励发现我们的建议存在问题的读者提出替代建议以及令人信服的证据",{"2":{"353":1}}],["我们已经步入",{"0":{"948":1}}],["我们已经描述了如何从第一轮",{"2":{"385":1}}],["我们已经看到它大于试验方差的情况以及它小得多的情况",{"2":{"378":1}}],["我们已经将深度学习应用到从语音识别到天文学的方方面面",{"2":{"353":1}}],["我们已经发现",{"2":{"143":1}}],["我们找不到任何系统性的资料来解释如何使用深度学习获得良好的结果",{"2":{"353":1}}],["我们假设从业者已经确定了让模型变得不稳定的学习率",{"2":{"409":1}}],["我们假设机器学习问题是监督学习或类似的东西",{"2":{"352":1}}],["我们假定您具备机器学习和深度学习概念的基本知识",{"2":{"352":1}}],["我们拥有的数据量是很有限的",{"2":{"344":1}}],["我们淘汰",{"2":{"338":1}}],["我们让缓存的token和当前正在运行的请求共享同一个memory",{"2":{"338":1}}],["我们让每层输出方差相等",{"2":{"248":1}}],["我们不用区分得太清楚",{"2":{"644":1}}],["我们不再需要对每一个任务都从头开始训练模型",{"2":{"616":1}}],["我们不鼓励使用它们",{"2":{"481":1}}],["我们不应该仅仅因为两个条件超参数具有相同的名称就认为它们是相同的",{"2":{"369":1}}],["我们不能改变一个非叶子节点的",{"2":{"462":1}}],["我们不能指望找到它",{"2":{"353":1}}],["我们不能淘汰当前正在运行的批处理中使用的节点",{"2":{"338":1}}],["我们不知道最好的深度学习秘诀",{"2":{"353":1}}],["我们不预先分配一个固定大小的内存池作为缓存",{"2":{"338":1}}],["我们不需要为计算复制键头和值头",{"2":{"323":1}}],["我们不需要应用因果掩码",{"2":{"322":1}}],["我们引入了一个简单的",{"2":{"338":1}}],["我们引入了",{"2":{"337":1}}],["我们引入了pagedattention",{"2":{"333":1}}],["我们确定llm服务的性能受到内存的限制",{"2":{"333":1}}],["我们从sharegpt数据集中对请求的输入",{"2":{"332":1}}],["我们从每个当前输入对应的所有可能输出",{"2":{"184":1}}],["我们很高兴地介绍vllm",{"2":{"332":1}}],["我们逐块计算原始transformer",{"2":{"327":1}}],["我们利用内部循环key",{"2":{"327":1}}],["我们调整前向传递算法",{"2":{"325":1}}],["我们重新设计了flashattention",{"2":{"325":1}}],["我们定义了一种专门针对warp的软件流水线方案",{"2":{"325":1}}],["我们希望在完全切换之前给它们更多的时间来适应",{"2":{"510":1}}],["我们希望测量出其对于模型由何种影响的参数",{"2":{"369":1}}],["我们希望无限期地改进模型",{"2":{"365":1}}],["我们希望这项工作成为一份活的文件",{"2":{"353":1}}],["我们希望本文档能鼓励其他人也来帮助系统化该领域的实验细节",{"2":{"353":1}}],["我们希望",{"2":{"326":1}}],["我们希望尽可能多地花费时间在矩阵乘法flop上",{"2":{"320":1}}],["我们希望gqa在较大的模型中能够达到一个特别好的权衡",{"2":{"219":1,"305":1}}],["我们迁移了这些学来的特征",{"2":{"254":1}}],["我们记为",{"2":{"248":1}}],["我们发现参数更新是基于两部分组成",{"2":{"271":1}}],["我们发现",{"2":{"240":1,"333":1,"393":1}}],["我们发现这比选择单个键和值头或从头开始随机初始化新的键和值头效果更好",{"2":{"220":1,"306":1}}],["我们看到了博客文章和社交媒体上的建议片段",{"2":{"353":1}}],["我们看到输出值迅速向0靠拢",{"2":{"239":1}}],["我们看到decoder的每一步产生隐状态",{"2":{"181":1}}],["我们应该尽量使用快速转换时间的试验来获得尽可能多的问题理解",{"2":{"383":1}}],["我们应该检查研究中的最佳学习率是否在搜索空间的边界",{"2":{"382":1}}],["我们应该期望能够训练到非常低的训练误差",{"2":{"380":1}}],["我们应该看到较低的训练损失",{"2":{"380":1}}],["我们应该有一个精确的搜索空间",{"2":{"379":1}}],["我们应该只采用产生的改进超过它们增加的复杂性的更改",{"2":{"378":1}}],["我们应该至少在目标超参数的每个设置相对应的最佳试验中检查是否有过拟合问题",{"2":{"375":1}}],["我们应该尝试调整搜索空间以避免对这些点进行采样",{"2":{"372":1}}],["我们应该进行另一项具有扩展搜索空间的研究",{"2":{"372":1}}],["我们应该问自己以下额外的问题",{"2":{"372":1}}],["我们应该训练足够长的时间以准确估计训练吞吐量",{"2":{"358":1}}],["我们应该知道对于这种解码的过程",{"2":{"190":1}}],["我们应用了两种已经建立的技术",{"2":{"224":1,"311":1}}],["我们还要感谢",{"2":{"420":1}}],["我们还应该考虑检查测试集上的性能",{"2":{"379":1}}],["我们还希望借此机会从每组实验中提取其他有用的见解",{"2":{"372":1}}],["我们还将比较标准注意力和我们的方法",{"2":{"223":1,"312":1}}],["我们还修改解码器堆栈中的self",{"2":{"197":1}}],["我们在购物的时候",{"2":{"967":1}}],["我们在生活中做出很多决定时",{"2":{"925":1}}],["我们在做长期计划时",{"2":{"922":1}}],["我们在这里还是包括了它",{"2":{"480":1}}],["我们在这一节会对此进行进一步探讨",{"2":{"401":1}}],["我们在实践中使用的许多函数并不具备这个性质",{"2":{"473":1}}],["我们在反向传播中评估这个图",{"2":{"471":1}}],["我们在深度学习中调优的学习率和大部分其他被叫做",{"2":{"411":1}}],["我们在训练期间定期进行评估",{"2":{"390":1}}],["我们在定期评估时的目标是在训练期间获得可靠信号",{"2":{"389":1}}],["我们在使用相同的超参数但不同的随机种子的训练运行之间看到的差异",{"2":{"378":1}}],["我们在其中绘制验证目标值与其中一个超参数",{"2":{"373":1}}],["我们在每一轮调整中都使用自动搜索算法",{"2":{"365":1}}],["我们在每个子层再采用残差连接",{"2":{"197":1}}],["我们在两种设置下进行评估",{"2":{"332":1}}],["我们在第2",{"2":{"325":1}}],["我们在附录d",{"2":{"308":1}}],["我们在下述算法中描述了这一过程",{"2":{"224":1,"311":1}}],["我们在算法0中描述了标准的注意力实现",{"2":{"223":1,"312":1}}],["我们的日常生活中到处都有算法的影子",{"2":{"916":1}}],["我们的系统架构中",{"2":{"723":1}}],["我们的系统中",{"2":{"723":1}}],["我们的一些优化器甚至具有更快的fused实现方式",{"2":{"510":1}}],["我们的许多算法都有各种不同的实现方式",{"2":{"510":1}}],["我们的偏好是linear",{"2":{"398":1}}],["我们的训练时间越长",{"2":{"383":1}}],["我们的主要目标是确保我们训练的时间足够长",{"2":{"381":1}}],["我们的主要目标是通过有效地在多个主机之间分配长序列",{"2":{"327":1}}],["我们的探索工作应该已经揭示了最重要的要调整的超参数",{"2":{"379":1}}],["我们的优先事项将从学习更多优化经验转向产生一个最佳配置来启动或以其他方式使用",{"2":{"379":1}}],["我们的优化目标为",{"2":{"38":1}}],["我们的增量调优策略需要重复以下四个步骤",{"2":{"365":1}}],["我们的最终目标是找到一种训练配置来最大化我们模型的性能",{"2":{"365":1}}],["我们的指导原则是找到一个简单",{"2":{"363":1}}],["我们的在此文档中一些建议也将需要更新以考虑新的结果和改进的工作流程",{"2":{"353":1}}],["我们的重点是超参数调优的过程",{"2":{"352":1}}],["我们的重计算由于减少了hbm访问次数而加速了反向传播过程",{"2":{"228":1,"318":1}}],["我们的方法在完成生成请求后不会丢弃kv",{"2":{"337":1}}],["我们的工作不同之处在于利用块并行transformer大幅降低内存成本",{"2":{"327":1}}],["我们的目标之一是不在反向传播过程中存储",{"2":{"228":1,"318":1}}],["我们的目标是找到最少的",{"2":{"409":1}}],["我们的目标是更深入地理解问题",{"2":{"366":1}}],["我们的目标是在固定截止日期",{"2":{"365":1}}],["我们的目标是减少",{"2":{"224":1,"311":1}}],["我们的目标是计算注意力输出",{"2":{"224":1,"311":1}}],["我们的算法比标准注意力运行得更快",{"2":{"222":1,"314":1}}],["我们的解码输出应该只能依赖于",{"2":{"216":1}}],["我们要尽量减小kl散度",{"2":{"659":1}}],["我们要感谢will",{"2":{"420":1}}],["我们要感谢max",{"2":{"420":1}}],["我们要寻找w的分布使得输出y与输入z的方差保持一致",{"2":{"245":1}}],["我们要对输入序列进行对齐",{"2":{"215":1}}],["我们要找出最佳的翻译是什么",{"2":{"190":1}}],["我们缩小点积",{"2":{"206":1}}],["我们怀疑",{"2":{"206":1}}],["我们这里也暂时不做深入的研究",{"2":{"190":1}}],["我们有三个主要的实现类别",{"2":{"510":1}}],["我们有以下经验法则",{"2":{"369":1}}],["我们有了更好的方法",{"2":{"189":1}}],["我们有了更为先进复杂的机器翻译技术",{"2":{"189":1}}],["我们有输出门",{"2":{"150":1}}],["我们有输入门",{"2":{"148":1}}],["我们使用redix",{"2":{"338":1}}],["我们使用与原始transformer相同的模型架构",{"2":{"327":1}}],["我们使用块量化和不一致处理技术来减轻由于转换为fp8精度而导致的精度损失",{"2":{"325":1}}],["我们使用cuda实现了flashattention",{"2":{"222":1,"314":1}}],["我们使用如下的score函数来定义序列得分",{"2":{"185":1}}],["我们使用交叉熵作为损失函数",{"2":{"181":1}}],["我们需要优先把最大的数字放在高位",{"2":{"932":1}}],["我们需要比较得精细一些",{"2":{"644":1}}],["我们需要保存哪些内容以在之前基础上继续训练",{"2":{"521":1}}],["我们需要更多的研究",{"2":{"384":1}}],["我们需要理解导致我们结果中不同的变化的来源",{"2":{"378":1}}],["我们需要分配有限的预算",{"2":{"371":1}}],["我们需要对",{"2":{"409":1}}],["我们需要对隐式复制的不同头部之间的梯度dk和dv进行求和",{"2":{"323":1}}],["我们需要对已完成的n个序列做一个抉择",{"2":{"186":1}}],["我们需要设定一个候选集的大小beam",{"2":{"184":1}}],["我们需要等到",{"2":{"179":1}}],["我们需要同时计算出",{"2":{"27":1}}],["我们以机器翻译为例",{"2":{"172":1}}],["我们将ta理解成",{"2":{"878":1}}],["我们将原来",{"2":{"655":1}}],["我们将这种规律用概率的形式表示",{"2":{"654":1}}],["我们将这个安排添加到现有安排上",{"2":{"409":1}}],["我们将此称为",{"2":{"392":1}}],["我们将保存一些单个示例的预测",{"2":{"390":1}}],["我们将对目标超参数的每个配置进行单独研究",{"2":{"370":1}}],["我们将一些冗余超参数转作为固定超参数",{"2":{"369":1}}],["我们将所有其他超参数视为冗余超参数",{"2":{"369":1}}],["我们将正则化后的目标函数记为",{"2":{"343":1}}],["我们将vllm的吞吐量与huggingface",{"2":{"332":1}}],["我们将预填集群中的每",{"2":{"329":1}}],["我们将与softmax相关的比较低吞吐量的非gemm操作",{"2":{"325":1}}],["我们将输入",{"2":{"226":1,"315":1}}],["我们将输入门的输出与细胞状态进行逐元素相加",{"2":{"149":1}}],["我们将展示标准的注意力实现在序列长度",{"2":{"223":1,"312":1}}],["我们将整个过程表达为矩阵形式",{"2":{"205":1}}],["我们将",{"2":{"150":1}}],["我们将经过修改后的细胞状态传递到",{"2":{"150":1}}],["我们将前一个隐藏状态和当前输入传递到",{"2":{"148":1,"150":1}}],["我们就得到了一个较为标准的数据压缩形态",{"2":{"656":1}}],["我们就可以增加训练时间并继续调整",{"2":{"383":1}}],["我们就可以更有效地使用我们的资源来调整最有可能在生产环境中表现良好的模型",{"2":{"383":1}}],["我们就可以继续评估实验为我们最初的目标提供的证据",{"2":{"372":1}}],["我们就可以进行反向传播",{"2":{"28":1}}],["我们就说它是等变",{"2":{"54":1}}],["我们通常还会采用迁移学习",{"2":{"616":1}}],["我们通常希望根据任何训练点上达到的验证误差来找到最佳试验",{"2":{"401":1}}],["我们通常会认为以某种方式将超过",{"2":{"410":1}}],["我们通常会在比较目标超参数的不同值之前使用额外的正则化技术重新运行实验和",{"2":{"375":1}}],["我们通常会采样我们可以负担得起的代价",{"2":{"374":1}}],["我们通常会发现在一组给定的实验能够朝着最初的目标取得很大进展之前需要纠正的问题",{"2":{"372":1}}],["我们通常可以认为每步的时间近似恒定",{"2":{"359":1}}],["我们通常将",{"2":{"13":1}}],["我们通过显示在主机环中",{"2":{"327":1}}],["我们通过将所有主机概念化为形成一个环结构来利用这一属性",{"2":{"327":1}}],["我们通过对该组内所有原始头进行平均汇总来构建每个组的键头和值头",{"2":{"219":1,"305":1}}],["我们通过数学统计学的应用可以来做人工感知方面的决定问题",{"2":{"5":1}}],["企图就是用一个简洁的神经网络结构",{"2":{"191":1}}],["繁多的功能模块",{"2":{"190":1}}],["海量的专家知识",{"2":{"190":1}}],["明天再解决一部分",{"2":{"924":1}}],["明确提供",{"2":{"544":1}}],["明确地说",{"2":{"328":1}}],["明显",{"2":{"190":1}}],["明白了内部结构",{"2":{"181":1}}],["很多经典算法的灵感就来源于我们生活中的需求",{"2":{"927":1}}],["很多时候",{"2":{"924":1}}],["很多人会感到有些害怕",{"2":{"916":1}}],["很相似",{"2":{"922":1}}],["很直观明了",{"2":{"844":1}}],["很显然",{"2":{"641":1}}],["很类似",{"2":{"572":1,"919":1}}],["很少有情况下原地操作能够显著降低内存使用量",{"2":{"481":1}}],["很难对高级黑盒优化算法进行benchmark测试",{"2":{"401":1}}],["很难利用先前的试验结果",{"2":{"401":1}}],["很复杂",{"2":{"362":1}}],["很明显",{"2":{"190":1}}],["很可能产生",{"2":{"122":1}}],["引用的是与",{"2":{"472":1}}],["引用",{"0":{"421":1},"2":{"351":1}}],["引入",{"0":{"835":1}}],["引入变分",{"0":{"659":1}}],["引入了冗余",{"2":{"369":2}}],["引入正则化可以限制模型的复杂度",{"2":{"341":1}}],["引入一个隐变量a",{"2":{"190":1}}],["引发了深度学习在各个领域的广泛应用和发展",{"2":{"122":1}}],["||",{"2":{"606":1}}],["||^",{"2":{"606":1}}],["|∣g∣",{"2":{"410":1}}],["|",{"2":{"190":2,"410":3,"590":67,"840":2}}],["统计学习方法",{"2":{"626":1}}],["统计损失和正确率",{"2":{"567":1}}],["统计非负整数数组中每个值的频率",{"2":{"445":1}}],["统计机器翻译",{"2":{"189":1,"190":1}}],["统一计算设备架构",{"2":{"74":1}}],["负无穷",{"2":{"215":1,"226":1}}],["负面的还是中性的",{"2":{"188":1}}],["负半轴",{"2":{"124":1}}],["情商",{"2":{"831":1}}],["情感分析",{"2":{"188":1}}],["情况相同",{"2":{"323":1}}],["情况二",{"2":{"28":1}}],["情况一",{"2":{"28":1}}],["回顾性最佳检查点选择",{"2":{"392":1}}],["回复",{"2":{"338":1}}],["回答用户提出的自然语言问题",{"2":{"188":1}}],["回归到开始",{"2":{"975":1}}],["回归该句",{"2":{"878":1}}],["回归",{"2":{"117":1}}],["问答系统",{"2":{"188":1}}],["问题描述",{"0":{"951":1}}],["问题就被彻底解决了",{"2":{"924":1}}],["问题说明",{"0":{"727":1}}],["问题制定",{"2":{"354":1}}],["问题",{"0":{"162":1,"163":1,"164":1,"931":1,"937":1,"941":1,"945":1},"2":{"11":3,"160":1,"162":1,"165":1,"177":1,"328":1,"656":1,"868":1,"883":1,"908":1}}],["主页页脚添加公安备案信息",{"2":{"871":1}}],["主页🏠",{"0":{"861":1}}],["主页",{"0":{"855":1}}],["主进程打印结果",{"2":{"827":1}}],["主成分分析法",{"2":{"652":1}}],["主机系统",{"2":{"909":1}}],["主机2",{"2":{"327":1}}],["主机1",{"2":{"327":1}}],["主题分类等",{"2":{"188":1}}],["主要用于教学和研究",{"2":{"802":1}}],["主要用于向上采样",{"2":{"61":1}}],["主要的mpi实现有",{"2":{"802":1}}],["主要完成self",{"2":{"509":1}}],["主要区别在于输入的构造",{"2":{"444":1}}],["主要在imagenet上",{"2":{"394":1}}],["主要思想是将输入的",{"2":{"224":1,"311":1}}],["主要是针对batch",{"2":{"89":1}}],["文科生都能懂的算法",{"2":{"916":1}}],["文档",{"2":{"718":2}}],["文档旋转等方式破坏后传给",{"2":{"621":1}}],["文件查找",{"0":{"764":1},"1":{"765":1,"766":1}}],["文件权限管理",{"0":{"744":1},"1":{"745":1,"746":1}}],["文件操作",{"0":{"743":1}}],["文件和目录管理",{"0":{"742":1}}],["文件系统结构采用树形结构",{"2":{"738":1}}],["文件系统结构",{"0":{"737":1},"1":{"738":1,"739":1,"740":1}}],["文件io也是一种持久化机制",{"2":{"722":1}}],["文件",{"2":{"676":1}}],["文章侧边栏配置取消",{"2":{"868":1}}],["文章结构建立整理并排查修复",{"2":{"868":1}}],["文章中的n为10000",{"2":{"640":1}}],["文章内容",{"2":{"21":1}}],["文献4",{"2":{"255":1}}],["文献3",{"2":{"255":1}}],["文献2",{"2":{"255":1}}],["文献1",{"2":{"255":1}}],["文本缩进和格式调整",{"0":{"791":1},"1":{"792":1,"793":1}}],["文本查看",{"0":{"747":1},"1":{"748":1,"749":1}}],["文本",{"2":{"605":1}}],["文本对之间的相关性更高",{"2":{"605":1}}],["文本摘要",{"2":{"188":2}}],["文本聚类",{"2":{"188":1}}],["文本生成",{"2":{"188":1}}],["文本分类就是将文本送入",{"2":{"621":1}}],["文本分类",{"2":{"188":1}}],["挑选出最好的那个",{"2":{"186":1}}],["候选结果的数量并不会一直增多",{"2":{"186":1}}],["序列索引",{"2":{"649":1}}],["序列中的每个词嵌入向量",{"2":{"648":1}}],["序列化时会触发",{"2":{"509":1}}],["序列",{"2":{"402":1}}],["序列的连续逻辑块通过块表映射到非连续的物理块",{"2":{"334":1}}],["序列视为进程",{"2":{"334":1}}],["序列并行性将请求的输入序列在不同节点之间分区",{"2":{"329":1}}],["序列并行",{"2":{"328":1}}],["序列标注",{"2":{"188":1}}],["序列越长",{"2":{"186":1}}],["序列得分",{"2":{"184":3,"185":1}}],["序列输入过程",{"2":{"135":1}}],["选中代码块并按",{"2":{"793":1}}],["选取nbest个最佳路径的index",{"2":{"634":1}}],["选择合适的贪心策略",{"2":{"974":1}}],["选择合适的batch",{"0":{"359":1,"360":1}}],["选择最便宜的出行方案",{"0":{"936":1},"1":{"937":1,"938":1,"939":1}}],["选择最佳试验会抑制出现过拟合问题的配置",{"2":{"375":1}}],["选择顺序",{"0":{"919":1}}],["选择成员列表并设置权限",{"2":{"889":1}}],["选择操作",{"0":{"784":1}}],["选择一种跟踪系统",{"2":{"393":1}}],["选择样本进行定期评估",{"0":{"391":1}}],["选择较小的学习率可以通过阻碍优化过程来规范训练",{"2":{"375":1}}],["选择试验次数",{"2":{"370":1}}],["选择试验所需的超参数变量",{"2":{"370":1}}],["选择这些超参数的取值范围",{"2":{"370":1}}],["选择训练步数的数量涉及平衡以下方面",{"2":{"363":1}}],["选择快速且消耗最少资源的初始配置将使超参数调整更加高效",{"2":{"363":1}}],["选择用于同类问题的最常用优化器",{"2":{"356":1}}],["选择架构实际上意味着选择一整个系列的各种模型",{"2":{"355":1}}],["选择下一轮实验的目标",{"0":{"367":1},"2":{"351":1}}],["选择初始配置",{"0":{"363":1},"2":{"351":1}}],["选择batchsize",{"0":{"357":1},"1":{"358":1,"359":1,"360":1,"361":1,"362":1,"363":1},"2":{"351":1}}],["选择优化器",{"0":{"356":1},"2":{"351":1}}],["选择模型架构",{"0":{"355":1},"2":{"351":1}}],["选择概率最大的那个",{"2":{"190":1}}],["选择",{"2":{"184":1,"648":1}}],["选择激活函数时",{"2":{"120":1}}],["选出最优的组合",{"2":{"183":1}}],["改动",{"2":{"868":1}}],["改操作需要提交事务",{"2":{"731":1}}],["改为只依赖于相对距离",{"2":{"643":1}}],["改为二元位置向量",{"2":{"643":1}}],["改善验证损失",{"2":{"380":1}}],["改进策略",{"0":{"850":1}}],["改进最近的研究",{"2":{"372":1}}],["改进的方法",{"2":{"183":1}}],["改变文件所有者和所属组",{"2":{"746":1}}],["改变",{"2":{"369":1,"457":1}}],["改变梯度积累为指数加权的移动平均",{"2":{"283":1}}],["改变数据分布的均值和方差",{"2":{"86":1}}],["捡了芝麻",{"2":{"183":1}}],["肯定会有问题",{"2":{"183":1}}],["贪心选择性质",{"2":{"974":1}}],["贪心与人生",{"0":{"967":1}}],["贪心更是人的一种本性",{"2":{"966":1}}],["贪心策略",{"0":{"973":1}}],["贪心策略的解释",{"0":{"960":1}}],["贪心策略是",{"2":{"939":1}}],["贪心思维",{"0":{"932":1,"938":1,"942":1,"946":1}}],["贪心算法原理",{"0":{"971":1},"1":{"972":1,"973":1,"974":1}}],["贪心算法是一种常用的算法设计策略",{"2":{"969":1}}],["贪心算法基本概念",{"0":{"968":1},"1":{"969":1,"970":1}}],["贪心算法大纲内容",{"2":{"966":1}}],["贪心算法的解法思路",{"0":{"955":1}}],["贪心算法并不复杂",{"2":{"929":1}}],["贪心算法",{"0":{"948":1},"2":{"921":1,"967":1}}],["贪心法则",{"0":{"921":1},"2":{"921":1}}],["贪心",{"0":{"929":1,"966":1},"1":{"930":1,"931":1,"932":1,"933":1,"934":1,"935":1,"936":1,"937":1,"938":1,"939":1,"940":1,"941":1,"942":1,"943":1,"944":1,"945":1,"946":1,"947":1,"948":1,"967":1,"968":1,"969":1,"970":1,"971":1,"972":1,"973":1,"974":1,"975":1},"2":{"183":1,"868":1,"929":2,"948":1,"967":1,"975":1}}],["贪心decoding",{"0":{"183":1}}],["映射成数据库中的记录",{"2":{"721":1}}],["映射实体类与数据库表",{"2":{"709":1}}],["映射关系如下",{"2":{"644":1}}],["映射的过程就是把最大概率的那个词找出来作为预测出的词",{"2":{"181":1}}],["映射到",{"2":{"208":1}}],["映射到输出",{"2":{"198":1}}],["映射到另一种语言的对应语句上",{"2":{"167":1}}],["映射到序列的神经网络",{"2":{"167":1}}],["那我们不妨用简单的案例来让你感受感受",{"2":{"929":1}}],["那我们到时候直接沠一个跑腿送过来就行",{"2":{"875":1}}],["那样",{"2":{"921":1}}],["那种不因别人的评价而影响自己",{"2":{"878":1}}],["那真的是很难得啊",{"2":{"878":1}}],["那也分为好多类",{"2":{"878":1}}],["那基本都是",{"2":{"878":1}}],["那更是比",{"2":{"878":1}}],["那就是要做到",{"2":{"880":1}}],["那就是每一步最优",{"2":{"183":1}}],["那就要不断地去见习",{"2":{"878":1}}],["那便自然而然能够说得通",{"2":{"878":1}}],["那这时候就是",{"2":{"878":1}}],["那这个标签序列就是模型的输出",{"2":{"624":1}}],["那你就真正明白什么是",{"2":{"878":1}}],["那是无法用文字来说清楚的",{"2":{"878":1}}],["那是一件多么快乐的事情啊",{"2":{"878":1}}],["那是由于内存本身的缺陷引起的",{"2":{"722":1}}],["那是很肤浅的",{"2":{"700":1}}],["那如何获得输入数字",{"2":{"654":1}}],["那一维归一化",{"2":{"643":1}}],["那一个是weight",{"2":{"467":1}}],["那下一个位置就很有可能是",{"2":{"628":1}}],["那什么是线性链crf呢",{"2":{"626":1}}],["那视图的底层逻辑到底是什么呢",{"2":{"437":1}}],["那dropblock为什么在卷积网络上可以有效果",{"2":{"348":1}}],["那卷积层呢",{"2":{"347":1}}],["那时relu激活函数还未兴起",{"2":{"245":1}}],["那些表现优异的smt模型",{"2":{"190":1}}],["那不就是通过前面定义的score函数来比较吗",{"2":{"186":1}}],["那怎么去计算每一步的损失呢",{"2":{"181":1}}],["那么它们就不应该有过多的交互",{"2":{"644":1}}],["那么它就是一个目标超参数",{"2":{"369":1}}],["那么最多就只能处理长度为512的句子",{"2":{"641":1}}],["那么最大训练step数就太高了",{"2":{"381":1}}],["那么就初始化一个512×768的矩阵作为位置向量",{"2":{"641":1}}],["那么就需要进行",{"2":{"410":1}}],["那么问题来了",{"2":{"624":1}}],["那么您需要负责调用",{"2":{"480":1}}],["那么您可能无需再次签署",{"2":{"423":1}}],["那么作为梯度使用的值是任意的",{"2":{"473":1}}],["那么可以免费获得性能提升",{"2":{"479":1}}],["那么可以对其进行调优",{"2":{"410":1}}],["那么可能需要重新运行整个过程",{"2":{"409":1}}],["那么可得到输出",{"2":{"245":1}}],["那么该模型可能存在着优化不稳定性的情况",{"2":{"408":1}}],["那么修复不稳定性可能会得到更好的训练结果",{"2":{"405":1}}],["那么对我们来说",{"2":{"401":1}}],["那么需要对学习率",{"2":{"400":1}}],["那么需要对学习率以及",{"2":{"400":1}}],["那么只需要对基本学习率进行调整",{"2":{"400":1}}],["那么理想情况是在许多不同的调整轮次中逐渐增加训练运行的长度",{"2":{"385":1}}],["那么max",{"2":{"382":1}}],["那么训练时间越长",{"2":{"381":1}}],["那么训练工作流可能存在瓶颈",{"2":{"358":1}}],["那么这个序列的转移分数可按照如下方式计算",{"2":{"628":1}}],["那么这个非叶子节点的requires",{"2":{"462":1}}],["那么这个搜索空间就有可疑之处",{"2":{"373":1}}],["那么这个神经元之后的梯度就永远是0了",{"2":{"122":1}}],["那么在预测时如果输入超过",{"2":{"645":1}}],["那么在尝试其他东西之前解决这些问题很重要",{"2":{"404":1}}],["那么在未来的实验中",{"2":{"369":1}}],["那么在前向传播过程中",{"2":{"237":1}}],["那么模型层数就是目标超参数",{"2":{"369":1}}],["那么模型更容易过拟合",{"2":{"341":1}}],["那么以后可能很难改变它",{"2":{"363":1}}],["那么直到项目成熟且容易权衡成本效益前",{"2":{"360":1}}],["那么使用更大的batch",{"2":{"359":1}}],["那么我们就可以用降维的数据进行机器学习模型的训练和预测",{"2":{"652":1}}],["那么我们不妨降低学习率",{"2":{"410":1}}],["那么我们可能应该只降低学习率",{"2":{"410":1}}],["那么我们可能应该采用它作为新的baseline为以后的比较",{"2":{"378":1}}],["那么我们可以更努力地尝试",{"2":{"410":1}}],["那么我们会将此图中的最佳点与没有权重衰减的baseline进行比较",{"2":{"376":1}}],["那么我们通常更愿意使用额外的正则化再次尝试",{"2":{"375":1}}],["那么我们只考虑使用该batch",{"2":{"358":1}}],["那么我们应该如何初始化weight呢",{"2":{"248":1}}],["那么",{"2":{"326":1,"409":1,"410":1}}],["那么一个自然的思路就是让每张卡去算",{"2":{"326":1}}],["那么每步消耗的增加可能超过训练所需步数的减少",{"2":{"360":1}}],["那么每一步资源消耗的增加可能被步骤数的减少所抵消",{"2":{"360":1}}],["那么每一步就需要分出k×v个分支并逐一计算score",{"2":{"184":1}}],["那么每个参数设置不同的学习率",{"2":{"276":1}}],["那么具体怎么做呢",{"2":{"216":1}}],["那么很明显这样的输出必须依赖以前的输入",{"2":{"132":1}}],["流水线",{"2":{"811":1}}],["流体动力学等",{"2":{"802":1}}],["流行的优化器",{"2":{"356":1}}],["流畅的语句",{"2":{"180":1}}],["流程图示",{"0":{"29":1}}],["预训练时模型很可能已经见过与我们任务类似的数据集",{"2":{"617":1}}],["预训练是一种从头开始训练模型的方式",{"2":{"617":1}}],["预训练好的",{"2":{"616":1}}],["预训练模型下载",{"2":{"613":1}}],["预训练的语言模型通常是在大规模的无监督数据上进行预训练",{"2":{"180":1}}],["预训练的语言模型通常经过大规模的数据和计算资源训练得到",{"2":{"180":1}}],["预训练的语言模型在大规模数据上学习到了丰富的语义信息和语言规律",{"2":{"180":1}}],["预钩子可以就地修改",{"2":{"509":1}}],["预热可以独立于现有的衰减计划进行调整",{"2":{"409":1}}],["预热的过程涉及了预先安排一个学习率计划",{"2":{"409":1}}],["预热期间不稳定的示例",{"2":{"407":1}}],["预处理方法等",{"2":{"367":1}}],["预算",{"2":{"359":1,"400":1}}],["预测出的实体个数",{"2":{"635":1}}],["预测正确的实体个数",{"2":{"635":1}}],["预测的正例个数",{"2":{"635":1}}],["预测的时候我们只能得到前一时刻预测出的输出",{"2":{"216":1}}],["预测为正例的个数",{"2":{"635":1}}],["预测到会跨过山谷时",{"2":{"269":1}}],["预测或推理时的流程图如下",{"2":{"176":1}}],["预测时不需要",{"2":{"216":1}}],["预测时",{"2":{"176":1}}],["预测时流程",{"0":{"176":1}}],["预测和决策等任务",{"2":{"4":1}}],["原因是子任务内部是局部性的",{"2":{"823":1}}],["原因如下",{"2":{"180":1}}],["原始论文链接",{"2":{"664":1,"665":1}}],["原地函数将引发错误",{"2":{"481":1}}],["原地操作可能会覆盖计算梯度所需的值",{"2":{"481":1}}],["原地操作",{"2":{"445":1}}],["原地取绝对值",{"2":{"445":1}}],["原地取余操作",{"2":{"443":1}}],["原地左移操作",{"2":{"443":1}}],["原地更新",{"2":{"441":1}}],["原则上",{"2":{"365":1,"379":1}}],["原本的公式只有一个翻译模型",{"2":{"190":1}}],["原理详解",{"0":{"625":1},"1":{"626":1,"627":1,"628":1}}],["原理简图",{"2":{"447":1}}],["原理简介",{"0":{"208":1}}],["原理及思想介绍",{"0":{"311":1}}],["原理概述",{"0":{"294":1,"446":1,"447":1},"1":{"295":1,"296":1,"297":1,"447":1,"448":1}}],["原理介绍",{"0":{"222":1}}],["原理图示",{"2":{"437":1}}],["原理图所示",{"2":{"160":1}}],["原理图",{"0":{"597":1},"2":{"114":1,"184":1}}],["原理",{"0":{"63":1,"156":1,"184":1,"308":1,"646":1},"2":{"86":1,"89":1,"93":1,"128":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"546":1,"547":1,"548":1,"549":1}}],["具有灵活的架构",{"2":{"802":1}}],["具有更好的外推性",{"2":{"645":1}}],["具有更多超参数的优化器可能需要更多的调优工作才能找到最佳配置",{"2":{"356":1}}],["具有",{"2":{"475":1,"620":1,"621":1}}],["具有复杂分段学习率",{"2":{"399":1}}],["具有固定动量的",{"2":{"356":1}}],["具有损失最大偏导的参数相应地有一个快速下降的学习率",{"2":{"277":1}}],["具有较好的语言表示能力",{"2":{"180":1}}],["具有了某种能力",{"2":{"180":1}}],["具体理解还是要看个人的悟性",{"2":{"876":1}}],["具体过程可展示如下",{"2":{"648":1}}],["具体如下",{"2":{"640":1}}],["具体地",{"2":{"624":1}}],["具体模型结构",{"0":{"600":1},"1":{"601":1,"602":1,"603":1}}],["具体代码为",{"2":{"505":1}}],["具体配置请查看",{"2":{"422":1}}],["具体请阅读",{"2":{"412":1}}],["具体安排如下",{"2":{"409":1}}],["具体原因和干预措施将高度依赖于任务",{"2":{"387":1}}],["具体而言",{"2":{"327":1,"333":1}}],["具体实现有不同的厂商或者社区实现",{"2":{"802":1}}],["具体实现有多种",{"2":{"801":1}}],["具体实现原理",{"0":{"327":1}}],["具体实施",{"2":{"324":2}}],["具体取决于序列长度",{"2":{"316":1}}],["具体的映射代码",{"2":{"644":1}}],["具体的加噪过程如下",{"2":{"595":1}}],["具体的glorot条件如下",{"2":{"244":1}}],["具体的做法是",{"2":{"215":1}}],["具体指的是在网络模型训练之前",{"2":{"233":1}}],["具体flashattention的算法",{"0":{"226":1}}],["具体来说",{"2":{"215":1,"563":1,"606":1,"822":1}}],["具体什么是对齐方式alignment呢",{"2":{"190":1}}],["具体见4",{"2":{"176":1}}],["具体计算",{"0":{"152":1}}],["具体计算过程为",{"2":{"152":1}}],["具体计算过程",{"0":{"45":1}}],["标签在发送和接收时需一致",{"2":{"809":1}}],["标签",{"2":{"628":1,"632":1}}],["标签向量",{"2":{"624":2}}],["标签的预处理",{"2":{"552":1}}],["标签平滑化",{"2":{"375":1}}],["标签平滑的优势是能够防止模型追求确切概率而不影响模型学习正确分类",{"2":{"345":1}}],["标签平滑",{"0":{"345":1},"2":{"345":1}}],["标记",{"2":{"373":1}}],["标记视为字节",{"2":{"334":1}}],["标准的一部分",{"2":{"822":1}}],["标准的注意力实现将矩阵",{"2":{"223":1,"312":1}}],["标准化工具链",{"2":{"822":1}}],["标准交叉熵损失可以用在这些非确切目标的输出上",{"2":{"345":1}}],["标准差为",{"2":{"239":1,"240":1}}],["标准attention",{"2":{"227":1,"317":1}}],["标准attention机制的算法实现",{"0":{"223":1,"312":1}}],["标准答案",{"2":{"179":1}}],["标量的梯度才能被隐式创建",{"2":{"462":1}}],["标量",{"2":{"50":1}}],["计划",{"2":{"923":1}}],["计划采样",{"2":{"179":1}}],["计算初值",{"2":{"845":1}}],["计算每个进程负责的范围",{"2":{"827":1}}],["计算每一条路的",{"2":{"184":1}}],["计算从",{"2":{"827":2}}],["计算机图形学",{"2":{"870":1,"871":1}}],["计算机图形学的应用潜力将持续扩大",{"2":{"859":1}}],["计算机图形学的主要内容",{"0":{"857":1}}],["计算机图形学领域的最新研究聚焦在高效物理模拟和逼真动画生成等方面",{"2":{"859":1}}],["计算机专业考研党",{"2":{"696":1}}],["计算机相关的入门人员",{"2":{"696":1}}],["计算机科学",{"2":{"694":2}}],["计算结果是个复数向量",{"2":{"649":1}}],["计算m",{"2":{"649":1}}],["计算词向量元素两两分组之后",{"2":{"649":1}}],["计算速度提高",{"2":{"619":1}}],["计算损失并返回它",{"2":{"505":1}}],["计算损失函数",{"2":{"497":1}}],["计算损失",{"2":{"495":1}}],["计算当前批次的均值和方差",{"2":{"493":1}}],["计算当前张量相对于计算图叶节子节点的梯度",{"2":{"441":1}}],["计算也不会被记录在反向图中",{"2":{"478":1}}],["计算行为就好像没有任何输入需要梯度一样",{"2":{"478":1}}],["计算梯度",{"2":{"452":1}}],["计算某个函数的输出",{"2":{"452":1}}],["计算一个实对称或复数方阵的特征值和特征向量",{"2":{"441":1}}],["计算一次score",{"2":{"184":1}}],["计算完该张量的梯度时",{"2":{"441":1}}],["计算限制",{"2":{"375":1}}],["计算简图",{"2":{"312":1}}],["计算简单",{"2":{"120":1}}],["计算公式如下所示",{"2":{"606":1}}],["计算公式",{"2":{"260":1,"261":1,"262":1}}],["计算公式为",{"2":{"122":1}}],["计算",{"2":{"226":1,"647":1}}],["计算如下",{"2":{"225":1,"313":1}}],["计算attention的",{"2":{"213":1}}],["计算过程",{"0":{"157":1},"2":{"488":1}}],["计算复杂度低",{"2":{"130":1}}],["计算的时间",{"2":{"130":1}}],["计算量小",{"2":{"122":1}}],["计算量大",{"2":{"122":1}}],["计算原理图",{"2":{"64":1}}],["计算规则又是怎样的",{"2":{"55":1}}],["计算流程概述",{"0":{"44":1}}],["让生活变得更加简单有序",{"2":{"928":1}}],["让我们简单步入",{"0":{"929":1},"1":{"930":1,"931":1,"932":1,"933":1,"934":1,"935":1,"936":1,"937":1,"938":1,"939":1,"940":1,"941":1,"942":1,"943":1,"944":1,"945":1,"946":1,"947":1,"948":1}}],["让我们的生活更加有趣",{"2":{"928":1}}],["让我们能对计算机本身有一个整体的认识",{"2":{"698":1}}],["让我感受到了不同的商家之间到底有多大明显的差距",{"2":{"875":1}}],["让你更懂得如何从底层实现酷炫的视觉效果",{"2":{"858":1}}],["让q接近真实的后验",{"2":{"659":1}}],["让它随着训练过程更新",{"2":{"641":1}}],["让它们不向后面的层传递信号",{"2":{"346":1}}],["让module",{"2":{"496":1}}],["让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练",{"2":{"344":1}}],["让所有的头之间",{"2":{"217":1,"303":1}}],["让老师来指导一下",{"2":{"178":1}}],["让结构简单的网络甚至超过sota性能",{"2":{"125":1}}],["误差在训练期间上升而不下降",{"2":{"405":1}}],["误差爆炸",{"2":{"177":1}}],["误差对",{"2":{"45":1}}],["步进主方向在",{"2":{"840":2}}],["步进方向选择",{"2":{"840":1}}],["步幅",{"2":{"445":1}}],["步骤四",{"2":{"827":1}}],["步骤三",{"2":{"827":1}}],["步骤二",{"2":{"827":1}}],["步骤一",{"2":{"827":1}}],["步骤",{"2":{"382":1}}],["步步错",{"2":{"177":1}}],["步长为2",{"2":{"111":1}}],["又或者说把结束最早的最先安排",{"2":{"973":1}}],["又或者输入很多的手写数字",{"2":{"653":1}}],["又无法让我真正感受到",{"2":{"917":1}}],["又称",{"2":{"616":1,"621":1}}],["又称自回归",{"2":{"616":1}}],["又称自编码",{"2":{"616":1}}],["又称权重初始化",{"2":{"233":1}}],["又称修正线性单元",{"2":{"122":1}}],["又不是不能跑",{"2":{"177":1}}],["语句",{"2":{"708":1}}],["语法",{"2":{"708":1}}],["语料进行微调",{"2":{"617":1}}],["语言对之间可能存在共享知识可以用来处理小众语言之间的翻译",{"2":{"621":1}}],["语言生成",{"2":{"188":1}}],["语言模型可能面临数据稀疏性的问题",{"2":{"180":1}}],["语言模型",{"2":{"176":1,"188":1,"620":1}}],["语义角色标注",{"2":{"188":1}}],["语音处理",{"2":{"160":1}}],["语音音频",{"2":{"21":1}}],["思路二",{"2":{"730":1}}],["思路一",{"2":{"730":1}}],["思路流程",{"2":{"725":1}}],["思路图如下",{"2":{"174":1}}],["思维树中的搜索历史",{"2":{"337":1}}],["思考题",{"0":{"734":1}}],["思考与尝试",{"0":{"516":1,"520":1}}],["思考",{"0":{"853":1,"961":1},"2":{"11":1,"27":3,"29":1,"48":1,"55":1,"57":1,"65":2,"86":1,"106":1,"108":1,"110":1,"114":1,"129":1,"138":1,"139":1,"140":3,"171":1,"173":1,"177":2,"178":1,"180":1,"186":3,"203":1,"209":1,"214":1,"215":1,"216":1,"248":1,"292":1,"340":1,"343":1,"345":1,"346":1,"347":1,"435":1,"437":2,"483":1,"485":1,"503":1,"508":1,"521":1,"524":1,"535":1,"645":1}}],["机器的",{"2":{"827":1}}],["机器的处理量将会很大",{"2":{"652":1}}],["机器",{"2":{"827":2}}],["机器学习开发的最终目标是最大化模型的效用",{"2":{"364":1}}],["机器学习中的一个核心问题是设计不仅在训练数据上表现好",{"2":{"340":1}}],["机器学习模型",{"2":{"167":1}}],["机器翻译的思路十分简单",{"2":{"189":1}}],["机器翻译的发展历程",{"0":{"189":1}}],["机器翻译",{"2":{"188":1}}],["机器翻译等任务",{"2":{"176":1,"188":1}}],["机制不足",{"0":{"467":1}}],["机制使得系统可以更好地处理长上下文输入",{"2":{"329":1}}],["机制来扩展单个请求的处理能力",{"2":{"329":1}}],["机制",{"0":{"173":1,"174":1},"1":{"174":1},"2":{"492":1}}],["索引",{"0":{"443":1},"2":{"172":1}}],["词语分类",{"2":{"619":1}}],["词语序列",{"2":{"167":1}}],["词汇替换",{"2":{"344":1}}],["词汇量为v",{"2":{"184":1}}],["词汇表的index",{"2":{"172":1}}],["橘黄点是线性变换后的值",{"2":{"172":1}}],["细节展示",{"2":{"448":1}}],["细节展开图如下",{"2":{"172":1}}],["细胞状态中的值有可能被丢弃",{"2":{"149":1}}],["细胞状态与忘记向量进行逐元素相乘",{"2":{"149":1}}],["形状或其他条件来选择适当的实现",{"2":{"441":1}}],["形状n",{"2":{"226":1}}],["形状为n",{"2":{"226":1}}],["形状为",{"2":{"226":1}}],["形式上和前面公式",{"2":{"648":1}}],["形式统一解决",{"2":{"621":1}}],["形式2",{"2":{"171":1}}],["形式1",{"2":{"171":1}}],["形成",{"2":{"60":1}}],["架构性能的位置编码方式",{"2":{"645":1}}],["架构的两个模块",{"2":{"621":1}}],["架构和迁移学习",{"2":{"620":1}}],["架构更高效",{"2":{"619":1}}],["架构参数以及我们在深度学习中调整的所有其他参数",{"2":{"411":1}}],["架构",{"0":{"169":1},"2":{"191":1}}],["把几何图元转换为像素点以显示在屏幕上",{"2":{"857":1}}],["把最终结果返回",{"2":{"552":1}}],["把最后一层看作线性预测器",{"2":{"13":1}}],["把parameters初始化为0是不可以的",{"2":{"237":1}}],["把这个矩阵作用在每一个序列上",{"2":{"216":1}}],["把这些位置的值加上一个非常大的负数",{"2":{"215":1}}],["把",{"2":{"216":1}}],["把多余的直接舍弃",{"2":{"215":1}}],["把所有的输入序列都编码成一个统一的语义向量context",{"2":{"168":1}}],["假定现在词嵌入向量的维度是两维",{"2":{"646":1}}],["假定",{"2":{"646":1}}],["假如随机取数据的时候",{"2":{"656":1}}],["假如我们的wight",{"2":{"245":1}}],["假如输入序列长度为n",{"2":{"165":1}}],["假设任务的截止时间分别是",{"2":{"943":1}}],["假设你有",{"2":{"945":1}}],["假设你有多种交通方式可以选择去不同的地点",{"2":{"937":1}}],["假设你有三件事情要做",{"2":{"919":1}}],["假设你正在训练一个深度学习模型",{"2":{"401":1}}],["假设一共有5个图片",{"2":{"655":1}}],["假设一个神经元",{"2":{"245":1}}],["假设我们现在有个标签序列",{"2":{"628":1}}],["假设我们想知道",{"2":{"369":1}}],["假设当前位置的标签是",{"2":{"628":1}}],["假设回顾性",{"2":{"381":1}}],["假设序列长度为8k",{"2":{"328":1}}],["假设是方块块",{"2":{"322":1}}],["假设随机变量",{"2":{"249":1}}],["假设进行conv",{"2":{"248":1}}],["假设",{"2":{"230":1,"330":1,"649":1}}],["假设beam",{"2":{"184":1}}],["假设词汇量是v",{"2":{"181":1}}],["假设深度学习要处理的信息是",{"2":{"15":1}}],["还剩下一些钱",{"2":{"939":1}}],["还剩",{"2":{"939":1,"947":2}}],["还原默认设置",{"2":{"914":1}}],["还展示了小样本学习",{"2":{"620":1}}],["还将",{"2":{"619":1}}],["还包括768x768版本的模型",{"2":{"608":1}}],["还要快",{"2":{"510":1}}],["还要检查其他问题的清单",{"2":{"372":1}}],["还有一种好处就是我们可以将数据降维至2d或3d以便于观察分布情况",{"2":{"652":1}}],["还有一种结构是把输入信息x作为每个阶段的输入",{"2":{"164":1}}],["还有",{"2":{"626":1}}],["还有三种梯度模式可以从",{"2":{"476":1}}],["还需要考虑具体",{"2":{"622":1}}],["还需要额外调整β2",{"2":{"400":1}}],["还需要庞大的人力去维护",{"2":{"190":1}}],["还可以用不同长度的元素序列标记",{"2":{"338":1}}],["还可以对每层的输出做加权后做变换得到context",{"2":{"170":1}}],["还可以对最后的隐状态做一个变换得到context",{"2":{"170":1}}],["还是最花费时间的最先安排",{"2":{"973":1}}],["还是制定计划",{"2":{"928":1}}],["还是做决策",{"2":{"927":1}}],["还是生活中的小确幸",{"2":{"881":1}}],["还是分布式",{"2":{"798":1}}],["还是有必要科普一下计算机的基本知识",{"2":{"697":1}}],["还是",{"2":{"27":1,"55":1}}],["值向下取整",{"2":{"840":1}}],["值得指出的是",{"2":{"647":1}}],["值得注意的是",{"2":{"161":1,"219":1,"305":1,"409":1}}],["值越低代表两个分布越相似",{"2":{"606":1}}],["值越大",{"2":{"50":2,"605":1}}],["值的方式选择",{"2":{"375":1}}],["值块发送到下一个主机",{"2":{"327":1}}],["值块通过主机环进行遍历",{"2":{"327":1}}],["值块",{"2":{"327":2}}],["值可以一起存储",{"2":{"322":1}}],["值太大的时候梯度信息传递过去了",{"2":{"241":1}}],["值和额外的统计信息",{"2":{"226":1,"315":1}}],["值",{"2":{"206":1,"369":1}}],["圆圈或方块表示的是向量",{"2":{"160":1}}],["会考虑薪资",{"2":{"925":1}}],["会有不一样的收获",{"2":{"880":1}}],["会有一种让你觉得作者大大讲的真清楚的感觉",{"2":{"699":1}}],["会分配不同的计算节点或",{"2":{"822":1}}],["会引起sql注入",{"2":{"734":1}}],["会引起问题",{"2":{"406":1}}],["会不会有思维",{"2":{"697":1}}],["会自动调用对象的",{"2":{"509":1}}],["会检测成员的",{"2":{"492":1}}],["会使得里面的新的tensor",{"2":{"462":1}}],["会使分母过于敏感",{"2":{"280":1}}],["会调用对象的",{"2":{"441":1}}],["会出现部分",{"2":{"390":1}}],["会将标了×",{"2":{"346":1}}],["会导致网络收敛缓慢或者收敛到局部极小值",{"2":{"236":1}}],["会导致我们训练出来的模型在翻译结果的语言通畅性方面很差",{"2":{"190":1}}],["会导致那些很短的句子更容易被选出",{"2":{"186":1}}],["会通过一个projection层映射到对应的词",{"2":{"181":1}}],["会遇到很多序列型输入数据的情况或问题",{"2":{"160":1}}],["会发生梯度消失问题",{"2":{"122":1}}],["到现在为止",{"2":{"657":1}}],["到生成式任务",{"2":{"622":1}}],["到了新的领域",{"2":{"617":1}}],["到我们正在应对的特定问题中",{"2":{"254":1}}],["到一个连续的表示",{"2":{"194":1}}],["到",{"0":{"159":1,"328":1,"329":1,"609":1},"1":{"160":1,"161":1,"162":1,"163":1,"164":1,"165":1},"2":{"208":1,"226":1,"496":1,"634":1,"827":2,"878":1}}],["静态分析",{"2":{"563":1}}],["静态方法",{"2":{"509":1}}],["静态图需要在转换过程中进行编译",{"2":{"560":1}}],["静态图允许pytorch在转换过程中应用一系列的图优化技术",{"2":{"560":1}}],["静态图的优势",{"0":{"560":1}}],["静态图的一个典型示例是tensorflow的计算图",{"2":{"559":1}}],["静态图在模型执行前可以进行静态优化和编译",{"2":{"559":1}}],["静态图和动态图各有其优势和应用场景",{"2":{"559":1}}],["静态图是在模型定义阶段构建的计算图",{"2":{"559":1}}],["静态图模型",{"0":{"528":1}}],["静态图",{"2":{"462":1,"559":1}}],["静态图如下",{"2":{"136":1}}],["静态原理图",{"2":{"447":1}}],["静态计算图",{"2":{"157":1}}],["哪一个是activation呢",{"2":{"467":1}}],["哪些任务要先完成",{"2":{"919":1}}],["哪些张量由特定",{"2":{"472":1}}],["哪些参数需要设置requires",{"2":{"467":1}}],["哪些超参数交互最多",{"2":{"366":1}}],["哪种优化算法最好呢",{"2":{"292":1}}],["哪种形式用的比较多呢",{"2":{"171":1}}],["哪种方法更好",{"2":{"156":1}}],["哪个是kernel",{"2":{"55":1}}],["哪个是输出",{"2":{"55":1}}],["哪个是输入",{"2":{"55":1}}],["门控循环单元",{"0":{"154":1},"1":{"155":1,"156":1,"157":1}}],["请将",{"2":{"544":1}}],["请检查您是否在退出推断模式后的自动求导记录的计算中使用了在推断模式下创建的张量",{"2":{"479":1}}],["请启用推断模式",{"2":{"479":1}}],["请使用模最小的超梯度",{"2":{"473":1}}],["请使用模最小的子梯度",{"2":{"473":1}}],["请使用它",{"2":{"473":1}}],["请查看",{"2":{"424":1}}],["请查看之前的章节",{"2":{"410":1}}],["请前往",{"2":{"423":1}}],["请不要在未通过问题跟踪系统与作者协调的情况下提交pull",{"2":{"422":1}}],["请关注我们的仓库",{"2":{"422":1}}],["请在",{"2":{"422":1}}],["请给我们",{"2":{"422":1}}],["请尽量确保其可重现性",{"2":{"399":1}}],["请暂停训练",{"2":{"399":1}}],["请偏向于选择延长训练时间",{"2":{"381":1}}],["请参阅推断模式",{"2":{"479":1}}],["请参阅",{"2":{"394":1,"472":1,"479":1,"496":1}}],["请参阅具有未知约束的贝叶斯优化是处理此问题的绝佳方法",{"2":{"379":1}}],["请参阅batchnorm的实现细节",{"2":{"362":1}}],["请修改实验并重新运行",{"2":{"372":1}}],["请修复瓶颈或使用较小的batch",{"2":{"358":1}}],["请注意效果",{"2":{"359":1}}],["请注意",{"2":{"356":1,"400":1,"403":1,"473":1,"496":1,"510":1,"537":1,"538":1,"539":1,"540":1,"544":1}}],["请尝试找到一篇尽可能接近手头问题的相关论文",{"2":{"355":1}}],["请确保您满足以下假设",{"2":{"354":1}}],["请记住",{"2":{"150":1}}],["请分析上图中参数的类别",{"2":{"27":1}}],["现已合并到open",{"2":{"802":1}}],["现有的系统也无法自动适应所有场景",{"2":{"337":1}}],["现有系统浪费了60",{"2":{"333":1}}],["现在我也并不会觉得我当时的理解有错",{"2":{"878":1}}],["现在我们应该有足够的信息来计算细胞状态",{"2":{"149":1}}],["现在看来以前我真的挺无知的",{"2":{"878":1}}],["现在动不动就是大模型",{"2":{"697":1}}],["现在这个人工智能的新纪元时代",{"2":{"697":1}}],["现在的bert",{"2":{"641":1}}],["现在",{"2":{"401":1}}],["现在可以通过一条简单的命令尝试vllm",{"2":{"332":1}}],["现在有一个预测后一步位置梯度的步骤",{"2":{"269":1}}],["现代神经网络是一种非线性统计性数据建模工具",{"2":{"5":1}}],["你是要选择时间最短的最先安排",{"2":{"973":1}}],["你最终到达了这座山的最高点",{"2":{"970":1}}],["你要将饼干分给这些小孩",{"2":{"951":1}}],["你要用python爬取三个网页的数据",{"2":{"795":1}}],["你能够毛慢感受到这里的",{"2":{"948":1}}],["你能够保证每次都省下更多的钱",{"2":{"938":1}}],["你优先处理紧急任务",{"2":{"943":1}}],["你今天有很多任务要做",{"2":{"941":1}}],["你有",{"2":{"939":1}}],["你在生活中已经不自觉地应用了这种算法思维",{"2":{"925":1}}],["你在选择工作时",{"2":{"925":1}}],["你都会选当前看起来最好的那个选项",{"2":{"921":1}}],["你可能会发现更高的山峰",{"2":{"970":1}}],["你可能会回忆上次用钥匙的地点",{"2":{"920":1}}],["你可能不会先计划好所有要买的东西",{"2":{"921":1}}],["你可以每次选择最便宜的出行方式",{"2":{"938":1}}],["你可以在不重新运行实验的情况下",{"2":{"401":1}}],["你可以将其视为网络的",{"2":{"145":1}}],["你需要按顺序完成这些任务",{"2":{"917":1}}],["你早上要上班",{"2":{"917":1}}],["你现在得过且过",{"2":{"880":1}}],["你唯一能做的",{"2":{"880":1}}],["你去阻止",{"2":{"878":1}}],["你内心深处依旧是愿意",{"2":{"878":1}}],["你自然而然会感受到",{"2":{"878":1}}],["你感到反感或者厌恶",{"2":{"878":1}}],["你看到别人随地吐痰",{"2":{"878":1}}],["你只能当做理解过程中的一点参考",{"2":{"876":1}}],["你说说",{"2":{"875":1}}],["你觉得他们之间的有何种关系",{"2":{"853":1}}],["你会根据重要性或紧急程度来决定先做什么",{"2":{"919":1}}],["你会不自觉地心怀感恩",{"2":{"878":1}}],["你会一个一个爬吗",{"2":{"795":1}}],["你会如何设计呢",{"2":{"435":1}}],["你该怎么讲",{"2":{"702":1}}],["你应该按照以下方式编写代码",{"2":{"533":1}}],["你想要更改评估指标",{"2":{"401":1}}],["你找到了一组超参数",{"2":{"401":1}}],["你使用随机搜索来寻找最优的超参数组合",{"2":{"401":1}}],["你将",{"2":{"148":1}}],["你还需要将隐藏状态和当前输入传递到",{"2":{"148":1}}],["接触前沿技术",{"2":{"858":1}}],["接受来自其他进程或节点的消息",{"2":{"796":1}}],["接口所有的普通参数",{"2":{"733":1}}],["接口中的方法名与映射文件中的sql语句id",{"2":{"730":1}}],["接下来的目标就是找到一个等价的位置编码方式",{"2":{"646":1}}],["接下来的指南中我们做出了这些假设",{"2":{"364":1}}],["接下来",{"2":{"369":1}}],["接收方可以通过标签区分不同的消息",{"2":{"809":1}}],["接收端处理收到的消息",{"2":{"796":1}}],["接收消息",{"2":{"796":2}}],["接收一个调度器列表",{"2":{"549":1}}],["接收key",{"2":{"327":1}}],["接收输入",{"2":{"24":1}}],["接着从剩下的",{"2":{"933":1}}],["接着对每个",{"2":{"648":1}}],["接着进行层标准化",{"2":{"196":1}}],["接着再转换为输出",{"2":{"160":1}}],["接近1",{"2":{"605":1}}],["接近",{"2":{"147":2}}],["忘记该遗忘的",{"2":{"145":1}}],["记住一个人的好",{"2":{"880":1}}],["记住该记住的",{"2":{"145":1}}],["记得还要起点",{"2":{"845":1}}],["记录日志",{"2":{"880":1}}],["记录当前idx",{"2":{"634":2}}],["记录对应位置相应标签结尾的路径中",{"2":{"634":1}}],["记录正确预测样本的数量",{"2":{"391":1}}],["记忆",{"2":{"145":1}}],["记忆力",{"2":{"132":1}}],["减法",{"2":{"706":1}}],["减小学习率",{"2":{"547":1}}],["减小特征图尺寸",{"2":{"92":1}}],["减少冗余通信",{"2":{"812":1}}],["减少或是保持不变都有可能",{"2":{"357":1}}],["减少开发周期的延迟",{"2":{"357":1}}],["减少过拟合的风险",{"2":{"341":1}}],["减少缓存的开销",{"2":{"338":1}}],["减少内存占用",{"2":{"338":1}}],["减少了网络消耗并简化了对频繁弹性扩展的依赖",{"2":{"329":1}}],["减少了随机性带来的波动",{"2":{"262":1}}],["减少震荡现象",{"2":{"266":1}}],["减少参数更新方向的震荡",{"2":{"266":1}}],["减少训练时间和资源消耗",{"2":{"180":1}}],["减少短期记忆的影响",{"2":{"145":1}}],["训练和预测的时间效率将大为提高",{"2":{"652":1}}],["训练和推理时dropout",{"2":{"346":1}}],["训练和推理时这个算子表现有何不同",{"2":{"114":1}}],["训练目标则是预测出被遮盖掉的文本",{"2":{"621":1}}],["训练出了类似",{"2":{"620":1}}],["训练编码器",{"2":{"619":1}}],["训练这些",{"2":{"616":1}}],["训练流程图",{"0":{"595":1}}],["训练流程的最佳学习率是多少",{"2":{"369":1}}],["训练周期数",{"2":{"544":1}}],["训练过程中断",{"2":{"521":1}}],["训练过程也可以更快收敛",{"2":{"178":1}}],["训练中的保存和加载",{"0":{"521":1},"1":{"522":1,"523":1}}],["训练中期突然出现的梯度尖峰",{"2":{"410":1}}],["训练中期突然出现的不稳定",{"2":{"405":1}}],["训练完成",{"2":{"500":1}}],["训练循环",{"2":{"500":1,"541":1}}],["训练脚本",{"2":{"500":1}}],["训练策略",{"2":{"484":1}}],["训练步骤的数量可能也需要进行调整",{"2":{"412":1}}],["训练步数",{"2":{"363":1}}],["训练早期中存在的不稳定",{"2":{"405":1}}],["训练次数试验次数小于10",{"2":{"400":1}}],["训练所需的配置和运行命令",{"2":{"393":1}}],["训练误差或某些替代评估指标来找到最佳试验",{"2":{"401":1}}],["训练误差会无限地改善",{"2":{"383":1}}],["训练误差在训练过程中增加",{"2":{"375":1}}],["训练集",{"2":{"381":1}}],["训练集所需的step数",{"2":{"381":1}}],["训练集和验证集的性能在最后的训练步骤之前很久就饱和了吗",{"2":{"375":1}}],["训练更长的时间并没有多大帮助",{"2":{"380":1}}],["训练更多的步数可以提高性能并使超参数调整更容易",{"2":{"363":1}}],["训练受限于我们愿意等待的时间",{"2":{"380":1}}],["训练损失或比平均值差很多标准差的训练误差的点",{"2":{"379":1}}],["训练数据集",{"2":{"497":1}}],["训练数据",{"2":{"378":1}}],["训练数据的shuffles",{"2":{"378":1}}],["训练程序方差",{"2":{"378":1}}],["训练结束时试验是否仍能改进",{"2":{"375":1}}],["训练或验证误差是否存在较高的步与步之间的方差",{"2":{"375":1}}],["训练时噪音的严重程度是和时间步有关的",{"2":{"595":1}}],["训练时间更长可能会略微减少训练误差",{"2":{"380":1}}],["训练时间总是",{"2":{"380":1}}],["训练时间的大幅加速可能会在过程的早期非常有利",{"2":{"360":1}}],["训练时间",{"2":{"359":1}}],["训练时流程",{"0":{"177":1},"1":{"178":1,"179":1}}],["训练吞吐量也应该加倍",{"2":{"358":1}}],["训练吞吐量",{"2":{"358":2}}],["训练好了之后",{"2":{"180":1}}],["训练起来非常艰难",{"2":{"177":1}}],["训练速度稍快一些",{"2":{"156":1}}],["训练",{"2":{"143":1}}],["无奈时候的自己",{"2":{"880":1}}],["无参",{"2":{"726":1}}],["无监督学习",{"2":{"616":1}}],["无振幅缩放",{"2":{"543":1}}],["无梯度模式可能非常有用",{"2":{"478":1}}],["无梯度模式",{"0":{"478":1},"2":{"476":1,"477":1}}],["无缝整合",{"2":{"444":1}}],["无意间的同步屏障干扰数据管道预读取",{"2":{"387":1}}],["无论你从哪个方向来看",{"2":{"970":1}}],["无论是否满足都要处理下一个饼干",{"2":{"957":1}}],["无论是否发生oom",{"2":{"328":1}}],["无论是做选择",{"2":{"928":1}}],["无论是选择日常任务的顺序",{"2":{"927":1}}],["无论是关于工作",{"2":{"881":1}}],["无论搜索算法如何",{"2":{"370":1}}],["无法创建普通用户",{"2":{"883":1}}],["无法直接走官方售后",{"2":{"875":1}}],["无法在由自动求导记录的计算中使用在推断模式下创建的张量",{"2":{"479":1}}],["无法在合理的时间内计算完整离线评估集的指标",{"2":{"391":1}}],["无法处理的不稳定影响",{"2":{"406":1}}],["无法处理很长的输入序列",{"2":{"143":1}}],["无法重叠通信延迟",{"2":{"328":1}}],["无需连续",{"0":{"334":1}}],["无需进行任何更改",{"2":{"328":1}}],["无需手动调整梯度",{"2":{"279":1}}],["无需再变化",{"2":{"180":1}}],["无数的资源积累",{"2":{"190":1}}],["无分支",{"2":{"28":1}}],["意不尽悟",{"2":{"876":1,"878":1}}],["意指是一个电脑系统中",{"2":{"680":1}}],["意义为是否需要保持图",{"2":{"468":1}}],["意在降低层参数的训练敏感性",{"2":{"406":1}}],["意味着尽可能避免花里胡哨的东西",{"2":{"363":1}}],["意图识别",{"0":{"142":1}}],["意为误差反向传播",{"2":{"25":1}}],["正好凑齐",{"2":{"947":1}}],["正真领悟了这两句话的含义之后",{"2":{"878":1}}],["正则化",{"2":{"384":1,"484":1}}],["正则化技术引入的超参数通常是冗余超参数",{"2":{"369":1}}],["正则化具有k",{"2":{"345":1}}],["正则化可以限制模型的复杂度",{"2":{"341":1}}],["正则化可以帮助减少模型参数的数量",{"2":{"341":1}}],["正则化在数据集规模较小",{"2":{"341":1}}],["正则化在以下情况下容易出现",{"2":{"341":1}}],["正则化在深度学习的出现前就已经被使用了数十年",{"2":{"340":1}}],["正则化概念",{"0":{"340":1}}],["正如期望的那样",{"2":{"475":1}}],["正如上面所述",{"2":{"475":1}}],["正如上述性能结果所示",{"2":{"334":1}}],["正如在序言中所讨论的",{"2":{"422":1}}],["正如figure",{"2":{"403":1}}],["正如之前讨论的那样",{"2":{"400":1}}],["正如图2所示",{"2":{"328":1}}],["正如我们在下一节中所展示的",{"2":{"327":1}}],["正如我们将展示的那样",{"2":{"219":1,"305":1}}],["正向的时候",{"2":{"464":1}}],["正向",{"2":{"463":1}}],["正向forward",{"2":{"462":1}}],["正向激活的分布和反向激活梯度的分布尽量维持一致",{"2":{"244":1}}],["正向和反向用到权重是同一份数据吗",{"2":{"140":1}}],["正确预测对应的词的那一维的概率大小",{"2":{"181":1}}],["正所谓一步错",{"2":{"177":1}}],["正反向的结果",{"2":{"140":1}}],["按回车接受默认设置",{"2":{"827":1}}],["按以下快捷键可以快速进入插入模式",{"2":{"778":1}}],["按文件名查找",{"2":{"765":1}}],["按",{"2":{"752":3,"774":3,"786":1,"792":1}}],["按序",{"2":{"671":1}}],["按序列展开形式如下",{"2":{"169":1}}],["按优先顺序列出",{"2":{"544":1}}],["按设备和数据类型对张量的列表进行分组",{"2":{"509":1}}],["按位取反操作符",{"2":{"443":1}}],["按转移概率的降序排列",{"2":{"384":1}}],["按行",{"2":{"223":1,"312":1}}],["按照提示",{"2":{"827":1}}],["按照实现方式划分",{"0":{"802":1}}],["按照处理机划分",{"0":{"801":1}}],["按照other",{"2":{"445":1}}],["按照另一个tensor的",{"2":{"441":1}}],["按照某个维度对张量进行反转操作",{"2":{"441":1}}],["按照前向传播最后的示例",{"2":{"249":1}}],["按照高斯分布来初始化的话",{"2":{"245":1}}],["按照glorot条件",{"2":{"245":1}}],["按照我们之前encoder",{"2":{"191":1}}],["按照对齐方式a翻译成x的概率",{"2":{"190":1}}],["按照逻辑先后顺序反向传播算法",{"2":{"27":1}}],["按时间步展开如下",{"0":{"136":1}}],["结果发现会有错误",{"2":{"889":1}}],["结果发现只有这些api",{"2":{"889":1}}],["结果他的回答让我有些意外",{"2":{"878":1}}],["结果",{"2":{"656":1}}],["结果是",{"2":{"533":1}}],["结合第二句",{"2":{"878":1}}],["结合我们的生活就知道",{"2":{"878":1}}],["结合人工智能算法",{"2":{"859":1}}],["结合共享内存和分布式内存模型",{"2":{"801":1}}],["结合了",{"2":{"620":1}}],["结合缩放的动量使用没有明确的理论动机",{"2":{"294":1}}],["结束值",{"2":{"827":1}}],["结束进程",{"2":{"756":1}}],["结束",{"2":{"328":2,"827":1}}],["结构体或对象",{"2":{"796":1}}],["结构的纯",{"2":{"619":1}}],["结构的模型",{"2":{"616":1}}],["结构与",{"2":{"616":1}}],["结构用于序列标注",{"2":{"616":1}}],["结构",{"0":{"601":1}}],["结构图如下",{"2":{"146":1}}],["结构如下",{"0":{"141":1}}],["结构详解",{"0":{"134":1},"1":{"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1}}],["结论",{"0":{"241":1,"934":1},"2":{"14":1,"54":1,"128":1,"729":1}}],["便于开发者编译和执行",{"2":{"822":1}}],["便于统一管理和优化",{"2":{"724":1}}],["便应运而生了",{"2":{"132":1}}],["便是进行相反的操作",{"2":{"61":1}}],["句子翻译",{"2":{"132":1}}],["彼此之间没有连续性",{"2":{"132":1}}],["就行",{"2":{"973":1}}],["就行了",{"2":{"190":1}}],["就一句话",{"2":{"969":1}}],["就只移动饼干的指针",{"2":{"956":1}}],["就能感悟并实践",{"2":{"878":1}}],["就把价格说的高高的",{"2":{"875":1}}],["就把机器翻译这么大的一个工程给包下来",{"2":{"191":1}}],["就叫做",{"2":{"659":1}}],["就像做饭时的菜谱",{"2":{"917":1}}],["就像要去破译密码",{"2":{"654":1}}],["就像卷积网络是专门用于处理网格化数据",{"2":{"132":1}}],["就需要了解它们的实际能力和局限性",{"2":{"622":1}}],["就",{"2":{"468":1}}],["就应该将其应用于baseline模型",{"2":{"409":1}}],["就应该可以重现六个月前的研究",{"2":{"401":1}}],["就很难计算出适合内存的batch",{"2":{"358":1}}],["就失去了正则化的效果",{"2":{"348":1}}],["就可以表达出任意长度的相对位置",{"2":{"643":1}}],["就可以进行操作",{"2":{"457":1}}],["就可以实现多卡的超长",{"2":{"326":1}}],["就可以达到我们的目的",{"2":{"216":1}}],["就不需要从零开始训练一个神经网络了",{"2":{"254":1}}],["就会按",{"2":{"538":1}}],["就会发生过度拟合",{"2":{"375":1}}],["就会导致网络优化陷入困境",{"2":{"238":1}}],["就会造成翻译精度的下降",{"2":{"173":1}}],["就称为",{"2":{"190":1}}],["就终止beam",{"2":{"186":1}}],["就意味着候选结果会一直增多吗",{"2":{"186":1}}],["就意味着到当前这一步为止",{"2":{"185":1}}],["就是迎接这些问题",{"2":{"880":1}}],["就是专业",{"2":{"875":1}}],["就是一个点一个点把坐标绘制出来",{"2":{"838":1}}],["就是让概率密度函数朝着",{"2":{"659":1}}],["就是经过样本训练后",{"2":{"653":1}}],["就是",{"2":{"648":1}}],["就是比较邻近的位置",{"2":{"644":1}}],["就是由于换了clip模型",{"2":{"608":1}}],["就是上一层传下来的梯度值",{"2":{"457":1}}],["就是显而易见的",{"2":{"326":1}}],["就是基于这种切分的方法",{"2":{"326":1}}],["就是给在较短的序列后面填充",{"2":{"215":1}}],["就是每个头",{"2":{"208":1}}],["就是求y这个句子的概率",{"2":{"190":1}}],["就是x的最佳翻译了",{"2":{"190":1}}],["就是使用",{"2":{"183":1}}],["就是m",{"2":{"10":1}}],["就没问题吗",{"2":{"178":1}}],["就表示对h0和x1各做了一次变换",{"2":{"160":1}}],["依旧能够对你的生活有启发作用",{"2":{"950":1}}],["依次点开",{"2":{"889":1}}],["依次类推",{"2":{"160":1,"627":1}}],["依然可以保持",{"2":{"619":1}}],["依然只能与仅含输出层的单层神经网络等价",{"2":{"120":1}}],["依据上文的讨论及激活函数的发展规律",{"2":{"130":1}}],["∑jexp",{"2":{"129":1}}],["平",{"2":{"880":1}}],["平常心",{"2":{"880":1}}],["平常最常用到的就是pca",{"2":{"652":1}}],["平台的核心版本",{"2":{"703":1}}],["平衡实验的信息量和成本",{"0":{"371":1}}],["平衡模型的拟合能力和泛化能力",{"2":{"341":1}}],["平滑参数更新路径",{"2":{"267":1}}],["平滑的激活函数允许更好的信息深入神经网络",{"2":{"128":1}}],["平行语料",{"2":{"190":1}}],["平均池化在每个池化窗口中选择特征值的平均值作为输出",{"2":{"94":1}}],["∞",{"2":{"127":1}}],["→",{"2":{"127":1,"383":1,"385":1}}],["βi",{"2":{"644":1}}],["β​i",{"2":{"644":1}}],["β​2​​",{"2":{"356":1}}],["β​1​​",{"2":{"356":1}}],["β2",{"2":{"356":1}}],["β1",{"2":{"356":1,"400":2}}],["β",{"2":{"127":2}}],["βx",{"2":{"127":2}}],["≈​2​​1​​×",{"2":{"126":1}}],["≈12×",{"2":{"126":1}}],["≈xσ",{"2":{"126":2}}],["研究领域的模型",{"2":{"617":1}}],["研究中的试验次数会对结果产生重大影响",{"2":{"403":1}}],["研究在",{"2":{"376":1}}],["研究的目的是使用目标超参数的不同值运行训练流程",{"2":{"370":1}}],["研究",{"2":{"370":1,"802":1}}],["研究人员提出了flashattention",{"2":{"325":1}}],["研究人员和从业者致力于开发和改进相应的算法和技术",{"2":{"188":1}}],["研究人员和工程师通常会尝试两种方法",{"2":{"156":1}}],["研究人员在所有编码器模块中都使用了",{"2":{"126":1}}],["研究者们对relu",{"2":{"124":1}}],["声名远播的无监督预训练模型",{"2":{"126":1}}],["上次还是高三那会",{"2":{"880":1}}],["上上周放假重温了",{"2":{"880":1}}],["上周五",{"2":{"875":1}}],["上每次增加一个单位",{"2":{"838":1}}],["上测试",{"2":{"827":1}}],["上生成",{"2":{"827":1}}],["上一篇笔记我们已经讲了进程信号量机制相关的知识",{"2":{"695":1}}],["上一篇笔记我们已经讲了进程通信相关的知识",{"2":{"674":1}}],["上一位置最佳tags的索引",{"2":{"634":1}}],["上节中",{"2":{"627":1}}],["上图最上边的解码过程可以看出",{"2":{"624":1}}],["上图是dropout示意图",{"2":{"346":1}}],["上方我们添加了一个crf层",{"2":{"624":1}}],["上面的命令将启动",{"2":{"822":1}}],["上面我们已经说了",{"2":{"608":1}}],["上面绘制了每个试验预算的最佳性能的箱线图",{"2":{"403":1}}],["上述属性那几个属性最为关键",{"2":{"508":1}}],["上述子模块在",{"2":{"488":1}}],["上述做法还有优化空间吗",{"2":{"485":1}}],["上述正是模型中可以使用控制流语句的原因",{"2":{"466":1}}],["上的",{"2":{"509":2}}],["上的张量",{"2":{"441":1}}],["上的被引用次数却只有",{"2":{"126":1}}],["上打开一个新的讨论主题",{"2":{"422":1}}],["上进行了",{"2":{"403":1}}],["上训练的",{"2":{"376":1}}],["上下文并行",{"2":{"328":1}}],["上读写中间结果",{"2":{"319":1}}],["上比标准注意力快3x倍",{"2":{"227":1,"317":1}}],["上实例化大型的𝑁×𝑁注意力矩阵",{"2":{"222":1,"314":1}}],["上",{"2":{"217":1,"303":1,"332":1,"338":1,"366":2,"496":3,"510":1,"634":1,"780":1,"790":1}}],["上三角的值全为0",{"2":{"216":1}}],["上句中的",{"2":{"215":1}}],["上式每一项可以分别理解为",{"2":{"644":1}}],["上式三个权重矩阵w每个时间步",{"2":{"138":1}}],["上式计算量太大",{"2":{"126":1}}],["上升",{"2":{"26":1}}],["学不是学习书本知识",{"2":{"878":1}}],["学",{"2":{"878":5}}],["学而时习",{"2":{"878":2}}],["学而时习之",{"0":{"877":1},"1":{"878":1,"879":1},"2":{"868":1,"877":1,"878":1}}],["学而篇",{"0":{"876":1},"1":{"877":1,"878":1,"879":1}}],["学前须知",{"2":{"794":1}}],["学到的线性映射",{"2":{"208":1}}],["学习图形学可以培养将理论转化为实践的能力",{"2":{"858":1}}],["学习图形学会锻炼数学建模和复杂算法实现的能力",{"2":{"858":1}}],["学习glsl",{"2":{"857":1}}],["学习如何通过opengl",{"2":{"857":1}}],["学习如何学习",{"2":{"4":1}}],["学习正交投影和透视投影的概念",{"2":{"857":1}}],["学习基本几何图形的表示方法",{"2":{"857":1}}],["学习",{"2":{"853":1,"881":1}}],["学习策略与建议",{"0":{"828":1},"1":{"829":1,"830":1,"831":1}}],["学习框架图",{"2":{"794":1}}],["学习前要自己配置一个linux虚拟机",{"2":{"794":1}}],["学习前一定要自己配置一个linux虚拟机",{"2":{"735":1}}],["学习前需要掌握",{"2":{"719":1}}],["学习ai算法技术",{"2":{"672":1}}],["学习方差取决于试验次数和搜索空间",{"2":{"378":1}}],["学习率可以同时被其他操作器在此调度器之外修改",{"2":{"545":1}}],["学习率是控制模型参数更新幅度的超参数",{"2":{"531":1}}],["学习率是一个冗余超参数",{"2":{"369":1}}],["学习率调度器",{"0":{"534":1}}],["学习率调度应该在优化器更新之后应用",{"2":{"533":1}}],["学习率调度是根据训练的迭代次数或验证误差的变化动态地调整学习率",{"2":{"531":1}}],["学习率调度",{"2":{"531":1}}],["学习率调度参数",{"2":{"369":1}}],["学习率调整是一种重要的技术",{"2":{"531":1}}],["学习率的控制",{"2":{"484":1}}],["学习率预热对解决训练不稳定性的有益影响",{"2":{"409":1}}],["学习率预热",{"0":{"407":1},"1":{"408":1,"409":1}}],["学习率衰减计划",{"2":{"384":1}}],["学习率也可以设置为",{"2":{"287":1}}],["学习率",{"2":{"284":1,"361":1,"376":1,"412":1}}],["学习率就会收缩并最终会变得非常小使得训练提前结束",{"2":{"280":1}}],["学习轨迹可能穿过了很多不同的结构",{"2":{"283":1}}],["学习到的主要是两种语言之间的对应关系",{"2":{"190":1}}],["学生也积极学习",{"2":{"179":1}}],["学术上的计算过程如下",{"2":{"152":1}}],["学者提出了gelu激活函数",{"2":{"126":1}}],["都会经过一定的推理和判断",{"2":{"925":1}}],["都会在后边叠加一个非线性的激活函数",{"2":{"120":1}}],["都到19岁左右了",{"2":{"878":1}}],["都没有让我完全理解孔子想传达的思想",{"2":{"878":1}}],["都可以看作是在运用算法",{"2":{"916":1}}],["都可以达到处理任意长度文本的需求",{"2":{"643":1}}],["都可以像往常一样工作",{"2":{"328":1}}],["都起作用",{"2":{"475":1}}],["都对应一个反向的函数",{"2":{"462":1}}],["都需要进行审核",{"2":{"424":1}}],["都与max",{"2":{"381":1}}],["都是为了优化资源的使用",{"2":{"926":1}}],["都是我们自己制定的",{"2":{"917":1}}],["都是尽最大可能让进程去占用资源",{"2":{"798":1}}],["都是一步步的指引",{"2":{"917":1}}],["都是一种资源",{"2":{"680":1}}],["都是一个资源",{"2":{"680":1}}],["都是将",{"2":{"659":1}}],["都是多维的",{"2":{"647":1}}],["都是leaf",{"2":{"462":1}}],["都是sparse的",{"2":{"444":1}}],["都是试验方差的潜在来源",{"2":{"378":1}}],["都是独立同分布的",{"2":{"249":1}}],["都是考虑了所有的输入向量才生成出来的",{"2":{"202":1}}],["都预测出概率最大的那个词",{"2":{"183":1}}],["都输入完才结束",{"2":{"179":1}}],["都送给下一步作为输入",{"2":{"176":1}}],["都有提高",{"2":{"128":1}}],["都希望将",{"2":{"126":1}}],["效果大的工作",{"2":{"926":1}}],["效果最优的一条路径",{"2":{"624":1}}],["效果往往并不好",{"2":{"616":1}}],["效果很好",{"2":{"282":1,"572":1}}],["效果展示",{"0":{"297":1},"2":{"270":1}}],["效果也一般",{"2":{"189":1}}],["效果",{"0":{"227":1,"317":1},"2":{"125":1,"193":1,"217":1,"303":1}}],["效果会变差",{"2":{"86":1}}],["虽同样都是激活了负半轴",{"2":{"125":1}}],["虽然贪心策略不一定总能找到最优解",{"2":{"929":1}}],["虽然是二倍速快看",{"2":{"880":1}}],["虽然硬件不支持真正的并行计算",{"2":{"799":1}}],["虽然可以根据模板",{"2":{"620":1}}],["虽然新的",{"2":{"616":1,"618":1}}],["虽然不一定需要完全理解其中的所有内容",{"2":{"470":1}}],["虽然这可能效率稍低",{"2":{"402":1}}],["虽然我们不知道最好的方案是什么",{"2":{"397":1}}],["虽然我们不能一一列举",{"2":{"375":1}}],["虽然我们只想采用能够产生真正改进的更改",{"2":{"378":1}}],["虽然在许多情况下",{"2":{"375":1}}],["虽然在每一步都会考虑k个候选项",{"2":{"186":1}}],["虽然深度学习已经从少数学术研究实验室中实践的机器学习方法发展成为为数十亿人使用的产品提供动力的技术",{"2":{"353":1}}],["虽然有些系统能够在某些场景中处理kv",{"2":{"337":1}}],["虽然随机梯度下降仍然是非常受欢迎的优化方法",{"2":{"263":1}}],["虽然已经提出了梯度检查点技术来减少所需的最大内存量",{"2":{"228":1,"318":1}}],["虽然",{"2":{"120":1,"510":1}}],["～4",{"2":{"123":1}}],["导航软件中用来找最短路径的算法",{"2":{"927":1}}],["导入mybatis相关",{"2":{"726":1}}],["导入mybatis",{"2":{"725":1}}],["导读2",{"2":{"660":1}}],["导读",{"2":{"660":1}}],["导数",{"2":{"659":2}}],["导数相乘很容易造成梯度弥散",{"2":{"121":1}}],["导致模型的泛化能力下降的问题",{"2":{"645":1}}],["导致模型过度依赖训练数据中的噪声和异常点",{"2":{"341":1}}],["导致反向传播时计算不准确",{"2":{"462":1}}],["导致反向时",{"2":{"323":1}}],["导致训练过程中出现不稳定性",{"2":{"405":1}}],["导致步间方差的最大可能的是batch的方差",{"2":{"375":1}}],["导致行业专家和搬砖工人门纷纷下岗",{"2":{"191":1}}],["导致相应参数永远不会被更新",{"2":{"122":1}}],["脆弱",{"2":{"122":1}}],["缺点",{"0":{"280":1},"2":{"122":1}}],["人生处处是算法",{"2":{"966":1}}],["人生也就到中后期了",{"2":{"831":1}}],["人",{"2":{"878":1}}],["人不知",{"2":{"878":2}}],["人不知而不愠",{"2":{"877":2,"878":1}}],["人的本性",{"0":{"966":1},"1":{"967":1,"968":1,"969":1,"970":1,"971":1,"972":1,"973":1,"974":1,"975":1},"2":{"868":1}}],["人性",{"2":{"831":1}}],["人际关系",{"2":{"831":1}}],["人们还无法保证内存永不掉电",{"2":{"722":1}}],["人为输入或随机输入数据",{"2":{"653":1}}],["人类大脑神经元大约只有",{"2":{"122":1}}],["人工神经网络能够类似人一样具有简单的决定能力和简单的判断能力",{"2":{"5":1}}],["人工神经网络",{"2":{"5":1}}],["人工智能是什么",{"0":{"2":1}}],["速度也可能令人惊讶地缓慢",{"2":{"332":1}}],["速度快",{"2":{"122":1}}],["速度慢",{"2":{"122":1}}],["失活",{"2":{"122":1}}],["造成信息损失",{"2":{"122":1}}],["比较",{"2":{"644":1}}],["比较本地",{"2":{"431":1}}],["比较足够多目标超参数的不同值",{"2":{"371":1}}],["比较batch",{"2":{"359":1}}],["比较优化器的性能也是一项艰巨的任务",{"2":{"356":1}}],["比较大时",{"2":{"206":1}}],["比tgi高出最多3",{"2":{"332":1}}],["比",{"2":{"217":1,"303":1}}],["比不带scale",{"2":{"206":1}}],["比赛中使用了激活函数",{"2":{"122":1}}],["比如你要规划任务",{"2":{"973":1}}],["比如你想讲给别人某个领域的东西",{"2":{"702":1}}],["比如制定学习计划",{"2":{"922":1}}],["比如工作时",{"2":{"919":1}}],["比如说",{"2":{"917":1}}],["比如实时光线追踪",{"2":{"858":1}}],["比如mpi与openmp的结合使用",{"2":{"801":1}}],["比如银行账号等",{"2":{"722":1}}],["比如样本为很多个人脸",{"2":{"653":1}}],["比如手写数字",{"2":{"652":1}}],["比如8～11",{"2":{"644":1}}],["比如最大长度为512",{"2":{"641":1}}],["比如为",{"2":{"468":1}}],["比如研究中检查点的最佳性能",{"2":{"393":1}}],["比如固定步长间隔评估一次",{"2":{"390":1}}],["比如llama",{"2":{"328":1}}],["比如已经走了t步",{"2":{"186":1}}],["比如",{"2":{"11":2,"21":1,"369":1,"492":1,"724":1,"801":1,"878":1,"924":1,"926":1,"927":1}}],["首单词发射分数",{"2":{"632":1}}],["首次提出了修正线性单元",{"2":{"122":1}}],["首先还是看这张图",{"2":{"674":1,"695":1}}],["首先计算其对应的",{"2":{"648":1}}],["首先将词语的内容与相对位置分离",{"2":{"619":1}}],["首先将词嵌入维度与隐藏维度解耦以减少模型参数",{"2":{"619":1}}],["首先选择一个完善且常用的模型架构来开始工作",{"2":{"355":1}}],["首先是转换检查点",{"2":{"220":1,"306":1}}],["首先",{"2":{"58":1,"86":1,"148":1,"149":1,"150":1,"184":1,"213":1,"294":1,"327":1,"444":1,"956":1}}],["整理来源",{"2":{"908":1}}],["整数+加法",{"2":{"848":1}}],["整数和浮点计算分开",{"2":{"325":1}}],["整除时",{"2":{"390":1}}],["整个过程走下来",{"2":{"831":1}}],["整个decoding",{"2":{"186":1}}],["整个seq2seq流程可以表述如下",{"2":{"174":1}}],["整个encoder",{"2":{"172":1}}],["整流线性单位函数",{"2":{"122":1}}],["整体最优包含了子问题最优",{"2":{"974":1}}],["整体实现方式",{"2":{"883":1}}],["整体该博客",{"0":{"864":1}}],["整体流程图",{"0":{"594":1}}],["整体图",{"2":{"152":1}}],["整体结构",{"0":{"145":1,"593":1},"1":{"594":1,"595":1,"596":1,"597":1,"598":1,"599":1}}],["整体介绍",{"0":{"120":1},"1":{"121":1,"122":1}}],["整体完善图",{"2":{"64":1}}],["另",{"2":{"248":1,"445":1}}],["另如果采用均匀分布初始化的话",{"2":{"245":1}}],["另外在效果上",{"2":{"217":1,"303":1}}],["另外",{"2":{"121":1,"126":1,"287":1}}],["另一个流行的开源mpi实现",{"2":{"802":1}}],["另一个要访问该资源的进程必须等待",{"2":{"678":1}}],["另一个包含非完整的反向传播钩子",{"2":{"496":1}}],["另一个是第二项",{"2":{"36":1}}],["另一方面",{"2":{"353":1,"360":1,"363":1}}],["另一方面在人工智能学的人工感知领域",{"2":{"5":1}}],["另一组使用sp",{"2":{"329":1}}],["另一种思考方式是",{"2":{"320":1}}],["另一部分为前面累计下来的梯度值",{"2":{"271":1}}],["−√​​​n​^​​​i​​​​6​​​​​",{"2":{"252":1}}],["−√​​n​i​​​​6​​​​​",{"2":{"252":1}}],["−6n^i",{"2":{"252":1}}],["−6ni",{"2":{"252":1}}],["−6nj+nj+1",{"2":{"245":1}}],["−​√​n​j​​+n​j+1​​​​​​​√​6​​​​​",{"2":{"245":1}}],["−m",{"2":{"225":8,"313":8}}],["−",{"2":{"181":2,"247":2}}],["−log",{"2":{"181":8}}],["−3",{"2":{"121":1}}],["−1",{"2":{"48":4}}],["且所有张量都是本地的并在",{"2":{"510":1}}],["且假设更新的过程中权重的均值一直是0",{"2":{"248":1}}],["且均值都为0",{"2":{"245":1}}],["且weight正态分布时",{"2":{"125":1}}],["且可以减少参数间的相互依赖",{"2":{"122":1}}],["且模型训练的时间复杂度较高",{"2":{"121":1}}],["且其导数范围为",{"2":{"121":1}}],["且不在",{"2":{"121":1}}],["且容易出现过拟合的情况",{"2":{"95":1}}],["右边或者右上",{"2":{"844":1}}],["右边是应用了dropout之后的网络结构",{"2":{"346":1}}],["右切换分屏",{"2":{"790":1}}],["右移动",{"2":{"780":1}}],["右侧真除法使用运算符",{"2":{"441":1}}],["右侧除法的行为",{"2":{"441":1}}],["右侧减法",{"2":{"441":1}}],["右图",{"2":{"222":1,"314":1}}],["右",{"2":{"121":1}}],["经济和环境成本都要低得多",{"2":{"617":1}}],["经常与前面的三种方法混淆",{"2":{"474":1}}],["经验上已经发现",{"2":{"277":1}}],["经过",{"2":{"215":1}}],["经过它激活得到的数据为非",{"2":{"121":1}}],["经典的相对位置编码",{"0":{"643":1}}],["经典结构可表示如下",{"2":{"169":1}}],["经典rnn的适用范围比较小",{"2":{"161":1}}],["经典rnn的计算图如下",{"0":{"137":1}}],["经典rnn",{"0":{"143":1}}],["经典激活函数",{"0":{"9":1}}],["左边是完整的神经网络",{"2":{"346":1}}],["左图",{"2":{"222":1,"314":1}}],["左",{"2":{"121":1,"780":1}}],["由intel提供",{"2":{"802":1}}],["由我们选择超参数的程序引起的结果变化",{"2":{"378":1}}],["由方差和期望的关系",{"2":{"248":1}}],["由此",{"2":{"243":1}}],["由贝叶斯公式",{"2":{"190":1}}],["由于我们希望尽可能多的小孩得到满足",{"2":{"955":1}}],["由于我们不再关心最大化我们对优化问题的经验",{"2":{"379":1}}],["由于前面我看的manage",{"2":{"889":1}}],["由于需要安装vim",{"2":{"889":1}}],["由于数据量大大缩减",{"2":{"652":1}}],["由于自然语言一般更依赖于相对位置",{"2":{"642":1}}],["由于注意力机制",{"2":{"621":1}}],["由于没有平行对照文本",{"2":{"619":1}}],["由于模型已经在大量数据上进行过预训练",{"2":{"617":1}}],["由于动态图可以根据实际输入数据生成计算图",{"2":{"559":1}}],["由于动量的引入",{"2":{"266":1,"267":1}}],["由于该调度器是递归定义的",{"2":{"545":1}}],["由于样本方差的原因",{"2":{"412":1}}],["由于你使用的是非自适应随机搜索",{"2":{"401":1}}],["由于很难知道我们什么时候采样足够",{"2":{"374":1}}],["由于运行实验的成本很高",{"2":{"372":1}}],["由于内存限制",{"2":{"338":1}}],["由于这是一个常见的模式",{"2":{"475":1}}],["由于这些块在内存中无需连续",{"2":{"334":1}}],["由于这个语言模型是根据context",{"2":{"176":1}}],["由于这个限制的存在",{"2":{"161":1}}],["由于碎片化和过度保留",{"2":{"333":1}}],["由于长上下文推理只是最近出现",{"2":{"329":1}}],["由于长上下文预填具有丰富的并行性",{"2":{"329":1}}],["由于每个主机只拥有一个key",{"2":{"327":1}}],["由于每次更新只使用一个样本或一小批样本的梯度",{"2":{"261":1}}],["由于减少内存读写",{"2":{"316":1}}],["由于不需要保存大小为𝑁×𝑁的大型矩阵s和p",{"2":{"316":1}}],["由于其随机性采样和快速更新的特点",{"2":{"261":1}}],["由于使用的是一小批次的样本",{"2":{"262":1}}],["由于使用随机采样的梯度",{"2":{"261":1}}],["由于使用整个数据集的梯度",{"2":{"260":1}}],["由于bgd使用整个训练数据集的梯度",{"2":{"260":1}}],["由于一些或大部分操作是内存密集型的",{"2":{"223":1,"312":1}}],["由于分支有时候会较多",{"2":{"186":1}}],["由于独特的设计结构",{"2":{"144":1}}],["由于",{"2":{"143":1,"225":1,"313":1,"338":1,"620":1,"647":1,"648":1}}],["由于relu在",{"2":{"122":1}}],["由于激活函数是没有上界的",{"2":{"122":1}}],["由于零中心激活函数的输出均值为零",{"2":{"120":1}}],["由上图左右对比可知",{"2":{"121":1}}],["由上图",{"2":{"121":2}}],["型运算",{"2":{"439":5}}],["型任务",{"0":{"165":1}}],["型非线性饱和激活函数",{"2":{"121":1}}],["型激活函数",{"0":{"121":1}}],["综上所述",{"2":{"120":1,"243":1,"365":1}}],["保存文件",{"2":{"777":1}}],["保存并退出",{"2":{"751":1,"777":2}}],["保存到可永久保存的存储设备中",{"2":{"722":1}}],["保存图片",{"2":{"580":1}}],["保存图像",{"2":{"555":1}}],["保存onnx",{"0":{"528":1}}],["保存和加载模型的静态图",{"0":{"524":1},"1":{"525":1,"526":1}}],["保存训练中的状态",{"0":{"522":1}}],["保存与加载模型",{"0":{"517":1},"1":{"518":1,"519":1,"520":1}}],["保存当前优化状态的字典",{"2":{"509":1}}],["保存输入",{"2":{"472":1}}],["保存计算当前张量梯度所需要的计算图中的其他张量",{"2":{"469":1}}],["保存计算当前张量梯度所需要的计算图中的自身张量",{"2":{"469":1}}],["保存哪些东西",{"2":{"467":1}}],["保存模型到文件",{"2":{"569":1}}],["保存模型静态图",{"0":{"525":1}}],["保存模型状态后",{"2":{"516":1}}],["保存模型的状态",{"0":{"514":1}}],["保存模型",{"0":{"518":1},"2":{"467":1,"580":1}}],["保存",{"2":{"457":1,"472":1,"518":1,"889":1}}],["保存中间tensor",{"2":{"457":1}}],["保存中间",{"0":{"457":1}}],["保存每次评估的足够信息",{"2":{"390":1}}],["保存检查点并追溯选择最佳检查点",{"0":{"392":1},"2":{"351":1}}],["保存成",{"2":{"323":1}}],["保留",{"2":{"184":1}}],["保持梯度一致性指的是在深度神经网络中",{"2":{"120":1}}],["保证在多主机之间使用相同的随机数生成器种子",{"2":{"395":1}}],["保证管道只在一台主机上进行日志记录和检查点",{"2":{"395":1}}],["保证了在优化中梯度的可计算性",{"2":{"120":1}}],["保证多层网络不退化成单层线性网络",{"2":{"120":1}}],["保证数据分布一致",{"2":{"88":1}}],["保证每一次数据经过归一化后还保留原有学习来的特征",{"2":{"86":1}}],["零中心激活函数并非在所有情况下都具有更好的性能",{"2":{"120":1}}],["零中心激活函数具有对称性",{"2":{"120":1}}],["零中心激活函数可以更好地捕捉数据中的不同特征",{"2":{"120":1}}],["零中心激活函数可以更好地支持梯度传播",{"2":{"120":1}}],["零中心激活函数可以提供更好的网络表示能力",{"2":{"120":1}}],["零中心激活函数在某些情况下可能具有一些优势",{"2":{"120":1}}],["例如bresenham画线算法",{"2":{"857":1}}],["例如点",{"2":{"857":1}}],["例如网页抓取",{"2":{"799":1}}],["例如查找mpicc",{"2":{"766":1}}],["例如键盘",{"2":{"680":1}}],["例如内存",{"2":{"676":1}}],["例如自动摘要",{"2":{"621":1}}],["例如自监督学习",{"2":{"352":1}}],["例如句子分类",{"2":{"619":1}}],["例如随机遮盖其中的词语",{"2":{"619":1}}],["例如可以根据上下文预测被遮盖掉的词语",{"2":{"616":1}}],["例如通过",{"2":{"505":1}}],["例如通过索引或转置创建",{"2":{"481":1}}],["例如运行平均值",{"2":{"496":1}}],["例如在验证数据上避免更新",{"2":{"480":1}}],["例如在出现过拟合问题时使用新的正则化器",{"2":{"366":1}}],["例如数据处理和模型评估",{"2":{"479":1}}],["例如本文",{"2":{"411":1}}],["例如误差上升而不下降",{"2":{"405":1}}],["例如贝叶斯优化",{"2":{"401":1}}],["例如测试数据与训练数据重叠",{"2":{"390":1}}],["例如使用",{"2":{"387":1}}],["例如添加数据增强",{"2":{"381":1}}],["例如激活函数",{"2":{"367":1}}],["例如提交给竞赛",{"2":{"365":1}}],["例如时间长度",{"2":{"364":1}}],["例如学习率",{"2":{"363":1,"369":1,"373":1,"503":1}}],["例如购买新硬件或重写训练工作流以实现多gpu",{"2":{"360":1}}],["例如架构超参数",{"2":{"356":1}}],["例如层数",{"2":{"355":1,"363":1}}],["例如工作流实施和优化",{"2":{"352":1}}],["例如深度神经网络具有大量的隐藏层和参数",{"2":{"341":1}}],["例如浮点乘加和指数",{"2":{"325":1}}],["例如将掩码操作与softmax操作融合在一起",{"2":{"223":1,"312":1}}],["例如应用于",{"2":{"223":1,"312":1}}],["例如softmax",{"2":{"223":1,"312":1}}],["例如概率",{"2":{"186":1}}],["例如每天的股票价格等等",{"2":{"160":1}}],["例如relu",{"2":{"120":1}}],["例如",{"2":{"120":2,"223":1,"312":1,"320":2,"325":1,"328":3,"329":1,"335":1,"353":1,"356":1,"358":3,"359":1,"360":4,"363":3,"365":1,"367":1,"369":6,"370":1,"372":2,"375":3,"376":2,"378":2,"379":1,"380":1,"381":4,"382":1,"384":1,"385":1,"387":2,"401":3,"406":3,"408":1,"409":2,"410":1,"411":1,"412":1,"440":1,"443":1,"444":1,"472":3,"473":3,"475":2,"478":1,"493":1,"496":1,"504":1,"509":1,"510":1,"533":1,"616":3,"617":1,"621":2,"624":1,"627":1,"645":1,"682":4,"822":1,"925":1}}],["带的团队能差吗",{"2":{"875":1}}],["带他去了另一家",{"2":{"875":1}}],["带着室友离开了",{"2":{"875":1}}],["带室友修电脑",{"0":{"875":1},"2":{"871":1,"907":1}}],["带头进行的",{"2":{"620":1}}],["带",{"2":{"546":1}}],["带scatter通信的",{"2":{"445":1}}],["带nesterov",{"2":{"284":1}}],["带了lr",{"2":{"281":1}}],["带动量的随机梯度下降可以平滑参数更新的路径",{"2":{"267":1}}],["带动量的随机梯度下降可以加速模型的收敛速度",{"2":{"267":1}}],["带动量的随机梯度下降可以加速参数更新的速度",{"2":{"266":1}}],["带动量的随机梯度下降能够在搜索空间中跳出局部最小值并继续寻找更好的解",{"2":{"267":1}}],["带动量的随机梯度下降利用一个动量变量来积累梯度的历史信息",{"2":{"266":1}}],["带单个参数会略微增加网络的大小",{"2":{"120":1}}],["带入数据",{"2":{"46":1}}],["像素中心偏移",{"2":{"841":1}}],["像ghost",{"2":{"362":1}}],["像",{"2":{"120":1}}],["单单一段话是理解不完的",{"2":{"878":1}}],["单独放在站点根目录",{"2":{"868":1}}],["单主多从",{"2":{"811":1}}],["单机的多处理器",{"2":{"801":1}}],["单一处理机",{"2":{"801":1}}],["单例",{"2":{"717":1}}],["单标志法",{"0":{"686":1}}],["单次",{"2":{"379":1}}],["单向和双向掩蔽",{"2":{"328":1}}],["单个进程与另一个进程通信",{"2":{"806":1}}],["单个序列",{"2":{"333":1}}],["单个",{"2":{"204":1}}],["单个神经元只对有限区域内的刺激作出反应",{"2":{"51":1}}],["单层网络能够保证是凸函数",{"2":{"120":1}}],["单调性",{"2":{"120":1}}],["饱和指的是在某些区间梯度接近于零",{"2":{"120":1}}],["变量",{"2":{"706":1,"708":1}}],["变分推断和变分自编码器的最终目标是相同的",{"2":{"659":1}}],["变分",{"2":{"659":1}}],["变分自编码器的变分就来源于此",{"2":{"659":1}}],["变成",{"2":{"643":1}}],["变为",{"2":{"639":1}}],["变为非叶子节点",{"2":{"457":1}}],["变为标准卷积",{"2":{"60":1}}],["变体",{"2":{"356":1,"619":1}}],["变换为另一个向量空间",{"2":{"120":1}}],["全连接层计算梯度",{"2":{"456":1}}],["全连接层",{"2":{"454":1}}],["全连接层或cnn只是对数据做仿射变换",{"2":{"120":1}}],["全为真则为真",{"2":{"445":1}}],["全损失梯度的",{"2":{"405":1}}],["全收集和reduce",{"2":{"328":1}}],["全0或常量初始化",{"0":{"237":1}}],["全局最优",{"2":{"970":1}}],["全局最优解",{"2":{"260":1}}],["全局光照",{"2":{"857":1}}],["全局替换整个文件的文本",{"2":{"787":1}}],["全局替换",{"2":{"753":1,"787":1}}],["全局设置",{"2":{"453":1}}],["全局信息作为指导进一步增强网络性能",{"2":{"95":1}}],["全局平均池化是在整个特征图上计算特征值的平均值",{"2":{"95":1}}],["组装家具时的说明书",{"2":{"917":1}}],["组和其他人可读执行",{"2":{"746":1}}],["组织机构等",{"2":{"188":1}}],["组合成一张有向无环图",{"2":{"117":1}}],["组成的可迭代对象",{"2":{"508":1}}],["组成的tensor",{"2":{"445":1}}],["组成",{"2":{"51":1,"117":1}}],["组成一个从前到后",{"2":{"15":1}}],["常心",{"2":{"880":1}}],["常相守是个考验",{"2":{"880":1}}],["常用于电影和高质量渲染",{"2":{"857":1}}],["常用的异步通信函数如mpi",{"2":{"807":1}}],["常用的函数包括mpi",{"2":{"806":1}}],["常用目录",{"0":{"739":1}}],["常用设计模式",{"2":{"717":1}}],["常用进程同步原语实现数据同步",{"2":{"677":1}}],["常用功能",{"0":{"491":1},"1":{"492":1,"493":1,"494":1,"495":1,"496":1}}],["常用且较为完善的优化器包括",{"2":{"356":1}}],["常见网络问题",{"0":{"911":1}}],["常见不稳定模式的潜在修复方式",{"0":{"406":1}}],["常见技巧",{"2":{"387":1}}],["常见问题",{"2":{"387":1}}],["常见问题的回答",{"0":{"396":1},"1":{"397":1,"398":1,"399":1,"400":1,"401":1,"402":1,"403":1,"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1,"412":1,"413":1,"414":1,"415":1,"416":1,"417":1,"418":1,"419":1},"2":{"351":1}}],["常见的评估方法可能会因为评估不够频繁而错过这些问题",{"2":{"405":1}}],["常见的正则化方法",{"0":{"342":1},"1":{"343":1,"344":1,"345":1,"346":1,"347":1,"348":1,"349":1}}],["常见的神经网络是形如下图所示的层级结构",{"2":{"13":1}}],["常将神经网络层",{"2":{"117":1}}],["该段子曰有三句",{"2":{"878":1}}],["该站点的整体结构",{"0":{"860":1},"1":{"861":1,"862":1}}],["该算法引入了直线的一般式方程",{"2":{"843":1}}],["该算法主要亮点就是引入了增量思想",{"2":{"838":1}}],["该模型是ipc进程间通信",{"2":{"801":1}}],["该模型使用特殊的前缀标记来指示源语言和目标语言",{"2":{"621":1}}],["该模型大幅超越了",{"2":{"619":1}}],["该模块的",{"2":{"496":1}}],["该模块的输入是一个索引列表",{"2":{"113":1}}],["该调度器会监测一个度量指标的数值",{"2":{"547":1}}],["该类中有三种内置的策略",{"2":{"543":1}}],["该策略在两个边界之间以恒定的频率循环调整学习率",{"2":{"543":1}}],["该策略首先淘汰最近最少使用的叶子节点",{"2":{"338":1}}],["该钩子可以就地修改state",{"2":{"509":1}}],["该钩子将在调用",{"2":{"509":1}}],["该钩子将在调用torch",{"2":{"509":1}}],["该钩子将在优化器步骤之后调用",{"2":{"509":1}}],["该钩子将在优化器步骤之前调用",{"2":{"509":1}}],["该钩子将在每次调用",{"2":{"496":1}}],["该对象将保存当前状态并根据计算得到的梯度更新参数",{"2":{"503":1}}],["该方法显著提升了实时模拟的计算效率",{"2":{"859":1}}],["该方法可以用来提供有关模块的附加信息",{"2":{"496":1}}],["该方法对于冻结模块的一部分以进行微调或单独训练模型的部分",{"2":{"496":1}}],["该方法会in",{"2":{"496":1}}],["该方法应返回一个表示对象状态的可序列化对象",{"2":{"496":1}}],["该方法始终返回",{"2":{"441":1}}],["该预钩子将在每次调用",{"2":{"496":1}}],["该函数",{"2":{"646":1}}],["该函数的行为将会发生变化",{"2":{"496":1}}],["该函数用于在稀疏张量中合并重复的索引和值",{"2":{"444":1}}],["该图表明模型正在经历训练不稳定",{"2":{"408":1}}],["该图展示的是训练开始时频繁更新评估的结果",{"2":{"405":1}}],["该图展示了基数树在响应各种请求时的动态演变",{"2":{"338":1}}],["该机制还通过层次预填充",{"2":{"329":1}}],["该项梯度就会对之前梯度有个修正",{"2":{"269":1}}],["该公式可最终化简为",{"2":{"248":1}}],["该层对编码器堆栈的输出执行multi",{"2":{"197":1}}],["该网络结构包含了多个卷积层和全连接层",{"2":{"122":1}}],["该架构训练两个神经网络相互竞争",{"2":{"21":1}}],["省略起始索引和结束索引来选择整个张量",{"2":{"111":1}}],["呢",{"2":{"110":1,"215":1,"345":1,"535":1,"878":1}}],["能先满足他们可以为后面胃口更大的小孩留出更大的饼干",{"2":{"955":1}}],["能静下心来真的很不容易",{"2":{"880":1}}],["能不带有一点情绪去面对吗",{"2":{"878":1}}],["能不生气吗",{"2":{"878":1}}],["能有效利用分布式集群的计算能力",{"2":{"812":1}}],["能提升程序并发性",{"2":{"807":1}}],["能更多地测试新想法",{"2":{"357":1}}],["能使固定时间间隔内超参数调整更彻底",{"2":{"357":1}}],["能随着我们理解的改变从而成长和演变",{"2":{"353":1}}],["能随卡数线性扩展",{"2":{"326":1}}],["能一定程度上抑制过拟合",{"2":{"346":1}}],["能直接存在缓存中",{"2":{"230":1,"330":1}}],["能的话规则是什么样的",{"2":{"108":1}}],["能够将自己心中的虚拟世界创造出来",{"2":{"858":1}}],["能够将大数据量的图片有效的降维成小数据量",{"2":{"21":1}}],["能够极大提升编码水平和思维能力",{"2":{"858":1}}],["能够更真实地模拟光线的多次反射和漫射",{"2":{"857":1}}],["能够重构出原始的文本",{"2":{"621":1}}],["能够处理动态控制流和变长输入数据等情况",{"2":{"559":1}}],["能够满足上述信息的记录要求并且对使用者友好易用是非常重要的",{"2":{"393":1}}],["能够约束梯度",{"2":{"279":1}}],["能够放大梯度",{"2":{"279":1}}],["能够减轻这种限制",{"2":{"63":1}}],["能够保留图片的特征",{"2":{"21":1}}],["能够较好地进行非线性分类",{"2":{"14":1}}],["类与对象",{"2":{"708":1}}],["类有哪些常用的方法",{"2":{"550":1}}],["类比到学习率调整中",{"2":{"544":1}}],["类",{"2":{"492":1}}],["类型推断",{"2":{"563":1}}],["类型",{"2":{"445":1,"457":1,"496":5,"503":1}}],["类型的tensor",{"2":{"444":2}}],["类型的非线性函数进行变换",{"2":{"120":1}}],["类型运算",{"2":{"439":1}}],["类似于抽象语法树",{"2":{"562":1}}],["类似于统计中的冗余参数",{"2":{"369":1}}],["类似于进程共享物理页面",{"2":{"335":1}}],["类似于训练中的流水线并行性",{"2":{"329":1}}],["类似于前面我们写的第t步的交叉熵损失的负数",{"2":{"185":1}}],["类似",{"0":{"153":1}}],["类似神经元信号传播",{"2":{"123":1}}],["类似人类的视觉原理",{"2":{"21":1}}],["类别",{"2":{"108":1}}],["操作步骤",{"0":{"884":1}}],["操作系统",{"2":{"868":1,"910":1}}],["操作系统进程同步",{"2":{"868":1}}],["操作之前",{"2":{"649":1}}],["操作的流程是",{"2":{"648":1}}],["操作和控制流等信息",{"2":{"563":1}}],["操作后的",{"2":{"509":1}}],["操作tensor对象",{"2":{"441":1}}],["操作中的行为",{"2":{"441":1}}],["操作指南",{"2":{"422":1}}],["操作示例",{"2":{"338":1}}],["操作是在row",{"2":{"319":1}}],["操作吗",{"2":{"108":1}}],["操作",{"2":{"108":1,"248":1,"322":1,"444":1,"456":1}}],["需求",{"2":{"730":1,"731":1,"732":1,"733":1}}],["需要提前创建好doccano服务才行",{"2":{"885":1}}],["需要提前建立一个全局通信组",{"2":{"329":1}}],["需要自己去领悟",{"2":{"878":1}}],["需要自己在该方法内做转化",{"2":{"441":1}}],["需要显式管理通信和数据分布",{"2":{"812":1}}],["需要传递参数类型",{"2":{"730":1}}],["需要持久化来缓存到外存",{"2":{"722":1}}],["需要事先定义一个net的实例",{"2":{"523":1}}],["需要多少多少钱",{"2":{"875":1}}],["需要多少次试验才能通过quasi",{"0":{"403":1}}],["需要多次重新评估函数",{"2":{"505":1}}],["需要有",{"2":{"488":1}}],["需要注意的重要一点是",{"2":{"471":1}}],["需要注意的是这些向量可能是整个网络的输入",{"2":{"202":1}}],["需要注意的是",{"2":{"120":1,"180":1,"260":1}}],["需要计算梯度的",{"2":{"464":1}}],["需要付出大量的努力和猜测",{"2":{"353":1}}],["需要手动配置和调整",{"2":{"337":1}}],["需要每层两次昂贵的基于rdma的全局归约操作",{"2":{"329":1}}],["需要与同一序列中所有标记的键值",{"2":{"328":1}}],["需要反复往shared",{"2":{"319":1}}],["需要反复读写",{"2":{"319":1}}],["需要知道上一层的输出个数吗",{"2":{"248":1}}],["需要高斯分布如下",{"2":{"245":1}}],["需要投入极大的成本",{"2":{"143":1}}],["需要根据具体任务",{"2":{"120":1}}],["需要满足什么规则",{"2":{"106":1}}],["需注意的是可训练的weight",{"2":{"87":1}}],["后一个点是前一个点的横坐标加一或者横纵坐标都加一",{"2":{"844":1}}],["后一个任务被称为下句预测",{"2":{"619":1}}],["后会自动生成一套与",{"2":{"822":1}}],["后跟查找的文本",{"2":{"786":1}}],["后端学习框架的学习指南",{"2":{"707":1}}],["后端学习框架",{"0":{"707":1},"1":{"708":1,"709":1,"710":1,"711":1,"712":1,"713":1,"714":1,"715":1,"716":1,"717":1,"718":1}}],["后续会提到",{"2":{"972":1}}],["后续我也会发布相关的章节视频在b站",{"2":{"702":1}}],["后续补充",{"0":{"685":1,"689":1},"1":{"686":1,"687":1,"688":1,"690":1,"691":1,"692":1,"693":1}}],["后面大家慢慢会有更深刻的认识",{"2":{"975":1}}],["后面会有具体的经典算法问题",{"2":{"948":1}}],["后面会让你越来越忙碌",{"2":{"942":1}}],["后面依旧会遇到同样的问题",{"2":{"875":1}}],["后面我们会讲分布式环境下的并行计算",{"2":{"799":1}}],["后面我们会介绍如何将椭圆尽可能堆叠",{"2":{"656":1}}],["后面详讲",{"2":{"676":1}}],["后面每一步都是分出来2×3=6支",{"2":{"184":1}}],["后执行后处理操作",{"2":{"509":1}}],["后钩子",{"2":{"509":1}}],["后置钩子函数",{"2":{"508":1,"509":1}}],["后再相加",{"2":{"445":1}}],["后期较大的时候",{"2":{"279":1}}],["后来跟一个室友说了一下",{"2":{"878":1}}],["后来",{"2":{"189":1}}],["后来又出现了基于",{"2":{"143":1}}],["后",{"2":{"181":1,"466":1}}],["后的输入向量",{"2":{"172":1}}],["后的形状可以随便写吗",{"2":{"106":1}}],["后半部分的卷积组负责处理后半部分的输入层",{"2":{"57":1}}],["除法",{"2":{"706":1}}],["除此以外",{"2":{"681":1}}],["除此之外",{"2":{"95":1,"167":1}}],["除非你有大量的语料",{"2":{"617":1}}],["除非您的内存压力非常大",{"2":{"481":1}}],["除非包装在",{"2":{"475":1}}],["除非明确同步处理",{"2":{"394":1}}],["除非所有目标超参数值都有相同的冗余超参数集",{"2":{"370":1}}],["除了第一个元素没有前继元素",{"2":{"626":1}}],["除了能生成令人印象深刻的真实篇章之外",{"2":{"620":1}}],["除了512x512版本的模型",{"2":{"608":1}}],["除了设置",{"2":{"476":1}}],["除了讨论上述机制之外",{"2":{"474":1}}],["除了尝试实现每组实验的原始科学目标之外",{"2":{"372":1}}],["除了通过实验为每个新问题找到它之外",{"2":{"359":1}}],["除了注意力之外的所有模块",{"2":{"328":1}}],["除了每个编码器层中的两个子层之外",{"2":{"197":1}}],["除了拼接维度",{"2":{"104":1}}],["除少数情况外",{"2":{"193":1}}],["除以序列的长度",{"2":{"186":1}}],["否则可能发生与时间有关的错误",{"2":{"678":1}}],["否则相比训练一个专门的模型",{"2":{"617":1}}],["否则直接报错",{"2":{"496":2}}],["否则您可能永远不需要使用它们",{"2":{"481":1}}],["否则这些统计数据在每个设备上都是不同的",{"2":{"394":1}}],["否则",{"2":{"98":1,"371":2}}],["返回得到满足的孩子数量",{"2":{"957":1}}],["返回状态",{"2":{"823":1}}],["返回当前用户的主目录",{"2":{"742":1}}],["返回上一级目录",{"2":{"742":1}}],["返回该对象的属性和方法的名称列表",{"2":{"496":1}}],["返回类实例的名称",{"2":{"496":1}}],["返回的对象是一个浅拷贝",{"2":{"496":1}}],["返回的张量将是输入的视图",{"2":{"98":1}}],["返回反向传播pre",{"2":{"496":1}}],["返回用于在调用函数中使用的反向传播钩子",{"2":{"496":1}}],["返回排序的索引",{"2":{"445":1}}],["返回拉平后最小值的索引",{"2":{"445":1}}],["返回最大值的索引",{"2":{"445":1}}],["返回输入张量在给定维度",{"2":{"445":2}}],["返回输入张量的唯一元素",{"2":{"441":1}}],["返回共轭张量的视图",{"2":{"445":1}}],["返回稀疏tensor",{"2":{"444":1}}],["返回tensor",{"2":{"444":1,"445":1}}],["返回给定张量的矩阵范数或向量范数",{"2":{"441":1}}],["返回与张量关联的底层数据存储对象",{"2":{"441":1}}],["返回",{"2":{"226":1,"441":1,"445":1}}],["返回一个装饰器",{"2":{"509":1}}],["返回一个迭代器",{"2":{"496":8}}],["返回一个包含模块整个状态的字典",{"2":{"496":1}}],["返回一个由整数组成的元组",{"2":{"441":1}}],["返回一个矩阵",{"2":{"440":1}}],["返回一个self张量的新视图",{"2":{"106":1}}],["返回一个具有与输入相同的数据和元素数量",{"2":{"98":1}}],["返回原始数据的不同shape",{"2":{"99":1}}],["作者的一些想法和我有共鸣",{"2":{"699":1}}],["作者通过图文并茂的方式来描述内容",{"2":{"698":1}}],["作者没有具体的解释",{"2":{"640":1}}],["作者发现了一个关键的优化机会",{"2":{"337":1}}],["作为参数被调用",{"2":{"509":2}}],["作为计算需要",{"2":{"475":1}}],["作为梯度",{"2":{"473":1}}],["作为起点",{"2":{"383":1}}],["作为一个目标超参数",{"2":{"369":1}}],["作为其中的一部分",{"2":{"325":1}}],["作为",{"2":{"171":1}}],["作为激活函数",{"2":{"122":1}}],["作为全连接层的替代操作",{"2":{"95":1}}],["作用",{"0":{"267":1},"2":{"86":1,"92":1,"93":1,"95":1,"777":1,"778":1,"780":1,"781":1,"782":1,"783":1,"784":1}}],["来解决生活中的问题",{"2":{"928":1}}],["来解决线性网络表达能力不足的问题",{"2":{"120":1}}],["来确定xstepxstepxstep和ystepystepystep的取值",{"2":{"840":1}}],["来估计",{"2":{"659":1}}],["来预测句子中被遮盖掉的词语",{"2":{"616":1}}],["来使pytorch代码运行更快",{"2":{"565":1}}],["来注册被禁用",{"2":{"490":1}}],["来注册",{"2":{"490":6}}],["来定义",{"2":{"490":1}}],["来控制",{"2":{"472":1}}],["来判断一个variable是否是leaf",{"2":{"468":1}}],["来排列",{"2":{"445":1}}],["来对最终结果进行非线性变换",{"2":{"444":1}}],["来触发",{"2":{"441":1}}],["来",{"2":{"441":1}}],["来创建类对象",{"2":{"440":1}}],["来增加输入管道生成数据的进程的数量",{"2":{"387":1}}],["来优化冗余超参数",{"2":{"370":1}}],["来计算梯度",{"2":{"472":1}}],["来计算统计数据",{"2":{"362":1}}],["来计算相对于q",{"2":{"228":1,"318":1}}],["来生成新的文本",{"2":{"344":1}}],["来自",{"2":{"338":2}}],["来自前一个隐藏状态和当前输入的信息通过",{"2":{"147":1}}],["来启用cp",{"2":{"328":1}}],["来实现迭代计算",{"2":{"326":1}}],["来实现的",{"2":{"92":1}}],["来克服在次二次方级别的hbm访问中计算精确注意力的技术挑战",{"2":{"224":1,"311":1}}],["来进行一次仅包含500次训练的计划",{"2":{"405":1}}],["来进行",{"2":{"223":1,"312":1}}],["来得到了一个质量更高的",{"2":{"220":1,"306":1}}],["来将源语言翻译成目标语言",{"2":{"189":1}}],["来改善或解决长度限制问题",{"2":{"174":1}}],["来取代最后的全连接层",{"2":{"95":1}}],["背景",{"2":{"95":1,"122":1,"126":1,"127":1,"217":1,"303":1}}],["抑制噪声",{"2":{"92":1}}],["池化",{"2":{"92":1}}],["提起",{"2":{"916":1}}],["提升编程和算法能力",{"2":{"858":1}}],["提升图形的真实感",{"2":{"857":1}}],["提升计算性能",{"2":{"798":1}}],["提升模型性能",{"2":{"227":1,"317":1}}],["提交事务",{"2":{"731":1,"732":1,"733":1}}],["提出的一种能够将相对位置信息依赖集成到",{"2":{"645":1}}],["提出了翻译语言建模",{"2":{"619":1}}],["提出了多查询注意力机制",{"2":{"308":1}}],["提出了一种新的简单的网络架构transformer",{"2":{"193":1}}],["提出了leakyrelu",{"2":{"124":1}}],["提出了rms",{"2":{"91":1}}],["提取码",{"2":{"584":1}}],["提取特征图中响应最强烈的部分进入下一层",{"2":{"93":1}}],["提示",{"2":{"335":1}}],["提高资源利用率",{"2":{"798":1}}],["提高了可维护性",{"2":{"724":1}}],["提高开发效率",{"2":{"724":1}}],["提高命名实体识别的准确率",{"2":{"628":1}}],["提高模型性能的科学方法",{"0":{"364":1},"1":{"365":1,"366":1,"367":1,"368":1,"369":1,"370":1,"371":1,"372":1,"373":1,"374":1,"375":1,"376":1,"377":1,"378":1,"379":1},"2":{"351":1}}],["提高模型的泛化能力和生成能力",{"2":{"180":1}}],["提高系统的性能和效率",{"2":{"337":1}}],["提高复杂",{"2":{"337":1}}],["提高gpu利用率",{"2":{"334":1}}],["提供xml标签",{"2":{"724":1}}],["提供",{"2":{"544":1}}],["提供给这个模块的state",{"2":{"496":1}}],["提供了开发桌面应用程序",{"2":{"703":1}}],["提供了几种根据训练轮数来调整学习率的方法",{"2":{"532":1}}],["提供了一种标准化的方式来将子模块添加到模型中",{"2":{"496":1}}],["提供了两个主要优点",{"2":{"329":1}}],["提供数据的丰富性",{"2":{"344":1}}],["提供更好的性能",{"2":{"328":1}}],["提供语义信息",{"2":{"180":1}}],["提供初始信息",{"2":{"24":1}}],["只能创建超管然后将别的超管作为员工添加到项目中",{"2":{"883":1}}],["只能被单一线程访问的设备",{"2":{"682":1}}],["只能单个进程的访问",{"2":{"681":1}}],["只能依赖小于i",{"2":{"197":1}}],["只不过我们是用大脑而不是计算机",{"2":{"920":1}}],["只不过",{"2":{"648":1}}],["只依赖于位置编号k",{"2":{"639":1}}],["只与当前位置的输入",{"2":{"626":1}}],["只用很少的标注数据就达到了最佳性能",{"2":{"616":1}}],["只用了",{"2":{"609":1}}],["只进行了两次",{"2":{"609":1}}],["只要今天比昨天好",{"2":{"880":1}}],["只要我们把我们需要保存的信息",{"2":{"572":1}}],["只要我们愿意",{"2":{"380":1}}],["只要有一个requires",{"2":{"464":1}}],["只要它保持相同的均匀性",{"2":{"401":1}}],["只要调整好所有超参数",{"2":{"357":1}}],["只要每个块的统计数据正确组合以进行重新缩放",{"2":{"327":1}}],["只存储一份",{"2":{"326":1}}],["只需将",{"2":{"475":1}}],["只需保留第一轮的基础",{"2":{"385":1}}],["只需在last循环缩放一次",{"2":{"321":1}}],["只需要有限个位置编码",{"2":{"643":1}}],["只需要在将它们保存在检查点之前进行同步",{"2":{"394":1}}],["只需要更新context",{"2":{"180":1}}],["只需要最后一层的输出o5",{"2":{"142":1}}],["只差了一个转置",{"2":{"249":1}}],["只是现实的量化而已😄",{"2":{"967":1}}],["只是大家潜意识没有对其量化认识",{"2":{"929":1}}],["只是需要慢慢自己领悟",{"2":{"917":1}}],["只是希望自己能够不断成长并帮助到大家",{"2":{"917":1}}],["只是create",{"2":{"889":1}}],["只是想说自己的知己或知音难遇罢了",{"2":{"878":1}}],["只是一个人生阶段罢了",{"2":{"878":1}}],["只是一个规范",{"2":{"802":1}}],["只是用了它",{"2":{"724":1}}],["只是为了好可视化",{"2":{"655":1}}],["只是多加了一个mask码",{"2":{"214":1}}],["只是数据流的方向改变了",{"2":{"29":1}}],["只有使用这个技术的人有高低之别",{"2":{"724":1}}],["只有满足了这些条件",{"2":{"681":1}}],["只有一条路径",{"2":{"634":1}}],["只有一小部分时间花在了",{"2":{"366":1}}],["只有self及其子模块的参数和缓存才能保证存在于state",{"2":{"496":1}}],["只有至少一个输入张量需要",{"2":{"475":1}}],["只有",{"2":{"474":1,"475":1}}],["只有非叶子节点才有意义",{"2":{"468":1}}],["只有叶子节点才有",{"2":{"468":1}}],["只有浮点",{"2":{"464":1}}],["只有偶尔在情况发生变化时",{"2":{"354":1}}],["只有在尝试编写这本",{"2":{"353":1}}],["只有深度学习才有正则化吗",{"2":{"340":1}}],["只有其中最好的k个候选项会被保留",{"2":{"186":1}}],["只有k个候选项会被保留",{"2":{"186":1}}],["只选择其中最大的k个保留",{"2":{"184":1}}],["只保留了缩放",{"2":{"91":1}}],["去了不同的两家店",{"2":{"875":1}}],["去掉了章节文件夹",{"2":{"874":1}}],["去掉的对应的文件夹",{"2":{"671":1}}],["去重作用",{"2":{"441":1}}],["去除了计算过程中的平移",{"2":{"91":1}}],["去噪",{"2":{"18":1}}],["认为一个非常大的max",{"2":{"382":1}}],["认为",{"2":{"91":1}}],["认识pytorch",{"0":{"69":1}}],["重构整个博客",{"2":{"873":1}}],["重构了注意力计算过程",{"2":{"222":1,"311":1}}],["重做撤销的操作",{"2":{"783":1}}],["重做",{"2":{"753":1}}],["重命名或移动文件",{"2":{"743":1}}],["重新运行模型",{"2":{"569":1}}],["重新加载模型",{"2":{"569":1}}],["重置所有被优化的",{"2":{"509":1}}],["重置所有模型参数的梯度",{"2":{"496":1}}],["重置门是另一个门",{"2":{"156":1}}],["重置门",{"2":{"156":1}}],["重点",{"0":{"462":1,"693":1},"2":{"731":1,"732":1,"733":1,"844":1}}],["重复此过程",{"2":{"399":1}}],["重复多次",{"2":{"58":1}}],["重用",{"2":{"337":1}}],["重计算",{"0":{"228":1,"318":1}}],["重要的任务可能来不及完成",{"2":{"942":1}}],["重要的是要注意",{"2":{"475":1}}],["重要的两个部分是平移不变性和缩放不变性",{"2":{"91":1}}],["重要",{"2":{"122":1}}],["算子列表",{"2":{"115":2}}],["算子以及",{"2":{"108":1}}],["算",{"2":{"89":1}}],["算法设计策略",{"2":{"970":1}}],["算法是我们生活中的无形助手",{"2":{"928":1}}],["算法是计算机图形学中最简单的直线绘制算法之一",{"2":{"839":1}}],["算法将越来越深刻地影响我们的生活",{"2":{"927":1}}],["算法不仅仅属于科学家和程序员",{"2":{"928":1}}],["算法不仅仅是解决计算机问题的工具",{"2":{"923":1}}],["算法不仅存在于技术中",{"2":{"927":1}}],["算法交织于生活",{"0":{"927":1}}],["算法思维",{"2":{"923":1,"928":1}}],["算法思想",{"0":{"224":1,"844":1}}],["算法就是解决一个问题或完成一项任务时所遵循的一系列步骤",{"2":{"917":1}}],["算法其实并不是只有电脑和编程才需要的东西",{"2":{"917":1}}],["算法其实没那么复杂",{"2":{"916":1}}],["算法似乎与编程",{"2":{"916":1}}],["算法进行优化",{"2":{"845":1}}],["算法步骤",{"0":{"840":1,"845":1}}],["算法步骤详述",{"2":{"226":1}}],["算法的另一个核心是效率",{"2":{"926":1}}],["算法的本质其实很简单",{"2":{"916":1}}],["算法的某些点是否有别的方法实现",{"2":{"853":1}}],["算法的基本步骤是通过增量迭代",{"2":{"839":1}}],["算法的第12行",{"2":{"226":1,"315":1}}],["算法概述",{"0":{"839":1}}],["算法图解",{"0":{"314":1}}],["算法图示",{"0":{"265":1}}],["算法实现流程",{"0":{"295":1}}],["算法实例",{"2":{"283":1}}],["算法8",{"2":{"294":1}}],["算法流程",{"0":{"284":1,"288":1}}],["算法中",{"2":{"282":1}}],["算法具有一些令人满意的理论性质",{"2":{"277":1}}],["算法详述",{"0":{"271":1}}],["算法原理图",{"0":{"270":1}}],["算法原理",{"0":{"269":1,"277":1,"299":1}}],["算法过程",{"0":{"264":1,"273":1}}],["算法1的第10行",{"2":{"226":1,"315":1}}],["算法1的第3行",{"2":{"226":1,"315":1}}],["算法经常简称为backprop",{"2":{"24":1}}],["算法",{"0":{"278":1},"2":{"21":1,"26":1,"27":1,"277":1,"283":1,"853":1,"868":2,"916":1,"917":2,"920":1}}],["生活化的例子来解释贪心思维",{"2":{"929":1}}],["生活离不开算法思维",{"0":{"923":1},"1":{"924":1,"925":1,"926":1}}],["生活中的很多方面都可以通过算法来解释",{"2":{"927":1}}],["生活中的",{"2":{"921":1}}],["生活中的搜索",{"0":{"920":1}}],["生活中我们经常在不经意间进行这样的搜索",{"2":{"920":1}}],["生活中我们经常需要做选择",{"2":{"919":1}}],["生活中常常有算法",{"0":{"918":1},"1":{"919":1,"920":1,"921":1,"922":1}}],["生活中很多习惯和行为",{"2":{"917":1}}],["生活",{"2":{"853":1}}],["生活案例",{"2":{"830":1}}],["生活与算法",{"0":{"916":1},"1":{"917":1,"918":1,"919":1,"920":1,"921":1,"922":1,"923":1,"924":1,"925":1,"926":1,"927":1,"928":1},"2":{"799":1}}],["生态系统的基础",{"2":{"703":1}}],["生产者",{"2":{"325":1}}],["生成的结果一定是类似于样本的数据",{"2":{"654":1}}],["生成的数据与真实数据分布越相似",{"2":{"606":1}}],["生成结果就是一些人脸",{"2":{"653":1}}],["生成结果主要依赖于某个图像实例",{"2":{"88":1}}],["生成",{"2":{"649":1}}],["生成旋转矩阵",{"2":{"649":1}}],["生成发射分数",{"2":{"624":1}}],["生成文本形式的标签",{"2":{"621":1}}],["生成式问答",{"2":{"621":1}}],["生成脚本",{"2":{"563":1}}],["生成随机数据",{"2":{"500":1}}],["生成像",{"2":{"390":1}}],["生成自然语言文本",{"2":{"188":1}}],["生成较短的摘要",{"2":{"188":1}}],["生成符合语法和语义规则的文本",{"2":{"188":1}}],["生成等任务",{"2":{"117":1}}],["生物学中的神经元",{"2":{"8":1}}],["中心点画线法",{"0":{"843":1},"1":{"844":1,"845":1,"846":1,"847":1}}],["中使用",{"2":{"799":1}}],["中使用的一种显式编码",{"2":{"640":1}}],["中有三种常用模式",{"2":{"774":1}}],["中断屏蔽方法",{"0":{"690":1}}],["中并提升",{"2":{"645":1}}],["中采用的就是这种编码方式",{"2":{"641":1}}],["中加入位置向量",{"2":{"639":1}}],["中所有可能路径的",{"2":{"634":1}}],["中都展现出了巨大的潜力",{"2":{"622":1}}],["中提出了一种名为",{"2":{"616":1}}],["中提出了",{"2":{"616":1}}],["中衰减每个参数组的学习率",{"2":{"542":1}}],["中对应的torch",{"2":{"482":1}}],["中尝试推断模式",{"2":{"479":1}}],["中选择最大值",{"2":{"933":3}}],["中选择最佳优化器",{"2":{"370":1}}],["中选择",{"2":{"476":1}}],["中局部禁用梯度计算",{"2":{"474":1}}],["中只要有一个",{"2":{"462":1}}],["中存储grad的地方",{"2":{"462":1}}],["中间含有两个字",{"2":{"880":1}}],["中间activation的梯度最好释放",{"2":{"464":1}}],["中间的tensor",{"2":{"464":1}}],["中间的",{"2":{"462":1}}],["中间计算过程",{"2":{"457":1}}],["中间tensor的梯度控制",{"2":{"457":1}}],["中间数量的组导致插值模型",{"2":{"219":1,"305":1}}],["中保存算子的梯度函数",{"2":{"447":1}}],["中非0元素的索引",{"2":{"445":1}}],["中维度",{"2":{"445":1}}],["中元素的相反数视图",{"2":{"444":1}}],["中每个group",{"2":{"508":1}}],["中每个",{"2":{"444":1}}],["中indices",{"2":{"444":1}}],["中数据的连续性",{"0":{"438":1}}],["中大家都了解过",{"2":{"437":1}}],["中源码定义位置",{"2":{"431":1}}],["中更改单个残差块",{"2":{"404":1}}],["中同步设备和主机之间的数据时",{"2":{"387":1}}],["中哪个优化器的验证错误率更低",{"2":{"369":1}}],["中后期",{"2":{"280":1}}],["中实现",{"0":{"272":1},"1":{"273":1,"274":1}}],["中需要",{"2":{"216":1}}],["中常见的数据增强手段",{"2":{"344":2}}],["中常见任务",{"0":{"188":1}}],["中常用的操作",{"2":{"92":1}}],["中必须包含原始序列中的所有信息",{"2":{"173":1}}],["中的rope",{"0":{"649":1}}],["中的相对位置编码",{"0":{"644":1}}],["中的dataset",{"0":{"555":1}}],["中的后置钩子函数",{"2":{"508":1}}],["中的前置钩子函数",{"2":{"508":1}}],["中的版本号实现特定于类的向后兼容加载",{"2":{"496":1}}],["中的容器",{"0":{"489":1}}],["中的实现也依赖于无梯度模式",{"2":{"478":1}}],["中的每个切片的最小值",{"2":{"445":2}}],["中的步幅会导致训练不稳定",{"2":{"404":1}}],["中的所有超参数都一样重要",{"2":{"400":1}}],["中的问题采样更多答案",{"2":{"338":1}}],["中的节点",{"2":{"338":3}}],["中的",{"0":{"173":1,"174":1,"182":1,"432":1,"553":1,"556":1},"1":{"174":1,"183":1,"184":1,"185":1,"186":1,"433":1,"434":1},"2":{"488":1,"508":1,"609":1,"643":1}}],["中的sequence长度",{"2":{"87":1}}],["中逐元素进行的操作",{"2":{"108":1}}],["中",{"2":{"87":1,"126":1,"171":1,"222":1,"223":1,"224":1,"294":1,"311":1,"312":1,"314":1,"337":1,"338":9,"369":1,"381":1,"445":2,"475":2,"476":1,"508":1,"609":1}}],["非知音",{"2":{"878":1}}],["非知己",{"2":{"878":1}}],["非持久性缓冲区不会被保存为模型的状态字典",{"2":{"490":1}}],["非叶张量",{"2":{"475":1}}],["非叶子节点才有",{"2":{"468":1}}],["非叶子节点对应函数的inputs",{"2":{"462":1}}],["非叶子",{"2":{"462":1}}],["非常有用",{"2":{"496":1}}],["非常大的风险",{"2":{"462":1}}],["非常适合用于序列化输入",{"2":{"87":1}}],["非自适应地采样搜索空间可以在不重新运行实验的情况下更改性能指标",{"2":{"401":1}}],["非恒定的",{"2":{"397":1}}],["非正式地",{"2":{"378":1}}],["非中心的",{"2":{"294":2}}],["非零中心激活函数的不足也可以在一定程度上被缓解",{"2":{"120":1}}],["非零中心的激活函数",{"2":{"120":1}}],["非饱和性",{"2":{"120":1}}],["非线性以及可微性",{"2":{"130":1}}],["非线性",{"2":{"120":1}}],["非线性变换",{"2":{"40":1}}],["加法",{"2":{"706":1}}],["加权平均得到的",{"2":{"595":1}}],["加权平均过程",{"2":{"205":1}}],["加噪过程是按照noisy",{"2":{"595":1}}],["加载训练中的状态",{"0":{"523":1}}],["加载模型到",{"2":{"570":1}}],["加载模型并运行",{"2":{"570":1}}],["加载模型静态图",{"0":{"526":1}}],["加载模型",{"0":{"519":1}}],["加载模型的状态",{"0":{"515":1}}],["加载存储的优化器状态",{"2":{"509":1}}],["加载完",{"2":{"509":1}}],["加载保存的模型状态",{"2":{"509":1}}],["加载状态时的后向钩子函数",{"2":{"490":1}}],["加载状态的pre",{"2":{"490":1}}],["加载到sram",{"2":{"226":1}}],["加载到",{"2":{"226":1}}],["加扰的",{"2":{"402":1}}],["加快训练速度就等于改善训练效果",{"2":{"380":1}}],["加快收敛速度",{"2":{"86":1}}],["加了一项随机扰动",{"2":{"279":1}}],["加速您的模型",{"2":{"479":1}}],["加速参数更新",{"2":{"266":1}}],["加速3x",{"2":{"227":1,"317":1}}],["加速15",{"2":{"227":1,"317":1}}],["加速效果",{"2":{"227":1,"317":1}}],["加速收敛",{"2":{"180":1,"267":1}}],["加速训练",{"2":{"86":1}}],["加速原理",{"0":{"77":1}}],["加入缩放和平移变量的原因是",{"2":{"86":1}}],["加入缩放和平移变量",{"2":{"86":1}}],["即可",{"2":{"889":1}}],["即f",{"2":{"843":1}}],["即对y添加0",{"2":{"841":1}}],["即对话的第一轮",{"2":{"338":1}}],["即把数据",{"2":{"722":1}}],["即y",{"2":{"659":1}}],["即计算框架中的",{"2":{"648":1}}],["即相对位置是",{"2":{"644":1}}],["即简化为",{"2":{"644":1}}],["即如果预训练最大长度为512的话",{"2":{"641":1}}],["即无法区分不同位置的token",{"2":{"638":1}}],["即当前时刻的状态与前面多个时刻的状态相关",{"2":{"630":1}}],["即满足一阶马尔可夫性质",{"2":{"630":1}}],["即满足马尔可夫性",{"2":{"626":1}}],["即标签",{"2":{"628":1}}],["即已经解码生成的词语",{"2":{"621":1}}],["即只能迭代地基于已经生成的词语来逐个预测后面的词语",{"2":{"620":1}}],["即具有",{"2":{"619":1}}],["即它不是数学函数",{"2":{"473":1}}],["即通过运算符",{"2":{"441":2}}],["即优化器超参数",{"2":{"412":1}}],["即不被大量标签噪声影响",{"2":{"391":1}}],["即网格搜索学习率",{"2":{"382":1}}],["即出现分歧的试验",{"2":{"372":1}}],["即充分搜索了足够大的空间",{"2":{"371":1}}],["即便我们无法从新的实验中进一步了解问题的结构了",{"2":{"366":1}}],["即便再添加更多的隐藏层",{"2":{"120":1}}],["即先前的技术水平进行比较",{"2":{"332":1}}],["即将预训练的模型",{"2":{"254":1}}],["即",{"2":{"248":1,"249":1,"271":1,"328":1,"647":1,"648":1,"974":1}}],["即参数",{"2":{"233":1}}],["即使是对于自定义任务",{"2":{"617":1}}],["即使是早期时间步的信息也可以传递到后续时间步",{"2":{"145":1}}],["即使用自己的任务语料对模型进行",{"2":{"617":1}}],["即使您不确定您的模型是否具有训练模式特定的行为",{"2":{"480":1}}],["即使存在",{"2":{"478":1}}],["即使针对的是其他项目",{"2":{"423":1}}],["即使进行了20次试验",{"2":{"403":1}}],["即使在搜索算法实现发生变化的情况下",{"2":{"401":1}}],["即使在昂贵的硬件上",{"2":{"332":1}}],["即使它不是故意的",{"2":{"375":1}}],["即使它们的作者具有在应用工作中提供有用建议的经验",{"2":{"353":1}}],["即使",{"2":{"375":1}}],["即使这对于解决主要的实验目标不是必要的",{"2":{"375":1}}],["即使这些见解与当前目标并不直接相关",{"2":{"372":1}}],["即使花里胡哨的东西在未来被证明是有用的",{"2":{"363":1}}],["即使更大的batch",{"2":{"359":1}}],["即使硬件支持更大的batch",{"2":{"358":1}}],["即使只是",{"2":{"356":1}}],["即使通过手动配置",{"2":{"337":1}}],["即使对于像lmsys这样具有有限计算资源的小型研究团队",{"2":{"332":1}}],["即使其中一个取决于另一个的输出",{"2":{"325":1}}],["即使无法减少键值缓存",{"2":{"309":1}}],["即使有更多的flops",{"2":{"228":1,"318":1}}],["即解码",{"2":{"190":1}}],["即源和目标两种语言的互相对照的语料",{"2":{"190":1}}],["即找到概率最大的那个y",{"2":{"190":1}}],["即x翻译成y的概率有多大",{"2":{"190":1}}],["即每一步",{"2":{"183":1}}],["即得到总体的损失函数",{"2":{"181":1}}],["即我们设置一个概率p",{"2":{"179":1}}],["即提示一下上一个词的正确答案",{"2":{"178":1}}],["即隐藏层之间的节点不再无连接而是有连接的",{"2":{"133":1}}],["即神经元同时只对输入信号的少部分选择性响应",{"2":{"122":1}}],["即在",{"2":{"441":1}}],["即在原有的翻译模型上",{"2":{"190":1}}],["即在一定数据范围内",{"2":{"121":1}}],["即在内核元素之间插入",{"2":{"60":1}}],["即导数符号不变",{"2":{"120":1}}],["即导数不是常数",{"2":{"120":1}}],["即梯度消失",{"2":{"120":1}}],["即非线性映射层",{"2":{"120":1}}],["即均方根",{"2":{"91":1}}],["即一个embedding",{"2":{"87":1}}],["即是将同一个batch中的所有样本的同一层特征图抽出来一起求mean和variance",{"2":{"86":1}}],["要凑出",{"2":{"945":1}}],["要表达的话我觉得可以理解成",{"2":{"878":1}}],["要么等于yi+1y",{"2":{"845":1}}],["要么等于yiy",{"2":{"845":1}}],["要么走了很多弯路才找到",{"2":{"292":1}}],["要计算的最大值",{"2":{"827":1}}],["要爬取的url列表",{"2":{"799":1}}],["要构建一个优化器",{"2":{"503":1}}],["要使用",{"2":{"503":1}}],["要使深度神经网络在实践中正常运行",{"2":{"353":1}}],["要冻结模型的某些部分",{"2":{"475":1}}],["要在代码的整个块中禁用梯度",{"2":{"474":1}}],["要丢掉有效特征的方法就是将有效特征点与相邻点都丢掉",{"2":{"348":1}}],["要求为",{"2":{"338":1}}],["要求输入为2维张量",{"2":{"84":1}}],["要求输入为3维张量",{"2":{"84":1}}],["要点总结",{"0":{"461":1,"657":1},"1":{"462":1,"463":1,"464":1,"465":1,"466":1,"467":1,"468":1,"469":1}}],["要点",{"0":{"488":1},"2":{"281":1}}],["要等到所有句子",{"2":{"186":1}}],["要比",{"2":{"120":1}}],["要做到这一点",{"2":{"13":1}}],["擅长逻辑控制",{"2":{"75":1}}],["总共用了",{"2":{"947":1}}],["总共47个章节",{"2":{"671":1}}],["总计",{"2":{"947":3}}],["总花费是",{"2":{"939":1}}],["总强过记住一个人的坏处",{"2":{"880":1}}],["总和",{"2":{"827":1}}],["总得知道那些个密码符号表示的含义是什么才可以吧",{"2":{"654":1}}],["总路径得分计算",{"0":{"633":1}}],["总是被覆盖为",{"2":{"477":1}}],["总消耗量",{"2":{"360":1}}],["总步数可以通过",{"2":{"544":1}}],["总步数",{"2":{"359":1,"360":1}}],["总的时间复杂度为",{"2":{"959":1}}],["总的",{"2":{"633":1}}],["总的训练周期数",{"2":{"545":1}}],["总的来说",{"2":{"341":1}}],["总的计算flop高于传统attention",{"2":{"227":1,"317":1}}],["总结",{"0":{"130":1,"151":1,"638":1,"975":1},"1":{"639":1,"640":1,"641":1,"642":1,"643":1,"644":1,"645":1,"646":1,"647":1,"648":1,"649":1},"2":{"120":1,"355":1,"356":1,"357":1,"365":1,"366":1,"367":1,"368":1,"372":1,"375":1,"378":1,"379":1,"387":1,"388":1,"392":1,"393":1,"394":1,"395":1,"404":1,"730":1}}],["总结来说",{"2":{"75":1,"648":1}}],["总误差为",{"2":{"41":1}}],["实时高保真物理模拟",{"2":{"859":1}}],["实时查看日志",{"2":{"772":2}}],["实时查看进程资源使用",{"2":{"755":1}}],["实体类",{"2":{"721":1}}],["实践证明",{"2":{"617":1}}],["实践",{"2":{"482":1}}],["实践中",{"2":{"264":1}}],["实例化数据集和数据加载器",{"2":{"568":1}}],["实例化模型",{"2":{"568":1}}],["实例化到",{"2":{"223":1,"312":1}}],["实例",{"2":{"441":1,"445":1}}],["实验的注释或简短描述",{"2":{"393":1}}],["实验配置存储位置的链接",{"2":{"393":1}}],["实验名称",{"2":{"393":1}}],["实施多机并行训练程序可能会引入错误和一些棘手的细节",{"2":{"360":1}}],["实际项目",{"2":{"829":1}}],["实际中",{"2":{"647":1}}],["实际的正例个数",{"2":{"635":1}}],["实际正例个数",{"2":{"635":1}}],["实际为这些模型提供服务是具有挑战性的",{"2":{"332":1}}],["实际伪代码",{"2":{"315":1}}],["实际工程上的",{"0":{"212":1}}],["实际工程中",{"2":{"180":1}}],["实际场景中",{"2":{"160":1}}],["实际上等价于",{"2":{"822":1}}],["实际上只是一个只依赖于",{"2":{"644":1}}],["实际上是表达式",{"2":{"471":1}}],["实际上我们把重心放在进一步理解问题上",{"2":{"366":1}}],["实际上",{"2":{"14":1,"181":1,"359":1,"401":1,"468":1,"927":1}}],["实现了细粒度的表情生成与动画控制",{"2":{"859":1}}],["实现实时光照",{"2":{"857":1}}],["实现复信",{"2":{"827":1}}],["实现同步也就是实现临界区进程",{"2":{"683":1}}],["实现命名实体识别",{"0":{"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1}}],["实现比",{"2":{"510":1}}],["实现可用",{"2":{"510":1}}],["实现可能会在版本之间发生重大变化",{"2":{"401":1}}],["实现则在此基础上在垂直方向上进行融合",{"2":{"510":1}}],["实现看作是在水平方向上进行融合",{"2":{"510":1}}],["实现通常更快",{"2":{"510":1}}],["实现绝对值运算符",{"2":{"441":1}}],["实现负号运算符",{"2":{"441":1}}],["实现正号运算符",{"2":{"441":1}}],["实现右侧的位右移运算符",{"2":{"441":1}}],["实现右侧的位左移运算符",{"2":{"441":1}}],["实现右侧整数除法运算",{"2":{"441":1}}],["实现就地幂运算",{"2":{"441":1}}],["实现幂运算",{"2":{"441":1}}],["实现并不总能正确处理每台设备的批次大小",{"2":{"394":1}}],["实现逻辑",{"0":{"309":1}}],["实现细节",{"0":{"448":1},"2":{"226":1,"315":1}}],["实现举例",{"0":{"172":1}}],["实现原理",{"2":{"95":1}}],["实现",{"0":{"281":1,"285":1,"289":1,"296":1,"836":1},"1":{"837":1,"838":1,"839":1,"840":1,"841":1,"842":1,"843":1,"844":1,"845":1,"846":1,"847":1,"848":1,"849":1,"850":1,"851":1,"852":1},"2":{"80":1,"81":1,"83":1,"86":1,"87":1,"88":1,"89":1,"93":1,"94":1,"95":1,"98":1,"99":1,"100":1,"101":1,"104":1,"106":1,"107":1,"108":1,"110":1,"113":1,"114":1,"121":2,"122":1,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"536":1,"822":1}}],["实现更高效的并行计算",{"2":{"74":1}}],["解题步骤",{"0":{"956":1}}],["解题思路",{"2":{"12":1}}],["解压缩",{"2":{"768":1}}],["解包",{"2":{"768":1}}],["解包操作",{"2":{"472":1}}],["解除sql与程序代码的耦合",{"2":{"724":1}}],["解方程",{"0":{"456":1}}],["解线性方程组",{"2":{"441":1}}],["解耦",{"2":{"299":1,"644":1}}],["解码过程",{"0":{"634":1}}],["解码序列长度也没有现阶段大模型的要求那么高",{"2":{"217":1,"303":1}}],["解码器还插入第三个子层",{"2":{"197":1}}],["解码器同样由n",{"2":{"197":1}}],["解码器",{"0":{"197":1}}],["解码器生成符号的一个输出序列",{"2":{"194":1}}],["解码器结构",{"2":{"194":1}}],["解码器进行相反的过程",{"2":{"167":1}}],["解码的过程中",{"2":{"168":1}}],["解码",{"2":{"168":1}}],["解决方案",{"0":{"912":1},"1":{"913":1,"914":1}}],["解决方案相比",{"2":{"329":1}}],["解决rollup",{"2":{"873":1}}],["解决之前的问题",{"0":{"484":1}}],["解决这个问题的一种方法是创建假数据并",{"2":{"344":1}}],["解决context长度限制问题",{"2":{"174":1}}],["解决此问题的结构称之为encoder",{"2":{"165":1}}],["解决",{"0":{"162":1,"163":1,"164":1},"2":{"130":1}}],["解决梯度消失问题",{"2":{"130":1}}],["解决思路",{"2":{"120":1,"467":1}}],["解决的是用更加廉价的设备资源",{"2":{"74":1}}],["与通信后并协调它们的行为而形成的系统",{"2":{"796":1}}],["与系统其他部分相对而言",{"2":{"723":1}}],["与硬盘",{"2":{"722":1}}],["与个人实际的生活或者学习内容相结合来阅读",{"2":{"702":1}}],["与从头训练相比",{"2":{"617":1}}],["与无梯度模式和推断模式完全无关",{"2":{"480":1}}],["与无梯度模式类似",{"2":{"479":1}}],["与我们进行了有益的讨论",{"2":{"420":1}}],["与我们现有的配置相比",{"2":{"378":1}}],["与对20个试验进行抽样时的四分位间距有多大的区别",{"2":{"403":1}}],["与自适应算法相比",{"2":{"401":1}}],["与更复杂的黑盒优化工具",{"2":{"401":1}}],["与初始学习率的关系",{"2":{"373":1}}],["与batch",{"2":{"361":1}}],["与此同时",{"2":{"353":1,"616":1}}],["与dropout不同的是",{"2":{"347":1}}],["与典型的树不同",{"2":{"338":1}}],["与传统方法不同",{"2":{"337":1}}],["与传统的注意力算法不同",{"2":{"333":1}}],["与传统的序列并行",{"2":{"329":1}}],["与之前的",{"2":{"328":1}}],["与gemm的异步wgmma指令重叠",{"2":{"325":1}}],["与其本质没有太大区别",{"2":{"967":1}}],["与其他的标签和输入没有关系",{"2":{"626":1}}],["与其余的cuda核心执行逻辑",{"2":{"325":1}}],["与其它激活函数有何不同",{"2":{"129":1}}],["与没有因果掩码的注意力相比",{"2":{"322":1}}],["与sgd相比",{"2":{"262":2}}],["与批量梯度下降",{"2":{"261":1}}],["与正常的反向传播推导不一样",{"2":{"249":1}}],["与encoder的multi",{"2":{"214":1}}],["与编码器类似",{"2":{"197":1}}],["与经典rnn结构不同的是",{"2":{"168":1}}],["与lstm非常相似",{"2":{"156":1}}],["与leakyrelu",{"2":{"125":1}}],["与rnn",{"0":{"153":1}}],["与",{"0":{"127":1},"2":{"327":1,"369":2,"444":1,"477":1,"619":1}}],["与cuda",{"2":{"71":1}}],["与目标值",{"2":{"29":1}}],["沿着输入图像的",{"2":{"65":1}}],["宽度",{"2":{"65":1}}],["动量",{"2":{"369":1,"412":1}}],["动量等",{"2":{"361":1}}],["动量直接并入了梯度一阶矩",{"2":{"294":1}}],["动量算法可以在一定程度缓解这些问题",{"2":{"276":1}}],["动量算法积累了之前梯度指数级衰减的移动平均",{"2":{"263":1}}],["动量的形式",{"2":{"284":1}}],["动量的方法",{"2":{"271":1}}],["动量的积累",{"2":{"266":1}}],["动量可以平滑参数更新的路径",{"2":{"266":1}}],["动量项",{"2":{"294":1}}],["动量项可以帮助算法在平坦区域上获得更大的动量",{"2":{"267":1}}],["动量项可以减少参数更新方向的震荡",{"2":{"266":1,"267":1}}],["动量项会逐渐增大",{"2":{"266":1}}],["动量项会考虑前一次更新的方向和幅度",{"2":{"266":1}}],["动量方法",{"2":{"263":1}}],["动态规划",{"2":{"922":1}}],["动态性的一个重要体现",{"2":{"471":1}}],["动态原理图",{"2":{"447":1}}],["动态效果展示",{"2":{"265":1}}],["动态计算图",{"2":{"157":1,"448":1}}],["动态展示为",{"2":{"152":1}}],["动态图更灵活",{"2":{"559":1}}],["动态图的一个典型示例是pytorch的计算图",{"2":{"559":1}}],["动态图是在模型执行阶段构建的计算图",{"2":{"559":1}}],["动态图机制",{"0":{"466":1}}],["动态图",{"2":{"462":1}}],["动态图如下",{"2":{"136":1}}],["动态图为",{"2":{"61":1}}],["动物的中枢神经系统",{"2":{"5":1}}],["之",{"2":{"868":1}}],["之所以要独立出一个",{"2":{"723":1}}],["之所以没有被关注到",{"2":{"217":1,"303":1}}],["之一",{"2":{"538":1}}],["之前版本异同",{"0":{"608":1}}],["之前",{"2":{"509":1}}],["之前将会被调用",{"2":{"509":1}}],["之前最大限度地改进模型",{"2":{"365":1}}],["之类的工具对输入管道预读取数据",{"2":{"387":1}}],["之后以并发方式来加以解决",{"2":{"797":1}}],["之后详述",{"2":{"624":1}}],["之后将会被调用",{"2":{"509":1}}],["之后调用该函数",{"2":{"505":1}}],["之后可以切换到更通用的优化器",{"2":{"356":1}}],["之后再反正切",{"2":{"445":1}}],["之后再构建自定义模型也是可行的",{"2":{"355":1}}],["之后再进行卷积来实现",{"2":{"61":1}}],["之后的一项研究表明",{"2":{"619":1}}],["之后的信息给隐藏起来",{"2":{"216":1}}],["之后的输出",{"2":{"216":1}}],["之后更是蔓延到了vision",{"2":{"193":1}}],["之后",{"2":{"191":1,"338":1,"353":1,"509":1,"878":1}}],["之间无密码运行",{"2":{"827":1}}],["之间也存在连线",{"2":{"628":1}}],["之间的互斥访问",{"2":{"683":1}}],["之间的内积得到",{"2":{"648":1}}],["之间的内积操作可以被一个函数",{"2":{"646":1}}],["之间的区别",{"2":{"359":1}}],["之间的一种梯度下降优化算法",{"2":{"262":1}}],["之间的范围",{"2":{"148":1}}],["之间",{"2":{"147":1,"148":1}}],["之间且总和为1的概率分布",{"2":{"129":1}}],["之间形状有何关系",{"2":{"55":1}}],["注册的钩子可以用于在",{"2":{"509":1}}],["注册的钩子可以用于在进行",{"2":{"509":1}}],["注册的钩子可用于在返回state",{"2":{"509":1}}],["注册的钩子可用于在进行state",{"2":{"509":1}}],["注册的钩子函数可用于在进行state",{"2":{"496":1}}],["注册",{"2":{"496":3}}],["注册一个",{"2":{"509":2}}],["注册一个状态字典后置钩子",{"2":{"509":1}}],["注册一个状态字典前置钩子",{"2":{"509":1}}],["注册一个优化器",{"2":{"509":2}}],["注册一个后置钩子函数",{"2":{"496":1}}],["注册一个不被视为模型参数的缓冲区",{"2":{"496":1}}],["注册一个梯度累加之后的反向钩子函数",{"2":{"441":1}}],["注册反向传播钩子函数",{"2":{"495":1}}],["注册反向钩子函数",{"2":{"441":1}}],["注册前向钩子函数",{"2":{"494":1}}],["注",{"2":{"388":1,"390":2}}],["注意点",{"2":{"731":1}}],["注意力层只能访问句子中位于它之前的词语",{"2":{"620":1}}],["注意力层都可以访问到原始输入句子中的所有词语",{"2":{"619":1}}],["注意力",{"2":{"619":1}}],["注意这里过滤了含有水印的图片",{"2":{"608":1}}],["注意横轴的刻度是以对数的形式展示",{"2":{"407":1}}],["注意选择冗余超参数的搜索空间",{"2":{"368":1}}],["注意不是充分条件",{"2":{"243":1}}],["注意到tanh",{"2":{"240":1}}],["注意",{"2":{"179":1,"245":2,"262":1,"338":1,"381":1,"382":1,"405":1,"504":1,"507":1,"544":1,"545":1,"595":1,"626":1,"655":1,"735":1,"841":1,"849":1,"876":1,"908":1}}],["注解",{"2":{"61":1}}],["注释2",{"2":{"440":1,"659":1}}],["注释1",{"2":{"440":1}}],["注释",{"2":{"4":1,"9":1,"21":1,"120":2,"122":1,"126":1,"127":1,"225":1,"244":1,"313":1,"329":1,"444":1,"544":1,"659":1}}],["但时间有限",{"2":{"941":1}}],["但你的预算有限",{"2":{"937":1}}],["但对着镜子又看不到自己",{"2":{"880":1}}],["但对于某些类别的超参数",{"2":{"369":1}}],["但每次都会有不一样的感触",{"2":{"880":1}}],["但每执行一次训练都要进行一次评估",{"2":{"405":1}}],["但尽管如此",{"2":{"880":1}}],["但依旧让我回味无穷",{"2":{"880":1}}],["但依旧还是有点问题",{"2":{"878":1}}],["但眼泪并不是因为难过而流",{"2":{"878":1}}],["但孔子的这个",{"2":{"878":1}}],["但孔老夫子所言的学可不是狭义的学",{"2":{"878":1}}],["但老师这句话就是孔子真正意义上的广义的",{"2":{"878":1}}],["但就我的理解来说答案是肯定的",{"2":{"878":1}}],["但我希望大家的日程安排是顺其自然",{"2":{"942":1}}],["但我觉得我们追求严谨并非是件好事",{"2":{"972":1}}],["但我觉得理解这个",{"2":{"878":1}}],["但我觉得",{"2":{"878":1}}],["但我在成长的过程中会更加像第二家老板学习",{"2":{"875":1}}],["但我们建议您熟悉它",{"2":{"470":1}}],["但我们能够按顺序运行许多试验",{"2":{"401":1}}],["但我们相信尝试一些",{"2":{"397":1}}],["但我们不相信这在通常情况下是正确的",{"2":{"384":1}}],["但我们通常不希望以这种方式选择学习率",{"2":{"375":1}}],["但我们还涉及深度学习学习的其他方面",{"2":{"352":1}}],["但没必要",{"2":{"875":1}}],["但最终都需要在硬件上实现效果",{"2":{"858":1}}],["但针对不同的k",{"2":{"853":1}}],["但当下一个点y为y+1的时候要d",{"2":{"849":1}}],["但当不稳定迫使我们使用太小的学习率时",{"2":{"405":1}}],["但需要更细致的同步控制",{"2":{"807":1}}],["但需要有配对好的文本集才能训练出对应的模型",{"2":{"167":1}}],["但会导致一定的同步开销",{"2":{"807":1}}],["但扩展性有限",{"2":{"801":1}}],["但可以基于其独特的id执行不同的任务",{"2":{"806":1}}],["但可以通过多线程或协程实现并行化",{"2":{"799":1}}],["但可能是模型状态的一部分",{"2":{"496":1}}],["但可能不能完全代表生产环境",{"2":{"389":1}}],["但可能有很多例外",{"2":{"384":1}}],["但可能会丢失一些细节",{"2":{"94":1}}],["但有一些对象是无论如何都不能丢失的",{"2":{"722":1}}],["但有一些共同的特征",{"2":{"509":1}}],["但同一时刻只能被一个进程或线程使用的资源",{"2":{"681":1}}],["但又不会聚成超小的小簇",{"2":{"657":1}}],["但另一方面",{"2":{"622":1}}],["但启用推断模式将使得",{"2":{"479":1}}],["但仍希望在后续的梯度模式中使用这些计算的输出时",{"2":{"478":1}}],["但仅对叶张量设置它才有意义",{"2":{"475":1}}],["但仅进行原始训练步骤的一小部分α",{"2":{"220":1,"306":1}}],["但出于性能原因",{"2":{"473":1}}],["但并非总是如此",{"2":{"472":1}}],["但并不一定在所有情况下都表现更好",{"2":{"120":1}}],["但超参数这个术语在深度学习社区中已经变得极为通俗",{"2":{"411":1}}],["但如果你继续往上爬",{"2":{"970":1}}],["但如果未传递任何对象",{"2":{"496":1}}],["但如果这个奏效",{"2":{"410":1}}],["但如果进行了调整",{"2":{"384":1}}],["但90",{"2":{"410":1}}],["但由于其名称",{"2":{"474":1}}],["但由于不稳定的影响",{"2":{"404":1}}],["但由于大大减少了对hbm的访问量",{"2":{"222":1,"314":1}}],["但肯定有可能找到最先进的贝叶斯优化技术可以击败两倍预算随机搜索的搜索空间和问题",{"2":{"401":1}}],["但作为验证错误函数的人在循环计划是脆弱的并且不容易重现",{"2":{"399":1}}],["但要求完全相信某些东西会有所帮助也不是正确的要求",{"2":{"378":1}}],["但往往仅试验方差就能在使用相同超参数设置的两个不同的训练模型之间产生统计上的显著差异",{"2":{"378":1}}],["但使用两个不同的种子进行quasi",{"2":{"378":1}}],["但套用杰弗里",{"2":{"377":1}}],["但还有许多其他的行为可以通过检查训练曲线而变得明显",{"2":{"375":1}}],["但它简单高效",{"2":{"929":1}}],["但它能让你快速做出决定",{"2":{"921":1}}],["但它的模型大小使其难以部署在低延迟需求的环境中",{"2":{"619":1}}],["但它是模块的状态的一部分",{"2":{"493":1}}],["但它们只是将状态与参数组关联起来的id",{"2":{"509":1}}],["但它们仍然共享相同的存储",{"2":{"472":1}}],["但它们通常会过于复杂",{"2":{"385":1}}],["但它只是因为更多的样本被正确预测了吗",{"2":{"391":1}}],["但它发生在所有试验中时",{"2":{"375":1}}],["但它也涵盖了我们在工作中遇到",{"2":{"353":1}}],["但它也可能陷入糟糕的局部最小值中",{"2":{"260":1}}],["但检查训练曲线是识别常见故障模式的简单方法",{"2":{"375":1}}],["但代价是显而易见的",{"2":{"374":1}}],["但值",{"2":{"369":1}}],["但通常会包含一些更复杂的任务",{"2":{"621":1}}],["但通常",{"2":{"383":1}}],["但通常应该假设优化器超参数必须单独调整",{"2":{"369":1}}],["但通常我们的最大资源预算低于调整所有非目标超参数所需的计算资源",{"2":{"369":1}}],["但通过",{"2":{"328":1}}],["但实践中这往往不实际",{"2":{"365":1}}],["但至少意味着经过训练的模型在验证集上的性能比随机机会好得多",{"2":{"363":1}}],["但不太影响正常阅读",{"2":{"702":1}}],["但不包括其子模块",{"2":{"496":1}}],["但不能保证",{"2":{"473":1}}],["但不保存",{"2":{"464":1}}],["但不是万无一失的",{"2":{"401":1}}],["但不是全部",{"2":{"277":1}}],["但不会显着减少验证误差",{"2":{"380":1}}],["但不限于",{"2":{"356":1}}],["但深度学习在工程领域仍处于起步阶段",{"2":{"353":1}}],["但据我们所知",{"2":{"329":1}}],["但重新组织计算",{"2":{"327":1}}],["但在高并行条件下",{"2":{"401":1}}],["但在多设备设置中",{"2":{"394":1}}],["但在不能替换的情况下",{"2":{"394":1}}],["但在模型开发阶段往往是不切实际的",{"2":{"389":1}}],["但在某些应用中",{"2":{"378":1}}],["但在重复实验后发现",{"2":{"378":1}}],["但在试验中将验证误差减少到固定数字时我们必须小心",{"2":{"375":1}}],["但在每个优化器中运行良好的值范围通常相差几个数量级",{"2":{"369":1}}],["但在初始配置中添加它们可能会浪费时间调整无用的功能和",{"2":{"363":1}}],["但在大众开始记录它并讨论各个步骤之前",{"2":{"353":1}}],["但在非矩阵乘法fp32上只有19",{"2":{"320":1}}],["但在实现上却更为复杂",{"2":{"316":1}}],["但在生成过程中",{"2":{"308":1}}],["但所取得的结果之间存在着巨大的差距",{"2":{"353":1}}],["但所需的kv缓存显著减少",{"2":{"308":1}}],["但所有已知的实现都需要以速度换取内存",{"2":{"228":1,"318":1}}],["但其不提供任何训练吞吐量优势",{"2":{"358":1}}],["但其性能无法与mha相媲美",{"2":{"308":1}}],["但其学习过程有时会很慢",{"2":{"263":1}}],["但这只能帮你解决简单的问题",{"0":{"935":1}}],["但这些人脸是从未出现过的全新的人脸",{"2":{"653":1}}],["但这些实现是较新的",{"2":{"510":1}}],["但这些方面并不详尽",{"2":{"352":1}}],["但这通常需要手动配置和特定的调整",{"2":{"337":1}}],["但这会给我们的架构增加复杂性",{"2":{"329":1}}],["但这可能会使计算",{"2":{"328":1}}],["但这样做的代价是引入了另一个超参数",{"2":{"276":1}}],["但这里说是",{"2":{"61":1}}],["但相对更稳定",{"2":{"262":1}}],["但总的运行时间还是加速的",{"2":{"227":1,"317":1}}],["但也许实际情况并非如此",{"2":{"723":1}}],["但也不会离得太近",{"2":{"657":1}}],["但也应该足够大",{"2":{"391":1}}],["但也容易在训练数据上表现出很好的性能而在新数据上表现较差",{"2":{"341":1}}],["但也容易产生过多的参数",{"2":{"341":1}}],["但也会引入显著的开销",{"2":{"328":1}}],["但也有一些问题适合用经典的rnn结构建模",{"2":{"161":1}}],["但也是很重要的",{"2":{"117":1}}],["但elu",{"2":{"125":1}}],["但",{"2":{"121":1}}],["但处处",{"2":{"120":1}}],["但您不应依赖于复制与视图行为",{"2":{"98":1}}],["但具有指定形状的张量",{"2":{"98":1}}],["但保留重要的特征信息",{"2":{"92":1}}],["但是有些似乎你明白的东西",{"2":{"702":1}}],["但是几乎无法控制生成序列的风格",{"2":{"620":1}}],["但是它们依然可以被归纳到以下三种结构中",{"2":{"618":1}}],["但是依然可以按模型结构将它们大致分为三类",{"2":{"616":1}}],["但是不保留",{"2":{"462":1}}],["但是backward对我们用户是不可见的",{"2":{"462":1}}],["但是quasi",{"2":{"401":1}}],["但是根据已有的结论我们可以提出一些猜测",{"2":{"384":1}}],["但是在这个时间限制下的结论不一定适用于20",{"2":{"383":1}}],["但是在最开始训练的时候需要每个参数有相应的初始值",{"2":{"233":1}}],["但是否使用正则化技术往往是目标或固定超参数",{"2":{"369":1}}],["但是我们可以看具体的例子",{"2":{"403":1}}],["但是我们会发现一个问题",{"2":{"271":1}}],["但是我们并不知道他的原理是什么",{"2":{"19":1}}],["但是会带来精度上的损失",{"2":{"220":1,"306":1}}],["但是如果直接拿来完成特定任务",{"2":{"616":1}}],["但是如果直接使用score来挑选的话",{"2":{"186":1}}],["但是如果输入的序列太长",{"2":{"215":1}}],["但是随着序列长度的增加",{"2":{"186":2}}],["但是既然叫",{"2":{"183":1}}],["但是",{"2":{"177":1,"190":1,"248":1,"338":1,"352":1,"370":1,"378":1,"379":1,"383":1,"384":1,"412":1,"889":1}}],["但是长期的记忆影响就很小",{"2":{"143":1}}],["但是激活函数如",{"2":{"120":1}}],["但是图像风格化中",{"2":{"88":1}}],["但是当batch",{"2":{"86":1}}],["但是一般会采用这个加速库",{"2":{"75":1}}],["但是并不能通用",{"2":{"19":1}}],["转到cuda",{"2":{"496":1}}],["转为复数域",{"2":{"649":1}}],["转为char",{"2":{"445":1}}],["转为bfloat16",{"2":{"445":1}}],["转为压缩稀疏行布局",{"2":{"444":1}}],["转为压缩稀疏列布局",{"2":{"444":1}}],["转为块稀疏行布局",{"2":{"444":1}}],["转为块稀疏列布局",{"2":{"444":1}}],["转为sparse",{"2":{"444":1}}],["转为",{"2":{"444":2}}],["转为整型",{"2":{"443":1}}],["转化",{"0":{"434":1}}],["转化为更容易理解的形式",{"2":{"52":1}}],["转移概率就越大",{"2":{"628":1}}],["转移的概率会比较大",{"2":{"628":1}}],["转移分数",{"0":{"628":1},"2":{"632":1}}],["转移",{"2":{"384":1}}],["转换后的检查点接着使用相同的预训练方法进行预训练",{"2":{"220":1,"306":1}}],["转置卷积",{"0":{"61":1}}],["反正学校他们是免费的嘛",{"2":{"878":1}}],["反缩进",{"2":{"792":1}}],["反缩进选择内容",{"2":{"784":1}}],["反之亦然",{"2":{"628":1}}],["反序列化时触发",{"2":{"509":1}}],["反余弦",{"2":{"445":1}}],["反映了损失函数在当前状态下沿着梯度方向的变化程度",{"2":{"405":1}}],["反卷积",{"0":{"61":1},"2":{"61":3}}],["反向钩子函数展示",{"0":{"495":1}}],["反向求导原理",{"0":{"465":1}}],["反向",{"2":{"463":2}}],["反向时变为",{"2":{"249":1}}],["反向时句子顺序需要倒序吗",{"2":{"140":1}}],["反向推导过程",{"0":{"249":1}}],["反向公式推导类似",{"2":{"245":1}}],["反向过程为",{"2":{"44":1}}],["反向传播和优化",{"2":{"567":1}}],["反向传播钩子函数",{"2":{"495":1}}],["反向传播用到的函数",{"2":{"465":1}}],["反向传播算法",{"0":{"463":1}}],["反向传播算法才被提出",{"2":{"29":1}}],["反向传播比正向传播更简单",{"2":{"316":1}}],["反向传播应用了平铺",{"2":{"316":1}}],["反向传播还实现了2",{"2":{"316":1}}],["反向传播中",{"2":{"316":1}}],["反向传播是的线性变换为",{"2":{"249":1}}],["反向传播通常需要矩阵",{"2":{"228":1,"318":1}}],["反向传播过程中",{"2":{"490":2}}],["反向传播过程",{"0":{"42":1},"1":{"43":1,"44":1,"45":1,"46":1}}],["反向传播总结",{"0":{"36":1}}],["反向传播目的确认",{"0":{"31":1}}],["反向传播数学推导",{"0":{"30":1},"1":{"31":1,"32":1,"33":1,"34":1,"35":1}}],["反向传播的目的是求",{"2":{"27":1}}],["反向传播的定义",{"0":{"25":1}}],["反向传播",{"2":{"24":1,"25":1,"27":1,"239":1,"454":1,"495":1}}],["图形变换",{"2":{"857":1}}],["图形硬件加速和gpu编程",{"2":{"857":1}}],["图形学包含大量的数学理论",{"2":{"858":1}}],["图形学技术不断创新",{"2":{"858":1}}],["图形学在影视动画",{"2":{"858":1}}],["图形学中的数学",{"2":{"857":1}}],["图形学基础",{"2":{"857":1}}],["图形学",{"2":{"833":1}}],["图形处理器",{"2":{"74":1}}],["图3中只设置了三列",{"2":{"627":1}}],["图优化",{"2":{"560":1}}],["图在每次迭代时都是从头开始重新创建的",{"2":{"471":1}}],["图2显示了在imagenet上训练的resnet",{"2":{"376":1}}],["图",{"0":{"562":1},"2":{"373":1,"376":1}}],["图中的每个点都对应于一次试验",{"2":{"373":1}}],["图b",{"2":{"327":1}}],["图a",{"2":{"327":1}}],["图解",{"2":{"313":1}}],["图像处理等需要对大规模数据进行并行处理的场景",{"2":{"811":1}}],["图像的预处理",{"2":{"552":1}}],["图像的跟目录",{"2":{"552":1}}],["图像翻转",{"2":{"344":1}}],["图像被视为独立的个体",{"2":{"132":1}}],["图像如下",{"2":{"125":1}}],["图像",{"2":{"102":1,"126":1,"127":1,"128":1,"605":1}}],["图如下",{"2":{"60":1}}],["图示如下",{"2":{"616":2}}],["图示",{"2":{"55":1,"81":1,"83":1,"84":1,"123":1,"124":1,"217":1,"220":1,"260":1,"261":1,"262":1,"303":1,"306":1,"537":1,"538":1,"540":1,"541":1,"543":1,"544":1,"545":1,"546":1}}],["图示卷积相对于mlp",{"2":{"55":1}}],["图示卷积是conv2d",{"2":{"55":1}}],["膨胀",{"2":{"60":1}}],["膨胀卷积",{"0":{"60":1}}],["空调却一直开着",{"2":{"878":1}}],["空间复杂度小",{"2":{"130":1}}],["空间可分离卷积是将卷积核分解为两项独立的核分别进行操作",{"2":{"59":1}}],["空间可分离卷积",{"0":{"59":1}}],["空洞卷积",{"0":{"60":1},"2":{"60":1}}],["次试验调整",{"2":{"403":1}}],["次",{"2":{"58":1,"126":1}}],["得分",{"2":{"186":1}}],["得到实际绘制的像素点",{"2":{"840":1}}],["得到结果",{"2":{"653":1}}],["得到一个类似于样本的结果",{"2":{"653":1}}],["得到一张图片的完整路径",{"2":{"552":1}}],["得到了一个新的model",{"2":{"525":1}}],["得到比baseline更好的结果",{"2":{"378":1}}],["得到非常糟糕的损失值",{"2":{"372":1}}],["得到的点有意义",{"2":{"657":1}}],["得到的结果也是一些手写数字",{"2":{"653":1}}],["得到的结果是源端",{"2":{"213":1}}],["得到的张量与",{"2":{"472":1}}],["得到的矩阵我们称之为",{"2":{"205":1}}],["得到",{"2":{"190":1}}],["得到context的方式有很多种",{"2":{"170":1}}],["得到只有",{"2":{"58":1}}],["得以优化",{"2":{"5":1}}],["再做截止时间是",{"2":{"943":1}}],["再做学问",{"2":{"878":1}}],["再选择",{"2":{"939":2}}],["再结合一点点数学",{"2":{"929":1}}],["再去深刻领悟其中的奥妙",{"2":{"878":1}}],["再说了",{"2":{"878":1}}],["再免费那也是费的学校的电",{"2":{"878":1}}],["再完善",{"2":{"829":1}}],["再系统",{"2":{"829":1}}],["再次测试",{"2":{"729":1}}],["再长就处理不了了",{"2":{"641":1}}],["再训练方差或试验方差",{"2":{"378":1}}],["再拼接到一张图上作为训练数据",{"2":{"344":1}}],["再后来",{"2":{"189":1}}],["再nlp中对最后一个维度求均值和方差",{"2":{"87":1}}],["再用",{"2":{"59":1}}],["再使用",{"2":{"58":1}}],["再堆叠在一起",{"2":{"58":1}}],["再进一步",{"2":{"27":1}}],["个地方",{"2":{"939":1}}],["个人参悟",{"0":{"878":1}}],["个人感悟",{"2":{"871":1}}],["个人提升",{"0":{"863":1}}],["个人能力与解决问题之间的差距在哪里",{"2":{"831":1}}],["个分量",{"2":{"640":1}}],["个向量",{"2":{"639":1}}],["个候选项中",{"2":{"634":1}}],["个词来预测下一个词",{"2":{"616":1}}],["个",{"2":{"609":3,"645":2,"822":1,"947":3}}],["个训练周期中没有改善",{"2":{"547":1}}],["个周期",{"2":{"537":1}}],["个输出",{"2":{"468":1}}],["个输出的softmax",{"2":{"345":1}}],["个数",{"2":{"444":1}}],["个样本计算这些归一化统计数据在实际应用中效果更好",{"2":{"394":1}}],["个最佳检查点",{"2":{"392":2}}],["个可调超参数",{"2":{"356":1}}],["个节点分组为一个流水线预填节点组",{"2":{"329":1}}],["个元素",{"2":{"309":1}}],["个参数都是从这个分布里面采样",{"2":{"248":1}}],["个中间值",{"2":{"228":1,"318":1}}],["个blocks",{"2":{"226":5}}],["个elements",{"2":{"226":1,"315":1}}],["个完全相同的层堆叠而成",{"2":{"196":1,"197":1}}],["个时间步",{"2":{"137":1}}],["个方向进行滑动",{"2":{"65":1}}],["个空格",{"2":{"60":1}}],["个通道的结果",{"2":{"58":1}}],["个通道",{"2":{"58":1}}],["个通道作卷积计算",{"2":{"58":1}}],["个卷积核分别对输入层的",{"2":{"58":1}}],["个其他神经元传递过来的输入信号",{"2":{"8":1}}],["显示隐藏文件",{"2":{"742":1}}],["显示详细信息",{"2":{"742":1}}],["显著降低了预填节点的mfu",{"2":{"329":1}}],["显卡对应的就是显卡驱动",{"2":{"73":1}}],["显卡驱动的作用就是用来驱动显卡的",{"2":{"73":1}}],["显卡驱动",{"0":{"73":1}}],["显存不足问题",{"2":{"57":1}}],["显然",{"2":{"9":1}}],["降低了计算成本",{"2":{"859":1}}],["降低了网络训练速度",{"2":{"95":1}}],["降低审查标准punsafe=0",{"2":{"608":1}}],["降低学习率",{"2":{"406":1}}],["降低到次二次方级别的水平",{"2":{"224":1,"311":1}}],["降低网络优化难度",{"2":{"92":1}}],["降低模型计算量",{"2":{"92":1}}],["降低信息冗余",{"2":{"92":1}}],["降低计算的复杂度",{"2":{"56":1}}],["降维",{"2":{"18":1}}],["滑动时的步长",{"2":{"55":1}}],["有兴趣的可以自己去研究",{"2":{"972":1}}],["有可能是当前的局部最优",{"2":{"970":1}}],["有可能出现神经网络输出为",{"2":{"122":1}}],["有一定的初步认识",{"2":{"975":1}}],["有一群小孩和若干块饼干",{"2":{"951":1}}],["有一些地方翻译的不是很恰当",{"2":{"702":1}}],["有一些同步的机制必须在临界区段的进入点与离开点实现",{"2":{"682":1}}],["有很多人天天都在焦虑",{"2":{"880":1}}],["有很多重复代码块",{"2":{"724":1}}],["有意义的事就是好好活",{"2":{"880":1}}],["有不同的理解",{"2":{"878":1}}],["有不同的解码方式可供选择",{"2":{"171":1}}],["有次回寝室",{"2":{"878":1}}],["有朋自远方来",{"2":{"877":1}}],["有多种实现",{"2":{"802":1}}],["有参",{"2":{"726":1}}],["有规律可循",{"2":{"657":1}}],["有几种机制可以在",{"2":{"474":1}}],["有几个kernel",{"2":{"55":1}}],["有关虚拟机创建的网络问题",{"0":{"908":1},"1":{"909":1,"910":1,"911":1,"912":1,"913":1,"914":1,"915":1}}],["有关",{"2":{"626":1}}],["有关requires",{"2":{"496":1}}],["有关推断模式的实现细节",{"2":{"479":1}}],["有关推断模式的详细信息",{"2":{"479":1}}],["有关更多信息",{"2":{"472":1}}],["有关详细讨论",{"2":{"362":1}}],["有密切的关系",{"2":{"463":1}}],["有哪些方法可以调用",{"2":{"431":1}}],["有哪些属性",{"2":{"431":1}}],["有些类似",{"2":{"925":1}}],["有些人很习惯去评论别人",{"2":{"880":1}}],["有些外行的都会担心人工智能会不会替代人类",{"2":{"697":1}}],["有些进程在临界区外无休止的等待",{"2":{"681":1}}],["有些操作需要保存中间结果以便执行反向传播",{"2":{"472":1}}],["有些模型可能只需要100次训练",{"2":{"409":1}}],["有些算子并不能和",{"2":{"117":1}}],["有某种衰减方案可以使模型更有可能达到良好的学习率",{"2":{"397":1}}],["有两种类型的工作模式",{"2":{"380":1}}],["有两种类型的资源成本与增加",{"2":{"360":1}}],["有足够的计算资源来进行调参实验",{"2":{"364":1}}],["有必要在开始下一步前对此进行诊断和矫正",{"2":{"358":1}}],["有",{"2":{"356":1}}],["有何不同",{"2":{"346":1}}],["有何联系",{"2":{"57":1}}],["有效",{"2":{"390":1}}],["有效的正则化策略",{"2":{"340":1}}],["有效地管理kv",{"2":{"333":1}}],["有效地管理注意力key",{"2":{"332":1}}],["有效地重叠块的传输与块级计算",{"2":{"327":1}}],["有了对分块计算",{"2":{"326":1}}],["有了以上背景知识",{"2":{"28":1}}],["有没有什么办法可以解决这个问题呢",{"2":{"319":1}}],["有助于找到更好的局部最小值或接近全局最优解",{"2":{"261":1}}],["有助于网络的收敛和训练",{"2":{"120":1}}],["有所下降",{"2":{"217":1,"303":1}}],["有所上升",{"2":{"217":1,"303":1}}],["有时候教材上解释成",{"2":{"878":1}}],["有时候根据业务的需求",{"2":{"733":1}}],["有时也被称为",{"2":{"477":1}}],["有时也被称为转置卷积",{"2":{"61":1}}],["有时",{"2":{"410":1}}],["有时可以处理一些",{"2":{"406":1}}],["有时称为intra",{"2":{"193":1}}],["有短期记忆问题",{"2":{"143":1}}],["有研究者尝试使用relu6",{"2":{"123":1}}],["有固定的梯度",{"2":{"122":1}}],["稀疏矩阵",{"2":{"444":2}}],["稀疏张量",{"2":{"444":1}}],["稀疏性再述",{"2":{"123":1}}],["稀疏连接图示",{"2":{"123":1}}],["稀疏连接",{"2":{"54":1}}],["稀疏交互",{"2":{"54":1}}],["用最小的饼干满足最小胃口的小孩",{"2":{"955":1}}],["用来去更多的地点",{"2":{"938":1}}],["用来控制移动平均的长度范围",{"2":{"283":1}}],["用真心去感受",{"2":{"878":1}}],["用强胶粘一下",{"2":{"875":1}}],["用哪查哪",{"2":{"817":1}}],["用途",{"2":{"802":6,"890":1}}],["用一个函数去近似另一个函数",{"2":{"659":1}}],["用另一个分布",{"2":{"659":1}}],["用概率的语言描述就是",{"2":{"659":1}}],["用oor",{"2":{"634":1}}],["用原score代替",{"2":{"634":1}}],["用我们的图像读取工具来读取图片",{"2":{"552":1}}],["用以遍历模块的buffers",{"2":{"496":1}}],["用register",{"2":{"490":1}}],["用户名>",{"2":{"888":1}}],["用户名",{"2":{"827":1}}],["用户不需要记住",{"2":{"822":1}}],["用户不应依赖此特性",{"2":{"472":1}}],["用户管理",{"0":{"763":1}}],["用户和组管理",{"0":{"762":1},"1":{"763":1}}],["用户程序及数据目录",{"2":{"739":1}}],["用户",{"2":{"739":1}}],["用户可以选择性地传递一个可映射对象给state",{"2":{"496":1}}],["用户应该实现此函数",{"2":{"496":1}}],["用户消息",{"2":{"338":1}}],["用起来不方便",{"2":{"467":1}}],["用作条件表达式的条件",{"2":{"443":1}}],["用np",{"2":{"441":1}}],["用netron打开查看",{"2":{"212":1}}],["用torch",{"0":{"427":1}}],["用余下神经元所构成网络来继续训练",{"2":{"346":1}}],["用了recompute",{"2":{"227":1,"317":1}}],["用",{"0":{"484":1},"2":{"215":1,"358":1,"441":1,"947":3}}],["用很小的计算代价实现了降维",{"2":{"95":1}}],["用在后面测试时用",{"2":{"86":1}}],["用卷积提取特征",{"2":{"53":1}}],["用于描述曲面",{"2":{"857":1}}],["用于描述深度学习模型的计算过程",{"2":{"559":1}}],["用于编写自定义的顶点和片段着色器",{"2":{"857":1}}],["用于模拟随机事件和逼近复杂光照模型",{"2":{"857":1}}],["用于模拟物体之间的相互作用",{"2":{"857":1}}],["用于模拟真实的光照环境",{"2":{"857":1}}],["用于模型初始化",{"2":{"395":1}}],["用于在像素网格中高效地绘制直线和圆等基本图形",{"2":{"857":1}}],["用于在注册非完整反向传播钩子时发出警告",{"2":{"496":1}}],["用于区分不同类型的消息",{"2":{"809":1}}],["用于点对点通信",{"2":{"808":1}}],["用于多个进程之间的数据传输和聚合",{"2":{"806":1}}],["用于gpu加速的并行计算",{"2":{"802":1}}],["用于学习和小规模并行计算",{"2":{"802":1}}],["用于分布式并行计算",{"2":{"802":1}}],["用于文本选择和批量操作",{"2":{"784":1}}],["用于文本选择操作",{"2":{"774":1}}],["用于文本编辑",{"2":{"752":1}}],["用于输入和编辑文本",{"2":{"774":1}}],["用于执行命令操作",{"2":{"774":1}}],["用于执行评估的",{"2":{"390":1}}],["用于保存",{"2":{"752":1}}],["用于导航和命令操作",{"2":{"752":1}}],["用于存储结果的字典",{"2":{"799":1}}],["用于存储数据",{"2":{"706":1}}],["用于存储提示和生成结果的kv",{"2":{"337":1}}],["用于表示模型的计算图及其相关操作",{"2":{"562":1}}],["用于表示和转换pytorch模型",{"2":{"562":2}}],["用于优化模型的训练过程",{"2":{"531":1}}],["用于插入",{"2":{"509":1}}],["用于pytorch2",{"2":{"509":1}}],["用于load",{"2":{"508":2}}],["用于step",{"2":{"508":1}}],["用于更新参数",{"2":{"505":1}}],["用于创建模块的副本",{"2":{"496":1}}],["用于创建子类时使用",{"2":{"444":1}}],["用于遍历网络中的所有模块",{"2":{"496":2}}],["用于遍历直接子模块",{"2":{"496":2}}],["用于遍历模块的参数",{"2":{"496":1}}],["用于生成模块的各种名称和成员的辅助方法",{"2":{"496":1}}],["用于计算复数张量的共轭张量",{"2":{"444":1}}],["用于通过索引或切片操作访问",{"2":{"443":1}}],["用于指示",{"2":{"441":1}}],["用于获取",{"2":{"441":1}}],["用于将张量的内存共享给其他进程",{"2":{"496":1}}],["用于将",{"2":{"441":1}}],["用于将一个稠密",{"2":{"441":1}}],["用于将一个连续的一维",{"2":{"441":1}}],["用于定义自定义的分发逻辑",{"2":{"441":1}}],["用于定期评估的数据集应该足够小",{"2":{"391":1}}],["用于原地修改",{"2":{"441":1}}],["用于判断某个值是否存在于",{"2":{"441":1}}],["用于返回模块的额外表示形式",{"2":{"496":1}}],["用于返回",{"2":{"441":1}}],["用于使",{"2":{"441":1}}],["用于实现右侧矩阵乘法运算符",{"2":{"441":1}}],["用于实现整数除法运算",{"2":{"441":1}}],["用于实现就地真除法运算符",{"2":{"441":1}}],["用于数据混洗和预处理",{"2":{"395":1}}],["用于",{"2":{"387":1,"508":3}}],["用于确定模型的大小和其他细节",{"2":{"355":1}}],["用于加速机器学习工作负载中最重要的操作",{"2":{"325":1}}],["用于最小化",{"2":{"258":1}}],["用于自动补全",{"2":{"176":1,"188":1}}],["用于决定要忘记多少过去的信息",{"2":{"156":1}}],["用于图像上",{"2":{"87":1}}],["用于传播误差的权重系数",{"2":{"29":1}}],["用于对函数进行估计或近似",{"2":{"5":1}}],["互相关函数形式",{"2":{"52":1}}],["等内容",{"2":{"873":1}}],["等包装器工具后",{"2":{"822":1}}],["等编译器工具并不是真正的编译器",{"2":{"822":1}}],["等待所有线程完成",{"2":{"799":1}}],["等待法",{"2":{"682":1}}],["等工具",{"2":{"705":1}}],["等模块",{"2":{"480":1}}],["等效地",{"2":{"358":1}}],["等效于mha",{"2":{"219":1,"305":1}}],["等效于mqa",{"2":{"219":1,"305":1}}],["等",{"2":{"358":1,"503":1,"706":2,"806":1,"822":1}}],["等价于",{"2":{"269":1}}],["等价变换如下",{"2":{"52":1}}],["等目前业内顶尖的",{"2":{"126":1}}],["等激活函数",{"2":{"124":1}}],["等在",{"2":{"122":1}}],["等并不满足单调的条件",{"2":{"120":1}}],["等操作的激活函数更受欢迎",{"2":{"120":1}}],["等都属于pointwise",{"2":{"108":1}}],["等于1",{"2":{"248":1}}],["等于最后一个维度",{"2":{"87":1}}],["等于计算输出值时使用的权重系数",{"2":{"29":1}}],["等变表示",{"2":{"54":2}}],["滤波器",{"2":{"52":1}}],["核心给每个进程",{"2":{"822":1}}],["核心概念",{"0":{"704":1},"1":{"705":1,"706":1}}],["核心基础知识",{"2":{"610":1,"612":1}}],["核心要点",{"2":{"323":1}}],["核心改进点",{"2":{"322":1}}],["核心不同",{"2":{"321":1}}],["核心思想",{"2":{"217":1,"303":1}}],["核心在于一个序列当前的输出与前面的输出也有关",{"2":{"133":1}}],["核心公式",{"2":{"46":1}}],["核函数",{"2":{"52":1}}],["叫做核函数",{"2":{"52":1}}],["号表示",{"2":{"52":1}}],["同步接收消息",{"2":{"808":1}}],["同步发送消息",{"2":{"808":1}}],["同步通信",{"2":{"807":1}}],["同步",{"2":{"694":1}}],["同步如何实现",{"0":{"683":1},"1":{"684":1,"685":1,"686":1,"687":1,"688":1,"689":1,"690":1,"691":1,"692":1,"693":1}}],["同步分为进程同步和资源同步",{"2":{"677":1}}],["同步是什么",{"0":{"677":1}}],["同理",{"2":{"646":1,"732":1,"733":1}}],["同理可求的",{"2":{"46":1}}],["同理可求得",{"2":{"45":1,"46":1}}],["同理可得",{"2":{"40":1,"41":1,"47":1}}],["同样沿用了",{"2":{"648":1}}],["同样转置",{"2":{"634":1}}],["同样的情况也发生在gpu1和gpu3之间",{"2":{"328":1}}],["同样的想法是一个",{"2":{"249":1}}],["同torch",{"2":{"441":1}}],["同一请求的不同块可以由不同节点同时处理",{"2":{"329":1}}],["同一份",{"2":{"217":1,"303":1}}],["同一个batch中的输入拥有相同的均值和方差",{"2":{"87":1}}],["同时结合了",{"2":{"621":1}}],["同时使用",{"2":{"621":1}}],["同时需要最小的代码更改",{"2":{"565":1}}],["同时产出模块的名称和模块本身",{"2":{"496":2}}],["同时产出buffers的名称和参数本身",{"2":{"496":1}}],["同时产出参数的名称和参数本身",{"2":{"496":1}}],["同时进行",{"2":{"496":1}}],["同时进一步了解问题",{"2":{"365":1}}],["同时保持其他参数组之间一致时",{"2":{"504":1}}],["同时保证这些结论与最终长时间运行相关",{"2":{"383":1}}],["同时保留了预训练模型所学到的通用语言表示能力",{"2":{"180":1}}],["同时避免在训练步数的数量上过度浪费",{"2":{"381":1}}],["同时优化冗余超参数",{"2":{"368":1}}],["同时深化对问题的理解",{"2":{"365":1}}],["同时从前一个主机",{"2":{"327":1}}],["同时从前一个主机接收键",{"2":{"327":2}}],["同时减少非矩阵的计算量",{"2":{"324":1}}],["同时做如下假设",{"2":{"245":1}}],["同时将k和v",{"2":{"226":1}}],["同时计算",{"2":{"226":1,"315":1}}],["同时",{"2":{"125":1,"370":1}}],["同时引入了负半轴的定义使得整体输出均值接近0",{"2":{"125":1}}],["同时这种操作方式也常常丢失了一些特征图中的细节信息",{"2":{"93":1}}],["同时又能完成归一化操作",{"2":{"86":1}}],["同时也包括关联权重和池化层",{"2":{"51":1}}],["卷积层通过池化层后一般要接多个全连接层进行降维",{"2":{"95":1}}],["卷积过程",{"2":{"64":1}}],["卷积核是具有感受野的",{"2":{"348":1}}],["卷积核被分成前后两个组",{"2":{"57":1}}],["卷积核被分成不同的组",{"2":{"57":1}}],["卷积核尺寸为",{"2":{"56":1}}],["卷积中",{"2":{"55":1}}],["卷积",{"0":{"54":1,"56":1,"65":1},"2":{"54":1,"58":1}}],["卷积的情况呢",{"2":{"65":1}}],["卷积的作用在于能有效地减少维度",{"2":{"56":1}}],["卷积的计算图",{"2":{"52":1}}],["卷积的第一个参数",{"2":{"52":1}}],["卷积是对输入图像提取出特征",{"2":{"61":1}}],["卷积是可交换的",{"2":{"52":1}}],["卷积是一种特殊的线性运算",{"2":{"51":1}}],["卷积运算通过三个重要的思想来帮助改进机器学习系统",{"2":{"54":1}}],["卷积运算动态图",{"2":{"52":1}}],["卷积运算的数学公式如下",{"2":{"52":1}}],["卷积运算",{"0":{"52":1}}],["卷积神经网络在进行完线性变换后",{"2":{"120":1}}],["卷积神经网络的灵感来自于动物视觉皮层组织的神经连接方式",{"2":{"51":1}}],["卷积神经网络需要考量的参数更少",{"2":{"51":1}}],["卷积神经网络由一个或多个卷积层和顶端的全连通层",{"2":{"51":1}}],["卷积神经网络",{"2":{"51":1}}],["卷积神经网络一词表明该网络使用了卷积",{"2":{"51":1}}],["卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络",{"2":{"51":1}}],["卷积网络",{"2":{"51":1}}],["vmware",{"2":{"909":1}}],["v4",{"2":{"636":1}}],["v0",{"2":{"613":1}}],["v0=0m",{"2":{"418":1,"419":1}}],["v0=0v",{"2":{"415":1,"416":1}}],["v0=1",{"2":{"417":1}}],["vgg19",{"2":{"590":2}}],["vgg16",{"2":{"590":2}}],["vgg13",{"2":{"590":2}}],["vgg11",{"2":{"590":2}}],["vgg",{"2":{"582":1,"585":2}}],["void",{"2":{"706":1,"726":1,"730":1,"731":1,"732":1,"733":1,"823":2}}],["vocab",{"2":{"499":2,"500":13}}],["volutional",{"2":{"51":1}}],["v3",{"0":{"665":1,"669":1},"2":{"456":1,"590":3}}],["vdot",{"2":{"445":1}}],["vd​v​​",{"2":{"208":1}}],["vulkan等图形api进行图形编程",{"2":{"857":1}}],["vulkan",{"2":{"445":1}}],["vt+1+ϵbt+1",{"2":{"419":1}}],["vt+1=β2vt+",{"2":{"418":1,"419":1}}],["vt+1=ρvt+",{"2":{"417":1}}],["vt+1=γvt+∇l",{"2":{"415":1,"416":1}}],["vtcv",{"2":{"226":1}}],["vllm的吞吐量最高提高了24倍",{"2":{"332":1}}],["vllm已经在加州大学伯克利分校开发",{"2":{"332":1}}],["vllm利用了我们的新注意力算法pagedattention",{"2":{"332":1}}],["vllm",{"0":{"331":1,"332":1},"1":{"332":1,"333":1,"334":1,"335":1}}],["video",{"2":{"897":1}}],["vim编辑器",{"0":{"817":1}}],["vim操作命令",{"0":{"773":1},"1":{"774":1,"775":1,"776":1,"777":1,"778":1,"779":1,"780":1,"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1,"788":1,"789":1,"790":1,"791":1,"792":1,"793":1}}],["vim",{"0":{"750":1,"774":1,"775":1},"1":{"751":1,"752":1,"753":1,"776":1,"777":1},"2":{"751":3,"753":1,"774":1,"787":2,"788":1,"789":1,"792":1,"794":1,"817":6}}],["vitepress解析展示latex数学公式",{"2":{"870":1}}],["viterbi",{"0":{"634":1},"2":{"634":2}}],["vit",{"2":{"590":4,"608":2}}],["virtualbox安装linux虚拟机",{"2":{"815":1}}],["virtual",{"2":{"333":1,"705":1}}],["viq",{"2":{"326":1}}],["view",{"0":{"97":1,"99":1},"1":{"98":1,"99":1,"100":1,"101":1},"2":{"99":3,"112":1,"437":1,"438":1,"440":2,"441":1,"444":2,"445":4,"455":1,"468":1,"497":1,"498":4,"500":6,"634":7,"649":7}}],["v已加载到sram中重新计算注意力矩阵s和p的值",{"2":{"316":1}}],["v2从以下三个方面做了改进",{"2":{"324":1}}],["v2设计了一种创新的注意力机制",{"2":{"308":1}}],["v2",{"0":{"321":1,"324":1,"664":1,"667":1},"2":{"307":1,"308":1,"455":1,"456":1,"590":5,"636":1}}],["v块轻松地重新计算注意力矩阵s和p",{"2":{"228":1,"318":1}}],["v的梯度",{"2":{"228":1,"318":1}}],["vjk",{"2":{"226":1,"326":1}}],["v​0​​=1",{"2":{"417":1}}],["v​0​​=0",{"2":{"415":1,"416":1,"418":1,"419":1}}],["v​t+1​​=β​2​​v​t​​+",{"2":{"418":1,"419":1}}],["v​t+1​​=ρv​t​​+",{"2":{"417":1}}],["v​t+1​​=γv​t​​+∇l",{"2":{"415":1,"416":1}}],["v​t​c​​​​",{"2":{"226":1}}],["v​i​​",{"2":{"326":1}}],["v​j​​",{"2":{"226":1,"326":1}}],["v​1​​",{"2":{"226":1}}],["v1",{"0":{"321":1,"324":1,"663":1},"2":{"226":1,"456":1,"518":1,"519":1,"608":9}}],["vw​i​v​​",{"2":{"209":1}}],["vwiv",{"2":{"209":1}}],["v",{"2":{"200":5,"205":1,"208":1,"209":8,"223":2,"224":2,"226":5,"230":1,"311":2,"312":2,"315":2,"326":2,"330":1,"415":3,"416":3,"417":2,"418":3,"419":3,"455":2,"498":4,"500":4,"605":6,"643":11,"774":3,"784":6}}],["vae做分类任务的基础",{"2":{"657":1}}],["vae做生成任务的基础",{"2":{"657":1}}],["vae框架已经形成",{"2":{"657":1}}],["vae",{"0":{"602":1,"650":1,"651":1,"657":1},"1":{"652":1,"653":1,"654":1,"655":1,"656":1,"657":1},"2":{"660":3}}],["valid",{"2":{"632":2,"633":1,"634":1}}],["validation",{"2":{"577":2,"584":1,"590":1}}],["validate",{"2":{"533":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"542":1,"547":2,"548":1,"549":1}}],["val",{"2":{"443":1,"547":2,"577":1,"585":2,"588":1,"589":2}}],["value=",{"2":{"726":4}}],["valueerror",{"2":{"508":1}}],["value头",{"2":{"220":1,"306":1}}],["values",{"2":{"217":1,"227":1,"303":1,"317":1,"444":3,"445":5,"499":10,"726":1,"731":1}}],["value",{"2":{"205":1,"215":2,"217":2,"303":2,"309":1,"327":14,"332":1,"333":2,"445":26,"496":1,"498":2,"499":5,"500":2,"509":3,"634":1,"734":2}}],["value和",{"2":{"198":1}}],["value对",{"2":{"198":1}}],["vaswani等人",{"2":{"308":1}}],["vattention",{"2":{"200":1}}],["varchar",{"2":{"726":2}}],["var2",{"2":{"503":1}}],["var1",{"2":{"503":1}}],["vars=false",{"2":{"496":1}}],["vars",{"2":{"496":3}}],["vars进行调用",{"2":{"496":1}}],["variance",{"2":{"493":2}}],["variable",{"2":{"440":1,"444":1,"468":3}}],["various",{"2":{"444":1}}],["varun",{"2":{"350":1,"421":1}}],["var",{"2":{"86":10,"87":4,"88":3,"89":3,"112":2,"244":6,"245":2,"247":10,"248":42,"249":1,"445":5,"455":1,"456":3,"457":1,"460":1,"493":15,"739":1,"772":3}}],["vehicles",{"2":{"900":1}}],["very",{"2":{"544":1}}],["version=",{"2":{"726":2}}],["version>8",{"2":{"726":1}}],["version>",{"2":{"726":2}}],["version>3",{"2":{"726":1}}],["version",{"2":{"421":1,"440":1,"468":2,"490":1,"496":1,"817":1}}],["versus",{"0":{"163":1}}],["vedio",{"2":{"448":1}}],["vec",{"2":{"445":1}}],["vec2",{"2":{"445":2}}],["vector就好了",{"2":{"180":1}}],["vector来进行文本的生成的",{"2":{"176":1}}],["vector再解码",{"2":{"173":1}}],["vector",{"2":{"113":1,"170":5,"171":3,"180":1,"198":1}}],["vscode",{"2":{"816":1}}],["vsp",{"2":{"790":1}}],["vsplit",{"2":{"445":3,"790":1}}],["vs",{"0":{"162":1,"164":1,"165":1,"321":1},"2":{"10":1,"127":1,"164":1,"165":1,"462":1,"577":1}}],["随时随地",{"2":{"880":1}}],["随时随地地见习",{"2":{"878":1}}],["随手记得关一下",{"2":{"878":1}}],["随后的一系列工作对",{"2":{"619":1}}],["随后出现恢复",{"2":{"405":1}}],["随意复制生成的衰减方案通常不是一个好主意",{"2":{"399":1}}],["随机变量序列",{"2":{"626":1}}],["随机数生成器",{"2":{"395":1}}],["随机色彩处理和许多其他技术来更改图像的色彩空间",{"2":{"344":1}}],["随机",{"2":{"294":1}}],["随机梯度下降",{"2":{"261":1}}],["随机生成的值集中在距离原点位置为",{"2":{"240":1}}],["随机生成的值都较小",{"2":{"239":1}}],["随机初始化其实很难的",{"2":{"241":1}}],["随机初始化是很多人经常使用的方法",{"2":{"238":1}}],["随机初始化",{"0":{"238":1},"1":{"239":1,"240":1,"241":1}}],["随着自己的能力的提升后续尝试自己证明",{"2":{"972":1}}],["随着自己的成长和认知的提升",{"2":{"917":1}}],["随着人工智能的发展",{"2":{"927":1}}],["随着科技的进步",{"2":{"927":1}}],["随着慢慢的成长",{"2":{"878":1}}],["随着多核处理器和分布式计算系统的发展",{"2":{"797":1}}],["随着我们的探索",{"2":{"365":1}}],["随着batch",{"2":{"358":1}}],["随着深度学习的成熟并对世界产生更大的影响",{"2":{"353":1}}],["随着生成新标记",{"2":{"334":1}}],["随着网络层数的加深",{"2":{"244":1}}],["随着层数的增加",{"2":{"239":1}}],["随着模型维度的增加而扩展",{"2":{"219":1,"305":1}}],["随着序列长度的增加",{"2":{"186":1}}],["随着细胞状态的旅程进行",{"2":{"145":1}}],["随着隐层层数的增多",{"2":{"14":1}}],["随着隐层的增加",{"2":{"14":1}}],["随便给的初始值",{"2":{"50":1}}],["代替",{"2":{"441":1,"634":1}}],["代码演示",{"0":{"726":1}}],["代码和手动设置参数以及获取结果集的过程",{"2":{"721":1}}],["代码优化",{"2":{"717":1}}],["代码详解",{"0":{"631":1},"1":{"632":1,"633":1,"634":1,"635":1}}],["代码复现步骤",{"0":{"592":1}}],["代码介绍",{"0":{"591":1}}],["代码生成和优化等步骤",{"2":{"560":1}}],["代码案例2",{"2":{"487":1}}],["代码案例1",{"2":{"487":1}}],["代码案例",{"0":{"487":1}}],["代码实践之",{"0":{"437":1,"438":1}}],["代码实现",{"0":{"274":1,"449":1,"649":1,"957":1},"1":{"450":1,"451":1,"452":1,"453":1,"454":1,"455":1,"456":1,"457":1,"458":1,"459":1,"460":1},"2":{"215":1}}],["代码仓库",{"2":{"591":1}}],["代码仓中找到这些方法",{"2":{"550":1}}],["代码仓",{"2":{"431":1}}],["代码审核",{"0":{"424":1}}],["代码",{"2":{"232":1,"339":1}}],["代码地址",{"2":{"228":1,"310":1}}],["代码展示",{"0":{"50":1,"568":1,"569":1},"2":{"503":1}}],["代表一共有3个标签",{"2":{"627":1}}],["代表相应的标签序列",{"2":{"627":1}}],["代表输入变量",{"2":{"627":1}}],["代表负无穷",{"2":{"215":1}}],["代表",{"2":{"127":1,"181":1}}],["代表我们期望的那个值",{"2":{"50":1}}],["矩阵和向量运算是计算机图形学的核心工具",{"2":{"857":1}}],["矩阵型运算",{"2":{"439":1}}],["矩阵分割为",{"2":{"226":1}}],["矩阵乘法",{"2":{"226":2,"315":2}}],["矩阵的参数量",{"2":{"217":1,"303":1}}],["矩阵",{"2":{"217":1,"303":1,"444":1,"634":1}}],["矩阵化",{"2":{"205":1}}],["矩阵求导公式",{"2":{"50":1}}],["矩阵反向传播公式",{"2":{"50":1}}],[">=",{"2":{"538":1,"539":1,"540":1,"542":1,"548":1,"957":1}}],[">nqhd",{"2":{"499":1}}],[">nhqk",{"2":{"499":1}}],[">tensor",{"2":{"445":1}}],[">>",{"2":{"441":1}}],[">",{"2":{"50":3,"83":1,"328":15,"373":1,"376":1,"403":1,"404":2,"405":1,"407":1,"408":2,"409":1,"410":1,"441":5,"443":76,"444":27,"445":731,"456":3,"457":1,"496":46,"509":29,"556":1,"570":2,"595":1,"632":1,"633":2,"634":8,"635":1,"649":1,"726":15,"730":3,"731":1,"732":1,"733":1,"734":2,"743":1}}],["k=​x​1​​−x​0​​​​y​1​​−y​0​​​​",{"2":{"840":1}}],["kkk",{"2":{"840":1}}],["kx",{"2":{"839":1}}],["kxmf",{"2":{"647":1}}],["kl散度",{"2":{"659":1}}],["knk",{"2":{"646":1}}],["knowledge",{"2":{"619":1}}],["known",{"2":{"262":1}}],["kthvalue",{"2":{"445":4}}],["ktck",{"2":{"226":1}}],["kron",{"2":{"445":1}}],["krizhevsky等人提出了一种名为alexnet的深度卷积神经网络架构",{"2":{"122":1}}],["krizhevsky",{"2":{"122":1}}],["kafka",{"2":{"715":1}}],["kashgari",{"2":{"613":1}}],["kaggle",{"2":{"379":1}}],["kaiming初始化的推导过程只包含卷积和relu激活函数",{"2":{"246":1}}],["kaiming",{"0":{"246":1},"1":{"247":1,"248":1,"249":1,"250":1,"251":1,"252":1}}],["kinds",{"2":{"897":1}}],["kingma",{"2":{"294":1}}],["kill",{"2":{"756":1,"757":1}}],["kit",{"2":{"705":1}}],["ki",{"2":{"326":1}}],["k×k×ck",{"2":{"248":1}}],["kj",{"2":{"226":1,"326":1}}],["k​​x​m​​",{"2":{"647":1}}],["k​​",{"2":{"647":1}}],["k​n​​",{"2":{"646":1}}],["k​i​​",{"2":{"326":1}}],["k​j​​",{"2":{"226":1,"326":1}}],["k​t​c​​​​",{"2":{"226":1}}],["k​1​​",{"2":{"226":1}}],["k100002i",{"2":{"640":2}}],["k1",{"2":{"226":1}}],["kvcache",{"2":{"329":1}}],["kv通信发生在一个gpu和其他tp组中的对等gpu之间",{"2":{"328":1}}],["kv",{"0":{"230":1,"330":1},"2":{"219":1,"230":2,"305":1,"308":1,"309":3,"328":1,"329":1,"330":2,"333":2,"337":2,"338":1}}],["kwargs",{"2":{"490":3,"496":8,"497":9,"509":4,"510":1}}],["kwargs=none",{"2":{"441":1}}],["kw​i​k​​",{"2":{"209":1}}],["kwik",{"2":{"209":1}}],["k^",{"2":{"200":1}}],["keeping",{"2":{"556":1}}],["keep",{"2":{"496":4}}],["keepdim",{"2":{"445":42}}],["keepdim=false",{"2":{"441":1}}],["keepdim=true",{"2":{"112":1,"497":1}}],["keepdims=true0",{"2":{"86":1,"87":1,"88":1,"89":1}}],["keepdims=true",{"2":{"86":1,"87":1,"88":1,"89":1}}],["kevin",{"2":{"401":1}}],["keygen",{"2":{"827":1}}],["key应与优化器接受的关键字参数匹配",{"2":{"504":1}}],["keys",{"2":{"217":1,"303":1,"444":1,"496":2,"499":10}}],["key和value头的投影矩阵被平均汇总为单个投影矩阵",{"2":{"220":1,"306":1}}],["key和value",{"2":{"208":1}}],["key和value执行单个attention函数",{"2":{"208":1}}],["key和value分别用不同的",{"2":{"208":1}}],["key",{"0":{"892":1},"1":{"893":1,"894":1,"895":1,"896":1,"897":1},"2":{"198":2,"215":2,"217":2,"303":2,"309":1,"327":2,"333":1,"498":2,"499":7,"500":2,"504":1,"509":1,"581":1,"646":1,"648":3,"726":1,"730":1,"905":1}}],["kernels",{"2":{"80":3,"81":2}}],["kernel的shape",{"2":{"57":1}}],["kernel的通道数",{"2":{"55":1}}],["kernel",{"2":{"52":2,"55":4,"57":1,"226":1,"248":1,"315":1,"580":1}}],["k",{"2":{"50":2,"83":3,"200":4,"205":1,"206":4,"208":1,"209":8,"215":2,"223":2,"224":2,"225":1,"226":4,"228":2,"230":1,"248":2,"311":2,"312":2,"313":1,"315":2,"316":1,"318":2,"326":1,"330":1,"338":1,"345":2,"445":4,"487":1,"498":4,"500":4,"639":6,"640":7,"643":9,"644":8,"646":2,"647":6,"780":1,"790":1,"836":1,"840":2,"841":1,"849":1,"853":3}}],["kolmogorov理论指出",{"2":{"14":1}}],["两项attention可以删掉",{"2":{"644":1}}],["两数据差异比较",{"2":{"445":1}}],["两个或两个以上的进程",{"2":{"678":1}}],["两个可取函数y",{"2":{"659":1}}],["两个边界之间的距离可以按每次迭代或每个循环来进行缩放",{"2":{"543":1}}],["两个属性",{"2":{"469":1}}],["两个tensor",{"2":{"445":1}}],["两个角度认识",{"0":{"436":1}}],["两个矩阵",{"2":{"50":1}}],["两种点积机制",{"2":{"206":1}}],["两者是很相似的",{"2":{"18":1}}],["趋于一致吗",{"2":{"48":1}}],["迭代训练",{"0":{"48":1}}],["更像是一种随机应变",{"2":{"972":1}}],["更高效地处理生活中的各种挑战",{"2":{"928":1}}],["更高端的教学模式是老师只给适量的引导",{"2":{"179":1}}],["更根据不同的情况更新yi+1y",{"2":{"845":1}}],["更易单元测试",{"2":{"724":1}}],["更易维护",{"2":{"724":1}}],["更加体现出了研究人员的",{"2":{"642":1}}],["更好的区分开每个位置",{"2":{"640":1}}],["更好更快地提取稀疏特征",{"2":{"122":1}}],["更容易",{"2":{"617":1}}],["更改设置",{"2":{"914":1}}],["更改文件所有者",{"2":{"746":1}}],["更改是否自动梯度过程中应记录此module中参数",{"2":{"496":1}}],["更改batch",{"0":{"361":1},"2":{"361":1}}],["更清晰的程序",{"2":{"470":1}}],["更复杂的算法也有其自身的缺陷",{"2":{"401":1}}],["更复杂的搜索算法可能并不总能正确处理不可行的点",{"2":{"401":1}}],["更广泛的工程考虑",{"2":{"387":1}}],["更多回合可能更有意义",{"2":{"385":1}}],["更不用说100",{"2":{"383":1}}],["更详细的描述如下",{"2":{"371":1}}],["更有效的方法是从简单的配置开始",{"2":{"365":1}}],["更少步数的训练意味着每次训练运行得更快并且使用更少的资源",{"2":{"363":1}}],["更通用",{"2":{"356":1}}],["更糟糕的是",{"2":{"353":1}}],["更快的训练来改善结果",{"2":{"380":1}}],["更快的更新速度",{"2":{"261":1}}],["更快地接近最优解",{"2":{"266":1}}],["更大的模型通常会按比例增加头的数量",{"2":{"219":1,"305":1}}],["更节省空间",{"2":{"203":1}}],["更重要的是gap极大减少了网络参数",{"2":{"95":1}}],["更新进度",{"0":{"882":1}}],["更新日志",{"0":{"865":1,"907":1},"1":{"866":1,"867":1,"868":1,"869":1,"870":1,"871":1,"872":1,"873":1,"874":1}}],["更新系统和安装软件包",{"0":{"770":1}}],["更新学习率",{"2":{"545":1}}],["更新的模板为",{"2":{"533":1}}],["更新的幅度也很小",{"2":{"236":1}}],["更新module的状态",{"2":{"496":1}}],["更新运行时的均值和方差",{"2":{"493":1}}],["更新权重",{"2":{"484":2}}],["更新剪辑",{"2":{"405":1}}],["更新门的功能类似于lstm中的遗忘门和输入门",{"2":{"156":1}}],["更新门",{"2":{"156":1}}],["更新weight",{"2":{"50":1}}],["更新",{"2":{"47":1,"709":1}}],["更一般的",{"2":{"13":1}}],["于是排查错误",{"2":{"889":1}}],["于是我尝试使用create",{"2":{"889":1}}],["于是我们寻找新的方法",{"2":{"659":1}}],["于是我们得到随机变量",{"2":{"248":1}}],["于是我们得到最终方差传递公式",{"2":{"248":1}}],["于是我们可以得到两组结论",{"2":{"245":1}}],["于是我们可以得出这样的结论",{"2":{"14":1}}],["于是上式可化简为",{"2":{"248":1}}],["于是可得到",{"2":{"46":1}}],["×",{"2":{"445":1}}],["×d",{"2":{"309":1}}],["×0",{"2":{"46":4}}],["×w​8​​",{"2":{"46":1}}],["×w​7​​",{"2":{"46":1}}],["×w8",{"2":{"46":1}}],["×w7",{"2":{"46":1}}],["×​∂net​h1​​​​∂out​h1​​​​×​∂w​1​​​​∂net​h1​​​​",{"2":{"46":1}}],["×∂outh1∂neth1×∂neth1∂w1",{"2":{"46":1}}],["×outo2×",{"2":{"46":1}}],["×outo1×",{"2":{"44":1,"46":1}}],["×out​o2​​×",{"2":{"46":1}}],["×out​o1​​×",{"2":{"44":1,"46":1}}],["×out​h1​​",{"2":{"44":1}}],["×outh1",{"2":{"44":1}}],["∂cost∂si",{"2":{"244":2}}],["∂eo2∂outh1",{"2":{"46":1}}],["∂eo2∂outh1=∂eo2∂outo2×∂outo2∂neto2×∂neto2∂outh1=−",{"2":{"46":1}}],["∂eo1∂outh1=−",{"2":{"46":1}}],["∂eo1∂outh1=∂eo1∂outo1×∂outo1∂neto1×∂neto1∂outh1=−",{"2":{"46":1}}],["∂eo1∂outh1+∂eo2∂outh1",{"2":{"46":1}}],["∂etotal∂w1=0",{"2":{"46":1}}],["∂etotal∂w1=∂etotal∂outh1×∂outh1∂neth1×∂neth1∂w1=",{"2":{"46":1}}],["∂etotal∂w7=0",{"2":{"45":1}}],["∂etotal∂w7=−",{"2":{"44":1}}],["∂etotal∂w7=∂etotal∂outo1×∂outo1∂neto1×∂neto1∂w7",{"2":{"44":1}}],["∂etotal∂outo1=2×12",{"2":{"45":1}}],["∂neto1∂w7=1×outh1+0+0+0=0",{"2":{"45":1}}],["∂outo1∂neto1=outo1",{"2":{"45":1}}],["∂loss∂w",{"2":{"28":1}}],["gfortran",{"2":{"822":1}}],["gg",{"2":{"780":1}}],["gunzip",{"2":{"768":1}}],["guide",{"2":{"483":1,"501":1,"671":1}}],["gcc",{"2":{"822":1}}],["gc",{"2":{"787":1}}],["gcp",{"2":{"716":1}}],["gcd",{"2":{"445":2}}],["glm",{"2":{"645":1}}],["glue",{"2":{"619":2}}],["glorot条件和xavier方法是在2010年提出的",{"2":{"245":1}}],["glorot条件",{"2":{"244":1}}],["glorot",{"0":{"244":1},"2":{"244":2}}],["globalavgpool",{"2":{"95":1}}],["global",{"0":{"95":1}}],["gzip",{"2":{"768":1}}],["gz",{"2":{"613":1,"768":1}}],["g​",{"2":{"410":2}}],["ghost",{"2":{"394":2}}],["git",{"2":{"592":1,"613":2,"636":2}}],["github上找",{"2":{"726":1}}],["github",{"2":{"302":1,"421":1,"422":1,"424":1,"431":1,"592":1,"613":1,"636":1,"721":2}}],["given",{"2":{"490":1,"556":1}}],["gilmer",{"2":{"350":1,"421":1}}],["got",{"2":{"508":1}}],["godbole",{"2":{"350":1,"421":1}}],["good",{"2":{"255":1}}],["google把第一项位置去掉",{"2":{"643":1}}],["googlenet",{"2":{"590":1}}],["googlegroups",{"2":{"422":1}}],["google",{"2":{"126":1,"127":1,"350":1,"421":1,"423":1,"616":1,"759":1}}],["g表示具有g个组的分组查询",{"2":{"219":1,"305":1}}],["gqa来减少通信量",{"2":{"328":1}}],["gqa和mqa的消融分析",{"2":{"308":1}}],["gqa不适用于编码器",{"2":{"219":1,"305":1}}],["gqa消除了这种分区的浪费",{"2":{"219":1,"305":1}}],["gqa使我们能够随着模型的增大而保持带宽和容量的相同比例减少",{"2":{"219":1,"305":1}}],["gqa",{"0":{"218":1,"219":1,"304":1,"305":1},"1":{"219":1,"305":1},"2":{"219":4,"220":1,"305":4,"306":1,"308":1,"323":1,"328":1}}],["gmail等",{"2":{"167":1}}],["gpt等模型所用的就是这种位置编码",{"2":{"641":1}}],["gpt",{"2":{"126":1,"222":1,"227":1,"314":1,"317":1,"616":3,"619":1,"620":16,"621":1}}],["gpu架构与编程",{"2":{"857":1}}],["gpus",{"0":{"588":1},"2":{"590":2}}],["gpu显存是很宝贵的",{"2":{"464":1}}],["gpu节点并行处理它们是可取的",{"2":{"329":1}}],["gpu0和gpu2组成一个cp组",{"2":{"328":1}}],["gpu在fp16",{"2":{"320":1}}],["gpu上和llama",{"2":{"332":1}}],["gpu上的张量核心",{"2":{"320":1}}],["gpu上接受少至十二小时的训练后达到翻译质量的新的最佳结果",{"2":{"193":1}}],["gpu擅长并行高强度并行计算",{"2":{"75":1}}],["gpu",{"0":{"76":1,"77":1},"1":{"77":1,"78":1},"2":{"57":1,"74":1,"326":1,"332":1,"338":1,"358":1,"441":1,"497":1,"511":1,"590":5,"895":1}}],["general",{"2":{"619":2}}],["generateschema",{"2":{"889":1}}],["generate",{"2":{"889":1}}],["generative",{"2":{"616":1}}],["generation",{"2":{"188":2,"334":1,"335":1,"622":1}}],["generator",{"2":{"445":28,"556":2}}],["ger",{"2":{"445":1}}],["geqrf",{"2":{"445":2}}],["ge",{"2":{"443":1,"445":4}}],["geoffrey",{"2":{"377":1}}],["george",{"2":{"350":1,"421":1}}],["geometric",{"2":{"344":1,"445":1}}],["gelu",{"0":{"126":1},"2":{"126":8,"444":2}}],["getenv",{"2":{"827":1}}],["getmapper",{"2":{"726":1,"730":1,"731":1,"732":1,"733":1}}],["getsession",{"2":{"726":2,"730":1,"731":1,"732":1,"733":1}}],["getstate",{"2":{"496":1,"509":1}}],["getresourceasstream",{"2":{"726":1}}],["getattr",{"2":{"496":1}}],["getitem",{"2":{"443":1,"552":2,"567":1}}],["get",{"2":{"113":1,"441":1,"445":1,"496":9,"497":1,"529":2,"541":1,"570":1,"586":1,"726":1,"799":1}}],["gemm",{"0":{"83":1}}],["g=16",{"2":{"89":1}}],["g",{"2":{"89":2,"338":1,"410":7,"556":1,"646":8,"647":1,"753":1,"780":1,"787":2,"953":2,"956":2,"957":4,"958":1}}],["gn将channel方向分group",{"2":{"89":1}}],["gn",{"2":{"87":1}}],["gather",{"2":{"328":3,"445":2,"634":1,"806":1,"808":1}}],["gated",{"0":{"154":1},"1":{"155":1,"156":1,"157":1}}],["gate",{"2":{"147":1,"148":1,"150":1,"156":4}}],["gaussian",{"0":{"126":1}}],["gap对整个网络在结构上做正则化防止过拟合",{"2":{"95":1}}],["gamma​cycle​i​​terations​​",{"2":{"543":1}}],["gammacycleiterationsgamma^",{"2":{"543":1}}],["gamma=0",{"2":{"533":3,"537":1,"538":1,"541":1,"548":1,"549":1}}],["gamma=args",{"2":{"497":1}}],["gamma",{"2":{"86":2,"87":2,"88":2,"89":2,"415":1,"416":2,"417":1,"497":3,"537":1,"538":1,"541":2}}],["gan训练",{"2":{"496":1}}],["gan",{"2":{"21":1}}],["grid",{"2":{"580":5}}],["grdients",{"2":{"464":1}}],["great",{"2":{"891":1,"899":1}}],["greater",{"2":{"445":8}}],["grep",{"2":{"749":2}}],["greedy",{"2":{"183":1}}],["gru网络来避免梯度消失问题",{"2":{"167":1}}],["gru的张量操作较少",{"2":{"156":1}}],["gru摒弃了细胞状态",{"2":{"156":1}}],["gru是循环神经网络的新一代",{"2":{"156":1}}],["gru",{"0":{"154":1,"155":1},"1":{"155":1,"156":1,"157":1}}],["gru就是典型代表",{"2":{"143":1}}],["grafana",{"2":{"716":1}}],["grayscale",{"2":{"580":1}}],["graphs",{"0":{"893":1},"2":{"447":1,"893":1}}],["graph",{"0":{"571":1},"2":{"441":1,"447":1,"448":1,"509":1,"559":2,"562":1,"579":3,"580":1,"671":1,"893":1}}],["graph=true",{"2":{"454":2,"459":3}}],["graph=false",{"2":{"441":1}}],["graph=none",{"2":{"441":1}}],["graphics",{"2":{"74":1}}],["grad属性",{"2":{"496":1}}],["grad=false",{"2":{"478":1}}],["grad=true时",{"2":{"465":1}}],["grad=true",{"2":{"440":1,"450":1,"451":1,"452":1,"453":3,"454":2,"456":7,"459":1,"460":2,"464":1,"472":2,"474":3,"475":3,"478":1}}],["gradients",{"2":{"451":2,"459":1,"894":1,"904":5}}],["gradient=none",{"2":{"441":1}}],["gradient",{"0":{"257":1,"260":1,"261":1,"268":1,"414":1,"894":1},"1":{"258":1,"259":1,"260":1,"261":1,"262":1,"269":1,"270":1,"271":1},"2":{"258":1,"260":1,"261":1,"262":7,"302":1,"381":1,"454":2,"462":1,"495":2,"505":1,"545":1,"546":1}}],["grad",{"0":{"451":1,"462":1,"467":1,"469":1,"475":1,"477":1},"2":{"50":12,"113":1,"274":1,"440":7,"441":1,"444":2,"445":15,"450":2,"451":2,"452":1,"453":11,"454":9,"455":4,"456":16,"457":9,"458":2,"459":4,"460":10,"462":10,"464":4,"465":4,"467":1,"468":7,"469":1,"471":1,"472":8,"473":1,"474":5,"475":12,"476":3,"477":3,"484":1,"487":4,"495":4,"496":15,"497":2,"500":1,"505":2,"509":1,"533":2,"546":1,"567":1,"904":2}}],["groupid>mysql",{"2":{"726":1}}],["groupid>",{"2":{"726":2}}],["groupid>org",{"2":{"726":1}}],["grouped",{"0":{"218":1,"304":1},"1":{"219":1,"305":1}}],["groupnorm",{"2":{"89":4}}],["groupnorm永远不再batch维度上做平均",{"2":{"89":1}}],["groups",{"2":{"89":2,"508":9,"509":4,"535":1,"537":1,"538":1,"539":1,"540":1,"542":1,"545":1,"548":1,"549":1}}],["group",{"0":{"57":1,"89":1},"2":{"89":1,"508":3,"509":3,"746":2,"763":1}}],["gt",{"2":{"44":6,"122":2,"223":6,"280":1,"312":6,"328":3,"394":1,"443":1,"445":4,"462":5,"510":2,"572":1,"608":1,"635":3,"723":1,"724":1,"725":3,"757":1,"784":1,"792":1,"796":3,"840":6,"889":5,"914":4}}],["末层权重梯度计算",{"0":{"43":1}}],["​⊤​​",{"2":{"643":1,"647":1}}],["​10000​2i",{"2":{"640":2}}],["​12​​",{"2":{"252":1}}],["​t​i​​​​t​cur​​​​π",{"2":{"546":1}}],["​t​max​​​​t​cur​​​​π",{"2":{"545":1}}],["​power​​",{"2":{"542":1}}],["​p​^​​",{"2":{"181":2}}],["​j​~​​",{"2":{"343":1}}],["​fan​out​​​​2​​",{"2":{"251":1}}],["​fan​in​​​​2​​",{"2":{"251":1}}],["​64×3×3​​2​​",{"2":{"249":1}}],["​w​l​​​^​​",{"2":{"249":2}}],["​w​^​​",{"2":{"249":1}}],["​32×3×3​​2​​",{"2":{"248":1}}],["​√​n​j​​+n​j+1​​​​​​​√​6​​​​​",{"2":{"245":1}}],["​√​d​k​​​​​​​1​​",{"2":{"206":1}}],["​√​d​k​​​​​​​qk​t​​​​",{"2":{"200":1}}],["​4d​​m​​",{"2":{"226":1}}],["​i​​",{"2":{"225":1,"313":1}}],["​e​x​1​​−m",{"2":{"225":1,"313":1}}],["​y​i​​​^​​",{"2":{"181":1}}],["​y​n​​​^​​",{"2":{"181":1}}],["​y​2​​​^​​",{"2":{"181":1}}],["​y​1​​​^​​",{"2":{"181":1}}],["​​b​t+1​​",{"2":{"419":1}}],["​​是新的梯度",{"2":{"410":1}}],["​​ℓ",{"2":{"225":2,"313":2}}],["​​f",{"2":{"225":4,"313":4}}],["​​​​",{"2":{"225":1,"244":1,"313":1}}],["​​​​​​∂cost​​",{"2":{"244":1}}],["​​​​​",{"2":{"225":1}}],["​​​e​x​b​​−m",{"2":{"225":1}}],["​​=a​x​​+b​y​​+c=0",{"2":{"843":1}}],["​​=argmax​y​​p",{"2":{"190":1}}],["​​=λ×​∣g∣​​g​​",{"2":{"410":1}}],["​​=​",{"2":{"45":1}}],["​​p",{"2":{"190":2,"659":1}}],["​​exp",{"2":{"129":1}}],["​​",{"2":{"127":1,"129":1,"190":1,"225":16,"244":2,"249":1,"313":17,"659":1}}],["​dx​​dtanh​​=1−tanh​2​​",{"2":{"121":1}}],["​dx​​dsigmoid​​=sigmoid",{"2":{"121":1}}],["​2−1​​∗−1+0=−",{"2":{"45":1}}],["​2​​1​​​n​l​​​^​​var",{"2":{"249":1}}],["​2​​1​​n​l​​var",{"2":{"248":1}}],["​2​​var",{"2":{"248":1}}],["​2​​+",{"2":{"248":1}}],["​2​​+var",{"2":{"247":1}}],["​2​​+​2​​1​​",{"2":{"41":1}}],["​2​​x​​",{"2":{"127":1}}],["​2​​​​",{"2":{"252":1}}],["​2​​​​1​​=out​o1​​",{"2":{"45":1}}],["​2​​​​1+e​−net​​−1​​=​1+e​−net​​​​1​​−​",{"2":{"45":1}}],["​2​​​​e​−net​​​​=​",{"2":{"45":1}}],["​2​​",{"2":{"45":1,"247":2,"248":2,"417":1,"418":1,"419":1}}],["​2​​=0",{"2":{"41":1}}],["​∂s​i​",{"2":{"244":1}}],["​∂s​i​​​​∂cost​​",{"2":{"244":1}}],["​∂out​h1​​​​∂e​o2​​​​",{"2":{"46":1}}],["​∂out​h1​​​​∂e​o2​​​​=​∂out​o2​​​​∂e​o2​​​​×​∂net​o2​​​​∂out​o2​​​​×​∂out​h1​​​​∂net​o2​​​​=−",{"2":{"46":1}}],["​∂out​h1​​​​∂e​o1​​​​=−",{"2":{"46":1}}],["​∂out​h1​​​​∂e​o1​​​​=​∂out​o1​​​​∂e​o1​​​​×​∂net​o1​​​​∂out​o1​​​​×​∂out​h1​​​​∂net​o1​​​​=−",{"2":{"46":1}}],["​∂out​h1​​​​∂e​o1​​​​+​∂out​h1​​​​∂e​o2​​​​",{"2":{"46":1}}],["​∂out​o1​​​​∂e​total​​​​=2×​2​​1​​",{"2":{"45":1}}],["​∂net​o1​​​​∂out​o1​​​​=out​o1​​",{"2":{"45":1}}],["​∂w​1​​​​∂e​total​​​​=0",{"2":{"46":1}}],["​∂w​1​​​​∂e​total​​​​=​∂out​h1​​​​∂e​total​​​​×​∂net​h1​​​​∂out​h1​​​​×​∂w​1​​​​∂net​h1​​​​=",{"2":{"46":1}}],["​∂w​7​​​​∂net​o1​​​​=1×out​h1​​+0+0+0=0",{"2":{"45":1}}],["​∂w​7​​​​∂e​total​​​​=0",{"2":{"45":1}}],["​∂w​7​​​​∂e​total​​​​=−",{"2":{"44":1}}],["​∂w​7​​​​∂e​total​​​​=​∂out​o1​​​​∂e​total​​​​×​∂net​o1​​​​∂out​o1​​​​×​∂w​7​​​​∂net​o1​​​​",{"2":{"44":1}}],["​∂w​​∂loss​​",{"2":{"28":1}}],["ecosystem",{"0":{"897":1}}],["echo",{"2":{"743":1}}],["easier",{"2":{"894":1,"897":1}}],["easy",{"0":{"896":1},"2":{"893":1,"896":1,"901":1}}],["each",{"2":{"113":1,"633":3,"634":2,"904":3}}],["especially",{"2":{"891":1,"895":1}}],["esc",{"2":{"752":1,"774":1}}],["ehtan",{"2":{"726":1}}],["effortlessly",{"2":{"899":1}}],["effective",{"2":{"718":1}}],["efficientnet",{"2":{"590":8}}],["efficient",{"2":{"326":1}}],["efficiency",{"0":{"307":1},"1":{"308":1,"309":1}}],["education",{"0":{"901":1}}],["edge",{"2":{"899":1}}],["edges",{"2":{"556":1}}],["edition",{"2":{"703":1}}],["either",{"2":{"590":1}}],["einsum",{"2":{"499":2}}],["eigenvectors=false",{"2":{"441":1}}],["eig",{"2":{"441":1}}],["evolve",{"2":{"905":1}}],["every",{"2":{"581":1,"585":1,"633":2,"634":2}}],["everytime",{"2":{"556":1}}],["evaluation",{"2":{"619":2}}],["evaluate",{"2":{"590":2,"635":1}}],["eval",{"0":{"480":1},"2":{"474":1,"480":4,"496":2,"497":1,"525":1,"636":1}}],["evict",{"2":{"338":1}}],["erfinv",{"2":{"445":2}}],["erfc",{"2":{"445":2}}],["erf",{"2":{"445":2}}],["error",{"0":{"126":1},"2":{"441":11,"496":1,"799":5}}],["eq",{"2":{"443":1,"445":4,"497":1,"635":1}}],["equivalent",{"2":{"89":2,"445":2}}],["equivariance",{"2":{"54":1}}],["equivariant",{"2":{"54":2}}],["equal",{"2":{"80":1,"81":1,"99":1,"445":15,"472":2}}],["epoch=len",{"2":{"544":1}}],["epoch=",{"2":{"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1}}],["epoch+1",{"2":{"500":1,"545":1,"567":1,"904":1}}],["epochs=10",{"2":{"544":1,"568":1}}],["epochs",{"2":{"497":2,"500":3,"541":1,"542":1,"544":2,"545":4,"567":3,"585":1,"590":3,"636":1,"904":6}}],["epoch",{"2":{"359":1,"493":1,"497":5,"500":2,"522":3,"523":2,"533":3,"535":6,"536":2,"537":4,"538":4,"539":6,"540":6,"541":3,"542":7,"543":1,"544":3,"545":2,"546":3,"547":1,"548":6,"549":6,"567":2,"571":1,"577":1,"590":3,"904":5}}],["epsilon",{"2":{"369":1,"370":1,"417":1,"418":1,"419":1}}],["epsilonϵ",{"2":{"356":1,"400":1}}],["eps",{"2":{"86":2,"87":4,"88":2,"89":2,"445":2}}],["ew​l​​",{"2":{"248":1}}],["ewl",{"2":{"248":1}}],["eye",{"2":{"428":1,"459":1}}],["ey",{"2":{"247":2}}],["emmm",{"2":{"948":1}}],["empowering",{"2":{"905":1}}],["employed",{"2":{"899":1}}],["empty",{"2":{"429":2,"445":3,"496":1,"508":1}}],["emb",{"2":{"649":2}}],["embed",{"2":{"445":1,"499":21}}],["embeddings作为condition",{"2":{"608":1}}],["embeddings",{"2":{"113":1,"897":1}}],["embedding",{"0":{"113":1,"638":1},"1":{"639":1,"640":1,"641":1,"642":1,"643":1,"644":1,"645":1,"646":1,"647":1,"648":1,"649":1},"2":{"87":5,"113":15,"499":8,"500":7,"640":1,"645":3,"647":1}}],["emitting",{"2":{"633":1}}],["emissions",{"2":{"632":4,"633":7,"634":6}}],["emission",{"2":{"627":1,"632":2,"633":2,"634":5}}],["email",{"2":{"888":1}}],["ema",{"2":{"394":2}}],["em",{"2":{"225":2,"313":2}}],["elif",{"2":{"497":1}}],["eleutherai",{"2":{"620":1}}],["electra",{"2":{"619":2}}],["ele",{"2":{"444":1}}],["elements",{"2":{"444":1}}],["element",{"2":{"441":1,"445":1}}],["else",{"2":{"434":1,"460":1,"493":1,"497":1,"511":1,"556":3,"634":1,"706":1,"799":1}}],["eln",{"2":{"326":1}}],["elliot",{"2":{"448":1}}],["ellipsis",{"2":{"445":63}}],["ell",{"2":{"225":7,"313":7}}],["elu",{"0":{"125":2},"2":{"125":5}}],["ens33",{"2":{"915":1}}],["ensures",{"2":{"904":1}}],["enabling",{"2":{"899":1}}],["enables",{"2":{"444":1}}],["enabled",{"2":{"444":2,"453":1,"474":1}}],["enjoys",{"2":{"899":1}}],["enhance",{"2":{"897":1}}],["enhanced",{"2":{"645":1}}],["environment>",{"2":{"726":1}}],["environments>",{"2":{"726":1}}],["environments",{"2":{"726":1}}],["environment",{"2":{"705":1,"726":1}}],["en",{"2":{"667":1,"668":1,"669":1,"670":1,"726":2}}],["en数据集中美学评分在5分以上的子集",{"2":{"608":1}}],["en数据集中256以上的样本量共1324m",{"2":{"608":1}}],["en数据集上以256x256大小训练237",{"2":{"608":1}}],["encoding=",{"2":{"726":2}}],["encoding",{"2":{"500":4,"616":1,"619":1}}],["encoder的nosiy",{"2":{"608":1}}],["encoderlayer",{"2":{"500":3}}],["encoder端没什么变化",{"2":{"176":1}}],["encoder把所有的输入序列都编码成一个统一的语义特征context",{"2":{"173":1}}],["encoder",{"0":{"169":1,"170":1,"499":1,"619":1,"621":1},"2":{"168":1,"169":1,"170":1,"212":1,"217":1,"219":1,"303":1,"305":1,"499":2,"500":5,"608":2,"616":3,"619":6,"621":8}}],["enc",{"2":{"500":7}}],["energy",{"2":{"499":5}}],["entry",{"2":{"633":2}}],["entropy",{"2":{"454":1}}],["entity2tuple",{"2":{"635":2}}],["entity粒度",{"2":{"635":1}}],["entity",{"2":{"188":1,"635":6}}],["enumerate",{"2":{"497":1,"529":1,"546":1,"553":1}}],["enum",{"2":{"441":1}}],["engine=innodb",{"2":{"726":1}}],["engine",{"2":{"328":1,"446":1,"447":1}}],["ends",{"2":{"632":2,"634":3}}],["end",{"2":{"181":1,"186":1,"225":1,"226":2,"313":1,"445":8,"632":2,"633":4,"634":8,"827":4}}],["eos",{"2":{"181":3}}],["eo1=12",{"2":{"45":1}}],["exec",{"2":{"886":1}}],["executing",{"2":{"494":1,"495":1}}],["exchange",{"0":{"692":1}}],["exceptions",{"2":{"799":1}}],["except",{"2":{"217":1,"303":1,"799":1}}],["exists",{"2":{"726":1}}],["existing",{"2":{"444":1}}],["exit",{"2":{"590":1}}],["external",{"2":{"556":1}}],["extensively",{"2":{"899":1}}],["extensible",{"2":{"496":1}}],["extension",{"0":{"470":1},"1":{"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1}}],["extract",{"2":{"584":1}}],["extraction",{"2":{"188":1}}],["extra",{"2":{"496":4,"897":1}}],["ex​l​​",{"2":{"248":3}}],["exl",{"2":{"248":3}}],["ex",{"2":{"247":4,"248":2,"441":3}}],["exb−m",{"2":{"225":1,"313":1}}],["ex1−m",{"2":{"225":1,"313":1}}],["experiments",{"2":{"891":1}}],["expect",{"2":{"556":1}}],["expected",{"2":{"453":1,"454":1}}],["explanation",{"2":{"904":1}}],["explained",{"2":{"448":1}}],["explore",{"2":{"873":1}}],["exploring",{"2":{"644":1}}],["expansion=forward",{"2":{"499":1}}],["expansion",{"2":{"499":5}}],["expand",{"0":{"103":1,"106":1},"1":{"104":1,"105":1,"106":1,"107":1},"2":{"106":3,"445":4,"498":1,"499":1,"580":1,"634":4}}],["expm1",{"2":{"445":2}}],["exp2",{"2":{"445":2}}],["express",{"2":{"444":1}}],["export",{"0":{"570":1},"2":{"497":1,"528":1,"570":1,"580":1,"581":1,"613":1,"636":1}}],["exponent",{"2":{"445":8}}],["exponentiallr",{"0":{"541":1},"2":{"533":2,"541":2,"548":1,"549":1}}],["exponential",{"0":{"125":1},"2":{"445":1}}],["exposure",{"2":{"177":1}}],["exp",{"2":{"120":1,"129":2,"322":1,"323":4,"445":3,"458":3,"472":1,"543":1,"633":2}}],["examples",{"2":{"337":1,"613":1,"636":1}}],["example",{"0":{"460":1,"655":1},"2":{"113":2,"334":1,"335":2,"436":1,"497":1,"556":1,"581":1,"671":3,"761":1,"904":1}}],["exact",{"2":{"81":1}}],["eg",{"2":{"63":1,"122":1}}],["etc",{"2":{"739":1,"740":1,"915":1}}],["ethan",{"2":{"726":5,"730":3,"731":1,"732":1,"843":1,"856":1,"966":1}}],["et",{"2":{"277":1,"357":1,"359":1,"363":1,"381":1,"412":1}}],["eta",{"2":{"47":1,"414":1,"415":1,"416":1,"417":1,"545":5,"546":4}}],["etotal=eo1+eo2e",{"2":{"45":1}}],["etotal=eo1+eo2=12",{"2":{"41":1}}],["etotale",{"2":{"44":1}}],["e^",{"2":{"45":1,"121":5,"225":4,"313":4}}],["e​x​b​​−m",{"2":{"313":1}}],["e​m",{"2":{"225":2,"313":2}}],["e​o1​​=​2​​1​​",{"2":{"45":1}}],["e​total​​=e​o1​​+e​o2​​",{"2":{"45":1}}],["e​total​​=e​o1​​+e​o2​​=​2​​1​​",{"2":{"41":1}}],["e​total​​",{"2":{"44":1}}],["e",{"2":{"44":3,"45":2,"46":11,"47":1,"50":1,"181":1,"247":3,"248":17,"249":1,"338":1,"350":1,"421":1,"556":2,"590":2,"634":1,"726":2,"799":3}}],["^2",{"2":{"417":1,"418":1,"419":1}}],["^3",{"2":{"401":2}}],["^",{"2":{"41":2,"45":6,"47":13,"181":1,"185":1,"209":10,"223":4,"226":5,"247":3,"248":12,"252":1,"309":2,"312":4,"542":1,"643":10,"644":14,"647":8,"648":1}}],["分发饼干",{"2":{"952":1}}],["分发饼干问题",{"0":{"950":1},"1":{"951":1,"952":1,"953":1,"954":1,"955":1,"956":1,"957":1,"958":1,"959":1,"960":1,"961":1},"2":{"868":1}}],["分而治之",{"2":{"924":1}}],["分布式实现",{"0":{"827":1}}],["分布式内存模型",{"2":{"801":1}}],["分布式计算",{"2":{"799":1}}],["分布式系统",{"2":{"796":1}}],["分屏切换",{"2":{"790":1}}],["分屏操作",{"0":{"790":1}}],["分页查看文件内容",{"2":{"743":1}}],["分桶",{"2":{"644":1}}],["分数最大",{"2":{"634":1}}],["分数越高",{"2":{"628":1}}],["分支",{"0":{"619":1,"620":1,"621":1}}],["分离张量y",{"2":{"452":1}}],["分解",{"2":{"441":1}}],["分解后的卷积计算过程如下图",{"2":{"59":1}}],["分类结果按一定的比例分配",{"2":{"344":1}}],["分块管道并行",{"2":{"329":1}}],["分母缩放顺序调节避免了非矩阵的",{"2":{"322":1}}],["分母会不断积累使",{"2":{"280":1}}],["分母上梯度平方的累加将会越来越大",{"2":{"280":1}}],["分母较大",{"2":{"279":1}}],["分母较小",{"2":{"279":1}}],["分割为",{"2":{"226":2}}],["分为卡数那么多份",{"2":{"326":1}}],["分为",{"2":{"226":1}}],["分成块",{"2":{"226":1,"315":1}}],["分组查询注意力",{"2":{"219":1,"305":1}}],["分组卷积",{"0":{"57":1}}],["分别从最小的开始处理",{"2":{"956":1}}],["分别用于发送和接收消息",{"2":{"806":1}}],["分别表示两个分布的特征向量的协方差矩阵",{"2":{"606":1}}],["分别表示两个分布的特征向量的均值",{"2":{"606":1}}],["分别46us和3",{"2":{"217":1,"303":1}}],["分别耗时1",{"2":{"217":1,"303":1}}],["分别显示在上图的左边和右边",{"2":{"194":1}}],["分别是位置",{"2":{"640":1}}],["分别是k和v的上投影矩阵",{"2":{"309":1}}],["分别是",{"2":{"65":1,"214":1}}],["分别是几维的",{"2":{"55":1}}],["分别是多少呢",{"2":{"11":1}}],["分析模型的结构",{"2":{"563":1}}],["分析文本的情感倾向",{"2":{"188":1}}],["分析",{"0":{"186":1}}],["分析性变换",{"2":{"41":1}}],["human",{"2":{"891":1}}],["huggingface",{"2":{"592":1,"613":1,"636":1}}],["h>",{"2":{"823":2,"827":3}}],["hpc",{"2":{"802":1}}],["host2ip",{"2":{"827":1}}],["host1ip",{"2":{"827":1}}],["hostname",{"2":{"827":1}}],["host",{"2":{"816":1,"827":1,"904":1}}],["home",{"2":{"739":1,"742":1}}],["how",{"0":{"662":1,"902":1},"1":{"903":1,"904":1},"2":{"447":1,"497":1,"556":1,"891":1,"904":1}}],["hop",{"2":{"445":1}}],["hook来注册",{"2":{"490":2}}],["hook",{"2":{"441":5,"456":2,"457":6,"490":8,"494":4,"495":6,"496":20,"509":20}}],["hooks",{"2":{"440":1,"472":1,"490":11,"496":4,"508":6}}],["hypot",{"2":{"445":2}}],["hyperband的论文也有类似的观点",{"2":{"401":1}}],["hsplit",{"2":{"445":3}}],["here",{"2":{"904":1}}],["health",{"2":{"509":1,"889":2}}],["heaviside",{"2":{"445":2}}],["heads",{"2":{"217":1,"303":1,"498":17,"499":25,"500":21}}],["head​h​​",{"2":{"209":1}}],["head​1​​",{"2":{"209":1}}],["headh",{"2":{"209":1}}],["head1",{"2":{"209":1}}],["head",{"0":{"207":1,"212":1,"213":1,"214":1,"307":1},"1":{"208":1,"209":1,"210":1,"211":1,"215":1,"216":1,"308":1,"309":1},"2":{"196":1,"197":1,"209":3,"210":2,"214":1,"217":1,"220":1,"223":1,"227":1,"303":1,"306":1,"312":1,"317":1,"498":6,"499":14,"500":6,"608":1,"748":1}}],["height",{"2":{"441":2}}],["helps",{"2":{"891":1}}],["help=",{"2":{"497":11}}],["help",{"2":{"424":1,"590":2,"889":1,"897":1}}],["helpful",{"2":{"338":1}}],["helloworld",{"2":{"706":1}}],["hello",{"2":{"338":2,"706":1,"743":1,"823":1}}],["hf",{"2":{"332":1}}],["hbm的访问次数是决定注意力运行时间的主要因素",{"2":{"227":1,"317":1}}],["hbm",{"2":{"222":1,"223":2,"224":3,"226":2,"311":3,"312":2,"314":1}}],["h表示组数等于头数",{"2":{"219":1,"305":1}}],["hd",{"2":{"209":1}}],["have",{"2":{"580":1,"595":1,"894":1}}],["hadoop",{"2":{"802":1}}],["had",{"2":{"556":1}}],["has",{"2":{"445":1,"535":1,"581":1,"590":1,"633":2,"894":1,"897":1}}],["hashmap",{"2":{"730":1}}],["hashable",{"2":{"509":1}}],["hash",{"2":{"441":1}}],["half",{"2":{"445":1,"496":2}}],["halton",{"2":{"402":1}}],["handler",{"2":{"581":4}}],["handle",{"2":{"441":11,"494":2,"495":2}}],["hat",{"2":{"181":6,"249":6,"252":2,"770":1}}],["hardshrink",{"2":{"445":1}}],["hardswish",{"0":{"127":1},"2":{"127":4}}],["hard",{"2":{"127":1}}],["h​t​​",{"2":{"174":1,"181":1}}],["html",{"2":{"556":1,"721":1}}],["http",{"2":{"421":1,"584":1,"613":1,"721":1,"726":2,"761":1}}],["https",{"2":{"122":1,"423":1,"556":1,"584":1,"592":1,"613":2,"636":1,"721":1,"799":3}}],["hth",{"2":{"174":1,"181":1}}],["h0输入到decoder中",{"2":{"171":1}}],["h可以对序列形的数据提取特征",{"2":{"160":1}}],["hibernate",{"2":{"709":1}}],["high",{"2":{"585":1,"857":1}}],["histogram",{"2":{"445":4}}],["history",{"2":{"337":2,"634":6}}],["histc",{"2":{"445":1}}],["hints",{"2":{"440":1}}],["hinton",{"2":{"122":1,"283":1,"284":1,"377":1}}],["hi",{"2":{"338":2}}],["hidden",{"2":{"160":1,"213":1,"227":1,"317":1}}],["hh",{"2":{"138":1}}],["hw的均值",{"2":{"89":1}}],["h3",{"2":{"40":1,"41":1,"45":1}}],["h2",{"2":{"40":1,"41":1,"45":1}}],["h100",{"2":{"78":1}}],["h1",{"2":{"40":2,"41":1,"44":2,"45":2,"46":15}}],["h",{"2":{"40":2,"50":8,"81":3,"86":1,"87":1,"88":1,"89":1,"208":1,"209":1,"309":4,"338":1,"440":1,"460":4,"468":1,"556":20,"590":2,"608":1,"780":1,"790":1}}],["为虚拟互动提供了更具情感表达的体验",{"2":{"859":1}}],["为游戏中的人物动态表现设定了新标准",{"2":{"859":1}}],["为保证绘制逼真",{"2":{"841":1}}],["为高性能计算和infiniband网络优化的mpi实现",{"2":{"802":1}}],["为初始化",{"2":{"648":1}}],["为线性链条件随机场",{"2":{"626":1}}],["为线性结构",{"2":{"122":1}}],["为前缀的属性",{"2":{"472":1}}],["为max",{"2":{"381":1}}],["为下一轮实验确定适当的目标",{"2":{"365":1}}],["为此我们大体有两个选择",{"2":{"638":1}}],["为此",{"2":{"353":1}}],["为解决这一问题",{"2":{"333":1}}],["为解决这个问题",{"2":{"329":1}}],["为满足上述公式继续推导",{"2":{"245":1}}],["为tanh激活函数",{"2":{"245":1}}],["为0",{"2":{"226":2}}],["为实现这一目标",{"2":{"222":1,"311":1,"327":1}}],["为句子中的谓词和论元分配语义角色",{"2":{"188":1}}],["为每个序列元素分配一个标签",{"2":{"188":1}}],["为隐藏层的第t步的状态",{"2":{"137":1}}],["为了见名知意",{"2":{"957":1}}],["为了去尽量多的地方",{"2":{"938":1}}],["为了组成最大的数",{"2":{"932":1}}],["为了使",{"2":{"827":1}}],["为了规范操作",{"2":{"733":1}}],["为了阅读美观",{"2":{"671":1}}],["为了能利用上token的相对位置信息",{"2":{"646":1}}],["为了引入相对位置信息",{"2":{"643":1}}],["为了实现这一点",{"2":{"504":1}}],["为了更细粒度地排除子图不进行梯度计算",{"2":{"474":1}}],["为了更新细胞状态",{"2":{"148":1}}],["为了尽量减少不可微分函数的影响",{"2":{"473":1}}],["为了防止引用循环",{"2":{"472":1}}],["为了计算这些梯度",{"2":{"463":1}}],["为了面向普通大众",{"2":{"411":1}}],["为了检查出这一问题",{"2":{"405":1}}],["为了检查搜索空间边界",{"2":{"373":1}}],["为了提升性能",{"2":{"395":1}}],["为了公平比较",{"2":{"376":1}}],["为了为这些请求腾出空间",{"2":{"338":1}}],["为了系统地利用这些重用机会",{"2":{"337":1}}],["为了确保安全共享",{"2":{"335":1}}],["为了解决上述挑战",{"2":{"327":1}}],["为了解决relu",{"2":{"124":1}}],["为了保持高吞吐量",{"2":{"320":1}}],["为了减少激活内存占用",{"2":{"328":1}}],["为了减少训练过程中的激活内存",{"2":{"309":1}}],["为了减少kv缓存",{"2":{"308":1}}],["为了避免分母为0",{"2":{"279":1}}],["为了数值稳定性",{"2":{"225":1,"313":1}}],["为了抵消这种影响",{"2":{"206":1}}],["为了方便这些残差连接",{"2":{"196":1}}],["为了展示seq2seq模型的运行过程",{"2":{"172":1}}],["为了建模序列问题",{"2":{"160":1}}],["为了赋予网络这样的",{"2":{"132":1}}],["为比较大的正值和比较小的负值时都会接近于",{"2":{"120":1}}],["为扩大感受野",{"2":{"60":1}}],["为什么编译器和运行程序会自动生成",{"2":{"822":1}}],["为什么要学习计算机图形学",{"0":{"858":1}}],["为什么要用",{"2":{"535":1}}],["为什么要定义torch",{"2":{"483":1}}],["为什么要进行缩放",{"0":{"206":1}}],["为什么将学习率和其他优化参数称为超参数",{"0":{"411":1}}],["为什么在优化的探索阶段使用quasi",{"0":{"401":1}}],["为什么有些论文有复杂的学习率衰减方案",{"0":{"399":1}}],["为什么不应该调整batch",{"0":{"412":1},"2":{"357":2}}],["为什么需要mybatis",{"0":{"724":1}}],["为什么需要持久化服务呢",{"2":{"722":1}}],["为什么需要这份调优手册",{"0":{"353":1},"2":{"351":1}}],["为什么需要添加这两种mask码呢",{"2":{"214":1}}],["为什么是",{"2":{"345":1}}],["为什么参数初始化很重要",{"0":{"235":1}}],["为什么多头效果更好呢",{"2":{"209":1}}],["为什么",{"2":{"55":1}}],["为",{"2":{"38":5,"216":1,"226":1,"248":1,"284":2,"730":1,"753":1,"787":3,"827":2}}],["为何要用深度神经网络",{"0":{"14":1}}],["题目",{"0":{"38":1}}],["此调度器的默认行为遵循",{"2":{"544":1}}],["此调度器不可链式使用",{"2":{"544":1}}],["此衰减可以与来自调度器外部的学习率的其他变化同时发生",{"2":{"537":1,"538":1,"539":1,"540":1}}],["此过程假设不仅可以",{"2":{"382":1}}],["此处的",{"2":{"410":1}}],["此处的w为",{"2":{"249":1}}],["此处有歧义",{"2":{"328":1}}],["此处",{"2":{"248":1}}],["此激活函数早在",{"2":{"126":1}}],["此激活函数的特点是随着",{"2":{"126":1}}],["此外在解码头的",{"2":{"619":1}}],["此外",{"2":{"120":1,"219":1,"305":1,"309":1,"329":1,"337":1,"363":1,"369":1,"377":1,"412":1,"496":1,"609":1}}],["此项就是反向传播",{"2":{"36":1}}],["此项其实就是前向传播",{"2":{"36":1}}],["此时取",{"2":{"840":2}}],["此时保存的模型中都包含哪些内容呢",{"2":{"520":1}}],["此时保存后的模型可以直接给他人使用吗",{"2":{"520":1}}],["此时eager",{"2":{"496":1}}],["此时使用超参数一词是不合适的",{"2":{"411":1}}],["此时因为后续是卷积核来进行特征的提取",{"2":{"348":1}}],["此时经过多个前馈层",{"2":{"239":1}}],["此时输入的x就是图像的特征",{"2":{"164":1}}],["此时",{"2":{"11":1,"160":1,"180":1,"379":1}}],["一说到",{"2":{"967":1}}],["一步步来",{"0":{"924":1}}],["一步上结束",{"2":{"375":1}}],["一生",{"2":{"880":1}}],["一起为了祖国的美好未来而尽心尽力那也是志同道合",{"2":{"878":1}}],["一起贩卖毒品那也是志同道合",{"2":{"878":1}}],["一起工作",{"2":{"328":1}}],["一看",{"2":{"875":1}}],["一",{"0":{"736":1,"795":1},"1":{"737":1,"738":1,"739":1,"740":1,"741":1,"742":1,"743":1,"744":1,"745":1,"746":1,"747":1,"748":1,"749":1,"750":1,"751":1,"752":1,"753":1,"754":1,"755":1,"756":1,"757":1,"758":1,"759":1,"760":1,"761":1,"762":1,"763":1,"764":1,"765":1,"766":1,"767":1,"768":1,"769":1,"770":1,"771":1,"772":1,"796":1,"797":1,"798":1,"799":1}}],["一一对应",{"2":{"730":1}}],["一下",{"2":{"634":1}}],["一些优化算法",{"2":{"505":1}}],["一些研究表明",{"2":{"120":1}}],["一系列属性初始化",{"2":{"496":1}}],["一元加法",{"2":{"441":3}}],["一词而引起的潜在混淆",{"2":{"411":1}}],["一定要注意一些要点",{"2":{"393":1}}],["一样增大",{"2":{"385":1}}],["一组实验的目标是比较目标超参数的不同值",{"2":{"376":1}}],["一组仅使用tp",{"2":{"329":1}}],["一项研究将包括",{"2":{"373":1}}],["一项研究指定了一组要运行的超参数配置以供后续分析",{"2":{"370":1}}],["一开始最好是用一个比较简单的工作流",{"2":{"360":1}}],["一开始会完全是瞎预测",{"2":{"177":1}}],["一份关于如何调试和如何减少训练失败的文档在两年前是不可能写出来的",{"2":{"353":1}}],["一方面",{"2":{"353":1,"363":1}}],["一次计算成功",{"2":{"323":1}}],["一次一个元素",{"2":{"194":1}}],["一部分为当前位置的梯度",{"2":{"271":1}}],["一部分是第一项",{"2":{"36":1}}],["一旦学习停滞不前",{"2":{"547":1}}],["一旦训练周期数达到里程碑",{"2":{"538":1}}],["一旦考虑了所有这些因素带来的影响",{"2":{"412":1}}],["一旦建立了不会破坏以",{"2":{"409":1}}],["一旦给定的每次试验时间限制中产生了有用的见解",{"2":{"383":1}}],["一旦我们完成了对",{"2":{"379":1}}],["一旦我们回答了上述问题",{"2":{"372":1}}],["一旦随机分布选择不当",{"2":{"238":1}}],["一旦模型规模很大长度很长时",{"2":{"230":1,"330":1}}],["一直是机器翻译的巅峰技术",{"2":{"190":1}}],["一对多",{"2":{"190":1}}],["一种模拟真实光线传播的渲染方法",{"2":{"857":1}}],["一种经典的线性链crf的结构图如下",{"2":{"626":1}}],["一种用于在运行时自动重用键值缓存的新技术",{"2":{"337":1}}],["一种自然的思路是",{"2":{"178":1}}],["一种特殊结构的神经网络",{"2":{"132":1}}],["一状态",{"2":{"146":1}}],["一般是指许多指令得以同时进行的计算模式",{"2":{"797":1}}],["一般是还原后的尺寸与输入图像一致",{"2":{"61":1}}],["一般认为",{"2":{"643":1}}],["一般认为参数初始化需满足以下两个必要条件",{"2":{"243":1}}],["一般的认为它的缺点是没有外推性",{"2":{"641":1}}],["一般说来",{"2":{"616":1}}],["一般情况下数据的维度都是高维的",{"2":{"652":1}}],["一般情况下",{"2":{"462":2}}],["一般来说",{"2":{"362":1,"374":1,"639":1}}],["一般采用默认值0",{"2":{"280":1}}],["一般初始化的权重为高斯或均匀分布中随机抽取的值",{"2":{"238":1}}],["一般我们会进一步进行分解",{"2":{"190":1}}],["一般为",{"2":{"172":1}}],["一般要对数据做归一化",{"2":{"86":1}}],["一个指向",{"2":{"956":2}}],["一个整数",{"2":{"954":1}}],["一个整数数组",{"2":{"953":2}}],["一个十五岁的孩子",{"2":{"878":1}}],["一个主进程负责任务分发",{"2":{"811":1}}],["一个较早的mpi实现",{"2":{"802":1}}],["一个广泛使用的开源mpi实现",{"2":{"802":1}}],["一个基于network",{"2":{"801":1}}],["一个基于总线",{"2":{"801":1}}],["一个进程可以包含多个线程",{"2":{"796":1}}],["一个进程正在访问临界资源",{"2":{"678":1}}],["一个程序运行起来就相当于一个进程",{"2":{"796":1}}],["一个包含优化选项默认值的字典",{"2":{"507":1}}],["一个包含",{"2":{"507":1}}],["一个包含完整的反向传播钩子",{"2":{"496":1}}],["一个特定的候选变化最初取得了更好的验证误差",{"2":{"378":1}}],["一个超参数是冗余还是固定超参数将取决于目标超参数的值",{"2":{"369":1}}],["一个超参数是目标超参数",{"2":{"369":1}}],["一个冗余超参数和目标超参数的相互影响越多",{"2":{"369":1}}],["一个冗余超参数",{"2":{"369":1}}],["一个好的经验法则",{"2":{"359":1}}],["一个是输入",{"2":{"347":1}}],["一个是输出",{"2":{"347":1}}],["一个新的聊天会话开始",{"2":{"338":1}}],["一个新的提示到达",{"2":{"338":1}}],["一个批量的少样本学习查询和一个自一致性采样",{"2":{"338":1}}],["一个使用",{"2":{"328":1}}],["一个设备从左侧开始处理第一个查询块",{"2":{"327":1}}],["一个函数的output",{"2":{"462":1}}],["一个函数",{"2":{"258":1}}],["一个损失函数",{"2":{"256":1}}],["一个最直接的方法就是",{"2":{"190":1}}],["一个context可能存不下那么多信息",{"2":{"173":1}}],["一个箭头就表示对该向量做一次变换",{"2":{"160":1}}],["一个重置门",{"2":{"156":1}}],["一个lstm",{"2":{"146":1}}],["一个向量空间进行一次线性变换并接上一个平移",{"2":{"120":1}}],["一个",{"2":{"59":1,"634":1}}],["一个输出特征点需要多少输入数据和kernel参与运算",{"2":{"55":1}}],["一个深度神经网络可以理解为一个复杂的复合函数",{"2":{"28":1}}],["一个深度学习模型中的所有数据可划分为如下类别",{"2":{"27":1}}],["一个典型的深度神经网络图如下",{"2":{"27":1}}],["损失通常高度敏感于参数空间中的某些方向",{"2":{"276":1}}],["损失值",{"2":{"50":1}}],["损失c对w的权重有两部分",{"2":{"36":1}}],["损失函数我们使用mseloss",{"2":{"38":1}}],["损失函数",{"2":{"24":1,"484":1}}],["所谓数据的生成",{"2":{"653":1}}],["所谓相对位置",{"2":{"643":1}}],["所贡献的内容将保留其相关版权",{"2":{"423":1}}],["所使用的gpu数量增加一倍",{"2":{"360":1}}],["所需的步骤数减少一半",{"2":{"360":1}}],["所有解读和参悟都是我个人理解",{"2":{"876":1}}],["所有算法通常进行",{"2":{"841":1}}],["所有算法主要以斜率为",{"2":{"836":1}}],["所有mpi函数之后必须调用",{"2":{"808":1}}],["所有处理器共享相同的内存空间",{"2":{"801":1}}],["所有实现会更加简单",{"2":{"724":1}}],["所有内容只是我个人想法",{"2":{"702":1}}],["所有的解读其实都是",{"2":{"876":1}}],["所有的增删改操作都需要提交事务",{"2":{"733":1}}],["所有的事情",{"2":{"724":1}}],["所有的模型权重都被随机初始化",{"2":{"617":1}}],["所有的优化器都实现了",{"2":{"505":1}}],["所有的提交",{"2":{"424":1}}],["所有参数应该是",{"2":{"503":1}}],["所有这些模式都可以通过上下文管理器和装饰器进行切换",{"2":{"476":1}}],["所有非叶张量将自动具有",{"2":{"475":1}}],["所有流行的优化算法的更新规则是什么",{"0":{"413":1},"1":{"414":1,"415":1,"416":1,"417":1,"418":1,"419":1}}],["所有在残差前的f",{"2":{"406":1}}],["所有超参数都将是目标超参数",{"2":{"369":1}}],["所有",{"2":{"356":1}}],["所有weight的权重衰减系数相同吗",{"2":{"343":1}}],["所有共享gpt代码路径的模型也应该能够受益于cp",{"2":{"328":1}}],["所有张量必须具有相同的形状",{"2":{"104":1}}],["所有权重梯度求解",{"2":{"36":1}}],["所有激活梯度求解",{"2":{"36":1}}],["所以大家不用太怕",{"2":{"967":1}}],["所以即使对象不需要永久保存",{"2":{"722":1}}],["所以推荐给大家",{"2":{"696":1}}],["所以叫做变分推断",{"2":{"659":1}}],["所以直接贝叶斯这个方法报废",{"2":{"659":1}}],["所以直接用矩阵乘法来实现会很浪费算力",{"2":{"648":1}}],["所以它们可以共用一个位置编码",{"2":{"644":1}}],["所以它们在反向传播中的",{"2":{"475":1}}],["所以给它们都分配一个独立的位置编码",{"2":{"644":1}}],["所以相对位置编码通常也有着优秀的表现",{"2":{"642":1}}],["所以要broadcast",{"2":{"634":1}}],["所以要使用非线性线将其分类",{"2":{"11":1}}],["所以本实验将聚焦在线性链crf来探讨",{"2":{"626":1}}],["所以增强了人像的生成效果",{"2":{"608":1}}],["所以通常不必要支持预期提前停止",{"2":{"392":1}}],["所以有必要对于针对每个batch",{"2":{"361":1}}],["所以无论如何",{"2":{"360":1}}],["所以并不影响有效特征的提取",{"2":{"348":1}}],["所以当在山谷附近时",{"2":{"269":1}}],["所以我们需要进行一些处理",{"2":{"215":1}}],["所以我们的attention机制不应该把注意力放在这些位置上",{"2":{"215":1}}],["所以我们要找出这个v维向量中",{"2":{"181":1}}],["所以这个score越大",{"2":{"185":1}}],["所以在图中我们可以看到除了第一步",{"2":{"184":1}}],["所以如果要改进seq2seq结构",{"2":{"174":1}}],["所以数据的幅度会随着模型层数的增加不断扩张",{"2":{"122":1}}],["所以最大池化更多保留些图像的纹理信息",{"2":{"93":1}}],["所以对整个batch归一化不适合图像风格化中",{"2":{"88":1}}],["所以",{"2":{"87":1,"178":1,"248":1,"249":1,"644":1,"878":3,"972":1}}],["所以需要非线性线将它们分成各自的类别",{"2":{"11":1}}],["所以也是数学统计学方法的一种实际应用",{"2":{"5":1}}],["zz",{"2":{"777":1}}],["zxcvbn",{"2":{"731":1}}],["zh",{"2":{"721":1,"799":1}}],["z∣x",{"2":{"659":10}}],["z|x",{"2":{"659":1}}],["z2",{"2":{"635":4}}],["zelda",{"2":{"420":1}}],["zeroing",{"2":{"459":1}}],["zerotensor",{"2":{"444":1}}],["zeros",{"2":{"428":1,"445":2,"453":1,"454":1,"493":2,"500":1,"634":3}}],["zero",{"2":{"120":2,"274":1,"444":1,"445":3,"454":1,"456":3,"459":1,"460":2,"484":1,"487":2,"496":1,"497":1,"500":1,"505":2,"509":1,"533":2,"546":1,"567":1,"904":4}}],["zachary",{"2":{"350":1,"421":1}}],["z​i​",{"2":{"244":1}}],["z​i​​",{"2":{"244":1,"245":1}}],["z^",{"2":{"244":2}}],["ziz",{"2":{"245":1}}],["zi",{"2":{"244":2}}],["z",{"0":{"35":2},"2":{"99":2,"194":3,"245":5,"440":2,"451":2,"452":2,"453":8,"454":1,"456":6,"457":2,"474":1,"635":5,"659":9}}],["下拉展示",{"2":{"966":1}}],["下拉展开",{"2":{"674":1,"695":1}}],["下一个点的更新只会在",{"2":{"844":1}}],["下一点",{"2":{"840":1}}],["下一节详细讲解",{"0":{"693":1}}],["下",{"2":{"780":1,"790":1}}],["下step",{"2":{"634":1}}],["下游任务使用时",{"2":{"619":1}}],["下采样",{"2":{"609":2}}],["下的deep",{"2":{"874":1}}],["下的doccano添加普通用户",{"2":{"868":1}}],["下的",{"2":{"445":1,"870":1}}],["下面进行优化",{"2":{"845":1}}],["下面简单介绍一些在自然语言理解",{"2":{"621":1}}],["下面就简要介绍一些常见的生成模型",{"2":{"620":1}}],["下面两个常用的预训练任务",{"2":{"616":1}}],["下面我们还会介绍评估模式",{"2":{"474":1}}],["下面我们将描述如何根据使用恒定学习率",{"2":{"381":1}}],["下面是一些里面的经典而富有哲理的话语",{"2":{"880":1}}],["下面是一个关于如何进行梯度截断的案例",{"2":{"410":1}}],["下面是示例图解",{"2":{"29":1}}],["下产生最佳验证性能的权重衰减值",{"2":{"376":1}}],["下标",{"2":{"248":1}}],["下图展示了记录转移分数的矩阵",{"2":{"628":1}}],["下图显示了如何为多个传入请求维护",{"2":{"338":1}}],["下图显示了分组查询注意力和多头",{"2":{"219":1,"305":1}}],["下图图1右图所示",{"2":{"222":1,"314":1}}],["下载一个预训练好的深度学习模型",{"0":{"118":1}}],["下层是中间层的情况",{"2":{"35":1}}],["下层是output的情况",{"2":{"35":1}}],["下层激活",{"0":{"35":1}}],["下降",{"2":{"26":1}}],["则将指针都向后移动",{"2":{"956":1}}],["则将其标记为不可微分",{"2":{"473":1}}],["则结果介于0和1之间",{"2":{"655":1}}],["则说明",{"2":{"655":1}}],["则在隐空间中一共有5个二维正态分布",{"2":{"655":1}}],["则在调整目标中运行更多点或不那么雄心勃勃",{"2":{"372":1}}],["则称",{"2":{"626":1}}],["则称该问题是线性可分的",{"2":{"11":1}}],["则预测第一个模型的输出中哪些词语是被遮盖的",{"2":{"619":1}}],["则跳过此步骤",{"2":{"509":1}}],["则state",{"2":{"496":1}}],["则不会自动归类",{"2":{"492":1}}],["则划归于",{"2":{"492":1}}],["则被归于",{"2":{"492":1}}],["则被称为翻译模型",{"2":{"190":1}}],["则任意选择一个",{"2":{"473":1}}],["则两个batch",{"2":{"412":1}}],["则添加它们",{"2":{"406":1}}],["则很有用",{"2":{"405":1}}],["则可能需要增加max",{"2":{"409":1}}],["则可能需要扩展搜索空间边界",{"2":{"373":1}}],["则可以换成伪随机均匀搜索",{"2":{"402":1}}],["则可以很好地使用",{"2":{"399":1}}],["则保持第一轮中衰减大小的固定值",{"2":{"385":1}}],["则模型可能处于正则化不太可能有太大的帮助",{"2":{"384":1}}],["则模型可能遇到了稳定性问题",{"2":{"373":1}}],["则max",{"2":{"381":1}}],["则搜索可能不够广泛",{"2":{"372":1}}],["则为新的batch",{"2":{"361":1}}],["则该节点可以被淘汰",{"2":{"338":1}}],["则该层的权重",{"2":{"248":1}}],["则n的大小表示一个输出值是由多少个输入值计算出来的",{"2":{"248":1}}],["则根据gorot",{"2":{"245":1}}],["则loss",{"2":{"236":1}}],["则会降低学习率",{"2":{"547":1}}],["则会视为普通属性",{"2":{"492":1}}],["则会导致梯度消失",{"2":{"236":1}}],["则会导致梯度爆炸",{"2":{"236":1}}],["则会输出一个v维度的向量",{"2":{"181":1}}],["则是截取左边的内容",{"2":{"215":1}}],["则这一步的损失就是它的负导数",{"2":{"181":1}}],["则只有以start",{"2":{"107":1}}],["则内核元素之间没有插入空格",{"2":{"60":1}}],["则最后便会得到一个深度的卷积结果",{"2":{"58":1}}],["则",{"2":{"50":1,"248":1,"249":1,"326":1,"649":1}}],["则进行相加",{"2":{"29":1}}],["信念不是说出来的",{"2":{"880":1}}],["信号量机制pv操作之",{"0":{"695":1}}],["信号量机制",{"0":{"693":1},"2":{"801":1}}],["信号",{"2":{"401":1}}],["信号依次从输出传播到输入",{"2":{"29":1}}],["信息传不过去",{"2":{"241":1}}],["信息抽取",{"2":{"188":1}}],["信息通过网络向前流动",{"2":{"24":1}}],["传入sql语句的参数类型",{"2":{"730":1}}],["传入crf之后",{"2":{"624":1}}],["传输相关的网络资源争用",{"2":{"329":1}}],["传播时激活值的分布情况如下图所示",{"2":{"239":1}}],["传播回所有输出信号作为该神经元的输入的神经元中",{"2":{"29":1}}],["传统思想启发的注意力算法",{"2":{"333":1}}],["传统",{"2":{"121":1}}],["传统的jdbc操作",{"2":{"724":1}}],["传统的transformer模型通常采用多头注意力机制",{"2":{"308":1}}],["传统的attention是基于source端和target端的隐变量",{"2":{"213":1}}],["传统的",{"2":{"117":1}}],["传统的神经网络使用矩阵乘法来建立输入与输出的连接关系",{"2":{"54":1}}],["传统机器学习的特征提取主要依赖人工",{"2":{"19":1}}],["其核心思想是基于直线公式y=kx+by",{"2":{"839":1}}],["其基于",{"2":{"619":1}}],["其参数量为354",{"2":{"608":1}}],["其声称",{"2":{"544":1}}],["其他参数同send",{"2":{"823":1}}],["其他工作进程",{"2":{"811":1}}],["其他目录和文件都是在此基础上扩展的",{"2":{"738":1}}],["其他线程或是进程必须等待",{"2":{"682":1}}],["其他",{"2":{"504":1}}],["其他一些方案可能也不错",{"2":{"398":1}}],["其叶节点是输入张量",{"2":{"471":1}}],["其共轭转置为",{"2":{"440":1}}],["其大小取决于序列长度",{"2":{"333":1}}],["其输入标记被分成小块",{"2":{"329":1}}],["其输入为",{"2":{"245":1}}],["其输出传递给前馈网络",{"2":{"327":1}}],["其庞大的关键值",{"2":{"308":1}}],["其权重值为",{"2":{"245":1}}],["其质量高于mqa但比mha快",{"2":{"219":1,"305":1}}],["其次所有模型层共享参数",{"2":{"619":1}}],["其次",{"2":{"213":1,"294":1,"327":1}}],["其次在网络中间",{"2":{"86":1}}],["其它超参数",{"2":{"508":1}}],["其它参考",{"2":{"436":1}}],["其它正则化方法",{"0":{"349":1}}],["其它的是为了",{"2":{"328":1}}],["其它",{"2":{"204":1}}],["其它relu",{"0":{"124":1}}],["其等价表示为",{"2":{"164":1}}],["其结构如下",{"0":{"140":1}}],["其实就是不同的实现方式",{"2":{"973":1}}],["其实就是linear",{"2":{"208":1}}],["其实贪心算法不是一种具体模板化的算法",{"2":{"972":1}}],["其实我们在日常生活中会不自觉的去使用",{"2":{"929":1}}],["其实我在一年前对这些还没有太多的认识",{"2":{"917":1}}],["其实他会讲的更透彻",{"2":{"702":1}}],["其实是没什么意义的",{"2":{"215":1}}],["其实是最简单的decoding方式",{"2":{"183":1}}],["其实",{"2":{"126":1}}],["其实所说的都是",{"2":{"52":1}}],["其导数收敛于",{"2":{"121":1}}],["其梯度恒为",{"2":{"120":1}}],["其通道数",{"2":{"55":2}}],["其中比较有名有",{"2":{"616":1}}],["其中计算图是根据实际输入数据的流动而动态生成的",{"2":{"559":1}}],["其中所有的操作和数据流都在定义时确定",{"2":{"559":1}}],["其中包含模型的结构和计算逻辑",{"2":{"563":1}}],["其中包含属于该组的参数列表",{"2":{"504":1}}],["其中包含要优化的参数",{"2":{"503":1}}],["其中包含输入项的内容",{"2":{"167":1}}],["其中input使用",{"2":{"444":1}}],["其中最简单的配置是在同一计算实例中执行训练和定期评估",{"2":{"390":1}}],["其中每个参数组是一个字典",{"2":{"509":1}}],["其中每个试验训练",{"2":{"382":1}}],["其中每个研究都会调整冗余超参数",{"2":{"370":1}}],["其中gpu的总数等于tpxcpxppxdp",{"2":{"328":1}}],["其中多个查询头关注相同的键头和值头",{"2":{"323":1}}],["其中l表示层数",{"2":{"309":1}}],["其中激活函数为relu",{"2":{"248":1}}],["其中分配给每个value的权重通过query与相应key的兼容函数来计算",{"2":{"198":1}}],["其中query",{"2":{"198":1}}],["其中sublayer",{"2":{"196":1}}],["其中x是源语言",{"2":{"190":1}}],["其中核心部分为三门",{"2":{"146":1}}],["其中隐藏层会重复执行",{"2":{"135":1}}],["其中β是一个常数或可学习的参数",{"2":{"127":1}}],["其中的单例维度被扩展到更大的大小",{"2":{"106":1}}],["其中",{"2":{"38":1,"46":1,"54":1,"122":1,"126":1,"137":1,"160":1,"172":1,"181":1,"185":1,"209":1,"223":1,"248":1,"249":1,"258":1,"309":1,"312":1,"606":1,"639":1,"640":1,"643":1,"647":1,"648":1,"807":1,"959":1}}],["其思想是将误差信号",{"2":{"29":1}}],["其典型结构如下图所示",{"2":{"13":1,"133":1}}],["直线光栅化",{"2":{"871":1}}],["直线是所有图形中的基础",{"2":{"835":1}}],["直观来看",{"2":{"235":1}}],["直至主机n",{"2":{"327":1}}],["直至结束",{"2":{"184":1}}],["直至输出end就结束",{"2":{"176":1}}],["直接说",{"2":{"875":1}}],["直接明了",{"2":{"875":1}}],["直接使用顺序文章",{"2":{"874":1}}],["直接使用插件生成侧边栏",{"2":{"868":1}}],["直接法这里不再赘述",{"2":{"838":1}}],["直接传递参数即可",{"2":{"730":1}}],["直接取",{"2":{"730":1}}],["直接在方法中传递参数",{"2":{"730":1}}],["直接理解同步",{"2":{"677":1}}],["直接整理成文档内容",{"2":{"671":1}}],["直接相连的两个邻居",{"2":{"626":1}}],["直接将模型加载到device上",{"2":{"519":1}}],["直接生成特殊的tensor",{"0":{"428":1}}],["直接",{"2":{"340":1}}],["直接用索引来实现",{"2":{"111":1}}],["直接赋予了每个channel实际的类别意义",{"2":{"95":1}}],["直接剔除了全连接层中黑箱的特征",{"2":{"95":1}}],["直接计算内部神经元的误差信号是不可能的",{"2":{"29":1}}],["直到找到为止",{"2":{"920":1}}],["直到大三",{"2":{"878":1}}],["直到达到指定范围再clip",{"2":{"644":1}}],["直到达到浮点极限",{"2":{"381":1}}],["直到训练周期数达到预定义的里程碑",{"2":{"539":1,"540":1}}],["直到会议",{"2":{"399":1}}],["直到性能提升似乎停滞为止",{"2":{"399":1}}],["直到最佳观察点不再靠近边界",{"2":{"373":1}}],["直到其中一个实验超过可用内存",{"2":{"358":1}}],["直到这些祖先成为叶子节点并被淘汰",{"2":{"338":1}}],["直到输出停止符为止",{"2":{"168":1}}],["直到上世纪八十年代中期",{"2":{"29":1}}],["直到生成最后的输出",{"2":{"13":1}}],["δθ",{"2":{"287":2}}],["δθt",{"2":{"280":1}}],["δy=y1−y0",{"2":{"840":1}}],["δy​l​​=f​",{"2":{"249":1}}],["δy​l​​",{"2":{"249":3}}],["δyl=f",{"2":{"249":1}}],["δyl",{"2":{"249":3}}],["δx=x1−x0",{"2":{"840":1}}],["δx​l+1​​",{"2":{"249":1}}],["δx​l​​",{"2":{"249":4}}],["δx​l​​=​w​l​​​^​​δy​l​​",{"2":{"249":1}}],["δxl+1",{"2":{"249":1}}],["δxl",{"2":{"249":4}}],["δxl=wl^δyl",{"2":{"249":1}}],["δ",{"2":{"29":1,"249":1}}],["当你逛超市时",{"2":{"921":1}}],["当你",{"2":{"878":1}}],["当你理解",{"2":{"878":1}}],["当真正领悟到",{"2":{"878":1}}],["当手册使用",{"2":{"817":1}}],["当有线程进入临界区段时",{"2":{"682":1}}],["当clip",{"2":{"605":1}}],["当度量指标停止改善时",{"2":{"547":1}}],["当last",{"2":{"535":1,"536":1}}],["当需要指定每个层的学习率时",{"2":{"504":1}}],["当需要进行大量的调优实验时",{"2":{"360":1}}],["当您只想改变单个选项",{"2":{"504":1}}],["当您需要执行不应由自动求导记录的操作",{"2":{"478":1}}],["当在类中定义成员时",{"2":{"492":1}}],["当进行不需要在反向图中记录的计算",{"2":{"479":1}}],["当编写优化器时",{"2":{"478":1}}],["当应用于模块时",{"2":{"475":1}}],["当应用于非凸函数训练神经网络时",{"2":{"283":1}}],["当定义一个自定义的",{"2":{"472":1}}],["当调用",{"2":{"441":1}}],["当修改batch",{"2":{"412":1}}],["当出现较大或离群的梯度问题时",{"2":{"410":1}}],["当学习率过大时",{"2":{"405":1}}],["当对6个试验进行抽样时",{"2":{"403":1}}],["当评估集不能被",{"2":{"390":1}}],["当使用jit",{"2":{"563":1}}],["当使用打乱后的训练",{"2":{"390":1}}],["当使用最大隐藏层数的最佳试验表现出过拟合问题",{"2":{"375":1}}],["当模型在代表生产环境的离线训练",{"2":{"389":1}}],["当模型在生产环境中提供预测时收集指标",{"2":{"389":1}}],["当模型架构或数据发生变化时",{"2":{"381":1}}],["当工作模式受计算限制时",{"2":{"380":1}}],["当决定是否对我们的模型或训练程序进行改变或采用新的超参数配置时",{"2":{"378":1}}],["当第一次生成此类图表花费的努力越多",{"2":{"377":1}}],["当验证误差在训练期间的某个时刻开始增加时",{"2":{"375":1}}],["当研究中很大一部分点是不可行时",{"2":{"372":1}}],["当加速器内存未饱和时",{"2":{"358":1}}],["当训练集中的错误分类为0时",{"2":{"381":1}}],["当训练损失为log",{"2":{"381":1}}],["当训练不受计算限制时",{"2":{"380":1}}],["当训练不受计算限制时如何决定该训练多久",{"0":{"381":1},"1":{"382":1},"2":{"351":1}}],["当训练为不受计算限制时",{"2":{"380":1}}],["当训练为受计算限制时",{"2":{"380":1}}],["当训练受计算限制时如何决定该训练多久",{"0":{"383":1},"1":{"384":1,"385":1},"2":{"351":1}}],["当训练数据集的规模相对较小时",{"2":{"341":1}}],["当输入特征的维度较高时",{"2":{"341":1}}],["当输入不是序列而输出为序列的情况怎么处理",{"2":{"164":1}}],["当足够多的等待请求运行时",{"2":{"338":1}}],["当前进程计算的部分和",{"2":{"827":1}}],["当前的通讯域",{"2":{"823":1}}],["当前seq",{"2":{"633":1}}],["当前单词发射分数",{"2":{"632":1}}],["当前单词转移分数",{"2":{"632":1}}],["当前公布的模型具有",{"2":{"620":1}}],["当前状态",{"2":{"503":1}}],["当前状态下的梯度向量越大",{"2":{"405":1}}],["当前优化器比其他优化器使用更少的内存",{"2":{"369":1}}],["当前优化器的训练曲线更容易理解",{"2":{"369":1}}],["当前系统无法有效地处理kv",{"2":{"337":1}}],["当前kv",{"0":{"337":1}}],["当前项的内容总来源于前一步的输出",{"2":{"167":1}}],["当softmax在得分矩阵的一个块上执行时",{"2":{"325":1}}],["当刚好下降到山谷附近时",{"2":{"271":1}}],["当梯度在相同方向上持续增加时",{"2":{"266":1}}],["当参数初始化很小时",{"2":{"239":1}}],["当生成下一个时",{"2":{"194":1}}],["当然我依旧觉得这句话很有道理哈",{"2":{"917":1}}],["当然这只是我个人的看法",{"2":{"878":1}}],["当然",{"2":{"344":1,"641":1}}],["当然就是最佳的翻译",{"2":{"190":1}}],["当然没有",{"2":{"190":1}}],["当然是可以的",{"2":{"177":1}}],["当然不同的硬件使用的驱动程序也不一样",{"2":{"73":1}}],["当要翻译的句子较长时",{"2":{"173":1}}],["当做每一步的输入",{"2":{"171":1}}],["当我们面对很多任务时",{"2":{"926":1}}],["当我们面对复杂问题时",{"2":{"924":1}}],["当我们在交互式环境中输出对象或使用",{"2":{"509":1}}],["当我们只训练",{"2":{"383":1}}],["当我们的训练时间越长",{"2":{"383":1}}],["当我们试图得出超出超参数空间中单个点水平的结论时",{"2":{"378":1}}],["当我们试图改进我们的模型时",{"2":{"378":1}}],["当我们试图找到各种其他超参数",{"2":{"356":1}}],["当我们正在考虑为一个连续的超参数来绘制isolation图时",{"2":{"376":1}}],["当我们判断将一个冗余超参数转换为固定超参数所带来的限制少于调优它所需的计算资源时",{"2":{"369":1}}],["当我们判断意图的时候",{"2":{"142":1}}],["当我们更新我们的最佳配置时",{"2":{"365":1}}],["当我们选择均值为0",{"2":{"239":1,"240":1}}],["当我们使用前馈神经网络",{"2":{"24":1}}],["当激活函数是单调的时候",{"2":{"120":1}}],["当",{"2":{"60":1,"125":1,"127":2,"206":2,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"878":1}}],["当时主要为了解决",{"2":{"57":1}}],["当计算完每个神经元的误差信号后",{"2":{"29":1}}],["当计算",{"2":{"28":1}}],["wd=小狗",{"2":{"799":1}}],["wd",{"2":{"590":2}}],["www",{"2":{"584":1,"721":1,"799":2}}],["well",{"2":{"896":1,"901":1,"904":1,"905":1}}],["website",{"2":{"903":1}}],["web",{"0":{"710":1}}],["we",{"2":{"556":9,"571":1,"633":1,"634":2}}],["weights",{"2":{"38":1,"113":1,"445":1,"498":2,"500":2}}],["weight",{"0":{"32":1},"2":{"27":1,"113":5,"233":3,"248":1,"281":1,"299":1,"445":7,"456":1,"462":2,"464":1,"465":1,"467":1,"487":4,"503":1,"590":2,"671":1}}],["wv",{"2":{"498":2,"500":2,"649":2}}],["wk",{"2":{"498":2,"500":2,"649":2}}],["wq",{"2":{"498":2,"500":2,"649":2,"751":1,"777":1}}],["wazg123456",{"2":{"888":1,"889":1}}],["way",{"2":{"590":1}}],["want",{"2":{"556":2}}],["waiting",{"2":{"682":1}}],["wait=1",{"2":{"581":2}}],["wait",{"2":{"497":1,"889":1}}],["waite",{"2":{"448":1}}],["warming",{"2":{"581":1}}],["warm",{"2":{"545":1,"546":2}}],["warmup=1",{"2":{"581":2}}],["warmup",{"2":{"409":6}}],["warmup时长",{"2":{"384":1}}],["warn",{"2":{"496":1}}],["warning",{"2":{"441":1}}],["wrapper",{"2":{"509":1,"822":1}}],["wrapped",{"2":{"496":2}}],["wrap",{"2":{"441":12,"445":1}}],["writer",{"2":{"497":2,"576":5,"577":2,"579":4,"580":5}}],["write",{"2":{"217":1,"303":1,"556":2,"896":1}}],["wgmma在异步代理中执行以计算下一个块",{"2":{"325":1}}],["wl^",{"2":{"249":2}}],["wl",{"2":{"248":10,"249":1}}],["wl⋅xl",{"2":{"248":1}}],["w∼u",{"2":{"245":2,"252":4}}],["w∼n",{"2":{"245":2,"248":2,"249":2,"251":4}}],["world",{"2":{"588":1,"589":2,"590":4,"810":1,"823":3,"827":13,"891":1}}],["word",{"2":{"499":2,"616":1,"897":1}}],["working",{"2":{"893":1,"895":1,"897":1}}],["works",{"2":{"891":1,"896":1}}],["worker",{"2":{"811":1}}],["workers",{"2":{"497":1,"556":1,"590":2}}],["work",{"0":{"320":1},"1":{"321":1,"322":1,"323":1,"324":1},"2":{"229":1}}],["wo∈rhdv×dmodel",{"2":{"209":1}}],["womultihead",{"2":{"209":1}}],["when",{"2":{"581":2,"590":1,"634":1,"895":1}}],["wherehead​i​​=attention",{"2":{"209":1}}],["whereheadi=attention",{"2":{"209":1}}],["where",{"2":{"209":1,"445":2,"633":3,"634":6,"730":3,"732":1,"733":1,"734":2}}],["which",{"2":{"444":1,"556":1,"581":1,"590":1,"766":1,"894":1,"895":1,"904":1}}],["while",{"2":{"444":1,"595":2,"706":2,"893":1,"957":1}}],["what",{"0":{"891":1},"2":{"142":1}}],["wsxxt+whhst−1",{"2":{"138":1}}],["w2",{"2":{"50":5,"460":13}}],["w2+=0",{"2":{"47":1}}],["wt",{"2":{"50":1}}],["w^",{"2":{"48":1,"138":3,"209":2,"245":2,"249":1}}],["w9+=0",{"2":{"47":1}}],["w8+=0",{"2":{"47":1}}],["w6+=0",{"2":{"47":1}}],["w5+=0",{"2":{"47":1}}],["w4+=0",{"2":{"47":1}}],["w3+=0",{"2":{"47":1}}],["w7+=0",{"2":{"47":1}}],["w7+=w7+δw7=w7−η∂etotal∂w7=0",{"2":{"47":1}}],["w7w",{"2":{"43":1,"47":1}}],["w1∗z1+⋅+wn∗zn",{"2":{"245":1}}],["w1000=",{"2":{"48":1}}],["w10+=0",{"2":{"47":1}}],["w12+=0",{"2":{"47":1}}],["w11+=0",{"2":{"47":1}}],["w1+=0",{"2":{"47":1}}],["w1",{"0":{"46":1},"2":{"50":5,"460":13}}],["w​l​​",{"2":{"248":10,"249":1}}],["w​l​​⋅x​l​​",{"2":{"248":1}}],["w​i​​",{"2":{"245":3}}],["w​i​v​​∈r​d​model​​×d​v​​​​",{"2":{"209":1}}],["w​i​k​​∈r​d​model​​×d​k​​​​",{"2":{"209":1}}],["w​i​q​​∈r​d​model​​×d​k​​​​",{"2":{"209":1}}],["w​o​​∈r​hd​v​​×d​model​​​​",{"2":{"209":1}}],["w​o​​",{"2":{"209":1}}],["w​sx​​x​t​​+w​hh​​s​t−1​​",{"2":{"138":1}}],["w​1​​∗z​1​​+⋅+w​n​​∗z​n​​",{"2":{"245":1}}],["w​1​+​​=0",{"2":{"47":1}}],["w​1000​​=",{"2":{"48":1}}],["w​10​+​​=0",{"2":{"47":1}}],["w​12​+​​=0",{"2":{"47":1}}],["w​11​+​​=0",{"2":{"47":1}}],["w​9​+​​=0",{"2":{"47":1}}],["w​8​+​​=0",{"2":{"47":1}}],["w​6​+​​=0",{"2":{"47":1}}],["w​5​+​​=0",{"2":{"47":1}}],["w​4​+​​=0",{"2":{"47":1}}],["w​3​+​​=0",{"2":{"47":1}}],["w​2​+​​=0",{"2":{"47":1}}],["w​7​+​​=0",{"2":{"47":1}}],["w​7​+​​=w​7​​+δw​7​​=w​7​​−η​∂w​7​​​​∂e​total​​​​=0",{"2":{"47":1}}],["w​7​​",{"2":{"43":1,"47":1}}],["w​mn​​",{"2":{"29":1}}],["wildcardname",{"2":{"734":4}}],["will",{"2":{"556":2,"580":1,"581":2}}],["wide",{"2":{"590":2}}],["wideresnet",{"2":{"404":1}}],["win",{"2":{"445":1}}],["windows系统win",{"2":{"913":1}}],["windows10",{"2":{"909":1}}],["window",{"2":{"93":2,"94":2,"445":1}}],["wiw",{"2":{"245":1}}],["wiv∈rdmodel×dv",{"2":{"209":1}}],["wiki",{"2":{"799":1}}],["wikipedia",{"2":{"51":1,"167":1,"799":1}}],["wik∈rdmodel×dk",{"2":{"209":1}}],["wiq∈rdmodel×dk",{"2":{"209":1}}],["wish就是希望的意思",{"2":{"127":1}}],["wise",{"2":{"108":1,"194":1,"223":1,"312":1,"329":1}}],["without",{"2":{"86":1,"88":1}}],["with",{"0":{"263":1,"320":1,"325":1,"460":1,"481":1,"896":1},"1":{"264":1,"265":1,"266":1,"267":1,"321":1,"322":1,"323":1,"324":1},"2":{"80":3,"81":2,"86":1,"88":1,"89":2,"113":2,"229":1,"269":1,"270":1,"334":1,"356":1,"430":1,"440":1,"444":2,"445":2,"453":1,"454":1,"455":1,"456":1,"474":2,"490":2,"496":3,"497":1,"509":1,"545":1,"546":1,"556":1,"581":3,"585":4,"588":1,"589":2,"633":1,"634":2,"643":1,"644":1,"645":1,"799":1,"895":1,"896":1,"897":2,"901":1,"904":1}}],["wi",{"2":{"38":1,"245":2}}],["wmnw",{"2":{"29":1}}],["w",{"2":{"28":4,"41":2,"44":3,"45":7,"46":11,"47":10,"50":7,"52":1,"83":1,"86":1,"87":1,"88":1,"89":1,"209":6,"233":1,"245":7,"248":14,"249":7,"251":2,"252":2,"309":3,"450":7,"452":2,"453":3,"454":7,"456":14,"556":20,"590":3,"643":7,"644":12,"647":5,"745":1,"777":1,"780":1,"790":3}}],["和饼干数组",{"2":{"956":1}}],["和截距bbb",{"2":{"840":1}}],["和p1",{"2":{"840":1}}],["和prelu",{"2":{"125":1}}],["和链接选项",{"2":{"822":1}}],["和自定义数据类型",{"2":{"809":1}}],["和自然语言生成",{"2":{"621":1}}],["和集体通信",{"2":{"806":1}}],["和从数据库中取数据",{"2":{"724":1}}],["和运行",{"2":{"705":1}}],["和y0",{"2":{"659":1}}],["和它们之间的相对位置",{"2":{"646":1}}],["和相对位置编码相比",{"2":{"645":1}}],["和多语言",{"2":{"619":1}}],["和协方差矩阵",{"2":{"606":1}}],["和图像对之间的匹配度和相关性",{"2":{"605":1}}],["和label",{"2":{"580":1}}],["和lbfgs",{"2":{"505":1}}],["和动态图",{"2":{"559":1}}],["和对字典值进行迭代的迭代器",{"2":{"507":1}}],["和缓冲区",{"2":{"496":1}}],["和推断模式",{"2":{"476":1}}],["和存储偏移",{"2":{"445":1}}],["和不同的种子",{"2":{"395":1}}],["和冗余超参数为",{"2":{"370":2}}],["和正则化超参数",{"2":{"361":1,"412":1}}],["和步数预算",{"2":{"359":1}}],["和1",{"2":{"345":1}}],["和value",{"2":{"333":1}}],["和transformer",{"2":{"328":1}}],["和dp",{"2":{"328":1}}],["和反向传播中的",{"2":{"328":2}}],["和分组查询注意力",{"2":{"323":1}}],["和分组查询注意力机制",{"2":{"308":1}}],["和值",{"2":{"309":1}}],["和具有一些重要区别的动量的变种",{"2":{"294":1}}],["和0",{"2":{"264":1}}],["和随机梯度下降",{"2":{"262":1}}],["和偏置",{"2":{"233":1}}],["和卷积",{"2":{"193":1}}],["和一个更新门",{"2":{"156":1}}],["和relu",{"2":{"128":1}}],["和中央处理器",{"2":{"74":1}}],["和weight",{"2":{"65":1}}],["和填充",{"2":{"61":1}}],["和输出序列",{"2":{"626":1}}],["和输出",{"2":{"55":1}}],["和",{"0":{"54":1,"102":1,"103":1,"109":1,"125":1,"155":1,"485":1},"1":{"104":1,"105":1,"106":1,"107":1,"110":1,"111":1},"2":{"27":1,"38":3,"48":1,"55":2,"57":1,"87":3,"120":1,"121":1,"143":1,"146":1,"147":1,"148":2,"206":1,"208":1,"214":1,"217":3,"223":1,"230":1,"244":1,"249":1,"281":1,"287":1,"294":1,"303":3,"312":1,"322":1,"323":1,"330":1,"332":1,"333":1,"338":3,"345":1,"347":1,"356":1,"369":1,"370":1,"389":1,"401":1,"431":1,"439":1,"445":1,"457":1,"463":2,"469":1,"480":2,"496":3,"508":1,"509":2,"510":1,"544":1,"572":1,"595":1,"606":2,"609":2,"616":1,"619":1,"620":1,"621":2,"632":1,"635":1,"646":2,"648":3,"655":1,"710":1,"730":1,"742":1,"743":1,"822":1,"827":2,"840":1,"878":4}}],["激励传播",{"2":{"27":1}}],["激活很小时会使得下层mlp的weight",{"2":{"239":1}}],["激活值均为0",{"2":{"237":1}}],["激活函数是一个固定超参数",{"2":{"369":1}}],["激活函数类型",{"2":{"355":1}}],["激活函数变换为",{"2":{"249":1}}],["激活函数在最终准确度上比swish",{"2":{"128":1}}],["激活函数在正半轴具有与relu",{"2":{"125":1}}],["激活函数一样的优势",{"2":{"125":1}}],["激活函数保持一致",{"2":{"125":1}}],["激活函数的选择可以是一个目标超参数",{"2":{"369":1}}],["激活函数的正半轴与relu",{"2":{"125":1}}],["激活函数的基础上将大于6",{"2":{"123":1}}],["激活函数几乎同时有一半的神经元被激活",{"2":{"123":1}}],["激活函数存在的双向饱和性仍然使得梯度弥散问题存在",{"2":{"121":1}}],["激活函数梯度弥散的问题",{"2":{"121":1}}],["激活函数非",{"2":{"121":1}}],["激活函数解决了",{"2":{"121":1}}],["激活函数求导过程计算量较大",{"2":{"121":1}}],["激活函数导数范围为",{"2":{"121":1}}],["激活函数导数计算",{"2":{"45":1}}],["激活函数具有双向饱和性",{"2":{"121":1}}],["激活函数值的范围为",{"2":{"121":1}}],["激活函数复杂就会降低计算速度",{"2":{"120":1}}],["激活函数应该具有什么样的性质",{"2":{"120":1}}],["激活函数可以看作卷积神经网络模型中一个特殊的层",{"2":{"120":1}}],["激活函数综述",{"2":{"116":1,"131":1}}],["激活函数汇总",{"2":{"116":1,"131":1}}],["激活函数z对w的偏导数",{"2":{"36":1}}],["激活函数",{"0":{"33":1,"34":1,"122":1,"124":1},"2":{"40":1,"41":1,"123":1,"126":1,"245":1,"484":1}}],["激活的梯度",{"2":{"27":2}}],["激活",{"2":{"27":1,"44":1}}],["可否互换",{"2":{"961":1}}],["可否让胃口最大的孩子吃相应最大",{"2":{"961":1}}],["可省略",{"2":{"840":1}}],["可视模式",{"0":{"784":1},"2":{"774":1}}],["可视化这个深度学习模型",{"0":{"119":1}}],["可视化",{"2":{"116":1,"131":1}}],["可变数据目录",{"2":{"739":1}}],["可变形卷积在kernel中加入偏移量offset",{"2":{"63":1}}],["可变形卷积",{"0":{"62":1},"1":{"63":1,"64":1}}],["可是这些数字不能是随随便便的数字吧",{"2":{"654":1}}],["可学习",{"0":{"641":1}}],["可直接设定中间过程",{"2":{"546":1}}],["可有效解决鞍点问题",{"2":{"545":1}}],["可读性和",{"2":{"510":1}}],["可迭代对象",{"2":{"507":1}}],["可扩展处理单元",{"2":{"496":1}}],["可通过register",{"2":{"490":1}}],["可参考umut",{"2":{"381":1}}],["可用计算资源",{"2":{"364":1}}],["可用硬件通常能能够支持一系列batch",{"2":{"358":1}}],["可用硬件支持的最大batch",{"2":{"357":1,"359":1}}],["可共享的部分包括",{"2":{"337":1}}],["可在相同功耗和芯片面积下实现双倍或四倍的吞吐量",{"2":{"325":1}}],["可调节的更新步长",{"2":{"262":1}}],["可见",{"0":{"695":1},"2":{"239":1,"695":1}}],["可增加序列长度",{"2":{"227":1,"317":1}}],["可选的掩码和dropout",{"2":{"226":1,"315":1}}],["可恨之处",{"2":{"191":1}}],["可容许机器通过此模型发现及学习将一种语言的语句",{"2":{"167":1}}],["可化简为",{"2":{"126":1}}],["可知",{"2":{"121":2}}],["可能举例举的不好",{"2":{"973":1}}],["可能大家不太理解我具体在说什么",{"2":{"972":1}}],["可能出现问题说明",{"2":{"727":1}}],["可能出现的问题",{"0":{"656":1}}],["可能存在更复杂的依赖关系",{"2":{"630":1}}],["可能存在各种kv",{"2":{"337":1}}],["可能有重复值",{"2":{"444":1}}],["可能返回原始张量的视图",{"2":{"441":1}}],["可能在讨论贝叶斯优化时",{"2":{"411":1}}],["可能你在解决某种模型需求",{"2":{"401":1}}],["可能可以用大多数计划做到",{"2":{"384":1}}],["可能转移",{"2":{"384":1}}],["可能的补救措施包括增加batch",{"2":{"375":1}}],["可能的变化",{"2":{"157":1}}],["可能很难知道是否搜索空间已经被足够密集地采样",{"2":{"374":1}}],["可能包括多种不同类型的成本",{"2":{"360":1}}],["可能都需要重复这些步骤",{"2":{"358":1}}],["可能会觉得很无趣",{"2":{"698":1}}],["可能会出现一些不可预期的问题",{"2":{"676":1}}],["可能会处理一些其他的内部机制",{"2":{"496":1}}],["可能会解决一些学习率预热无法解决的问题",{"2":{"406":1}}],["可能会导致较差的输入管道性能",{"2":{"387":1}}],["可能会看到明显的性能改进",{"2":{"384":1}}],["可能会转移",{"2":{"384":1}}],["可能会需要更多的训练步骤才能达到最优状态",{"2":{"383":1}}],["可能会减少max",{"2":{"381":1}}],["可能会以增大训练误差为代价",{"2":{"340":1}}],["可能会给深度网络训练带来潜在的问题",{"2":{"123":1}}],["可能是为了自一致性提示",{"2":{"338":1}}],["可能使得学习率在达到这样的凸结构前就变得太小了",{"2":{"283":1}}],["可能陷入局部最小值",{"2":{"261":1}}],["可能耗时太久",{"2":{"186":1}}],["可能表现更好",{"2":{"120":1}}],["可能尺寸会变小",{"2":{"61":1}}],["可微性",{"2":{"120":1}}],["可以是centos7",{"2":{"909":1}}],["可以是基于检索的问答或阅读理解型问答",{"2":{"188":1}}],["可以生成非常逼真的图像",{"2":{"857":1}}],["可以求出直线的斜率",{"2":{"840":1}}],["可以包含需要传递的任何信息",{"2":{"796":1}}],["可以考虑使用map传递参数",{"2":{"733":1}}],["可以多尝试使用",{"2":{"730":1}}],["可以比较完全的掌握它的设计思路和实现",{"2":{"724":1}}],["可以使用简单的",{"2":{"721":1}}],["可以使用像",{"2":{"474":1}}],["可以视为乘性的",{"2":{"648":1}}],["可以视为是乘性位置编码的变体",{"2":{"648":1}}],["可以得到包含相对位置信息的",{"2":{"647":1}}],["可以表示如下",{"2":{"646":1,"647":1}}],["可以表示成下面的式子",{"2":{"646":1}}],["可以看做一台服务器或者pc机",{"2":{"796":1}}],["可以看作从概率密度函数所在的函数空间到实数域r的一个函数f",{"2":{"659":1}}],["可以看到",{"2":{"648":1}}],["可以看到随着n的增大",{"2":{"640":1}}],["可以看下源码对应的计算",{"2":{"248":1}}],["可以加速您的pytorch代码",{"2":{"565":1}}],["可以加速模型收敛",{"2":{"88":1}}],["可以提前优化模型的计算图",{"2":{"560":1}}],["可以提高复杂的大型语言模型",{"2":{"337":1}}],["可以减少不必要的计算",{"2":{"560":1}}],["可以添加其他训练信息",{"2":{"522":1}}],["可以直接使用",{"2":{"887":1}}],["可以直接使用预测时语言模型",{"2":{"177":1}}],["可以直接给别人使用吗",{"2":{"516":1}}],["可以在",{"2":{"827":1}}],["可以在计算梯度",{"2":{"505":1}}],["可以在每次迭代中更改形状",{"2":{"466":1}}],["可以清为0",{"2":{"496":1}}],["可以改变这种行为",{"2":{"493":1}}],["可以传参数",{"2":{"490":1}}],["可以启用无梯度模式",{"2":{"478":1}}],["可以设置张量的",{"2":{"474":1}}],["可以通过给定的名称将缓冲区作为属性进行访问",{"2":{"493":1}}],["可以通过",{"2":{"471":1}}],["可以通过引入非线性变换",{"2":{"120":1}}],["可以用以下的贪心策略",{"2":{"955":1}}],["可以用",{"2":{"441":1}}],["可以给我们的邮箱",{"2":{"422":1}}],["可以指出某些实现错误",{"2":{"390":1}}],["可以无限地改善",{"2":{"383":1}}],["可以舒适地包含最佳观察试验周围的局部区域",{"2":{"379":1}}],["可以学习到更多数据中的细节和噪声",{"2":{"341":1}}],["可以灵活地适应训练数据",{"2":{"341":1}}],["可以将计算的过程分解成小部分",{"2":{"797":1}}],["可以将块视为页面",{"2":{"334":1}}],["可以将这些丰富的语言表示能力引入到模型中",{"2":{"180":1}}],["可以理解为给定句子y",{"2":{"190":1}}],["可以模型学习的结果更好",{"2":{"190":1}}],["可以利用预训练模型在大规模数据上学习到的语言分布信息",{"2":{"180":1}}],["可以处理不同的context",{"2":{"180":1}}],["可以初步得出一个良好的激活函数常具备以下一些特点",{"2":{"130":1}}],["可以更深入地了解准确性改进",{"2":{"391":1}}],["可以更容易地保持梯度的一致性",{"2":{"120":1}}],["可以更多的保留图像的背景信息",{"2":{"94":1}}],["可以替代梯度",{"2":{"120":1}}],["可以进行pointwise",{"2":{"108":1}}],["可以实现任意图像大小的输入",{"2":{"95":1}}],["可以修改每个神经元输入节点的权重系数",{"2":{"29":1}}],["可以解决的问题也更加广泛",{"2":{"14":1}}],["可划分为两个阶段",{"2":{"27":1}}],["参见",{"2":{"356":1,"357":1,"363":1}}],["参考资料",{"0":{"694":1,"718":1},"2":{"870":1}}],["参考3",{"2":{"660":1}}],["参考4",{"2":{"610":1}}],["参考",{"2":{"447":2,"868":1}}],["参考torch",{"2":{"441":2}}],["参考网站",{"2":{"192":1}}],["参考下一课时",{"2":{"96":1}}],["参考链接",{"0":{"66":1,"116":1,"131":1,"158":1,"232":1,"339":1,"610":1,"612":1},"2":{"231":1,"232":1,"270":1,"331":1,"339":1,"446":1,"448":1,"610":1,"629":1,"630":1,"649":1}}],["参考文献3",{"2":{"22":1,"158":1,"192":1}}],["参考文献2",{"2":{"22":1,"158":1,"192":1}}],["参考文献1",{"2":{"22":1,"158":1,"192":1}}],["参考文献",{"0":{"22":1,"192":1,"255":1,"302":1,"660":1},"2":{"66":1}}],["参数类型为map",{"2":{"730":1}}],["参数直接传递map",{"2":{"730":1}}],["参数是用户传递给",{"2":{"509":1}}],["参数是正在使用的优化器实例",{"2":{"509":2}}],["参数id可能看起来像索引",{"2":{"509":1}}],["参数需要以具有确定性顺序且在运行之间保持一致的集合形式进行指定",{"2":{"507":1}}],["参数用于指定一个元类",{"2":{"440":1}}],["参数范数惩罚",{"0":{"343":1}}],["参数更新",{"2":{"509":1}}],["参数更新方向就是将两者矢量相加的方向",{"2":{"271":1}}],["参数更新的幅度也会很大",{"2":{"236":1}}],["参数难以被更新",{"2":{"240":1}}],["参数初始化必要条件二",{"2":{"243":1}}],["参数初始化必要条件一",{"2":{"243":1}}],["参数初始化要确保信息能够顺利传递",{"2":{"243":1}}],["参数初始化的必要条件",{"0":{"243":1}}],["参数初始化的重要性",{"0":{"234":1},"1":{"235":1,"236":1}}],["参数初始化",{"2":{"233":1}}],["参数初始化概念",{"0":{"233":1}}],["参数控制着函数的斜率变化",{"2":{"125":1}}],["参数少",{"2":{"120":1}}],["参数共享的特殊形式使得神经网络层具有对平移等变",{"2":{"54":1}}],["参数共享",{"2":{"54":1}}],["参数矩阵中每一个单独的参数都描述了一个输入单元与一个输出单元间的交互",{"2":{"54":1}}],["参数",{"2":{"27":1,"217":1,"303":1,"490":1}}],["进去第二家",{"2":{"875":1}}],["进去说明了情况",{"2":{"875":1}}],["进入vmware",{"2":{"914":1}}],["进入doccano容器",{"0":{"886":1}}],["进入块选择模式",{"2":{"784":1}}],["进入可视模式",{"2":{"784":1}}],["进入列选择",{"2":{"774":1}}],["进入行选择模式",{"2":{"784":1}}],["进入行选择",{"2":{"774":1}}],["进入字符选择模式",{"2":{"784":1}}],["进入字符选择",{"2":{"774":1}}],["进入插入模式",{"2":{"774":1}}],["进入",{"2":{"752":1}}],["进入退出",{"0":{"751":1}}],["进入指定目录",{"2":{"742":1}}],["进入和退出目录",{"2":{"742":1}}],["进程可以在不同的通信域内工作",{"2":{"810":1}}],["进程的id",{"2":{"806":1}}],["进程和通信",{"0":{"806":1}}],["进程之间的通信通过消息传递实现",{"2":{"805":1}}],["进程",{"2":{"796":1,"822":1}}],["进程管理",{"0":{"754":1},"1":{"755":1,"756":1,"757":1}}],["进程互斥",{"2":{"694":1}}],["进程我们前面已经提及过了",{"2":{"677":1}}],["进程同步指多个进程在特定点会合",{"2":{"677":1}}],["进程同步我们下面会详细讲述",{"2":{"677":1}}],["进程同步是为了协调多个进程或线程对共享资源的访问",{"2":{"676":1}}],["进程同步",{"0":{"674":1},"1":{"675":1,"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1,"683":1,"684":1,"685":1,"686":1,"687":1,"688":1,"689":1,"690":1,"691":1,"692":1,"693":1,"694":1},"2":{"868":1}}],["进阶主题",{"0":{"717":1}}],["进阶",{"0":{"607":1,"826":1},"1":{"608":1,"609":1,"827":1}}],["进而把它们转换成相应的权重",{"2":{"254":1}}],["进行排序",{"2":{"956":1}}],["进行创建账户",{"2":{"887":1}}],["进行中",{"2":{"868":2}}],["进行缩进",{"2":{"792":1}}],["进行缩放",{"2":{"322":1,"543":1}}],["进行衰减",{"2":{"537":1,"541":1}}],["进行优化步骤",{"0":{"505":1}}],["进行处理",{"2":{"496":1}}],["进行设置",{"2":{"475":1}}],["进行左移位运算",{"2":{"445":1}}],["进行格式化时调用",{"2":{"441":1}}],["进行操作",{"2":{"441":4,"496":1}}],["进行梯度截断会发生什么",{"2":{"410":1}}],["进行一次学习率扫描",{"2":{"405":1}}],["进行调整",{"2":{"400":2}}],["进行评估",{"2":{"388":1}}],["进行转换",{"2":{"385":1}}],["进行短时间的训练来找到较佳的模型和优化器超参数",{"2":{"383":1}}],["进行了补充",{"2":{"329":1}}],["进行了简化",{"2":{"91":1}}],["进行迭代",{"2":{"327":1}}],["进行更新",{"2":{"233":1}}],["进行初始化赋值的过程",{"2":{"233":1}}],["进行指数缩放",{"2":{"226":1}}],["进行分解",{"2":{"225":2,"313":2}}],["进行",{"2":{"220":1,"306":1}}],["进行训练的warmup",{"2":{"409":1}}],["进行训练",{"2":{"190":1}}],["进行计算",{"2":{"58":1,"328":1}}],["进行比较",{"2":{"29":1}}],["进行传递",{"2":{"8":1}}],["进一步地",{"2":{"646":1}}],["进一步放大",{"2":{"620":1}}],["进一步影响损失及回传的梯度",{"2":{"235":1}}],["进一步表明神经元工作的稀疏性",{"2":{"123":1}}],["进一步",{"2":{"27":1}}],["bbb",{"2":{"840":1}}],["btz",{"2":{"635":1}}],["bt+1=1−β2t+11−β1t+1b",{"2":{"418":1,"419":1}}],["b−organization​​+t​b−organization",{"2":{"628":1}}],["b−organization+tb−organization",{"2":{"628":1}}],["b−person​​+t​o",{"2":{"628":1}}],["b−person+to",{"2":{"628":1}}],["b−a",{"2":{"252":2}}],["bmio",{"2":{"613":1}}],["bmm",{"2":{"84":1,"445":1,"450":1}}],["bmm是用于批量矩阵乘法的函数",{"2":{"84":1}}],["b7",{"2":{"590":1}}],["b6",{"2":{"590":1}}],["b5",{"2":{"590":1}}],["b4",{"2":{"590":1}}],["b3",{"2":{"590":1}}],["b0",{"2":{"590":1}}],["buf",{"2":{"823":3}}],["buffer",{"2":{"490":2,"493":5,"496":3}}],["buffers键",{"2":{"496":1}}],["buffers",{"0":{"493":1},"2":{"490":4,"496":5}}],["building",{"2":{"904":1}}],["builds",{"2":{"893":1}}],["build",{"2":{"613":1,"726":1,"891":1,"896":1}}],["builtins",{"2":{"443":7}}],["but",{"2":{"585":1,"633":1,"905":1}}],["bs",{"2":{"649":1}}],["bsz",{"2":{"649":1}}],["bsr",{"2":{"444":1,"445":1}}],["bsc",{"2":{"444":1,"445":1}}],["bf16背后的想法是通过降低数字的精度来减少计算能力和将张量相乘所需的能源消耗",{"2":{"433":1}}],["bf16矩阵乘法的最大理论吞吐量为312",{"2":{"320":1}}],["bfloat16",{"2":{"433":2,"445":1,"496":2}}],["bounded",{"2":{"682":1}}],["bound=dict",{"2":{"496":1}}],["board",{"2":{"572":1}}],["both",{"2":{"556":1,"891":1,"895":1}}],["bookcorpus",{"2":{"620":1}}],["boolean",{"2":{"706":1}}],["bool",{"2":{"440":2,"443":3,"444":13,"445":155,"490":7,"496":27,"509":6,"633":1,"634":3}}],["boosting",{"0":{"307":1},"1":{"308":1,"309":1}}],["boldsymbol",{"2":{"406":3}}],["b图上的黑色的点即是导致失活的特征点",{"2":{"348":1}}],["bgd的参数更新相对稳定",{"2":{"260":1}}],["bgd的计算开销较大",{"2":{"260":1}}],["bgd是批量梯度下降",{"2":{"260":1}}],["bgd",{"0":{"260":1,"262":1},"2":{"261":1,"262":2}}],["bcast",{"2":{"806":1,"808":1}}],["bcb",{"2":{"226":1}}],["bc=m4d",{"2":{"226":1}}],["bresenham算法",{"0":{"848":1},"1":{"849":1,"850":1,"851":1,"852":1}}],["break",{"2":{"497":1,"556":1}}],["broadcast",{"2":{"439":1,"445":2,"633":6,"634":8}}],["brb",{"2":{"226":4}}],["br=min",{"2":{"226":1}}],["brain",{"2":{"127":1,"891":1}}],["blinn",{"2":{"857":1}}],["blocking",{"2":{"445":7,"496":3}}],["block结合用于计算自注意力",{"2":{"327":1}}],["block在主机之间轮转",{"2":{"327":1}}],["block所需的时间",{"2":{"327":1}}],["block发送给下一个主机",{"2":{"327":1}}],["block之间的注意力时",{"2":{"327":1}}],["block之间的attention可以按任何顺序计算",{"2":{"327":1}}],["block与一个key",{"2":{"327":1}}],["block与一组key",{"2":{"327":1}}],["block有效地发送到下一个主机",{"2":{"327":1}}],["block操作的置换不变性属性",{"2":{"327":1}}],["block的累积会导致内存使用增加",{"2":{"327":1}}],["blockwise",{"2":{"326":2,"327":1}}],["blocksize",{"2":{"444":3,"445":3}}],["blocks",{"2":{"333":2,"609":1}}],["blocks内部warp级别的工作模式",{"2":{"324":1}}],["blocks的并行化计算",{"2":{"324":1}}],["block",{"0":{"334":1},"2":{"226":1,"326":1,"327":6,"348":1,"609":1}}],["bleu",{"2":{"217":1,"303":1}}],["by=kx+b推导而来",{"2":{"839":1}}],["by=",{"2":{"581":1}}],["bytetensor",{"2":{"632":1,"633":1,"634":1}}],["bytes",{"2":{"509":1}}],["byte",{"2":{"445":1}}],["bypass",{"2":{"444":1}}],["by",{"2":{"167":1,"448":1,"458":1,"498":1,"499":1,"500":1,"509":1,"556":1,"580":1,"585":1,"586":1,"891":1,"893":1,"897":1}}],["bn3",{"2":{"497":2}}],["bn2",{"2":{"497":2}}],["bn1",{"2":{"497":2}}],["bn注重对每个batch进行归一化",{"2":{"88":1}}],["bn中则针对不同神经元输入计算均值和方差",{"2":{"87":1}}],["bn不适用于深度不固定的网络",{"2":{"87":1}}],["bn",{"2":{"86":6,"87":1,"590":4}}],["bn示意图",{"2":{"86":1}}],["bar",{"2":{"734":2}}],["bart",{"2":{"616":1,"621":1}}],["basic",{"0":{"904":1}}],["bashmpirun",{"2":{"822":1}}],["bashmpicc",{"2":{"822":1,"827":1}}],["bashgcc",{"2":{"822":1}}],["bashgrep",{"2":{"749":1}}],["bash",{"2":{"817":5,"885":1,"886":1}}],["bashssh",{"2":{"816":1}}],["bashsudo",{"2":{"746":1,"770":2}}],["bashvim",{"2":{"776":1}}],["bashtail",{"2":{"772":1}}],["bashtouch",{"2":{"743":1}}],["bashwhich",{"2":{"766":1}}],["bashkill",{"2":{"756":1}}],["bashcat",{"2":{"743":1,"748":1}}],["bashcp",{"2":{"743":1}}],["bashls",{"2":{"740":1}}],["bashusage",{"2":{"590":1}}],["bashpython",{"2":{"585":2,"586":1,"588":1,"589":2}}],["base",{"0":{"506":1,"603":1},"1":{"507":1,"508":1,"509":1},"2":{"409":10,"440":1,"468":1,"504":2,"542":1,"543":1,"590":1,"613":1}}],["baseline的学习率也应该同样得到很好的调整",{"2":{"376":1}}],["based",{"2":{"327":1}}],["baidu",{"2":{"584":1,"799":1}}],["baddbmm",{"2":{"445":2}}],["ba",{"2":{"294":1}}],["batches",{"2":{"497":1}}],["batch2",{"2":{"445":2}}],["batch1",{"2":{"445":2}}],["batching",{"2":{"338":1}}],["batch",{"0":{"260":1,"362":1},"2":{"87":2,"113":1,"260":1,"262":7,"357":3,"358":1,"359":2,"360":6,"362":3,"388":1,"390":4,"394":3,"441":2,"445":1,"493":21,"497":14,"498":10,"500":9,"543":2,"544":2,"553":3,"568":1,"571":2,"577":1,"580":1,"585":1,"590":3,"632":13,"633":15,"634":23,"636":1,"649":7}}],["batchnorm的实现细节",{"0":{"394":1},"2":{"351":1}}],["batchnorm",{"2":{"86":1,"480":1,"493":1}}],["batchnorm是在batch上",{"2":{"86":1}}],["batchnorm2d",{"0":{"86":1},"2":{"86":2,"480":1,"497":3}}],["backends",{"2":{"497":1}}],["backend",{"2":{"444":1,"465":1,"490":1,"587":1,"588":1,"589":2,"590":5}}],["backwad",{"2":{"316":1}}],["backward",{"0":{"316":1,"323":1},"2":{"50":5,"274":1,"316":1,"440":1,"441":1,"450":1,"452":1,"453":2,"454":2,"455":1,"456":3,"457":2,"458":2,"459":3,"460":1,"462":2,"463":1,"466":1,"472":1,"475":1,"484":1,"487":2,"490":6,"495":5,"496":9,"497":1,"500":1,"505":3,"533":2,"546":1,"567":1,"904":4}}],["backpropagation",{"2":{"25":1,"904":1}}],["back",{"0":{"42":1},"1":{"43":1,"44":1,"45":1,"46":1},"2":{"24":1,"28":1,"634":1,"671":1}}],["become",{"2":{"581":1}}],["becomes",{"2":{"581":1,"633":1}}],["because",{"2":{"556":2,"891":1,"894":1,"901":1}}],["behavior",{"2":{"556":1}}],["below",{"2":{"556":1}}],["before",{"2":{"487":2,"497":1,"904":1}}],["bernoulli",{"2":{"445":4}}],["bert+crf模型架构实现ner任务",{"2":{"624":1}}],["bert4torch",{"2":{"613":3}}],["bert",{"0":{"614":1,"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"126":1,"227":1,"317":1,"613":1,"614":2,"616":3,"619":9,"621":1,"624":3,"641":1,"671":1}}],["being",{"2":{"444":1}}],["best",{"2":{"405":1,"587":1,"634":13}}],["benchmark",{"2":{"586":1,"590":1,"619":2}}],["ben",{"2":{"401":1}}],["bengio",{"2":{"244":1,"402":1}}],["between",{"2":{"329":1}}],["better",{"0":{"320":1},"1":{"321":1,"322":1,"323":1,"324":1},"2":{"229":1}}],["beta2",{"2":{"369":1,"370":1}}],["beta1",{"2":{"369":1,"370":1}}],["beta",{"2":{"86":2,"87":2,"88":2,"89":2,"127":1,"356":2,"400":3,"418":6,"419":8,"444":2,"445":3,"644":2}}],["begin",{"2":{"225":1,"313":1}}],["beam",{"0":{"182":1,"184":1,"186":1},"1":{"183":1,"184":1,"185":1,"186":1},"2":{"183":1,"184":2,"186":2}}],["be",{"2":{"81":1,"333":1,"498":1,"499":1,"500":1,"547":1,"556":2,"896":1}}],["b2",{"2":{"50":2,"460":2,"590":1}}],["b2=0",{"2":{"47":1}}],["b1",{"2":{"50":2,"460":2,"590":1}}],["b1=0",{"2":{"47":1}}],["b​t+1​​=​1−β​1​t+1​​​​√​1−β​2​t+1​​​​​​​",{"2":{"418":1,"419":1}}],["b​c​​",{"2":{"226":1}}],["b​c​​=​4d​​m​​",{"2":{"226":1}}],["b​r​​",{"2":{"226":4}}],["b​r​​=min",{"2":{"226":1}}],["b​2​​=0",{"2":{"47":1}}],["b​1​​=0",{"2":{"47":1}}],["b",{"2":{"41":1,"47":2,"50":1,"86":1,"87":3,"88":1,"89":1,"98":2,"99":3,"105":2,"112":2,"225":1,"226":10,"252":4,"313":1,"338":1,"418":1,"419":1,"444":2,"451":2,"453":1,"454":1,"456":7,"457":3,"571":2,"576":1,"590":4,"624":3,"628":7,"780":1,"843":1}}],["big",{"2":{"895":1}}],["bigbird",{"2":{"621":2}}],["bidirectional",{"2":{"616":1}}],["bin",{"2":{"739":1,"740":1}}],["binary",{"2":{"454":1}}],["bins",{"2":{"445":3}}],["bincount",{"2":{"445":1}}],["bitwise",{"2":{"445":22}}],["bit",{"2":{"439":1,"445":1}}],["bileschi",{"2":{"420":2}}],["bias=false",{"2":{"499":3,"580":1}}],["bias",{"2":{"87":1,"177":1,"233":1}}],["bi",{"2":{"38":1,"440":2,"619":1}}],["bpt",{"2":{"327":1}}],["bp时",{"2":{"239":1}}],["bp",{"0":{"27":1,"29":1},"2":{"27":1,"50":2,"671":1}}],["iy​i​​",{"2":{"845":1}}],["irecv",{"2":{"807":1,"808":1}}],["irshift",{"2":{"443":3}}],["ibatis",{"2":{"726":4}}],["i∈",{"2":{"647":2}}],["i−1",{"2":{"647":2}}],["i−j",{"2":{"643":4}}],["i−organization​​",{"2":{"628":1}}],["i−organizationseq",{"2":{"628":1}}],["i−person​​+t​o",{"2":{"628":1}}],["i−person+to",{"2":{"628":1}}],["iloc",{"2":{"552":2}}],["ilshift",{"2":{"443":3}}],["ilsvrc",{"2":{"122":1,"584":1}}],["iperson",{"2":{"628":1}}],["ip",{"2":{"589":2,"759":1,"816":1,"827":4,"910":1}}],["ipu",{"2":{"445":1,"496":2}}],["ipow",{"2":{"441":1}}],["igammac",{"2":{"445":2}}],["igamma",{"2":{"445":2}}],["ignore",{"2":{"443":2,"500":1}}],["i0",{"2":{"445":2}}],["ixor",{"2":{"443":3}}],["iand",{"2":{"443":3}}],["iadd",{"2":{"443":1}}],["its",{"2":{"899":1,"905":1}}],["it学习",{"2":{"870":1}}],["it学习指南",{"0":{"833":1}}],["it",{"2":{"458":1,"556":3,"586":1,"587":1,"868":1,"886":1,"891":3,"893":2,"895":1,"896":1,"899":1,"901":1,"905":1}}],["items",{"2":{"799":1}}],["item",{"2":{"445":1,"493":4,"497":3,"500":1,"522":1,"529":2,"567":2,"635":3,"904":1}}],["iteration",{"2":{"581":3}}],["iterations",{"2":{"543":1,"581":2}}],["iterators",{"2":{"507":1}}],["iterator",{"2":{"496":7}}],["iter",{"2":{"26":1,"441":1,"576":8,"580":1,"581":2}}],["iters=2",{"2":{"548":1,"549":1}}],["iters=4",{"2":{"539":1,"540":1,"542":1}}],["iters",{"2":{"26":2,"539":1,"540":1,"542":1,"546":2}}],["itruediv",{"2":{"441":1}}],["i++",{"2":{"827":1}}],["i+",{"2":{"406":1}}],["i+1",{"2":{"245":1,"383":1,"406":1,"626":3,"628":1,"640":1,"840":4,"845":2}}],["i​",{"2":{"244":2}}],["i^",{"2":{"244":3}}],["ioexception",{"2":{"726":2}}],["ior",{"2":{"443":3}}],["io",{"2":{"227":1,"317":1,"555":1,"726":3}}],["id​i​​和di+1d",{"2":{"845":1}}],["id=",{"2":{"726":2,"730":3,"731":1,"732":1,"733":1,"734":2}}],["ideas",{"2":{"893":1,"896":1,"899":1}}],["idea",{"2":{"719":1}}],["identical",{"2":{"217":1,"303":1,"556":1}}],["ids",{"2":{"635":2}}],["idiv",{"2":{"441":1,"443":1}}],["id",{"2":{"436":8,"509":1,"590":1,"726":2,"730":4,"731":2,"732":2,"733":3,"757":1,"827":3}}],["idx=padding",{"2":{"113":1}}],["idx=0",{"2":{"113":1}}],["idx",{"2":{"113":4,"445":1,"497":5,"552":4,"553":2,"634":14}}],["i=1",{"2":{"185":1}}],["imitate",{"2":{"891":1}}],["immediate",{"2":{"807":1}}],["img",{"2":{"552":11,"556":2}}],["imul",{"2":{"443":1}}],["imod",{"2":{"443":1}}],["imag",{"2":{"440":1,"595":1}}],["images",{"2":{"212":1,"556":4,"580":5,"584":1,"843":1,"897":1}}],["image",{"2":{"164":1,"489":2,"529":3,"552":5,"555":7,"556":28,"580":2,"584":2,"605":1,"606":1,"608":1,"843":2,"897":2,"899":1,"900":1}}],["imagenet",{"0":{"582":1},"2":{"122":1,"376":1,"403":1,"582":1,"584":2,"585":3,"586":1,"588":1,"589":2,"590":2}}],["implicit",{"2":{"445":2}}],["impl",{"2":{"441":1,"490":3,"496":3}}],["implements",{"2":{"582":1}}],["implement",{"0":{"666":1},"2":{"556":1}}],["implemented",{"2":{"441":11}}],["implementation",{"2":{"122":1}}],["importance",{"2":{"271":1}}],["import",{"0":{"575":1},"2":{"50":1,"80":1,"81":1,"83":1,"87":1,"95":1,"493":1,"494":1,"495":1,"497":9,"498":2,"499":2,"500":3,"513":6,"528":1,"541":2,"545":2,"553":1,"555":8,"570":1,"571":1,"575":7,"579":1,"726":6,"799":1,"904":3}}],["isend和mpi",{"2":{"807":1,"808":1}}],["issue",{"2":{"556":1}}],["isinstance",{"2":{"508":1,"556":4}}],["isinf",{"2":{"445":1}}],["isreal",{"2":{"445":1}}],["isposinf",{"2":{"445":1}}],["isneginf",{"2":{"445":1}}],["isnan",{"2":{"445":1}}],["isfinite",{"2":{"445":1}}],["isclose",{"2":{"445":1}}],["isub",{"2":{"443":1}}],["istft",{"2":{"441":1,"445":1}}],["isolation图可以更轻松地在目标超参数的不同值之间进行同类比较",{"2":{"376":1}}],["isolation图上的每个点对应着在优化某些",{"2":{"376":1}}],["isolation图是基本超参数轴图的特例",{"2":{"376":1}}],["is",{"0":{"193":1,"891":1},"2":{"99":1,"215":2,"217":2,"227":1,"255":1,"303":2,"317":1,"434":1,"441":1,"444":7,"445":26,"462":1,"468":1,"472":2,"490":1,"493":1,"497":2,"498":1,"499":1,"500":1,"511":1,"556":7,"581":2,"585":1,"586":2,"590":2,"616":1,"632":2,"633":1,"634":5,"891":3,"899":1,"901":1,"904":3,"905":3}}],["i",{"2":{"50":5,"129":2,"181":2,"185":4,"197":1,"209":7,"225":4,"226":24,"244":11,"245":7,"252":4,"313":4,"319":2,"326":3,"327":2,"338":1,"358":1,"383":1,"406":2,"456":4,"457":1,"458":2,"460":2,"484":1,"487":3,"529":2,"546":3,"556":5,"577":1,"624":5,"626":9,"627":5,"628":8,"632":7,"633":7,"634":9,"640":3,"643":20,"644":14,"647":3,"648":11,"649":3,"731":2,"732":2,"733":2,"749":1,"752":1,"774":1,"778":2,"807":1,"822":2,"823":1,"827":3,"840":4,"845":1,"953":1}}],["innovate",{"2":{"905":1}}],["inner",{"2":{"445":1}}],["inroads",{"2":{"905":1}}],["inspectdb",{"2":{"889":1}}],["insert>",{"2":{"731":1}}],["insert",{"0":{"731":1},"2":{"634":1,"726":1,"731":2}}],["instead",{"2":{"220":1,"306":1,"546":1,"556":2}}],["instancenorm",{"2":{"88":1,"89":1}}],["instancenorm2d",{"2":{"88":2}}],["instance",{"0":{"88":1},"2":{"88":1}}],["install",{"0":{"71":1},"2":{"573":1,"583":2,"613":1,"671":1,"770":2,"817":4}}],["inception",{"2":{"590":1,"606":2}}],["include>",{"2":{"727":8}}],["includes>",{"2":{"727":4}}],["include",{"2":{"445":4,"822":1,"823":1,"827":3}}],["inverse",{"2":{"445":2}}],["inverse=false",{"2":{"441":2}}],["invert",{"2":{"443":1}}],["inp",{"2":{"459":4}}],["inp+1",{"2":{"459":1}}],["inplace的操作",{"2":{"462":1}}],["inplace",{"0":{"455":1},"2":{"439":1,"441":1,"455":2,"496":4}}],["input1",{"2":{"460":2}}],["input3",{"2":{"445":1}}],["input2",{"2":{"445":3}}],["input自身相关的self",{"2":{"213":1}}],["input或者target",{"2":{"213":1}}],["inputstream",{"2":{"726":4}}],["inputs=none",{"2":{"441":1}}],["inputs",{"2":{"38":1,"444":1,"496":1,"529":2,"546":3,"570":3,"904":2}}],["input",{"0":{"33":1,"35":1},"2":{"50":5,"52":1,"55":1,"57":2,"65":1,"80":2,"81":4,"83":2,"84":2,"86":2,"88":2,"89":1,"93":2,"94":2,"95":6,"113":6,"114":2,"121":4,"122":5,"123":2,"124":6,"125":4,"126":2,"127":2,"128":2,"129":2,"148":1,"248":1,"274":1,"441":1,"444":1,"445":2,"453":1,"454":1,"456":1,"458":1,"484":2,"487":9,"489":2,"493":2,"494":7,"495":5,"496":1,"497":3,"498":1,"505":4,"515":2,"518":2,"519":2,"523":2,"528":2,"529":15,"533":4,"569":2,"570":2,"571":2}}],["initializing",{"2":{"590":1}}],["initialization",{"0":{"233":1,"245":1,"246":1},"1":{"247":1,"248":1,"249":1,"250":1,"251":1,"252":1},"2":{"233":2,"271":1,"671":1}}],["initial",{"2":{"545":1,"585":1,"590":1}}],["init所示",{"2":{"406":1}}],["init",{"2":{"255":1,"436":1,"443":4,"478":1,"487":4,"488":2,"490":1,"493":2,"494":2,"495":2,"496":1,"497":4,"498":8,"499":6,"500":10,"509":1,"513":2,"552":2,"556":3,"567":3,"649":2,"808":1,"823":1,"827":1,"904":2}}],["infiniband",{"2":{"822":1}}],["inf",{"2":{"498":1,"500":1}}],["infos=false",{"2":{"441":1}}],["information",{"2":{"188":1}}],["infty",{"2":{"248":2}}],["infer",{"0":{"530":1},"2":{"529":2,"530":3,"570":1,"571":1}}],["inferencesession",{"2":{"529":2,"570":1}}],["inferencemode",{"2":{"479":1}}],["inference",{"0":{"307":1,"479":1},"1":{"308":1,"309":1},"2":{"176":1,"445":1,"476":1,"479":1,"530":1}}],["inferred",{"2":{"99":1}}],["inbox",{"2":{"167":1}}],["industry",{"0":{"900":1},"2":{"905":1}}],["index=0",{"2":{"500":1}}],["index",{"2":{"113":1,"443":2,"445":64,"497":1,"552":3,"567":3,"634":3,"721":1}}],["indices的维度",{"2":{"444":1}}],["indices",{"2":{"113":1,"443":2,"444":2,"445":16,"509":3,"634":9}}],["intuitive",{"2":{"896":1}}],["introduction",{"0":{"890":1},"1":{"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1,"899":1,"900":1,"901":1,"902":1,"903":1,"904":1,"905":1},"2":{"868":1}}],["introduce",{"0":{"506":1},"1":{"507":1,"508":1,"509":1}}],["inttensor",{"2":{"595":1}}],["int`",{"2":{"556":1}}],["int64",{"2":{"487":1}}],["integrates",{"2":{"901":1}}],["integration",{"2":{"444":1}}],["intelligence",{"2":{"891":1}}],["intel",{"2":{"496":1,"802":1}}],["intenum",{"2":{"441":1}}],["intersection",{"2":{"635":1}}],["interval",{"2":{"497":2}}],["interleave",{"2":{"445":2}}],["interpolation",{"2":{"445":4}}],["interface",{"2":{"441":1,"726":1,"730":1}}],["internal",{"2":{"441":2,"446":1}}],["interactions",{"2":{"54":1}}],["int32",{"2":{"433":1}}],["int",{"2":{"248":1,"440":5,"441":1,"443":7,"444":12,"445":268,"490":12,"496":4,"509":1,"556":10,"634":3,"649":2,"706":2,"726":2,"730":1,"731":2,"732":2,"733":4,"809":1,"823":11,"827":11,"841":1}}],["into",{"2":{"89":3,"333":1,"498":1,"499":1,"500":1,"726":1,"731":1,"905":1}}],["in",{"0":{"481":1,"582":1},"2":{"26":1,"50":3,"87":1,"99":1,"209":4,"223":3,"226":4,"245":1,"251":1,"271":1,"312":3,"333":1,"337":3,"440":1,"441":1,"444":1,"447":1,"448":1,"456":3,"457":1,"460":1,"481":1,"484":1,"487":2,"493":1,"496":1,"497":3,"498":2,"499":2,"500":5,"505":2,"508":1,"529":2,"533":5,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":2,"544":2,"545":1,"546":3,"547":1,"548":1,"549":1,"553":1,"556":8,"567":2,"571":1,"576":1,"580":1,"581":2,"586":1,"632":1,"633":3,"634":2,"635":1,"647":1,"799":4,"893":1,"899":1,"904":2,"905":2}}],["ifcfg",{"2":{"915":1}}],["ifconfig",{"2":{"759":1}}],["ifloordiv",{"2":{"443":1}}],["if",{"2":{"26":1,"50":1,"215":2,"434":1,"456":2,"460":2,"493":2,"497":6,"498":2,"499":1,"500":2,"508":2,"511":1,"537":3,"538":3,"539":5,"540":5,"542":5,"548":5,"549":5,"552":2,"556":8,"632":2,"633":1,"634":4,"706":1,"726":1,"799":1,"827":1,"957":1}}],["=ax+by+c=0f",{"2":{"843":1}}],["=argmax​y​​​p",{"2":{"190":1}}],["=argmax",{"2":{"190":1}}],["=argmaxyp",{"2":{"190":2}}],["=k=y1−y0x1−x0k",{"2":{"840":1}}],["=r​θ",{"2":{"647":1}}],["=r",{"2":{"647":1}}],["=rθ",{"2":{"647":1}}],["=rowsum",{"2":{"226":1}}],["=rowmax",{"2":{"226":1}}],["=g",{"2":{"646":2}}],["=t",{"2":{"628":1}}],["=∣∣μ​p​​−μ​q​​∣∣​2​​+tr",{"2":{"606":1}}],["=∣∣μp−μq∣∣2+tr",{"2":{"606":1}}],["=||",{"2":{"606":1}}],["=λ×g∣g∣",{"2":{"410":1}}],["=每秒处理的样本数量",{"2":{"358":1}}],["=∫​−∞​+∞​​p",{"2":{"248":1}}],["=∫−∞+∞p",{"2":{"248":1}}],["=n​l​​",{"2":{"248":2}}],["=n​l​​var",{"2":{"248":3}}],["=nl",{"2":{"248":2}}],["=nlvar",{"2":{"248":3}}],["=n",{"2":{"248":5}}],["=d",{"2":{"248":1}}],["=var",{"2":{"244":6,"247":6}}],["=q",{"2":{"226":1}}],["=ℓ",{"2":{"225":2,"313":2}}],["=f^",{"2":{"249":1}}],["=f",{"2":{"225":2,"248":1,"249":1,"313":2}}],["=∑if",{"2":{"225":1,"313":1}}],["=∑i=1tlogp",{"2":{"185":1}}],["=concat",{"2":{"209":2}}],["=softmax",{"2":{"200":3,"223":1,"312":1,"643":1}}],["=p",{"2":{"190":1,"626":3,"643":2,"659":1}}],["=−​t​​1​​​i​∑​t​​log",{"2":{"181":1}}],["=−1t∑itlog",{"2":{"181":1}}],["=x​m​⊤​​w​q​​r​θ",{"2":{"647":1}}],["=x​6​​relu6",{"2":{"127":1}}],["=xm⊤wqrθ",{"2":{"647":1}}],["=x×tanh",{"2":{"128":2}}],["=xrelu6",{"2":{"127":1}}],["=x",{"2":{"127":2,"647":1}}],["=x⋅sigmoid",{"2":{"127":2}}],["=xφ",{"2":{"126":2}}],["=xp",{"2":{"126":2}}],["=m",{"2":{"225":3,"313":3}}],["=min",{"2":{"123":3}}],["=max",{"2":{"122":3,"225":5,"313":5}}],["=​n​l​​​​2​​",{"2":{"248":1}}],["=​2​​1​​n​l​​var",{"2":{"248":1}}],["=​2​​1​​var",{"2":{"248":1}}],["=​2​​1​​e",{"2":{"248":1}}],["=​ℓ",{"2":{"225":2,"313":2}}],["=​i​∑​​f",{"2":{"225":1,"313":1}}],["=​i=1​∑​t​​logp",{"2":{"185":1}}],["=​p",{"2":{"190":1,"659":1}}],["=​∑​j​​exp",{"2":{"129":1}}],["=​e​x​​+e​−x​​​​e​x​​−e​−x​​​​",{"2":{"121":1}}],["=​1+e​−x​​​​1​​",{"2":{"121":1}}],["=10000^",{"2":{"647":1,"648":4}}],["=1000",{"2":{"441":1}}],["=12nlvar",{"2":{"248":1}}],["=12var",{"2":{"248":1}}],["=12e",{"2":{"248":1}}],["=11+e−xsigmoid",{"2":{"121":1}}],["=1",{"2":{"45":1,"245":6,"248":3,"249":3,"328":1}}],["=out",{"2":{"45":1}}],["=2nlvar",{"2":{"248":1}}],["=2",{"2":{"45":1}}],["=e​m",{"2":{"225":1,"313":1}}],["=e^",{"2":{"225":1,"313":1}}],["=em",{"2":{"225":1,"313":1}}],["=exp",{"2":{"129":1,"226":1}}],["=ex−e−xex+e−xtanh",{"2":{"121":1}}],["=e−net",{"2":{"45":1}}],["=e",{"2":{"41":1,"45":1,"247":3,"248":4}}],["=0e",{"2":{"248":2,"249":2}}],["=0",{"2":{"40":1,"41":3,"45":9,"47":1,"248":1,"249":1,"328":1}}],["=w∗max",{"2":{"605":2}}],["=w",{"2":{"40":1,"41":1,"45":1,"47":2,"248":1,"605":1}}],["=",{"2":{"26":7,"28":3,"40":6,"41":4,"44":2,"45":8,"46":8,"47":14,"48":1,"50":46,"80":5,"81":9,"83":6,"84":7,"86":16,"87":13,"88":10,"89":12,"93":4,"94":4,"95":9,"98":2,"99":6,"100":1,"101":1,"104":1,"105":2,"106":1,"107":1,"108":1,"110":1,"111":4,"112":6,"113":10,"114":3,"121":10,"122":6,"123":3,"124":9,"125":6,"126":5,"127":4,"128":4,"129":4,"138":2,"181":2,"185":1,"190":2,"194":1,"196":2,"197":1,"209":2,"215":6,"223":2,"225":13,"226":4,"248":5,"249":1,"258":1,"274":2,"312":2,"313":13,"322":1,"323":1,"358":1,"359":1,"360":1,"405":1,"406":1,"410":1,"414":1,"415":3,"416":3,"417":5,"418":6,"419":6,"421":5,"427":4,"428":5,"429":4,"430":9,"433":4,"434":7,"436":4,"440":6,"441":16,"443":4,"444":22,"445":371,"450":9,"451":5,"452":4,"453":7,"454":10,"455":4,"456":22,"457":8,"458":3,"459":2,"460":17,"462":4,"464":2,"465":1,"472":4,"474":7,"484":13,"487":36,"489":3,"490":6,"492":1,"493":12,"494":5,"495":7,"496":41,"497":76,"498":46,"499":39,"500":83,"503":2,"505":4,"508":11,"509":9,"511":4,"513":18,"514":1,"515":4,"518":3,"519":5,"522":5,"523":7,"525":2,"526":2,"528":2,"529":10,"530":1,"533":10,"535":3,"536":2,"537":7,"538":6,"539":7,"540":7,"541":3,"542":8,"543":3,"544":4,"545":7,"546":7,"547":3,"548":9,"549":9,"552":13,"553":1,"555":3,"556":27,"567":15,"568":8,"569":5,"570":5,"571":4,"576":1,"577":1,"579":2,"580":11,"595":9,"626":2,"632":5,"633":7,"634":29,"635":8,"640":2,"643":3,"644":1,"646":1,"647":1,"649":32,"655":1,"659":1,"706":1,"726":7,"730":10,"731":4,"732":5,"733":4,"734":4,"793":1,"799":7,"803":1,"823":1,"827":10,"839":1,"840":11,"843":2,"849":1,"904":15,"957":2,"958":3}}],["=========loss",{"2":{"487":1}}],["==========y",{"2":{"456":1}}],["============output",{"2":{"580":1}}],["============images",{"2":{"580":1}}],["================model",{"2":{"487":2}}],["=============",{"2":{"50":1}}],["===========w",{"2":{"456":1}}],["=======loss",{"2":{"487":1}}],["======",{"2":{"28":1}}],["=====",{"2":{"28":1}}],["==",{"2":{"26":1,"50":1,"215":1,"497":2,"498":3,"499":2,"500":3,"508":1,"529":1,"539":4,"540":4,"542":4,"548":4,"549":5,"556":2,"567":1,"632":2,"633":1,"634":5,"827":2}}],["dhcp服务未开启",{"2":{"911":1}}],["dhcp",{"2":{"910":1}}],["django",{"2":{"889":1}}],["dbshell",{"2":{"889":1}}],["db",{"2":{"889":1}}],["d$",{"2":{"781":2}}],["d0",{"2":{"781":1}}],["dda",{"0":{"839":1},"2":{"839":2}}],["dda算法",{"0":{"838":1},"1":{"839":1,"840":1,"841":1,"842":1}}],["dd",{"2":{"753":1,"781":1}}],["dst",{"2":{"496":2}}],["dsplit",{"2":{"445":3}}],["dsigmoid",{"2":{"121":1}}],["dsigmoiddx=sigmoid",{"2":{"121":1}}],["dlpack",{"2":{"441":5}}],["dloss",{"2":{"50":1}}],["dtd",{"2":{"726":6}}],["dtype=original",{"2":{"595":1}}],["dtype=torch",{"2":{"444":1,"498":1,"500":1,"634":5}}],["dtype=none",{"2":{"441":2}}],["dtype",{"2":{"436":3,"440":2,"444":2,"445":79,"496":5,"509":2,"595":2}}],["dtanh",{"2":{"121":1}}],["dtanhdx=1−tanh2",{"2":{"121":1}}],["due",{"2":{"905":1}}],["during",{"2":{"894":1}}],["dummy",{"0":{"586":1},"2":{"586":3,"590":2,"904":1}}],["dumpdata",{"2":{"889":1}}],["dumps",{"2":{"496":1}}],["dump",{"2":{"490":1,"496":1,"572":1}}],["duplicate",{"2":{"496":4}}],["dubois以及charles",{"2":{"420":1}}],["duchi",{"2":{"277":1}}],["date",{"2":{"746":1,"875":1,"877":2,"880":1}}],["datatype",{"2":{"823":2}}],["datasource>",{"2":{"726":1}}],["datasource",{"2":{"726":1}}],["dataset2",{"2":{"497":2}}],["dataset1",{"2":{"497":2}}],["datasets",{"2":{"497":3,"555":2,"575":1,"580":1,"897":3}}],["dataset",{"0":{"551":1},"2":{"387":1,"497":4,"505":2,"533":2,"552":2,"555":1,"556":3,"567":4,"568":2,"582":1,"584":1,"585":1,"586":1,"590":1,"636":1,"904":1}}],["database",{"2":{"726":1}}],["dataloader",{"0":{"553":1},"2":{"497":2,"543":1,"544":1,"546":2,"553":4,"568":3,"571":2,"580":1,"671":1}}],["data0",{"2":{"429":4,"450":2}}],["data4",{"2":{"428":3}}],["data1",{"2":{"428":1,"429":1,"455":4}}],["data3",{"2":{"427":1,"428":1,"429":1,"450":2}}],["data2",{"2":{"427":3,"428":2,"429":2,"450":2}}],["data",{"0":{"586":1,"587":1},"1":{"588":1,"589":1},"2":{"387":2,"427":3,"428":2,"429":1,"430":11,"436":22,"440":1,"444":2,"445":3,"493":2,"495":2,"496":1,"497":13,"529":8,"543":3,"544":3,"552":5,"553":5,"555":5,"556":4,"567":10,"568":1,"569":4,"580":1,"586":1,"590":5,"634":1,"635":2,"723":1,"799":5,"891":1,"895":2,"897":1,"904":1}}],["dao",{"2":{"723":1,"726":2}}],["dao层",{"2":{"723":1}}],["daily",{"2":{"613":1}}],["dahl",{"2":{"350":1,"421":1}}],["dcg",{"2":{"448":1}}],["dc∗ld",{"2":{"309":1}}],["dc≪dhnhd",{"2":{"309":1}}],["dkv",{"2":{"309":1}}],["dkd",{"2":{"206":3,"208":1}}],["d表示的输出通道的数量",{"2":{"248":1}}],["d×nd",{"2":{"248":1}}],["d=64",{"2":{"223":1,"312":1}}],["dnf",{"2":{"817":1}}],["dn",{"2":{"223":2,"312":2}}],["dmodeld",{"2":{"208":1}}],["dvd",{"2":{"208":2}}],["d​i+1​​的递推关系式求解出来即可",{"2":{"845":1}}],["d​​",{"2":{"647":1,"648":4}}],["d​​​​k​​",{"2":{"640":2}}],["d​c​​≪d​h​​n​h​​",{"2":{"309":1}}],["d​model​​",{"2":{"208":1}}],["d​v​​",{"2":{"208":1}}],["d​q​​",{"2":{"208":1}}],["d​k​​",{"2":{"206":3,"208":1}}],["dqd",{"2":{"208":1}}],["drf",{"2":{"889":2}}],["dry",{"2":{"497":2}}],["drop",{"2":{"726":1}}],["dropblock",{"0":{"348":1},"2":{"347":1}}],["dropconnect的思想也很简单",{"2":{"347":1}}],["dropconnet",{"0":{"347":1}}],["dropout=dropout",{"2":{"499":1}}],["dropout=0",{"2":{"498":2,"500":3}}],["dropout=none",{"2":{"215":1}}],["dropout2",{"2":{"497":4,"513":2}}],["dropout1",{"2":{"497":4,"513":2}}],["dropout掩码",{"2":{"378":1}}],["dropout实现方法很简单",{"2":{"346":1}}],["dropout指在训练神经网络过程中随机丢掉一部分神经元来减少神经网络复杂度",{"2":{"346":1}}],["dropout",{"0":{"114":1},"2":{"114":1,"126":1,"215":2,"347":1,"369":6,"375":1,"380":1,"480":1,"497":4,"498":8,"499":12,"500":20,"513":2}}],["droupout",{"0":{"346":1}}],["driver",{"2":{"71":1,"73":1,"726":2}}],["don",{"2":{"894":1}}],["doccano",{"2":{"885":1,"886":1}}],["doctype",{"2":{"726":2}}],["docker下的doccano添加普通用户",{"0":{"883":1},"1":{"884":1,"885":1,"886":1,"887":1,"888":1,"889":1}}],["docker技术",{"2":{"832":1}}],["docker",{"2":{"716":1,"868":1,"885":2}}],["docs",{"2":{"556":1}}],["docstr",{"2":{"441":2}}],["doc",{"2":{"496":2,"636":1}}],["double",{"2":{"445":1,"496":2,"706":1}}],["dout",{"2":{"50":2}}],["domains",{"0":{"898":1},"1":{"899":1,"900":1,"901":1},"2":{"444":1}}],["do",{"2":{"226":2,"333":1,"556":1,"636":2,"706":1,"894":1}}],["dot",{"0":{"198":1},"1":{"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":1,"206":1},"2":{"203":1,"206":1,"215":1,"445":1,"498":1,"500":1}}],["dots",{"2":{"161":2,"194":3,"245":2}}],["does",{"2":{"99":1,"451":2}}],["downblock",{"2":{"609":1}}],["downsample",{"2":{"81":2}}],["download=true",{"2":{"497":1,"555":1,"580":1}}],["download",{"2":{"74":1,"75":1,"555":1,"584":1,"586":1}}],["digital",{"2":{"839":1}}],["digamma",{"2":{"445":2}}],["diffsettings",{"2":{"889":1}}],["diffusion中u",{"2":{"610":1}}],["diffusion",{"0":{"593":1,"600":1},"1":{"594":1,"595":1,"596":1,"597":1,"598":1,"599":1,"601":1,"602":1,"603":1},"2":{"610":1,"612":1,"671":1}}],["diffusers",{"2":{"592":1}}],["diff",{"2":{"445":1}}],["differential",{"2":{"839":1}}],["differentiable",{"2":{"510":1}}],["different",{"2":{"217":1,"303":1,"444":1,"499":1,"571":1,"581":1,"897":2}}],["difference",{"2":{"29":1,"444":1}}],["diagflat",{"2":{"445":1}}],["diagonal",{"2":{"445":9}}],["diag",{"2":{"445":2}}],["dialogue",{"2":{"188":1}}],["disables",{"2":{"497":2}}],["disable",{"2":{"496":2,"509":4}}],["disabled",{"2":{"441":1}}],["distribute",{"2":{"671":1}}],["distributed",{"0":{"587":1},"1":{"588":1,"589":1},"2":{"445":1,"587":2,"588":1,"589":2,"590":8}}],["distillation",{"2":{"619":1}}],["distilbert",{"2":{"619":2}}],["distance",{"2":{"606":1}}],["dist",{"2":{"445":1,"588":2,"589":4,"590":8}}],["dispatch",{"2":{"441":2,"444":2}}],["directx",{"2":{"857":1}}],["directional",{"2":{"619":1}}],["directory>",{"2":{"727":2}}],["directory>src",{"2":{"727":2}}],["directory",{"2":{"580":1}}],["directed",{"2":{"447":1}}],["dir=",{"2":{"556":1}}],["dir",{"2":{"441":1,"496":1,"552":4,"578":1,"590":2,"636":1,"742":5}}],["dict的形式返回优化器的状态",{"2":{"509":1}}],["dict的键必须与该模块的torch",{"2":{"496":1}}],["dict调用该钩子",{"2":{"509":1}}],["dict调用之前执行预处理操作",{"2":{"496":1,"509":1}}],["dict函数返回的键完全匹配",{"2":{"496":1}}],["dict复制到当前模块及其子模块",{"2":{"496":1}}],["dict复制到当前模块",{"2":{"496":1}}],["dict方法之后运行",{"2":{"496":1}}],["dict将返回相同的对象",{"2":{"496":1}}],["dict之后",{"2":{"509":1}}],["dict之后被调用",{"2":{"509":1}}],["dict之后调用",{"2":{"496":1}}],["dict之前对其进行后处理",{"2":{"509":1}}],["dict之前被调用",{"2":{"509":1}}],["dict之前",{"2":{"496":1,"509":1}}],["dict中对应的张量",{"2":{"496":1}}],["dict中保存的元数据作为local",{"2":{"496":1}}],["dict中的每个子模块上调用",{"2":{"496":1}}],["dict中的每个子模块上调用此方法",{"2":{"496":1}}],["dict中",{"2":{"496":1}}],["dict",{"2":{"440":1,"490":25,"493":1,"496":26,"504":2,"507":1,"508":12,"509":36,"514":1,"515":1,"522":4,"523":4,"529":4}}],["divergence",{"2":{"659":1}}],["divisible",{"2":{"498":1,"499":1,"500":1}}],["divide",{"2":{"445":12}}],["div",{"2":{"108":1,"443":1,"445":2,"634":1}}],["dim为64",{"2":{"608":1}}],["dim0",{"2":{"445":5}}],["dims",{"2":{"445":9}}],["dim2",{"2":{"445":4}}],["dim1",{"2":{"445":9}}],["dimv",{"2":{"444":1}}],["dimi",{"2":{"444":1}}],["dim=3",{"2":{"499":1}}],["dim=",{"2":{"498":1,"500":1,"649":1}}],["dim=0",{"2":{"441":1}}],["dim=none",{"2":{"441":3}}],["dim=1",{"2":{"105":1,"107":1,"112":1,"129":1,"497":3,"513":1,"632":1,"633":2,"634":3}}],["dim结尾的维度被扁平化",{"2":{"107":1}}],["dim开头且以end",{"2":{"107":1}}],["dim或end",{"2":{"107":1}}],["dimension从原来的768变成了1024",{"2":{"608":1}}],["dimension",{"2":{"99":1,"106":1,"223":1,"312":1,"445":1,"648":1}}],["dimensions",{"2":{"99":1,"440":1,"499":1}}],["dim",{"2":{"87":3,"107":1,"215":1,"436":1,"441":2,"444":6,"445":171,"498":6,"499":17,"500":6,"649":14}}],["dilation=",{"2":{"80":1}}],["dilation",{"2":{"80":1}}],["dilated",{"0":{"60":1}}],["dx",{"2":{"50":1,"121":2}}],["dynamo",{"0":{"571":1},"2":{"509":4,"571":2}}],["dynamic",{"0":{"893":1},"2":{"333":1,"448":1,"559":1,"893":1}}],["dy​l−1​​",{"2":{"248":1}}],["dyl−1e",{"2":{"248":1}}],["dy",{"2":{"50":3,"248":1}}],["dw1",{"2":{"50":2}}],["dw2",{"2":{"50":2}}],["dw",{"2":{"50":3,"781":1}}],["d",{"2":{"29":1,"200":1,"206":1,"209":7,"215":2,"223":3,"226":10,"227":1,"309":4,"312":3,"315":1,"317":1,"338":1,"440":1,"498":38,"500":51,"640":5,"647":10,"648":10,"780":1,"781":1,"784":1,"823":2,"827":6,"849":2}}],["dfun",{"2":{"26":4}}],["deel",{"2":{"874":1}}],["deepcopy",{"2":{"430":1,"441":1}}],["deepseek",{"0":{"667":1,"668":1,"669":1,"670":1},"2":{"307":1,"308":2,"671":1}}],["deepwise",{"0":{"58":1}}],["deep",{"0":{"671":1},"2":{"4":1,"6":1,"75":1,"271":1,"421":1,"422":1,"436":1,"441":1,"671":3,"891":1,"896":1,"901":1,"905":2}}],["debian",{"2":{"770":1,"772":1}}],["debug",{"2":{"636":1}}],["deberta",{"2":{"619":3}}],["denoiser",{"0":{"599":1}}],["density",{"2":{"445":2}}],["densenet201",{"2":{"590":1}}],["densenet169",{"2":{"590":1}}],["densenet161",{"2":{"590":1}}],["densenet121",{"2":{"590":1}}],["dense",{"2":{"441":1,"444":7,"445":9}}],["delete>",{"2":{"733":1}}],["deleteuser",{"2":{"733":3}}],["delete",{"0":{"733":1},"2":{"733":2}}],["delattr",{"2":{"496":1}}],["delta",{"2":{"47":1,"249":11,"258":1,"287":1,"840":10}}],["deltaδ",{"2":{"29":1,"249":1}}],["dependency>",{"2":{"726":4}}],["depth",{"2":{"448":1}}],["deprecation",{"2":{"441":1}}],["derivatives",{"2":{"446":1}}],["desktop",{"2":{"909":1}}],["desktop安装linux镜像",{"2":{"815":1}}],["designed",{"2":{"896":1}}],["desired",{"2":{"556":2,"585":1}}],["dest",{"2":{"823":2}}],["destination=none",{"2":{"496":1}}],["destination",{"2":{"445":4,"496":6}}],["description=",{"2":{"497":1}}],["descent在内存使用方面更有效率",{"2":{"262":1}}],["descent在大规模数据集上具有一定的优势",{"2":{"262":1}}],["descent的学习率可以根据需要进行调整",{"2":{"262":1}}],["descent的梯度估计具有更小的抖动",{"2":{"262":1}}],["descent的参数更新速度较慢",{"2":{"262":1}}],["descent的参数更新速度更快",{"2":{"262":1}}],["descent",{"0":{"414":1},"2":{"258":1,"260":1,"261":1,"262":1,"302":1,"545":1,"546":1}}],["descending",{"2":{"445":7}}],["descend",{"0":{"257":1,"260":1,"261":1},"1":{"258":1,"259":1,"260":1,"261":1,"262":1},"2":{"50":1}}],["detection",{"2":{"897":1}}],["det",{"2":{"445":1}}],["detached",{"2":{"441":1}}],["detach",{"0":{"452":1},"2":{"441":4,"445":2,"452":1,"493":6}}],["dequantize",{"2":{"445":1}}],["deg2rad",{"2":{"445":2}}],["developed",{"2":{"891":1}}],["developers",{"2":{"423":1}}],["development",{"2":{"705":1,"726":2}}],["device=freqs",{"2":{"649":1}}],["device=device",{"2":{"634":5}}],["device=original",{"2":{"595":1}}],["device设置",{"2":{"497":1}}],["device类型",{"2":{"496":1}}],["device",{"0":{"434":1},"2":{"74":1,"434":6,"436":3,"440":2,"441":1,"443":4,"444":3,"445":33,"496":10,"497":17,"499":4,"509":2,"511":3,"519":2,"595":3,"634":2,"636":1,"649":1}}],["dec",{"2":{"500":4}}],["decimals",{"2":{"445":2}}],["decays",{"2":{"585":1}}],["decay或cosine",{"2":{"398":1}}],["decay",{"2":{"281":2,"299":1,"398":1,"503":1,"590":2}}],["decomposition",{"2":{"441":1}}],["decoupled",{"2":{"299":1}}],["decode",{"2":{"634":1}}],["decoderlayer",{"2":{"498":3,"500":3}}],["decoder其实是一种条件语言模型",{"2":{"180":1}}],["decoder的预训练",{"0":{"180":1}}],["decoder即使遇到了end标识也不会结束",{"2":{"179":1}}],["decoder就可以快速步入正轨",{"2":{"178":1}}],["decoder结构中",{"2":{"173":1}}],["decoder",{"0":{"169":1,"171":1,"498":1,"620":1,"621":1},"2":{"168":2,"169":1,"171":3,"172":2,"180":1,"191":1,"216":2,"217":2,"303":2,"329":1,"498":2,"500":5,"616":2,"620":7,"621":8}}],["decoder模型",{"2":{"165":1}}],["decoding",{"0":{"182":1},"1":{"183":1,"184":1,"185":1,"186":1},"2":{"183":1,"190":1,"217":1,"303":1}}],["deconvolution",{"0":{"61":1}}],["dead",{"2":{"122":1}}],["demo",{"0":{"500":1},"2":{"50":4,"302":1,"332":1,"433":1,"434":1,"444":1,"450":2,"455":2,"456":3,"460":1,"484":1,"487":1,"489":1,"514":1,"515":1,"518":1,"519":1,"522":1,"523":1,"568":1,"569":1,"570":1,"671":1,"888":1,"889":1}}],["defaultdict",{"2":{"508":2}}],["defaults",{"2":{"506":1,"507":1,"508":2,"509":2}}],["default=",{"2":{"726":1}}],["default=false",{"2":{"497":4}}],["default=0",{"2":{"497":1}}],["default=10",{"2":{"497":1}}],["default=1000",{"2":{"497":1}}],["default=1",{"2":{"497":3}}],["default=64",{"2":{"497":1}}],["default",{"2":{"464":1,"497":6,"580":1,"581":1,"585":1,"590":7,"726":3}}],["defined",{"2":{"440":1}}],["define",{"2":{"274":1,"904":1}}],["deformable",{"0":{"62":1},"1":{"63":1,"64":1}}],["def",{"2":{"26":3,"50":6,"86":1,"87":1,"430":1,"441":55,"443":75,"444":27,"445":731,"455":1,"456":2,"457":1,"458":2,"487":6,"493":2,"494":3,"495":3,"496":72,"497":7,"498":8,"499":6,"500":11,"505":1,"509":23,"511":1,"513":2,"518":1,"529":1,"552":6,"555":1,"556":5,"567":6,"568":1,"570":1,"571":3,"581":1,"632":1,"649":4,"799":1,"904":2}}],["+1y​i​​+1​​",{"2":{"845":1}}],["+1m",{"2":{"765":1}}],["+x",{"2":{"644":1}}],["+p",{"2":{"643":1,"644":2}}],["+r",{"2":{"643":2}}],["+t",{"2":{"628":4}}],["+=",{"2":{"497":2,"567":3,"632":4,"633":1,"635":6,"827":1,"957":2}}],["+var",{"2":{"247":4,"248":6}}],["+⋯+var",{"2":{"247":2}}],["+norm",{"2":{"406":1}}],["+n",{"2":{"245":2}}],["+e​m",{"2":{"225":1,"313":1}}],["+e^",{"2":{"225":1,"313":1}}],["+em",{"2":{"225":1,"313":1}}],["+e",{"2":{"41":1,"45":1}}],["+b",{"2":{"40":1,"45":1,"248":1,"453":2,"454":1}}],["+w",{"2":{"40":1,"45":2}}],["+2",{"2":{"26":1}}],["+",{"0":{"443":2,"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"26":3,"40":2,"41":4,"45":3,"46":1,"47":14,"50":8,"86":4,"87":4,"88":2,"89":2,"121":2,"126":1,"128":2,"138":1,"196":1,"227":1,"232":1,"245":3,"247":2,"248":6,"317":1,"322":1,"323":1,"327":1,"339":1,"403":1,"406":1,"415":1,"416":2,"417":3,"418":3,"419":4,"433":4,"436":1,"440":1,"445":2,"451":2,"456":3,"457":1,"460":2,"484":6,"493":5,"498":2,"499":3,"500":8,"545":1,"546":2,"556":2,"571":1,"577":1,"581":2,"595":1,"606":2,"633":3,"634":6,"635":2,"639":1,"644":1,"649":2,"706":1,"719":1,"753":1,"774":1,"780":2,"783":1,"784":2,"790":2,"794":3,"816":1,"827":2,"829":2,"839":1,"840":2,"841":1,"843":2,"849":1,"913":1}}],["ubuntu等",{"2":{"909":1}}],["ubuntu版本",{"2":{"817":2}}],["uber",{"2":{"900":1}}],["u+x",{"2":{"746":1}}],["ulmfit",{"2":{"616":1}}],["utilize",{"2":{"900":1}}],["util",{"2":{"726":1}}],["utils",{"2":{"497":3,"543":1,"544":1,"553":1,"555":1,"575":2,"580":3}}],["utf",{"2":{"726":2}}],["utf8",{"2":{"26":1}}],["usr",{"2":{"739":1}}],["usage",{"0":{"590":1}}],["us",{"2":{"556":1}}],["using",{"2":{"490":1,"544":1,"556":1,"571":1,"584":1,"586":1,"590":1}}],["useunicode=true",{"2":{"726":1}}],["useless",{"2":{"586":1}}],["useful",{"2":{"586":1,"590":1,"891":1}}],["usessl=true",{"2":{"726":1}}],["uses",{"2":{"537":1,"538":1,"539":1,"540":1,"542":1,"548":1,"549":1,"556":1,"893":1}}],["usermod",{"2":{"763":1}}],["usermodbashsudo",{"2":{"763":1}}],["usermapper",{"2":{"726":6,"730":3,"731":2,"732":2,"733":2}}],["useradd",{"2":{"763":1}}],["useraddbashsudo",{"2":{"763":1}}],["user>",{"2":{"726":3,"730":1}}],["username",{"2":{"726":1,"730":5,"888":2,"889":2}}],["user",{"2":{"483":1,"581":1,"726":7,"730":13,"731":8,"732":8,"733":1,"742":1,"746":2,"763":1,"816":1,"827":3,"843":1,"905":1}}],["users",{"2":{"444":1,"726":3,"843":1,"905":1}}],["use",{"0":{"586":1,"896":1,"902":1},"1":{"903":1,"904":1},"2":{"441":1,"444":1,"458":1,"497":5,"556":1,"585":1,"587":1,"590":5,"726":1,"891":1}}],["used",{"2":{"337":1,"581":1,"590":1,"634":1,"895":1}}],["urls",{"2":{"799":2}}],["url",{"2":{"421":1,"588":1,"589":2,"590":5,"726":1,"799":12}}],["uv",{"2":{"309":1,"445":1}}],["uk",{"2":{"309":1}}],["u",{"2":{"245":1,"252":3,"545":1,"753":1,"780":1,"783":1}}],["upgrade",{"2":{"770":1}}],["up",{"2":{"497":1,"581":1,"590":1,"677":1}}],["upper",{"2":{"445":4}}],["uptraining",{"0":{"220":1,"306":1},"2":{"220":3,"306":3}}],["updates",{"2":{"904":1}}],["update>",{"2":{"732":1}}],["updateuser",{"2":{"732":3}}],["update",{"0":{"732":1},"2":{"156":2,"441":1,"487":2,"497":2,"732":2,"770":2,"817":2,"894":1,"904":1}}],["upsample",{"2":{"81":2}}],["understanding",{"2":{"619":2}}],["underlying",{"2":{"441":1}}],["unclip",{"2":{"608":1}}],["unet",{"0":{"603":1},"2":{"608":1}}],["unexpected",{"2":{"496":1,"556":1}}],["unequenze",{"0":{"102":1}}],["unequal",{"2":{"80":2,"81":1}}],["unfold",{"2":{"445":1}}],["unflatten",{"2":{"441":1,"445":2}}],["unbind",{"2":{"445":2}}],["unbiased",{"2":{"445":6}}],["untyped",{"2":{"445":1}}],["untypedstorage",{"2":{"445":3}}],["unsetmultipleprimaryemails",{"2":{"889":1}}],["unsafe",{"2":{"445":3}}],["unstable",{"2":{"409":4}}],["unsqueeze",{"2":{"122":1,"445":2,"498":1,"595":2,"633":4,"634":13}}],["universities",{"2":{"901":1}}],["universal",{"2":{"616":1}}],["unimplemented",{"2":{"496":1}}],["uniform",{"2":{"445":1}}],["unified",{"2":{"74":1,"644":1}}],["union",{"2":{"443":13,"444":5,"445":260,"496":14,"509":1}}],["unique",{"2":{"441":2}}],["unitriangular",{"2":{"445":1}}],["units",{"0":{"125":1},"2":{"122":1}}],["unit",{"0":{"126":1,"154":1},"1":{"155":1,"156":1,"157":1},"2":{"10":1,"74":2,"122":1,"124":3,"496":1}}],["cj",{"2":{"726":1}}],["cis=freqs",{"2":{"649":1}}],["cis",{"2":{"649":10}}],["cqc",{"2":{"606":1}}],["cycle的实现",{"2":{"544":1}}],["cycle学习率策略在每个批次之后改变学习率",{"2":{"544":1}}],["cycle学习率策略设置每个参数组的学习率",{"2":{"544":1}}],["cycle策略将学习率从初始学习率逐渐退火到最大学习率",{"2":{"544":1}}],["cycle",{"2":{"543":1,"581":1}}],["cyclical",{"2":{"543":1}}],["cycliclr",{"0":{"543":1},"2":{"543":1}}],["ckpt",{"2":{"522":2,"523":2}}],["ck×k×c",{"2":{"248":1}}],["ccol",{"2":{"445":1}}],["csv",{"2":{"552":1,"556":2}}],["csr",{"2":{"444":1,"445":2}}],["csrc",{"2":{"440":1}}],["csc",{"2":{"444":1,"445":1}}],["c++",{"2":{"442":2,"822":1}}],["cd",{"2":{"613":1,"636":2,"742":4}}],["cdata",{"2":{"440":1}}],["cdots+var",{"2":{"247":1}}],["cdots+x",{"2":{"247":1}}],["cdot",{"2":{"127":1,"245":1,"248":1,"606":1}}],["ctrl",{"2":{"620":2,"753":1,"774":1,"780":2,"783":1,"784":2,"790":2}}],["ctx",{"2":{"458":4}}],["ctypes",{"2":{"430":2,"436":1}}],["ctkvc",{"2":{"309":1}}],["cutting",{"2":{"899":1}}],["cutmix就是将一部分区域cut掉但不填充0像素而是随机填充训练集中的其他数据的区域像素值",{"2":{"344":1}}],["curlbashcurl",{"2":{"761":1}}],["cur",{"2":{"546":1}}],["currently",{"2":{"587":1}}],["current",{"2":{"405":1,"441":1,"497":1,"545":2,"590":1,"633":2,"634":1,"904":1}}],["customimagedataset",{"2":{"552":1}}],["custom",{"2":{"488":2}}],["customer",{"0":{"458":1,"488":1}}],["cumsum",{"2":{"445":4}}],["cumprod",{"2":{"445":4,"595":5}}],["cummin",{"2":{"445":4}}],["cummax",{"2":{"445":4}}],["cudnn不是必须的",{"2":{"75":1}}],["cudnn",{"0":{"75":1},"2":{"75":2}}],["cuda默认为true",{"2":{"496":1}}],["cuda",{"0":{"74":1},"2":{"74":2,"75":1,"434":3,"441":3,"444":1,"445":2,"496":1,"497":11,"509":1,"510":1,"511":2,"519":1,"581":2,"802":1}}],["cpc",{"2":{"606":1}}],["cp+cq−2cpcq",{"2":{"606":1}}],["cpp",{"2":{"329":5,"440":1}}],["cp还可以与不同的注意力变体一起工作",{"2":{"328":1}}],["cp可以与tp",{"2":{"328":1}}],["cp可以更好地解决这些问题",{"2":{"328":1}}],["cp类似于环注意力",{"2":{"328":1}}],["cp需要跨gpu进行额外的allgather以收集完整的kv序列",{"2":{"328":1}}],["cp沿着序列维度分割网络输入和所有激活",{"2":{"328":1}}],["cp",{"2":{"328":3,"743":1}}],["cpu适合串行计算",{"2":{"75":1}}],["cpu",{"2":{"74":1,"338":1,"434":2,"444":1,"445":2,"496":2,"497":1,"511":1,"581":1,"822":1,"895":1}}],["c​q​​",{"2":{"606":1}}],["c​p​​",{"2":{"606":1}}],["c​p​​+c​q​​−2√​c​p​​c​q​​​​​",{"2":{"606":1}}],["c​t​kv​​",{"2":{"309":1}}],["c​l​​=d​l−1​​",{"2":{"248":1}}],["c×d",{"2":{"309":1}}],["c×lc",{"2":{"249":1}}],["c×​n​^​​",{"2":{"249":1}}],["c×n^c",{"2":{"249":1}}],["cnclude",{"2":{"823":1}}],["cn",{"2":{"661":1,"663":1,"664":1,"665":1,"667":1,"668":1,"669":1,"670":1}}],["cn=k×k×c",{"2":{"248":1}}],["cnn等模型",{"2":{"638":1}}],["cnn网络中全连接层占据了很大的参数",{"2":{"95":1}}],["cnn",{"2":{"21":1,"51":2,"497":1}}],["chown",{"2":{"746":2}}],["cholesky",{"2":{"445":3}}],["chmod",{"2":{"746":3}}],["chrome",{"2":{"581":1}}],["chris",{"2":{"420":1}}],["christopher",{"2":{"350":1,"421":1}}],["child",{"2":{"957":5}}],["children",{"2":{"496":2}}],["chinese",{"2":{"613":1,"614":1}}],["china",{"2":{"613":1}}],["chinchilla",{"2":{"385":1}}],["chunks",{"2":{"445":2}}],["chunk",{"2":{"445":2}}],["chunked",{"0":{"329":1},"2":{"329":1}}],["checkout",{"2":{"613":1,"636":1}}],["check",{"2":{"456":1,"497":1,"509":1,"889":3}}],["checkpoint",{"0":{"220":1,"306":1},"2":{"220":2,"306":2,"522":2,"523":5,"590":1}}],["chen对文档演讲内容提出的宝贵建议",{"2":{"420":1}}],["chainedscheduler",{"0":{"548":1},"2":{"548":1}}],["characters",{"2":{"799":1}}],["characterencoding=utf8",{"2":{"726":1}}],["charset=utf8",{"2":{"726":1}}],["char",{"2":{"445":1,"706":1,"823":1,"827":1}}],["chalf",{"2":{"445":1}}],["chatgpt",{"2":{"694":1}}],["chat",{"2":{"337":2}}],["channel",{"2":{"441":2,"445":3}}],["channels",{"2":{"89":3}}],["changing",{"2":{"106":1,"113":1}}],["changepassword",{"2":{"889":1}}],["change",{"2":{"99":1,"893":1}}],["crud操作",{"0":{"728":1},"1":{"729":1,"730":1,"731":1,"732":1,"733":1,"734":1}}],["critical",{"2":{"681":1}}],["criterion",{"2":{"500":2,"546":1,"567":2,"568":2,"904":2}}],["criteration",{"2":{"484":2,"487":3}}],["crawl",{"2":{"619":1}}],["crf的viterbi解码",{"0":{"630":1}}],["crf的作用就是在所有可能的路径中",{"2":{"624":1}}],["crf会据此解码出一串标签序列",{"2":{"624":1}}],["crf",{"0":{"623":1,"625":1,"629":1},"1":{"624":1,"625":1,"626":2,"627":2,"628":2,"629":1,"630":2},"2":{"613":1,"630":1}}],["crop",{"2":{"556":5}}],["crow",{"2":{"445":1}}],["crossattnmidblock",{"2":{"609":1}}],["crossattndownblock",{"2":{"609":2}}],["crossentropyloss",{"2":{"487":1,"500":1,"568":1,"904":1}}],["cross",{"0":{"213":1},"2":{"445":1,"454":1,"500":3,"608":1}}],["creates",{"2":{"904":1}}],["createsuperuser的使用前面讲过了",{"2":{"889":1}}],["createsuperuser",{"2":{"888":2,"889":1}}],["createcachetable",{"2":{"889":1}}],["create",{"2":{"441":1,"556":1,"726":1,"809":1,"889":6,"904":1}}],["crelu",{"2":{"122":1}}],["clr",{"2":{"543":1}}],["close",{"2":{"579":1,"580":1,"726":1,"730":1,"731":1,"732":1,"733":1}}],["closure",{"2":{"505":4,"509":3}}],["clone可以clone",{"2":{"862":1}}],["clone",{"2":{"444":1,"445":1,"592":1,"613":1,"636":1}}],["clearsessions",{"2":{"889":1}}],["clear",{"2":{"445":1}}],["clip−score",{"2":{"605":2}}],["clip",{"0":{"597":1,"601":1,"605":1},"2":{"445":4,"605":3,"608":1,"643":6}}],["cls",{"2":{"441":1,"444":1,"445":3}}],["clamp",{"2":{"445":12}}],["classes",{"2":{"556":1}}],["classtorch",{"2":{"506":1}}],["classifier",{"2":{"504":2}}],["classification",{"2":{"188":1,"616":1,"897":3}}],["classmethod",{"2":{"441":1}}],["class",{"0":{"506":1},"1":{"507":1,"508":1,"509":1},"2":{"440":2,"458":1,"493":1,"494":1,"495":1,"497":2,"498":4,"499":3,"500":5,"509":1,"513":1,"552":1,"556":4,"567":2,"649":1,"706":1,"726":4,"730":1,"731":1,"732":1,"733":1,"904":1}}],["cla",{"2":{"423":2}}],["cl=dl−1c",{"2":{"248":1}}],["clustering",{"2":{"188":1}}],["ceil",{"2":{"445":2}}],["cell",{"0":{"146":1,"149":1,"152":1},"1":{"147":1,"148":1,"149":1,"150":1,"151":1},"2":{"145":2,"146":2}}],["centos8及以上",{"2":{"817":1}}],["centos7及以下",{"2":{"817":1}}],["center",{"2":{"445":1}}],["centered激活函数指的是在激活函数的输出中心值为零",{"2":{"120":1}}],["centered",{"2":{"120":1,"122":1}}],["central",{"2":{"74":1}}],["c=",{"2":{"105":1}}],["calculate",{"2":{"904":1}}],["calculates",{"2":{"894":1}}],["calculated",{"2":{"827":1}}],["calculation",{"0":{"894":1}}],["calculations",{"2":{"893":1}}],["called",{"2":{"490":1,"547":1,"556":1,"581":2,"894":1}}],["call",{"2":{"459":2,"490":4,"496":7,"556":4}}],["calling",{"2":{"444":1,"445":1,"458":1}}],["callable",{"2":{"440":1,"445":6,"490":9,"496":11,"509":8,"552":1,"556":2}}],["case",{"2":{"556":1,"586":1,"634":1}}],["cast",{"2":{"508":1}}],["capture",{"2":{"509":1}}],["caption",{"2":{"164":1}}],["cauchy",{"2":{"445":1}}],["causal",{"2":{"322":1,"616":1}}],["cache填满",{"2":{"338":1}}],["cache张量存储在non",{"2":{"338":1}}],["cache张量之间的映射关系",{"2":{"338":1}}],["cache重用模式",{"2":{"337":1}}],["cache划分为块",{"2":{"333":1}}],["cache带来了重大挑战",{"2":{"333":1}}],["cache具有以下特点",{"2":{"333":1}}],["cache",{"0":{"230":1,"330":1,"337":1},"2":{"219":2,"230":1,"305":2,"330":1,"333":2,"337":7}}],["cat查看create",{"2":{"889":1}}],["catch",{"2":{"708":1,"726":1}}],["cat",{"2":{"104":2,"122":1,"743":1}}],["cat的别名",{"2":{"104":1}}],["candidate",{"2":{"634":2}}],["can",{"2":{"81":1,"556":3,"895":1,"896":1}}],["cvf",{"2":{"768":1}}],["cv",{"2":{"87":1,"344":1}}],["c",{"2":{"86":1,"87":1,"88":1,"89":2,"99":3,"226":9,"309":5,"338":1,"436":1,"440":1,"441":11,"457":1,"545":1,"556":2,"605":6,"606":4,"822":3,"827":2,"843":1}}],["courses",{"2":{"901":1}}],["counter",{"2":{"468":1}}],["count",{"2":{"445":3,"823":3}}],["counts=false",{"2":{"441":2}}],["co",{"2":{"613":1}}],["cov",{"2":{"445":1}}],["cosineannealingwarmrestarts",{"0":{"546":1},"2":{"546":2}}],["cosineannealinglr",{"0":{"545":1},"2":{"545":1}}],["cosh",{"2":{"445":2}}],["cos",{"2":{"445":2,"545":1,"571":1,"605":3,"640":1,"649":2}}],["cost",{"2":{"244":2}}],["coalesce",{"2":{"445":1}}],["coalesced",{"2":{"444":2,"445":1}}],["cookie",{"2":{"957":4}}],["coordinate",{"2":{"441":1,"444":1}}],["coo",{"2":{"441":2,"444":1}}],["copysign",{"2":{"445":4}}],["copy",{"2":{"436":1,"441":2,"445":9,"827":1}}],["collectstatic",{"2":{"889":1}}],["collaborate",{"2":{"220":1,"306":1}}],["column",{"2":{"633":2,"634":1,"636":3}}],["col",{"2":{"445":1}}],["color",{"2":{"344":1,"556":1}}],["corporations",{"2":{"900":1}}],["corpus",{"2":{"190":1,"613":1}}],["correct",{"2":{"497":4,"567":3}}],["correction",{"2":{"445":5}}],["corrcoef",{"2":{"445":1}}],["core",{"2":{"328":1,"895":1}}],["coderethan",{"2":{"799":1,"856":1,"860":1}}],["code",{"0":{"666":1},"2":{"312":1,"446":1,"482":1,"509":2,"556":1,"581":1,"721":1,"799":6,"893":2,"904":1}}],["coding",{"2":{"26":1}}],["com发送邮件",{"2":{"422":1}}],["com",{"2":{"421":1,"423":1,"584":1,"592":1,"613":1,"636":1,"721":1,"726":6,"730":3,"731":1,"732":1,"759":1,"761":1,"799":1}}],["community",{"2":{"905":1}}],["communicator",{"0":{"810":1}}],["commutative",{"2":{"52":1}}],["comm",{"2":{"808":2,"810":1,"823":9,"827":5}}],["commit",{"2":{"731":1,"732":1,"733":1}}],["common",{"2":{"619":1}}],["commonlooputils",{"2":{"387":1}}],["comprehend",{"2":{"901":1}}],["composed",{"2":{"556":1}}],["compose``",{"2":{"556":1}}],["compose",{"2":{"497":1,"556":4,"580":1}}],["compilemessages",{"2":{"889":1}}],["compile通过即时编译",{"2":{"565":1}}],["compile是最新的方法",{"2":{"565":1}}],["compile编译该模块的前向传播",{"2":{"496":1}}],["compiled",{"2":{"490":2}}],["compile",{"0":{"565":1,"571":1},"2":{"490":2,"496":2,"509":1,"571":3}}],["computing",{"2":{"797":1}}],["computation",{"0":{"893":1},"2":{"448":1,"893":1}}],["computational",{"2":{"447":1}}],["computes",{"2":{"904":1}}],["computer",{"2":{"895":1}}],["compute",{"2":{"74":1,"215":1,"445":1,"632":1,"633":2,"634":1,"904":1}}],["complex32",{"2":{"445":1}}],["complex",{"2":{"443":12,"444":2,"445":112,"649":2}}],["complexity",{"2":{"227":1,"317":1}}],["conclusion",{"0":{"905":1},"2":{"905":1}}],["concat之类的结构",{"2":{"246":1}}],["concatenate",{"2":{"220":1,"306":1,"498":1,"500":1}}],["concat",{"0":{"103":1,"104":1},"1":{"104":1,"105":1,"106":1,"107":1},"2":{"208":1,"209":1}}],["config",{"2":{"726":3}}],["configuration>",{"2":{"726":2}}],["configuration",{"2":{"726":1}}],["connector",{"2":{"726":1}}],["connection",{"2":{"499":1}}],["connect",{"2":{"487":1}}],["connect2",{"2":{"487":2}}],["connect1",{"2":{"487":4}}],["condition",{"2":{"445":2}}],["conditional",{"0":{"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"176":1,"180":1,"620":1}}],["conjugate",{"2":{"505":1}}],["conjugated",{"2":{"440":1}}],["conj",{"2":{"444":3,"445":5}}],["consuming",{"2":{"586":1}}],["const",{"2":{"823":1}}],["constantlr",{"0":{"539":1},"2":{"539":1,"548":1,"549":1}}],["constructed",{"2":{"447":1}}],["construction",{"2":{"444":1}}],["consecutive",{"2":{"441":1}}],["consistency",{"2":{"337":1}}],["cons",{"2":{"302":1}}],["continues",{"2":{"905":1}}],["contiguous",{"2":{"333":1,"338":2,"445":4,"498":1,"500":1}}],["contrastive",{"2":{"605":1}}],["contains",{"2":{"441":1}}],["containing",{"2":{"113":2}}],["contenttypes",{"2":{"889":2}}],["content",{"2":{"799":1}}],["contents=none",{"2":{"441":1}}],["context",{"0":{"328":1},"2":{"170":1,"171":1,"173":1,"326":5,"328":1,"636":2}}],["convnext",{"2":{"590":4}}],["conv3",{"2":{"497":2}}],["conv3d",{"2":{"55":1}}],["conv2",{"2":{"497":4,"513":2}}],["conv2d",{"0":{"80":1},"2":{"80":3,"81":1,"497":5,"513":2,"580":1}}],["conv1",{"2":{"497":4,"513":2,"580":2}}],["convert",{"2":{"556":2,"634":1}}],["converting",{"0":{"220":1,"306":1}}],["convergence",{"2":{"544":1}}],["conventional",{"2":{"444":1}}],["convtranspose2d",{"0":{"81":1},"2":{"81":3}}],["conv的权重",{"2":{"52":1}}],["convolutions",{"0":{"59":1}}],["convolution",{"0":{"57":1,"58":1,"60":2,"61":1,"62":1,"79":1},"1":{"63":1,"64":1,"80":1,"81":1},"2":{"51":1,"193":1,"671":1}}],["convolutional",{"2":{"51":2}}],["con",{"2":{"51":1}}],["c对激活函数z的偏导数",{"2":{"36":1}}],["函数y",{"2":{"659":1}}],["函数时",{"2":{"509":1}}],["函数时触发",{"2":{"443":1}}],["函数或在交互式环境中直接输出对象时被调用",{"2":{"496":1}}],["函数计算输出之后被调用",{"2":{"496":1}}],["函数之前被调用",{"2":{"496":1}}],["函数内获取状态前执行",{"2":{"490":1}}],["函数内获取状态后执行",{"2":{"490":1}}],["函数初始化",{"2":{"488":1}}],["函数有一个参数",{"2":{"457":1}}],["函数",{"2":{"441":1,"457":2,"472":1,"496":1,"509":1,"548":1}}],["函数永远无法真正预测0",{"2":{"345":1}}],["函数和明确目标的最大似然学习可能永远不会收敛",{"2":{"345":1}}],["函数的模型",{"2":{"345":1}}],["函数中",{"2":{"148":2,"150":2}}],["函数传递",{"2":{"147":1}}],["函数当",{"2":{"122":1}}],["函数图如下",{"2":{"121":1}}],["函数得到了广泛的应用",{"2":{"121":1}}],["函数w",{"2":{"52":1}}],["函数x",{"2":{"52":1}}],["函数f沿负梯度方向减小",{"2":{"26":1}}],["函数f沿梯度方向增加",{"2":{"26":1}}],["函数如图下图右所示",{"2":{"9":1}}],["梯度清0",{"2":{"484":1,"497":1}}],["梯度模式",{"0":{"476":1},"1":{"477":1,"478":1,"479":1,"480":1}}],["梯度会计算",{"2":{"464":1}}],["梯度累加和清0",{"0":{"454":1}}],["梯度范数与步骤数量的关系图",{"2":{"410":1}}],["梯度范数",{"2":{"410":1}}],["梯度截断可以修复早期训练中出现的不稳定性",{"2":{"410":1}}],["梯度截断会变得非常有用",{"2":{"410":1}}],["梯度截断纠正早期训练不稳定性的图示",{"2":{"410":1}}],["梯度截断",{"0":{"410":1}}],["梯度计算的结果更加平滑",{"2":{"262":1}}],["梯度计算为例",{"2":{"43":1}}],["梯度估计的抖动减少",{"2":{"262":1}}],["梯度",{"2":{"249":1}}],["梯度缺变成了0",{"2":{"241":1}}],["梯度为",{"2":{"122":1}}],["梯度传播等",{"2":{"496":1}}],["梯度传播",{"2":{"120":1}}],["梯度求解",{"0":{"35":1}}],["梯度下降法三个变种",{"0":{"259":1},"1":{"260":1,"261":1,"262":1}}],["梯度下降法被广泛应用于训练模型",{"2":{"258":1}}],["梯度下降法概念",{"0":{"258":1}}],["梯度下降法代码展示",{"2":{"26":1}}],["梯度下降法效果展示",{"2":{"26":1}}],["梯度下降法",{"2":{"26":1,"258":1}}],["梯度下降算法简述",{"0":{"26":1}}],["梯度有一个非常重要的性质",{"2":{"26":1}}],["以后要常相守了",{"2":{"880":1}}],["以后还是随手关一关",{"2":{"878":1}}],["以人类可读格式显示文件大小",{"2":{"742":1}}],["以适应不同任意的距离",{"2":{"643":1}}],["以适应顺序试验中的多个这样的评估",{"2":{"391":1}}],["以控制生成文本的风格",{"2":{"620":1}}],["以控制参数更新的步长",{"2":{"262":1}}],["以更大的批次训练了更长的时间",{"2":{"619":1}}],["以更新权重来最小化损失函数",{"2":{"25":1}}],["以生成一个面向学术",{"2":{"617":1}}],["以取得更好的性能",{"2":{"616":1}}],["以取得最大化的预期利益",{"2":{"21":1}}],["以有监督学习的方式对预训练模型参数进行微调",{"2":{"616":1}}],["以10",{"2":{"608":1}}],["以sd",{"2":{"608":4}}],["以提供确切的间隔来反映在给定历元应该调用哪个调度器",{"2":{"549":1}}],["以提高调整效率",{"2":{"366":1}}],["以提高缓存命中率",{"2":{"337":1}}],["以提高自然语言处理系统的性能和效果",{"2":{"188":1}}],["以class",{"2":{"509":1}}],["以捕获静态图",{"2":{"496":1}}],["以捕捉source端和target端词与词之间的依赖关系",{"2":{"213":1}}],["以捕捉source端或target端自身的词与词之间的依赖关系",{"2":{"213":1}}],["以计算梯度",{"2":{"471":1}}],["以此来让我们获得远高于unstable",{"2":{"409":1}}],["以一个恒定的速率进行训练",{"2":{"409":1}}],["以一定概率随机屏蔽每一层中若干神经元",{"2":{"346":1}}],["以下经验法则对应于研究中试验次数的不同",{"2":{"400":1}}],["以下是你在学习过程中可以覆盖的重要主题和内容",{"2":{"707":1}}],["以下是作者的猜测",{"2":{"384":1}}],["以下是一些最常用的函数",{"2":{"808":1}}],["以下是一些常见的nlp任务",{"2":{"188":1}}],["以下是一些与零中心激活函数相关的考虑因素",{"2":{"120":1}}],["以支持离线分析",{"2":{"390":1}}],["以防止损失函数产生偏向",{"2":{"390":1}}],["以防止位置关注到后面的位置",{"2":{"197":1}}],["以实时监控其进度",{"2":{"390":1}}],["以实现真实的交互效果",{"2":{"857":1}}],["以实现良好的训练效果",{"2":{"380":1}}],["以实现加速",{"2":{"329":1}}],["以实现对内存访问的细粒度控制",{"2":{"222":1,"314":1}}],["以确保这些共用资源是被互斥获得使用",{"2":{"682":1}}],["以确保数据一致性",{"2":{"676":1}}],["以确保它们在长时间运行中仍然适用",{"2":{"383":1}}],["以确定哪种方法在特定的使用案例中效果更好",{"2":{"156":1}}],["以优化max",{"2":{"381":1}}],["以使模型达到最佳效果",{"2":{"381":1}}],["以使用尽可能大的调整预算进行最终的自动调整研究",{"2":{"379":1}}],["以使损失函数达到最优或接近最优",{"2":{"256":1}}],["以估计训练方差",{"2":{"378":1}}],["以改进搜索空间和",{"2":{"372":1}}],["以公平地比较目标超参数",{"2":{"371":1}}],["以充分满足以下三个要求",{"2":{"371":1}}],["以朝着实验目标取得进展",{"2":{"370":1}}],["以在有限的资源和耐心内获得最大的理解",{"2":{"383":1}}],["以在不同设置之间进行公平比较目标超参数",{"2":{"369":1}}],["以在非凸设定下效果更好",{"2":{"283":1}}],["以平衡资源成本与科学价值",{"2":{"368":1}}],["以避免给训练工作流增加不必要的复杂性",{"2":{"365":1}}],["以避免增加不必要的复杂度",{"2":{"365":1}}],["以获得更高的执行效率",{"2":{"559":1}}],["以获得更好的效果",{"2":{"381":1}}],["以获得适当数量的批归一化统计样本",{"2":{"394":1}}],["以获得",{"2":{"363":1}}],["以gpu小时计",{"2":{"360":1}}],["以帮助大众追求最佳方法",{"2":{"353":1}}],["以帮助调节网络",{"2":{"148":1}}],["以及如何实现",{"2":{"975":1}}],["以及生活感悟",{"2":{"881":1}}],["以及将模型的规模扩大",{"2":{"620":1}}],["以及图片尺寸在512x512以下的样本",{"2":{"608":1}}],["以及对应的label",{"2":{"552":1}}],["以及对研究的简短描述",{"2":{"393":1}}],["以及参数组中参数的参数id列表",{"2":{"509":1}}],["以及post",{"2":{"409":1}}],["以及它们的合理范围",{"2":{"379":1}}],["以及在训练后期使用过高的学习率",{"2":{"375":1}}],["以及我们在生产中重现最佳试验结果的能力",{"2":{"375":1}}],["以及选择自动搜索算法",{"2":{"370":1}}],["以及哪些超参数对其他变化相对不敏感",{"2":{"366":1}}],["以及",{"2":{"363":1,"400":1,"643":1}}],["以及很多困惑",{"2":{"353":1}}],["以及特定于该块的前馈网络",{"2":{"327":1}}],["以呈现更清晰的原理",{"2":{"353":1}}],["以启用共享",{"2":{"338":1}}],["以允许两个聊天会话共享系统提示",{"2":{"338":1}}],["以允许针对gemm目标fp8张量核心",{"2":{"325":1}}],["以动态扩展或缩减sp组",{"2":{"329":1}}],["以满足ttft",{"2":{"329":1}}],["以块对块的方式进行注意力和前馈计算来解释这一点",{"2":{"327":1}}],["以规避softmax和gemm之间的某些顺序依赖关系",{"2":{"325":1}}],["以进一步改进在新的gpu架构上的性能",{"2":{"325":1}}],["以进一步提高连接的稀疏性",{"2":{"123":1}}],["以减少推断期间kv缓存的大小",{"2":{"323":1}}],["以减少非矩阵乘法flop的数量",{"2":{"320":1}}],["以上内容是旧版本",{"2":{"862":1}}],["以上",{"2":{"320":1}}],["以卷积为例",{"2":{"248":1}}],["以保持网络中正向和反向数据流动",{"2":{"244":1}}],["以达到较好的性能",{"2":{"233":1}}],["以便与系统的编译器集成",{"2":{"822":1}}],["以便未来可以轻松地集成更复杂的方法",{"2":{"501":1}}],["以便在每个设备上进行并行计算",{"2":{"496":1}}],["以便在后向传播中快速重新计算注意力",{"2":{"222":1,"311":1}}],["以便根据输入的类型",{"2":{"441":1}}],["以便可以准确地测量模型的改进",{"2":{"391":1}}],["以便很容易生成整个模型的预测",{"2":{"391":1}}],["以便我们可以在训练结束时检查训练曲线",{"2":{"390":1}}],["以便我们更新建议",{"2":{"353":1}}],["以便于追溯模型检查点选择",{"2":{"390":1}}],["以便公平的比较不同的目标超参数值",{"2":{"370":1}}],["以便更大的batch",{"2":{"338":1}}],["以便计算梯度",{"2":{"24":1}}],["以概率1",{"2":{"179":1}}],["以概率p靠自己上一步的输入来预测",{"2":{"179":1}}],["以概率p随机将输入张量的某些元素置零",{"2":{"114":1}}],["以决定隐藏状态应携带哪些信息",{"2":{"150":1}}],["以找到最适合的激活函数",{"2":{"120":1}}],["以增加卷积神经网络的非线性表达能力",{"2":{"120":1}}],["以",{"0":{"46":1},"2":{"43":1}}],["允许精确控制进程间的数据传输",{"2":{"812":1}}],["允许根据一些验证指标动态减小学习率",{"2":{"532":1}}],["允许以",{"2":{"404":1}}],["允许使用不同的激活函数",{"2":{"369":1}}],["允许来自代价函数的信息通过网络向后流动",{"2":{"24":1}}],["允许计算机学习使用特征的同时",{"2":{"4":1}}],["θi",{"2":{"648":3}}],["θi=10000−2i",{"2":{"648":4}}],["θi=10000−2",{"2":{"647":1}}],["θ​i​​",{"2":{"648":3}}],["θ​i​​=10000​−2i",{"2":{"648":4}}],["θ​i​​=10000​−2",{"2":{"647":1}}],["θ​t+1​​=θ​t​​−α​t​​​√​v​t+1​​​​​+ϵ​​β​1​​m​t+1​​+",{"2":{"419":1}}],["θ​t+1​​=θ​t​​−α​t​​​√​v​t+1​​​​​+ϵ​​m​t+1​​​​b​t+1​​",{"2":{"418":1}}],["θ​t+1​​=θ​t​​−m​t+1​​",{"2":{"417":1}}],["θ​t+1​​=θ​t​​−η​t​​",{"2":{"416":1}}],["θ​t+1​​=θ​t​​−η​t​​v​t+1​​",{"2":{"415":1}}],["θ​t+1​​=θ​t​​−η​t​​∇l",{"2":{"414":1}}],["θ​t​​",{"2":{"414":1,"415":1,"416":2,"417":2,"418":2,"419":3}}],["θ=",{"2":{"647":2}}],["θt+1=θt−αtβ1mt+1+",{"2":{"419":1}}],["θt+1=θt−αtmt+1vt+1+ϵbt+1",{"2":{"418":1}}],["θt+1=θt−mt+1",{"2":{"417":1}}],["θt+1=θt−ηt",{"2":{"416":1}}],["θt+1=θt−ηtvt+1",{"2":{"415":1}}],["θt+1=θt−ηt∇l",{"2":{"414":1}}],["θt",{"2":{"414":1,"415":1,"416":2,"417":2,"418":2,"419":3}}],["θ表示要更新的参数向量或矩阵",{"2":{"258":1}}],["θ",{"2":{"24":2,"227":4,"258":4,"317":4,"659":4}}],["junit",{"2":{"719":1,"726":1}}],["just",{"2":{"556":1}}],["justin",{"2":{"350":1,"421":1}}],["jdbc就是一种持久化机制",{"2":{"722":1}}],["jdbc",{"2":{"719":1,"721":1,"726":3}}],["jdk",{"0":{"705":1},"2":{"705":1,"719":1}}],["jsp",{"2":{"710":1}}],["json",{"2":{"581":1}}],["jre",{"0":{"705":1},"2":{"705":2}}],["jx",{"2":{"644":1}}],["jvm",{"0":{"705":1},"2":{"705":2}}],["jv=pv",{"2":{"643":1}}],["jv",{"2":{"643":1}}],["jvr",{"2":{"643":2}}],["jvj=∑jai",{"2":{"643":1}}],["j​v​​=p​v​​",{"2":{"643":1}}],["j​v​​",{"2":{"643":3}}],["j​​",{"2":{"643":2,"644":2}}],["j​​v​j​​=∑​j​​a​i",{"2":{"643":1}}],["j​​=softmax",{"2":{"643":1}}],["j​k​​=p​k​​",{"2":{"643":1}}],["j​k​​",{"2":{"643":3}}],["jk=pk",{"2":{"643":1}}],["jk",{"2":{"643":2}}],["jkr",{"2":{"643":1}}],["j=softmax",{"2":{"643":1}}],["j=−log",{"2":{"181":2}}],["jpg",{"2":{"555":2}}],["join",{"2":{"552":1,"677":1,"799":1}}],["jit",{"0":{"563":1,"564":1,"568":1,"569":1},"2":{"525":1,"526":1,"563":1,"564":2,"568":2,"569":2}}],["jar",{"2":{"726":1}}],["java后端",{"2":{"833":1}}],["javamap",{"2":{"730":1}}],["javauser",{"2":{"730":1}}],["javaimport",{"2":{"726":2}}],["java对象",{"2":{"721":1}}],["javapublic",{"2":{"706":1,"726":2,"730":1}}],["java",{"0":{"706":1,"707":1,"708":1,"710":1},"1":{"708":1,"709":1,"710":1,"711":1,"712":1,"713":1,"714":1,"715":1,"716":1,"717":1,"718":1},"2":{"703":3,"705":9,"707":1,"708":1,"718":2,"719":1,"721":2,"726":4,"727":1,"730":1,"731":2,"732":2,"733":2}}],["javase",{"0":{"703":1,"704":1},"1":{"704":1,"705":2,"706":2},"2":{"703":1,"706":1}}],["jamieson",{"2":{"401":1}}],["jax",{"2":{"387":1}}],["j~",{"2":{"343":1}}],["j+1",{"2":{"245":2}}],["j",{"2":{"24":3,"129":2,"181":1,"226":14,"245":2,"258":1,"322":3,"323":3,"326":2,"338":1,"343":1,"350":1,"421":1,"590":2,"620":2,"633":4,"634":2,"643":30,"644":15,"780":1,"790":1,"953":1}}],["的饼干",{"2":{"961":1}}],["的思维方式",{"2":{"924":1}}],["的思想",{"0":{"202":1},"2":{"929":1}}],["的前一半",{"2":{"880":1}}],["的前置钩子函数",{"2":{"496":1,"509":1}}],["的途中当你正真有",{"2":{"878":1}}],["的孔子这里说的很重要",{"2":{"878":1}}],["的时候",{"2":{"878":1}}],["的时刻",{"2":{"216":1}}],["的理解",{"2":{"877":1}}],["的和",{"2":{"827":1}}],["的总和",{"2":{"827":1}}],["的具体路径或链接细节",{"2":{"822":1}}],["的实际效果等价于在编译命令中手动添加包含路径",{"2":{"822":1}}],["的实验来在最佳超参数点上获得最终模型",{"2":{"383":1}}],["的共内存和非共内存的通信模式不同",{"2":{"801":1}}],["的共轭转置视图",{"2":{"440":1}}],["的文件",{"2":{"765":1,"776":1}}],["的文本",{"2":{"645":1}}],["的目录",{"2":{"742":1}}],["的主目录",{"2":{"739":1}}],["的主要作用是将输入序列编码成一个上下文向量",{"2":{"170":1}}],["的程序片段",{"2":{"682":1}}],["的负方向进行函数空间的梯度下降",{"2":{"659":1}}],["的负半轴为软饱和区",{"2":{"125":1}}],["的负半轴下功夫改造",{"2":{"124":1}}],["的变化或偏离程度",{"2":{"659":1}}],["的规律呢",{"2":{"654":1}}],["的作用",{"0":{"651":1},"1":{"652":1,"653":1,"654":1,"655":1,"656":1,"657":1}}],["的选择上",{"2":{"648":1}}],["的高效计算",{"0":{"648":1}}],["的形式如下",{"2":{"646":1}}],["的形状为",{"2":{"249":1}}],["的形状如何推导",{"2":{"57":1}}],["的函数并进行截断的做法",{"2":{"644":1}}],["的是",{"2":{"644":1}}],["的标量",{"2":{"644":1}}],["的标准形式",{"2":{"284":1}}],["的向量",{"2":{"643":1}}],["的编码向量的第",{"2":{"640":1}}],["的单词",{"2":{"634":1}}],["的索引",{"2":{"634":1}}],["的topk",{"2":{"634":1}}],["的tensor",{"2":{"431":1}}],["的路径在前一个位置的标签索引",{"2":{"634":1}}],["的发生分数",{"2":{"633":1}}],["的产生",{"2":{"626":1}}],["的条件概率分布",{"2":{"626":1}}],["的条件下",{"2":{"626":1}}],["的预训练过程",{"2":{"621":1}}],["的预训练目标和架构进行调整以进一步提高性能",{"2":{"619":1}}],["的注意力层则只能访问输入中给定词语之前的词语",{"2":{"621":1}}],["的注意力层都可以访问初始输入句子中的所有单词",{"2":{"621":1}}],["的能力",{"2":{"620":1}}],["的语料",{"2":{"619":1}}],["的迁移学习方法",{"2":{"616":1}}],["的两个",{"2":{"609":1}}],["的概率随机drop掉text",{"2":{"608":1}}],["的概念表示在训练过程中通过逐渐减小学习率来改变模型的行为和性能",{"2":{"544":1}}],["的概念",{"2":{"160":1,"437":1,"723":1}}],["的东西",{"2":{"572":1}}],["的余弦退火学习率",{"2":{"546":1}}],["的保存和加载",{"0":{"511":1}}],["的浅拷贝",{"2":{"509":1}}],["的转换",{"2":{"509":1}}],["的状态",{"2":{"509":1}}],["的可迭代对象",{"2":{"507":1}}],["的将所有参数和缓冲区转换为",{"2":{"496":4}}],["的缓冲区",{"2":{"490":1}}],["的集合",{"2":{"490":1}}],["的位置实际上对应的是",{"2":{"644":1}}],["的位置编码",{"0":{"641":1}}],["的位置",{"2":{"482":1,"634":1}}],["的运行统计信息",{"2":{"480":1}}],["的叶张量的中间结果",{"2":{"475":1}}],["的叶张量才会将梯度累积到其",{"2":{"475":1}}],["的参数将使用学习率",{"2":{"504":1}}],["的参数将使用默认学习率",{"2":{"504":1}}],["的参数",{"2":{"475":1}}],["的参数都是对术语的一种滥用",{"2":{"411":1}}],["的张量",{"2":{"475":2}}],["的工作原理和记录操作的方式",{"2":{"470":1}}],["的工作流程",{"0":{"175":1},"1":{"176":1,"177":1,"178":1,"179":1,"180":1}}],["的第一个",{"2":{"609":1}}],["的第",{"2":{"468":1}}],["的第几个输出",{"2":{"468":1}}],["的子类",{"2":{"445":1}}],["的别名",{"2":{"445":3,"496":1}}],["的value",{"2":{"444":1}}],["的stride",{"2":{"444":1}}],["的storage",{"2":{"444":1}}],["的sota",{"2":{"193":1}}],["的pre",{"2":{"496":1}}],["的production",{"2":{"383":2}}],["的pytorch",{"2":{"444":1}}],["的维度",{"2":{"444":1,"445":1}}],["的维度顺序或物理布局",{"2":{"441":1}}],["的行为",{"2":{"441":12}}],["的属性全解",{"0":{"440":1}}],["的更新剪裁为",{"2":{"410":1}}],["的训练损失曲线显示不稳定",{"2":{"405":1}}],["的训练损失曲线",{"2":{"405":1}}],["的验证误差的概率约为",{"2":{"403":1}}],["的最大学习率进行稳定训练",{"2":{"404":1}}],["的最大问题是如何调整学习率衰减计划",{"2":{"383":1}}],["的最佳权重衰减值的isolation图",{"2":{"376":1}}],["的最佳值时",{"2":{"356":1}}],["的初始化",{"2":{"467":1,"509":1}}],["的初始值",{"0":{"382":1}}],["的初步猜测",{"2":{"382":1}}],["的方式在大量生语料上进行训练",{"2":{"616":1}}],["的方法通常会导致较慢的训练进度",{"2":{"380":1}}],["的方差",{"2":{"249":1,"252":1}}],["的方差为",{"2":{"248":1}}],["的搜索空间的探索",{"2":{"379":1}}],["的话",{"2":{"377":1,"573":1}}],["的一种转移",{"2":{"628":1}}],["的一部分",{"2":{"493":1}}],["的一步上结束",{"2":{"375":1}}],["的一般取值为0",{"2":{"264":1}}],["的试验",{"2":{"373":1}}],["的关系",{"2":{"373":1}}],["的影响",{"2":{"367":1}}],["的结果",{"2":{"363":1}}],["的结构和功能的数学模型或计算模型",{"2":{"5":1}}],["的幂来尝试",{"2":{"358":1}}],["的超参数应该如何调整",{"0":{"400":1},"2":{"356":2}}],["的其他重要问题",{"2":{"353":1}}],["的丢掉有效特征",{"2":{"348":1}}],["的神经元从网络中删除",{"2":{"346":1}}],["的神经网络",{"2":{"132":1}}],["的学习能力",{"2":{"343":1}}],["的节点",{"2":{"338":3}}],["的自回归语言建模和来自",{"2":{"619":1}}],["的自回归属性",{"2":{"329":1}}],["的自动推理机制",{"0":{"451":1}}],["的自注意力层",{"2":{"219":1,"305":1}}],["的了解",{"2":{"326":1}}],["的特定硬件单元",{"2":{"325":1}}],["的改进",{"0":{"324":1}}],["的操作才会在反向图中记录",{"2":{"475":1}}],["的操作",{"2":{"322":1}}],["的不足之处",{"0":{"319":1}}],["的压缩潜在向量",{"2":{"309":1}}],["的估计",{"2":{"294":1}}],["的扩展",{"2":{"287":1}}],["的缩写",{"2":{"260":1}}],["的分布在",{"2":{"249":1}}],["的正态分布",{"2":{"239":1,"240":1}}],["的列进行耦合",{"2":{"225":1,"313":1}}],["的flops数量和hbm访问数量",{"2":{"223":1,"312":1}}],["的dropout操作",{"2":{"223":1,"312":1}}],["的掩码操作或应用于",{"2":{"223":1,"312":1}}],["的内存要求",{"2":{"621":1}}],["的内存开销",{"2":{"335":1}}],["的内存",{"2":{"223":1,"312":1,"333":1,"358":1}}],["的大小减小",{"2":{"219":1,"305":1}}],["的每个词与目标端",{"2":{"213":1}}],["的每个时间步中",{"2":{"171":1}}],["的query",{"2":{"208":1}}],["的点积attention性能好",{"2":{"206":1}}],["的性能",{"2":{"619":1}}],["的性能相差相近",{"2":{"206":1}}],["的性质",{"2":{"54":1}}],["的获取写成矩阵形式",{"2":{"205":1}}],["的获取过程",{"2":{"205":1}}],["的速度更快",{"2":{"203":1}}],["的已知输出",{"2":{"197":1}}],["的计算公式为",{"2":{"840":1}}],["的计算结果",{"2":{"648":1}}],["的计算和内存可以在输出序列之间共享使用",{"2":{"335":1}}],["的计算",{"0":{"635":1},"2":{"185":1,"326":1}}],["的计算了",{"2":{"28":1}}],["的损失函数计算",{"0":{"629":1},"1":{"630":1}}],["的损失函数",{"0":{"181":1}}],["的模式不能在训练时使用吗",{"2":{"177":1}}],["的模式",{"2":{"177":1}}],["的原理图如下",{"2":{"174":1}}],["的值",{"2":{"544":1,"827":1}}],["的值是很多个",{"2":{"249":1}}],["的值比较小的时候",{"2":{"206":1}}],["的值相乘",{"2":{"149":1}}],["的值表示要保留",{"2":{"147":1}}],["的值表示要遗忘",{"2":{"147":1}}],["的优化算法",{"2":{"143":1}}],["的短期记忆问题",{"2":{"143":1}}],["的输出",{"2":{"472":1}}],["的输出作为后一个时刻",{"2":{"168":1}}],["的输出中保留哪些重要信息",{"2":{"148":1}}],["的输出将决定从",{"2":{"148":1}}],["的输出相乘",{"2":{"148":1,"150":1}}],["的输出与",{"2":{"148":1,"150":1}}],["的输出也产生了影响",{"2":{"142":1}}],["的输入是词嵌入向量",{"2":{"646":1}}],["的输入参数",{"0":{"507":1}}],["的输入",{"2":{"137":1,"168":1,"478":1}}],["的研究人员使用自动搜索",{"2":{"127":1}}],["的降低",{"2":{"126":1}}],["的激活信息规整为零",{"2":{"126":1}}],["的数据部分置为0",{"2":{"123":1}}],["的数据导数值很小",{"2":{"121":1}}],["的稀疏性",{"2":{"648":1}}],["的稀疏性可以提高学习的精度",{"2":{"123":1}}],["的稀疏性给卷积神经网络的训练带来了巨大的成功",{"2":{"123":1}}],["的情况下",{"2":{"478":1,"619":1}}],["的情况",{"2":{"122":1,"124":1,"322":1,"390":1}}],["的提出正是为了解决这一问题",{"2":{"120":1}}],["的逆运算",{"2":{"104":1}}],["的区别",{"0":{"485":1},"2":{"87":1}}],["的index",{"2":{"87":1,"634":1}}],["的空洞卷积",{"2":{"60":1}}],["的卷积核作纵向扫描计算",{"2":{"59":1}}],["的卷积核作横向扫描计算",{"2":{"59":1}}],["的卷积核分解如下图",{"2":{"59":1}}],["的卷积操作",{"2":{"58":1}}],["的卷积",{"2":{"58":1}}],["的label",{"2":{"38":1}}],["的梯度会被计算",{"2":{"474":1}}],["的梯度会计算",{"2":{"462":1}}],["的梯度很小",{"2":{"239":1}}],["的梯度计算",{"2":{"45":1,"474":1}}],["的梯度",{"0":{"32":1,"33":1,"34":1,"457":1,"464":1},"2":{"45":1,"46":1,"457":1,"509":1}}],["的梯度定义为",{"2":{"26":1}}],["的",{"0":{"445":1},"2":{"24":1,"38":1,"54":1,"170":1,"171":1,"217":2,"220":1,"225":2,"240":1,"303":2,"306":1,"313":2,"323":1,"326":1,"356":1,"387":2,"436":2,"441":1,"445":1,"464":1,"471":1,"490":1,"492":1,"493":1,"496":2,"508":1,"509":2,"609":2,"619":2,"620":1,"634":1,"644":1,"647":1,"648":1,"721":1,"878":1}}],["前任铺路后人走",{"0":{"963":1,"965":1},"1":{"964":1}}],["前一个任务被称为遮盖语言建模",{"2":{"619":1}}],["前一层权重梯度计算",{"0":{"46":1}}],["前置钩子",{"2":{"509":1}}],["前置钩子函数",{"2":{"508":1}}],["前",{"2":{"496":1,"509":1}}],["前期成本",{"2":{"360":1}}],["前期较小的时候",{"2":{"279":1}}],["前端提示",{"2":{"338":1}}],["前端首先发送前缀作为提示",{"2":{"338":1}}],["前端解释器将完整的提示发送到runtime",{"2":{"338":1}}],["前缀树",{"2":{"338":1}}],["前提是在更改batch",{"2":{"359":1}}],["前提",{"2":{"226":1,"315":1,"516":1,"520":1}}],["前面说了知己难遇",{"2":{"878":1}}],["前面一直说系统资源",{"2":{"680":1}}],["前面已经讲过",{"2":{"617":1}}],["前面画的几个图展示的预测过程",{"2":{"183":1}}],["前面我们详细介绍了seq2seq的内部的结构",{"2":{"181":1}}],["前面提到过",{"2":{"180":1}}],["前面所有的输入都对未来的输出产生了影响",{"2":{"142":1}}],["前面",{"2":{"142":1}}],["前半部分的卷积组负责处理前半部分的输入层",{"2":{"57":1}}],["前向执行完后调用",{"2":{"490":1}}],["前向钩子函数展示",{"0":{"494":1}}],["前向钩子函数是否带参数",{"2":{"490":1}}],["前向钩子函数是否always",{"2":{"490":1}}],["前向钩子函数",{"2":{"490":1}}],["前向时计算row",{"2":{"323":1}}],["前向推导过程",{"0":{"248":1}}],["前向",{"2":{"50":1,"490":1}}],["前向过程为",{"2":{"44":1}}],["前向传播计算",{"2":{"497":1}}],["前向传播",{"2":{"493":1,"495":1,"498":1,"567":1}}],["前向传播发生的两件事",{"2":{"447":1}}],["前向传播中的空操作和反向传播中的",{"2":{"328":1}}],["前向传播中的",{"2":{"328":2}}],["前向传播+反向传播求导",{"2":{"122":1}}],["前向传播过程",{"0":{"39":1},"1":{"40":1,"41":1}}],["前向传播可以持续向前直到它产生一个标量",{"2":{"24":1}}],["前馈神经网络的一种特例",{"2":{"54":1}}],["前馈神经网络的关系",{"0":{"54":1}}],["前馈神经网络的概念",{"0":{"6":1}}],["前馈神经网络计算流程",{"0":{"16":1}}],["前馈神经网络",{"0":{"0":1},"2":{"51":1}}],["时间复杂度",{"0":{"959":1}}],["时间管理",{"0":{"926":1}}],["时间步越小加的噪音越小",{"2":{"595":1}}],["时间序列问题",{"2":{"160":1}}],["时可被自动调用",{"2":{"496":1}}],["时不能传参数",{"2":{"490":1}}],["时使用",{"2":{"480":1}}],["时隐式存在的模式",{"2":{"477":1}}],["时的加速",{"2":{"509":1}}],["时的大多数函数",{"2":{"473":1}}],["时的卷积",{"2":{"56":1}}],["时记录了创建数据的所有操作",{"2":{"471":1}}],["时触发",{"2":{"443":2,"490":1}}],["时被调用",{"2":{"443":1}}],["时调用",{"2":{"443":1}}],["时生效",{"2":{"440":1}}],["时遇到了内存不足",{"2":{"328":1}}],["时刻之前的输出",{"2":{"216":1}}],["时梯度为",{"2":{"122":1}}],["时会输出为",{"2":{"122":1}}],["时就需要用到链式求导",{"2":{"28":1}}],["时",{"2":{"24":1,"60":1,"125":1,"127":2,"217":1,"239":1,"240":1,"303":1,"401":1,"441":1,"472":1,"496":1,"509":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"626":1,"822":1,"878":1}}],["yasg",{"2":{"889":1}}],["yaml",{"2":{"446":1}}],["ystep=1ystep",{"2":{"840":1}}],["ystep=k=​δx​​δy​​",{"2":{"840":1}}],["ystep=k=δyδxystep",{"2":{"840":1}}],["ystepy​i+1​​=y​i​​+ystep",{"2":{"840":1}}],["y|",{"2":{"840":1}}],["y|∣δx∣",{"2":{"840":1}}],["y|x",{"2":{"626":2}}],["yw",{"2":{"782":1}}],["yum",{"2":{"770":2,"817":1}}],["yy",{"2":{"753":1,"782":1}}],["y0",{"2":{"627":1,"659":1,"840":1}}],["yn",{"2":{"626":2,"627":1}}],["yn^",{"2":{"181":1}}],["year",{"2":{"421":1}}],["yl",{"2":{"248":5,"249":2}}],["yl−12",{"2":{"248":1}}],["yl−1",{"2":{"248":6}}],["yly",{"2":{"248":1}}],["yl=wlxl+bly",{"2":{"248":1}}],["y的数学表达式",{"2":{"245":1}}],["yoshua",{"2":{"244":1}}],["yourmodel",{"2":{"541":1}}],["yourself",{"2":{"274":1}}],["you",{"0":{"193":1},"2":{"217":1,"255":1,"303":1,"338":1,"587":1,"616":1,"893":2,"894":1,"896":1}}],["y∣x",{"2":{"190":4,"626":4}}],["y是目标语言",{"2":{"190":1}}],["y​0​​",{"2":{"627":1,"840":1}}],["y​n​​",{"2":{"626":2,"627":1}}],["y​l−1​2​​",{"2":{"248":1}}],["y​l−1​​",{"2":{"248":6}}],["y​l​​",{"2":{"248":6,"249":2}}],["y​l​​=w​l​​x​l​​+b​l​​",{"2":{"248":1}}],["y​i​​",{"2":{"626":2,"627":2,"628":2,"840":1}}],["y​i​​∣x",{"2":{"626":2}}],["y​i​​∣y​1​​",{"2":{"185":2}}],["y​i+1​​",{"2":{"626":3,"628":1,"840":1,"845":1}}],["y​i−1​​",{"2":{"185":2,"626":3}}],["y​2​​",{"2":{"185":2,"626":1}}],["y​t​​",{"2":{"185":1}}],["y​1​​",{"2":{"185":1,"626":2,"627":1,"840":1}}],["y2",{"2":{"185":2,"626":1,"635":4}}],["y2^",{"2":{"181":1}}],["yi直线光栅化",{"0":{"834":1},"1":{"835":1,"836":1,"837":1,"838":1,"839":1,"840":1,"841":1,"842":1,"843":1,"844":1,"845":1,"846":1,"847":1,"848":1,"849":1,"850":1,"851":1,"852":1,"853":1}}],["yi",{"2":{"627":1,"840":1}}],["yiy",{"2":{"626":2,"627":1,"628":2}}],["yi+1=yi+ystepy",{"2":{"840":1}}],["yi+1y",{"2":{"626":1,"628":1}}],["yi+1",{"2":{"626":2,"840":1}}],["yi∣x",{"2":{"626":2}}],["yi∣y1",{"2":{"185":2}}],["yi−1",{"2":{"185":2,"626":3}}],["yi^",{"2":{"181":1}}],["yt",{"2":{"185":1}}],["y1",{"2":{"185":1,"626":2,"627":1,"840":1}}],["y1^",{"2":{"181":1}}],["y=f",{"2":{"28":2,"245":3}}],["y=",{"2":{"26":1,"626":2,"627":3}}],["y",{"2":{"24":2,"26":15,"28":4,"29":1,"50":6,"99":2,"161":3,"181":4,"185":10,"190":25,"194":2,"245":1,"247":8,"248":12,"249":7,"441":1,"445":1,"451":2,"452":2,"453":1,"455":4,"456":7,"457":7,"472":11,"474":5,"500":2,"556":1,"571":2,"590":8,"626":15,"627":4,"635":5,"649":3,"782":1,"784":1,"840":17,"841":1,"843":4}}],["987654",{"2":{"726":1}}],["98",{"2":{"608":1}}],["95",{"2":{"535":1,"536":1}}],["9216",{"2":{"497":1,"513":1}}],["941715",{"2":{"48":3}}],["945864",{"2":{"48":3}}],["97",{"2":{"619":1}}],["977675",{"2":{"48":3}}],["979164+0",{"2":{"41":3}}],["979164",{"2":{"40":2}}],["979164out",{"2":{"40":1}}],["90",{"2":{"537":1}}],["908195",{"2":{"48":3}}],["904330",{"2":{"41":5}}],["904330out",{"2":{"41":1}}],["912934=0",{"2":{"45":2}}],["912934+0",{"2":{"41":3}}],["912934",{"2":{"40":2,"45":4}}],["912934out",{"2":{"40":1}}],["99−0",{"2":{"41":2}}],["995275=2",{"2":{"41":3}}],["995275",{"2":{"40":2}}],["995275out",{"2":{"40":1}}],["99",{"2":{"38":1,"41":1,"50":1,"264":1,"460":1,"484":1,"487":1}}],["9",{"0":{"22":1,"59":1,"108":1,"129":1,"217":1,"254":1,"293":1,"294":1,"295":1,"296":1,"297":1,"319":1,"329":1,"458":1,"543":1,"716":1,"764":1,"959":1},"1":{"295":1,"296":1,"297":1,"765":1,"766":1},"2":{"41":1,"45":2,"47":1,"95":3,"111":3,"113":1,"264":1,"274":1,"284":1,"338":1,"410":1,"487":1,"497":1,"503":1,"504":2,"533":4,"541":1,"543":1,"544":1,"547":1,"548":1,"549":2,"719":2,"756":1,"877":1}}],["tsetselectuserbyid",{"2":{"730":1}}],["tsl指令",{"0":{"691":1}}],["ts指令",{"0":{"691":1}}],["tsfm",{"2":{"556":2}}],["tqdm",{"2":{"635":1}}],["t02t",{"2":{"627":1}}],["t01t",{"2":{"627":1}}],["t00t",{"2":{"627":1}}],["tb",{"2":{"619":1}}],["tbt",{"2":{"329":1}}],["tlm",{"2":{"619":2}}],["tloss",{"2":{"497":1}}],["t5模型出自文章",{"2":{"644":1}}],["t5",{"0":{"637":1,"644":1},"2":{"616":1,"621":4,"636":1,"637":2,"644":1,"671":1}}],["txt",{"2":{"583":1,"743":8,"746":4,"748":3,"749":2,"751":1,"765":2}}],["ttt",{"2":{"580":1}}],["ttft",{"2":{"329":3}}],["tgt",{"2":{"500":23}}],["tgi",{"2":{"332":1}}],["two",{"0":{"460":1},"2":{"440":1,"499":1,"535":1}}],["typora",{"2":{"843":1}}],["type=",{"2":{"726":2}}],["type=float",{"2":{"497":2}}],["type=int",{"2":{"497":5}}],["typevar",{"2":{"496":1}}],["types",{"2":{"441":1,"445":30,"895":1,"897":1}}],["typedstorage",{"2":{"445":2}}],["typed",{"2":{"441":1}}],["type",{"2":{"428":2,"430":1,"439":1,"441":12,"443":2,"444":1,"445":5,"487":1,"492":1,"496":3,"649":2,"765":1,"809":1,"823":3,"891":1}}],["typical",{"2":{"227":1,"317":1}}],["t+1",{"2":{"414":1,"415":3,"416":3,"417":5,"418":9,"419":9}}],["tf",{"2":{"387":2}}],["tflops",{"2":{"320":2}}],["tip",{"2":{"683":1,"841":1}}],["tiny",{"2":{"456":1,"590":1}}],["tile",{"2":{"445":2}}],["tilde",{"2":{"343":1}}],["title",{"2":{"421":1}}],["time",{"2":{"216":1,"329":2,"454":2,"581":2,"586":1,"877":1,"904":2}}],["timestep",{"2":{"595":1,"632":2,"633":2,"634":1}}],["timesteps",{"2":{"595":5}}],["times",{"2":{"40":5,"41":7,"44":5,"45":5,"46":17,"126":1,"128":1,"209":4,"223":3,"226":2,"227":1,"228":1,"248":10,"249":4,"312":3,"317":1,"318":1,"410":1}}],["tuln",{"2":{"760":1}}],["tutorials",{"0":{"903":1}}],["tutorial",{"2":{"448":1}}],["tuple",{"2":{"441":1,"443":2,"445":7,"496":8,"509":4,"556":5,"649":1}}],["tuning",{"2":{"421":2,"422":1,"616":1,"671":1}}],["tuningplaybookgithub",{"2":{"421":1}}],["tune",{"2":{"220":1,"306":1,"616":1}}],["turn",{"2":{"337":1,"581":1}}],["tpu",{"2":{"358":1}}],["tp和cp的组合可以通过消除重新计算开销",{"2":{"328":1}}],["tp",{"2":{"328":2,"329":1}}],["tp2cp2",{"2":{"328":1}}],["tcp",{"2":{"588":1,"589":2,"822":1}}],["tcurtiπ",{"2":{"546":1}}],["tcurtmaxπ",{"2":{"545":1}}],["tct",{"2":{"226":1}}],["tc=nbct",{"2":{"226":1}}],["t​02​​",{"2":{"627":1}}],["t​01​​",{"2":{"627":1}}],["t​00​​",{"2":{"627":1}}],["t​c​​",{"2":{"226":1}}],["t​c​​=​b​c​​​​n​​",{"2":{"226":1}}],["t​r​​",{"2":{"226":4}}],["t​r​​=​b​r​​​​n​​",{"2":{"226":1}}],["tmp",{"2":{"581":1,"636":1,"739":1}}],["tma",{"2":{"325":1}}],["tm则需要通过",{"2":{"190":1}}],["tm",{"2":{"190":1}}],["t代表decoder有多少步",{"2":{"181":1}}],["teach",{"2":{"901":1}}],["teacher",{"0":{"178":1},"2":{"178":1}}],["texmpi的实现",{"2":{"802":1}}],["text",{"2":{"188":4,"417":1,"418":1,"419":1,"444":2,"616":1,"644":2,"753":2,"786":4,"799":3,"897":4}}],["tesla",{"2":{"900":1}}],["testserver",{"2":{"889":1}}],["testdeleteuser",{"2":{"733":1}}],["testupdateuser",{"2":{"732":1}}],["testadduser",{"2":{"731":1}}],["test1",{"2":{"576":1}}],["testing",{"2":{"497":1}}],["test",{"0":{"691":1},"2":{"497":18,"576":1,"581":1,"726":1,"730":1,"731":1,"732":1,"733":1,"889":1,"896":1,"899":1,"904":1}}],["tesnor",{"2":{"462":1}}],["template",{"2":{"445":2}}],["termius",{"2":{"816":1}}],["term",{"0":{"144":1},"1":{"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1},"2":{"144":1}}],["tensorlistlist",{"2":{"509":4}}],["tensorboard会自动安装",{"2":{"573":1}}],["tensorboardx",{"2":{"572":1}}],["tensorboard",{"0":{"572":1},"2":{"497":1,"572":1,"573":1,"575":2,"578":3,"581":2,"622":1,"671":1}}],["tensorbase",{"0":{"442":1},"1":{"443":1,"444":1,"445":1},"2":{"440":4,"441":8,"442":1}}],["tensor中",{"2":{"462":1}}],["tensormeta",{"2":{"440":1}}],["tensorflow",{"2":{"387":2,"462":1,"572":1,"573":1}}],["tensors",{"0":{"472":1,"895":1},"2":{"113":1,"458":1,"472":1,"509":1,"556":1,"895":2}}],["tensor2",{"2":{"84":2,"436":5,"445":5}}],["tensor1",{"2":{"84":2,"445":5}}],["tensor",{"0":{"426":1,"427":1,"432":1,"435":1,"436":1,"438":1,"439":1,"440":1,"441":1,"445":1,"457":1,"464":1,"485":1,"511":1},"1":{"427":1,"428":1,"429":1,"430":1,"433":1,"434":1,"436":1,"437":1,"438":1,"439":1},"2":{"55":1,"87":1,"98":1,"99":1,"101":1,"106":1,"107":1,"108":1,"111":14,"112":1,"117":1,"333":1,"427":3,"429":1,"430":14,"431":4,"433":9,"434":11,"436":20,"440":16,"441":26,"443":84,"444":41,"445":948,"452":1,"453":1,"454":1,"456":5,"457":4,"460":4,"462":4,"471":1,"472":1,"474":3,"484":2,"487":4,"490":1,"494":2,"496":8,"498":1,"500":1,"507":1,"508":1,"509":5,"511":7,"522":1,"528":2,"567":2,"632":2,"633":3,"634":1,"649":6,"671":1}}],["t=1",{"2":{"137":1}}],["ta是跨越时空的",{"2":{"878":1}}],["ta并非文字所能解释清楚",{"2":{"878":1}}],["tabstop=4",{"2":{"792":1}}],["table",{"2":{"581":1,"726":2}}],["table自然地实现了内存共享",{"2":{"335":1}}],["tail",{"2":{"748":1}}],["tag",{"2":{"632":2,"633":8,"634":16,"823":3,"862":1}}],["tags",{"2":{"632":12,"633":16,"634":26}}],["tasks",{"2":{"622":1,"897":5,"900":1}}],["task",{"2":{"613":1}}],["tarbashtar",{"2":{"768":1}}],["tar",{"2":{"613":1,"768":5}}],["target=fetch",{"2":{"799":1}}],["target端",{"2":{"213":1}}],["target​o2​​−out​o2​​",{"2":{"46":1}}],["target​o1​​−out​o1​​",{"2":{"45":2,"46":1}}],["targeto2−outo2",{"2":{"46":1}}],["targeto1−outo1",{"2":{"45":2,"46":1}}],["target−out​o1​​",{"2":{"44":1}}],["target−outo1",{"2":{"44":1}}],["target",{"2":{"44":1,"45":2,"46":2,"95":3,"190":1,"274":1,"495":1,"496":3,"497":9,"505":4,"533":4,"552":7,"553":2,"567":8}}],["tan",{"2":{"445":2}}],["tanh和softsign还有个很好的性质",{"2":{"245":1}}],["tanh^",{"2":{"121":1}}],["tanh",{"2":{"121":7,"126":1,"128":1,"148":3,"150":2,"245":1,"369":1,"445":2}}],["take",{"2":{"445":2,"580":1}}],["try",{"2":{"708":1,"726":1,"799":1,"893":1}}],["tr",{"2":{"606":2}}],["trunc",{"2":{"445":2}}],["true时",{"2":{"490":1}}],["truediv",{"2":{"443":1}}],["true",{"2":{"112":1,"440":1,"441":1,"444":2,"445":22,"450":1,"455":1,"456":1,"462":3,"464":1,"472":3,"478":1,"496":14,"497":6,"509":1,"544":1,"635":4}}],["triu",{"2":{"445":2}}],["tril",{"2":{"445":2,"498":1}}],["triangular2",{"2":{"543":1}}],["triangular",{"2":{"445":2,"543":1}}],["tries",{"2":{"891":1}}],["trie",{"2":{"338":1}}],["trick",{"0":{"321":1},"2":{"321":2}}],["tree的优势在于其能够高效地存储和检索大量的键值对",{"2":{"338":1}}],["tree的边不仅可以用单个元素标记",{"2":{"338":1}}],["tree来管理token序列与其对应的kv",{"2":{"338":1}}],["tree",{"2":{"337":2,"338":2,"613":1}}],["trt",{"2":{"226":4}}],["tr=nbrt",{"2":{"226":1}}],["track",{"2":{"904":1}}],["tracing",{"2":{"496":1,"857":2}}],["trace时",{"2":{"564":1}}],["trace是将pytorch模型转换为跟踪形式的工具",{"2":{"564":1}}],["traced",{"0":{"569":1},"2":{"525":4,"526":1,"569":6}}],["trace",{"0":{"564":1},"2":{"445":1,"525":3,"526":1,"564":1,"569":1,"581":10,"634":1}}],["trained",{"2":{"590":1,"897":3}}],["trainloader",{"2":{"580":2}}],["trainset",{"2":{"580":2}}],["train=false",{"2":{"497":1}}],["train=true",{"2":{"497":1,"555":1,"580":1}}],["trainning",{"2":{"497":1}}],["training",{"0":{"582":1,"585":1,"587":1,"662":1},"1":{"586":1,"587":1,"588":2,"589":2,"590":1},"2":{"490":1,"493":1,"496":1,"497":5,"543":1,"544":1,"555":2,"577":3,"581":1,"582":1,"584":1,"586":1,"587":2,"590":7,"605":1,"671":3,"894":2,"904":4}}],["train",{"0":{"382":1,"460":1},"2":{"220":1,"306":1,"381":6,"382":4,"385":1,"409":4,"460":1,"480":3,"487":2,"496":1,"497":14,"500":2,"533":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"547":1,"548":1,"549":1,"553":3,"567":1,"568":1,"571":1,"576":2,"577":1,"580":1,"585":3,"588":1,"589":2,"636":3,"891":1,"895":1}}],["transactionmanager",{"2":{"726":1}}],["trans",{"2":{"635":2}}],["transitioned",{"2":{"634":2}}],["transitioning",{"2":{"633":1}}],["transitions",{"2":{"632":3,"633":3,"634":4}}],["transition",{"2":{"632":3,"633":2,"634":2}}],["transfer",{"2":{"616":1,"644":1}}],["transform=totensor",{"2":{"555":1}}],["transform=transform",{"2":{"497":2,"580":1}}],["transform=transforms",{"2":{"497":1,"556":1}}],["transform=none",{"2":{"552":1}}],["transform",{"2":{"552":9,"556":4,"580":1}}],["transformsers",{"2":{"636":1}}],["transforms",{"0":{"556":1},"2":{"497":3,"555":1,"556":8,"575":1,"580":3}}],["transformed",{"2":{"556":4}}],["transforme",{"2":{"327":1}}],["transformer论文",{"2":{"640":1}}],["transformerblock",{"2":{"499":3}}],["transformerdecoder",{"2":{"498":3}}],["transformers",{"2":{"332":1,"616":1,"636":3}}],["transformers高出多达24倍",{"2":{"332":1}}],["transformer遵循这种整体架构",{"2":{"194":1}}],["transformer",{"0":{"194":1,"500":1,"615":1,"616":1,"618":1},"1":{"616":1,"617":1,"618":1,"619":1,"620":1,"621":1,"622":1},"2":{"193":1,"214":1,"217":1,"303":1,"326":1,"328":1,"329":1,"500":5,"609":2,"616":11,"618":1,"619":2,"620":5,"621":2,"644":1,"645":2}}],["transformer是第一个完全依靠self",{"2":{"193":1}}],["transformer允许进行更多的并行化",{"2":{"193":1}}],["transformations",{"2":{"344":2,"897":1}}],["transformation",{"2":{"120":1,"498":1,"500":1,"897":1}}],["transfomer",{"2":{"21":2}}],["translation",{"2":{"188":1,"189":2,"619":1}}],["transpose的区别",{"2":{"438":1}}],["transpose",{"0":{"97":1,"100":1},"1":{"98":1,"99":1,"100":1,"101":1},"2":{"99":1,"100":1,"215":1,"445":5,"498":5,"500":5,"556":1,"634":2,"649":1}}],["transposed",{"0":{"61":1},"2":{"440":2}}],["together",{"2":{"897":1}}],["touch",{"2":{"743":1}}],["tostring",{"2":{"726":1}}],["tomcat",{"2":{"710":1}}],["tongjilibo",{"2":{"613":1}}],["tools",{"2":{"897":3}}],["tool",{"2":{"891":1}}],["too",{"2":{"585":1}}],["totensor",{"2":{"497":1,"555":1,"556":2,"580":1}}],["total",{"2":{"41":1,"44":4,"45":3,"46":3,"47":1,"539":2,"540":2,"542":2,"544":2,"545":3,"548":1,"549":1,"567":3,"581":1,"590":2,"827":4}}],["tolist",{"2":{"445":1}}],["topk",{"2":{"445":2,"634":2}}],["top",{"2":{"223":1,"312":1,"556":4,"634":1,"643":2,"644":14,"647":3,"755":1,"827":1}}],["token粒度",{"2":{"635":1}}],["tokens",{"2":{"329":1}}],["token",{"2":{"181":1,"204":3,"217":1,"303":1,"329":1,"635":2,"645":2,"648":3,"649":1,"889":1}}],["to",{"0":{"432":1,"570":1,"571":1,"662":1,"890":1,"896":1,"902":1},"1":{"433":1,"434":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1,"899":1,"900":1,"901":1,"902":1,"903":2,"904":2,"905":1},"2":{"167":1,"329":1,"333":1,"433":4,"434":3,"441":16,"444":11,"445":27,"460":1,"484":1,"487":2,"496":9,"497":8,"499":2,"509":2,"511":1,"556":18,"580":1,"581":3,"584":1,"585":2,"586":2,"590":8,"595":2,"616":1,"632":1,"633":2,"634":2,"644":1,"822":2,"827":2,"868":1,"891":3,"893":1,"894":2,"895":2,"896":2,"897":1,"899":2,"901":2,"903":1,"904":3,"905":4}}],["torchaudio",{"2":{"897":2}}],["torchtext",{"2":{"897":2}}],["torchtitan",{"2":{"666":1}}],["torchvision",{"0":{"554":1,"555":1,"556":1},"1":{"555":1,"556":1},"2":{"497":1,"528":2,"555":3,"575":2,"579":1,"580":3,"897":2}}],["torchdynamo",{"2":{"490":1}}],["torch会做额外的一些事情",{"2":{"464":1}}],["torch",{"0":{"482":1,"483":1,"484":1,"491":1,"501":1,"506":1,"507":1,"508":1,"509":1,"532":1,"553":1,"563":1,"564":1,"565":1},"1":{"484":1,"485":1,"492":1,"493":1,"494":1,"495":1,"496":1,"507":1,"508":1,"509":1,"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1},"2":{"63":2,"80":3,"81":4,"83":3,"84":10,"86":1,"87":3,"88":1,"89":1,"93":2,"94":2,"95":5,"98":4,"99":3,"100":2,"101":2,"104":3,"105":3,"106":1,"107":3,"108":2,"110":3,"111":2,"112":13,"113":6,"114":1,"121":3,"122":3,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"215":2,"274":2,"427":4,"428":6,"429":5,"430":9,"433":3,"434":4,"436":3,"440":3,"441":19,"443":1,"444":7,"445":51,"446":1,"450":6,"451":3,"452":2,"453":10,"454":7,"455":2,"456":23,"457":4,"459":4,"460":11,"462":1,"468":1,"471":1,"472":3,"474":5,"478":1,"480":2,"484":9,"487":18,"489":1,"490":2,"493":9,"494":3,"495":4,"496":1,"497":20,"498":10,"499":7,"500":12,"501":2,"503":1,"507":1,"508":1,"509":13,"511":6,"513":5,"514":1,"515":2,"518":2,"519":4,"522":2,"523":2,"525":3,"526":2,"528":3,"532":2,"533":1,"541":3,"543":3,"544":3,"545":3,"547":1,"552":2,"553":1,"555":1,"556":4,"565":2,"567":5,"568":3,"569":4,"570":3,"571":9,"572":1,"575":5,"579":1,"580":4,"581":3,"595":4,"632":7,"633":6,"634":12,"649":17,"904":7}}],["t",{"2":{"50":6,"107":2,"137":4,"138":5,"168":2,"174":1,"181":3,"185":2,"200":1,"216":4,"226":7,"309":2,"323":1,"414":3,"415":4,"416":5,"417":6,"418":6,"419":7,"440":1,"445":2,"459":1,"496":52,"509":1,"511":2,"545":4,"546":7,"628":1,"649":3,"827":1,"894":1}}],["th",{"2":{"633":1}}],["third",{"2":{"581":1}}],["this",{"2":{"384":1,"440":1,"556":6,"581":1,"582":1,"585":1,"586":1,"590":3,"633":1,"634":2,"893":1,"894":1,"904":1}}],["thread",{"2":{"799":6}}],["threads",{"2":{"799":3}}],["threading",{"2":{"799":3}}],["three",{"2":{"544":1,"556":1,"904":1}}],["threshold",{"2":{"10":1}}],["through",{"2":{"499":1,"904":1}}],["thought",{"2":{"337":1}}],["than",{"2":{"227":1,"317":1,"580":1}}],["that",{"2":{"106":1,"217":1,"303":1,"335":1,"444":1,"547":1,"556":2,"581":1,"586":1,"633":3,"634":2,"891":2,"893":1,"894":1,"897":1}}],["they",{"2":{"895":1}}],["theory",{"2":{"671":1,"874":1}}],["thery的章节结构整改",{"2":{"874":1}}],["theroy",{"0":{"671":1}}],["therefore",{"2":{"556":1}}],["these",{"2":{"556":1,"897":1}}],["them",{"2":{"556":1,"899":1}}],["then",{"2":{"499":1,"556":2,"584":1}}],["the",{"0":{"220":1,"306":1,"898":1},"1":{"899":1,"900":1,"901":1},"2":{"89":1,"99":1,"106":1,"217":1,"271":1,"303":1,"440":1,"441":2,"444":4,"445":2,"458":1,"496":1,"497":3,"499":1,"556":15,"577":1,"581":10,"582":1,"584":2,"585":5,"586":1,"587":2,"590":3,"616":1,"633":7,"634":14,"644":1,"891":1,"893":4,"894":3,"895":1,"904":7,"905":2}}],["theta=",{"2":{"647":1}}],["theta",{"2":{"24":1,"227":2,"287":1,"317":2,"414":3,"415":3,"416":4,"417":4,"418":4,"419":5,"647":6,"648":8,"649":4,"659":2}}],["强调可移植性和性能",{"2":{"802":1}}],["强调如何基于环境而行动",{"2":{"21":1}}],["强制退出",{"2":{"777":1}}],["强制终止进程",{"2":{"756":1}}],["强制报错",{"2":{"441":1}}],["强化其他位置的特征点学习到丢失掉的位置的语义信息",{"2":{"348":1}}],["强化学习不需要带标签的输入输出对",{"2":{"21":1}}],["强化学习",{"2":{"21":1}}],["股票价格走势",{"2":{"21":1}}],["rhel",{"2":{"772":1}}],["rho",{"2":{"417":2}}],["rw",{"2":{"746":1}}],["rwx",{"2":{"745":1}}],["r1",{"0":{"670":1}}],["r​θ​d​​",{"2":{"647":1}}],["r​θ",{"2":{"647":2,"648":1}}],["r​i",{"2":{"643":6}}],["rθdr",{"2":{"647":1}}],["rθ",{"2":{"647":2,"648":1}}],["rbrace",{"2":{"647":1}}],["rgb",{"2":{"580":1}}],["rfc",{"2":{"479":1}}],["rfloordiv",{"2":{"441":1,"443":1}}],["rfloatdiv",{"2":{"441":1}}],["rcond",{"2":{"445":1}}],["rtol",{"2":{"445":3}}],["rtruediv",{"2":{"441":1,"443":1}}],["rxor",{"2":{"443":1}}],["rrshift",{"2":{"441":1}}],["rrelu",{"2":{"124":4}}],["rlshift",{"2":{"441":1}}],["rpow",{"2":{"441":1,"443":1}}],["rm",{"2":{"742":1}}],["rmdir",{"2":{"742":2}}],["rmul",{"2":{"443":1}}],["rmatmul",{"2":{"441":1}}],["rmod",{"2":{"441":1}}],["rms指的是均方根",{"2":{"282":1}}],["rmsprop",{"0":{"282":1,"417":1},"1":{"283":1,"284":1,"285":1},"2":{"282":2,"283":2,"284":1,"287":1,"292":1,"294":2}}],["rms",{"0":{"91":1},"2":{"287":3}}],["rdiv",{"2":{"441":2}}],["rng",{"2":{"395":1}}],["rnn就无法直接解决",{"2":{"165":1}}],["rnn的输入是",{"2":{"161":1}}],["rnn引入了隐状态h",{"2":{"160":1}}],["rnn扩展到多层构成循环神经网络",{"0":{"141":1}}],["rnn可扩展到双向的情况",{"0":{"140":1}}],["rnn具体计算公式为",{"0":{"138":1}}],["rnns之所以称为循环神经网路",{"2":{"133":1}}],["rnn",{"0":{"132":1,"134":1,"135":1,"139":1,"142":1,"160":1,"161":1,"162":1,"163":1,"164":1},"1":{"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1,"162":1,"163":1,"164":1},"2":{"21":1,"87":1,"132":1,"143":5,"144":1,"193":1}}],["rsa",{"2":{"827":3}}],["rsqrt",{"2":{"445":2}}],["rshift",{"2":{"443":3}}],["rsub",{"2":{"441":1,"443":1}}],["rs",{"2":{"328":10}}],["rich",{"0":{"897":1}}],["ri",{"2":{"643":6}}],["ring",{"2":{"326":2,"327":1}}],["ringattention",{"0":{"326":1},"1":{"327":1},"2":{"326":1}}],["right",{"2":{"225":1,"248":1,"249":1,"313":1,"406":1,"410":2,"445":4,"647":1}}],["ray",{"2":{"857":1}}],["rabbitmq",{"2":{"715":1}}],["ram",{"2":{"680":1}}],["rather",{"2":{"580":1}}],["ratio",{"2":{"556":1}}],["rates",{"2":{"543":1,"544":1}}],["rate来说",{"2":{"409":1}}],["rate的峰值学习率",{"2":{"409":1}}],["rate这样的数值",{"2":{"409":1}}],["rate要大一个数量级",{"2":{"409":1}}],["rate",{"0":{"531":1,"534":1},"2":{"258":1,"289":1,"369":3,"370":2,"409":6,"497":2,"500":2,"503":1,"531":1,"541":1,"545":1,"585":2,"590":2,"636":1}}],["raise",{"2":{"508":1}}],["raising",{"2":{"441":1}}],["ravel",{"2":{"445":1}}],["rad2deg",{"2":{"445":2}}],["radd",{"2":{"443":1}}],["radix",{"2":{"337":1,"338":3}}],["radixattention",{"0":{"336":1},"1":{"337":1,"338":1},"2":{"337":2,"338":1}}],["raw",{"2":{"436":8,"897":1}}],["rangle",{"2":{"646":1}}],["range",{"2":{"26":1,"50":3,"445":1,"456":3,"457":1,"460":1,"484":1,"487":2,"493":1,"497":1,"498":1,"499":1,"500":3,"533":3,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":2,"544":1,"545":1,"546":2,"547":1,"548":1,"549":1,"556":1,"567":1,"576":1,"581":1,"632":1,"633":1,"634":3,"904":1}}],["rank",{"2":{"588":1,"589":2,"590":5,"808":2,"823":1,"827":7}}],["rand",{"2":{"443":1,"451":3,"487":1,"489":1,"497":1,"498":1,"515":1,"518":1,"519":1,"523":1,"568":1,"579":1}}],["randint`",{"2":{"556":1}}],["randint",{"2":{"428":1,"500":3,"552":1,"556":2,"567":1,"904":1}}],["randomcrop",{"2":{"556":4}}],["randomly",{"2":{"556":3}}],["random",{"0":{"401":1,"402":1,"403":1,"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"370":1,"376":1,"378":1,"379":1,"401":9,"402":1,"445":3,"497":1,"556":6,"576":4}}],["randomized",{"2":{"124":1}}],["randn",{"2":{"80":1,"81":2,"83":1,"84":6,"86":1,"87":1,"88":1,"89":1,"93":1,"94":1,"95":3,"99":2,"100":1,"101":1,"104":1,"105":2,"108":1,"112":4,"114":1,"121":2,"122":2,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"428":1,"434":1,"440":1,"441":1,"444":2,"450":3,"453":3,"454":2,"455":1,"456":6,"472":2,"493":1,"494":1,"495":2,"525":1,"526":1,"528":1,"552":1,"567":1,"569":2,"570":2,"571":2,"580":1,"904":1}}],["r^b",{"2":{"225":2,"313":2}}],["r^",{"2":{"223":2,"224":2,"225":1,"226":4,"228":1,"309":3,"311":2,"312":2,"313":1,"318":1}}],["r",{"2":{"209":4,"223":3,"226":19,"312":3,"436":1,"509":2,"545":1,"583":1,"619":1,"643":3,"647":3,"742":1,"745":1,"746":2,"753":1,"783":1,"913":1}}],["roformer",{"2":{"645":1}}],["rope",{"0":{"646":1,"648":1},"2":{"645":2,"646":1,"647":2,"648":6}}],["rotray",{"2":{"645":1}}],["rotary",{"2":{"645":2,"649":2}}],["rot90",{"2":{"445":1}}],["roll",{"2":{"445":1}}],["roles",{"2":{"889":2}}],["role",{"2":{"188":1}}],["ror",{"2":{"443":1}}],["rohan",{"2":{"420":1}}],["roy",{"2":{"420":1}}],["rounding",{"2":{"445":6,"634":1}}],["round",{"2":{"383":2,"445":4}}],["row",{"2":{"223":1,"312":1,"445":1,"581":1,"633":1}}],["roberta",{"2":{"126":1,"619":5}}],["root=",{"2":{"555":1}}],["root",{"2":{"91":2,"282":2,"556":1,"726":1,"739":2}}],["runserver",{"2":{"889":2}}],["runs",{"2":{"580":2,"904":1}}],["runtime",{"2":{"338":1,"705":1}}],["runtime期间",{"2":{"337":1}}],["running",{"2":{"86":12,"176":1,"177":1,"493":14,"567":3,"577":1}}],["run",{"2":{"50":1,"450":1,"497":2,"499":1,"529":4,"530":1,"568":1,"570":2,"571":1,"577":1,"585":1,"586":1,"590":1,"636":1,"885":1,"893":1,"895":1}}],["related",{"2":{"897":1}}],["relationship",{"2":{"724":1}}],["relative",{"2":{"643":1}}],["relu还是统治着深度学习的激活函数",{"2":{"128":1}}],["relu6",{"0":{"123":1},"2":{"123":5,"127":1}}],["relu的输出不是zero",{"2":{"122":1}}],["relu不会对数据做幅度压缩",{"2":{"122":1}}],["relu神经元坏死了",{"2":{"122":1}}],["relu在训练的时候很",{"2":{"122":1}}],["relu激活函数在",{"2":{"122":1}}],["relu被用作卷积层和全连接层之间的激活函数",{"2":{"122":1}}],["relu可以更好地处理稀疏激活和非线性特征",{"2":{"120":1}}],["relu",{"0":{"122":1},"2":{"117":1,"120":4,"122":11,"123":5,"126":1,"369":2,"445":2,"473":1,"487":1,"489":2,"497":7,"498":1,"499":1,"500":1,"513":3,"567":1,"904":2}}],["re",{"2":{"633":1,"646":1,"893":1}}],["ref",{"2":{"496":1}}],["refine",{"2":{"441":1,"445":1}}],["remain",{"2":{"905":1}}],["remainder",{"2":{"445":4}}],["remote",{"2":{"816":1}}],["removablehandle",{"2":{"496":5,"509":6}}],["remove",{"2":{"494":1,"495":1,"496":4,"873":1,"889":1}}],["reqires",{"2":{"464":1}}],["requirements",{"0":{"583":1},"2":{"583":1}}],["required",{"2":{"556":1}}],["require",{"0":{"451":1},"2":{"444":1,"451":2,"464":1,"475":1,"478":1}}],["requires",{"0":{"475":1},"2":{"440":2,"445":11,"450":2,"451":3,"452":1,"453":9,"454":3,"455":1,"456":8,"459":1,"460":2,"462":5,"464":3,"465":2,"468":1,"472":2,"474":5,"475":8,"476":1,"477":2,"478":1,"496":2}}],["requres",{"2":{"440":1}}],["requestexception",{"2":{"799":1}}],["requests",{"2":{"799":3}}],["request功能来进行代码审核",{"2":{"424":1}}],["request",{"2":{"334":1,"335":1,"422":1,"424":1}}],["renorm",{"2":{"445":2}}],["rename",{"2":{"441":5,"445":2}}],["replicate",{"2":{"496":1}}],["replace",{"2":{"456":2}}],["replace操作",{"2":{"456":1}}],["replacement",{"2":{"445":1}}],["repeat=1",{"2":{"581":2}}],["repeats",{"2":{"445":4,"581":1}}],["repeat",{"2":{"445":4}}],["represents",{"2":{"904":1}}],["representations",{"2":{"54":1,"616":1,"643":1}}],["representation",{"2":{"4":1,"496":1}}],["repr",{"2":{"441":3,"445":1,"496":3,"509":3}}],["reversed",{"2":{"441":1}}],["reward",{"2":{"441":1}}],["reinforce",{"2":{"441":1}}],["reinforcement",{"2":{"21":1,"899":1}}],["regressive",{"2":{"616":1,"620":1}}],["regnet",{"2":{"590":15}}],["regiter",{"2":{"457":1}}],["register",{"2":{"441":2,"456":1,"457":2,"490":9,"493":5,"494":1,"495":1,"496":13,"509":6}}],["regular",{"2":{"444":1}}],["regularization",{"2":{"299":1,"671":1}}],["really",{"2":{"896":1}}],["realy",{"0":{"662":1}}],["real",{"2":{"440":1,"649":2,"891":1}}],["readme",{"2":{"868":1}}],["ready=torch",{"2":{"581":1}}],["ready=trace",{"2":{"581":1}}],["ready",{"2":{"581":1}}],["read",{"2":{"232":1,"339":1,"552":2,"555":1}}],["retain",{"2":{"441":1,"445":1,"454":2,"456":2,"457":2,"459":3,"460":2}}],["retains",{"2":{"440":1,"468":1}}],["returns",{"2":{"440":2,"441":1}}],["return",{"2":{"26":3,"50":3,"86":1,"87":2,"88":1,"89":1,"215":1,"441":4,"445":31,"457":1,"458":2,"487":2,"493":1,"494":1,"495":1,"497":2,"498":4,"499":3,"500":5,"505":1,"513":1,"529":2,"530":1,"552":4,"556":4,"567":3,"571":2,"595":1,"632":1,"633":1,"634":2,"635":1,"649":2,"726":1,"823":1,"827":1,"904":1,"957":1}}],["rezero",{"2":{"406":1}}],["red",{"2":{"770":1}}],["reduction=",{"2":{"497":1}}],["reducelronplateau",{"0":{"547":1},"2":{"532":1,"547":1}}],["reduce",{"0":{"112":1},"2":{"92":1,"328":2,"441":3,"445":12,"806":1,"808":1,"827":2}}],["redix",{"2":{"338":1}}],["redisattention",{"0":{"338":1}}],["reuse",{"2":{"337":2}}],["reuse意味着具有相同前缀的不同提示可以共享中间kv",{"2":{"337":1}}],["recv",{"2":{"806":1,"808":1,"823":1}}],["recall2",{"2":{"635":2}}],["recall",{"2":{"635":2}}],["recursive",{"2":{"634":1}}],["recurse",{"2":{"496":5}}],["recurse=true",{"2":{"496":2}}],["recurrent",{"0":{"132":1,"154":1},"1":{"155":1,"156":1,"157":1},"2":{"132":1,"671":1}}],["reciprocal",{"2":{"445":2}}],["recht",{"2":{"401":1}}],["recently",{"2":{"337":1}}],["recommendation",{"2":{"900":1}}],["recompute",{"0":{"228":1,"318":1}}],["record",{"2":{"445":1,"581":1}}],["recognition",{"2":{"188":1,"897":1,"899":1,"900":1}}],["rectified",{"2":{"122":2,"124":3}}],["rest",{"2":{"889":1}}],["restart",{"2":{"885":1}}],["restarts",{"2":{"545":1,"546":2,"590":1}}],["response",{"2":{"799":4}}],["respectively",{"2":{"556":1}}],["resource>",{"2":{"727":4}}],["resources>",{"2":{"727":2}}],["resources",{"2":{"726":2,"727":1}}],["resource=",{"2":{"726":1}}],["resource",{"2":{"680":2,"681":1,"726":2}}],["resolve",{"2":{"445":2}}],["resnext50",{"2":{"590":1}}],["resnext101",{"2":{"590":1}}],["resnet34",{"2":{"590":1}}],["resnet152",{"2":{"590":1}}],["resnet101",{"2":{"590":2}}],["resnet18",{"2":{"528":1,"585":1,"586":1,"590":2}}],["resnet50",{"2":{"579":1,"580":2,"588":1,"589":2,"590":2}}],["resnet",{"2":{"376":1,"403":1,"580":1,"582":1,"585":1}}],["resume",{"2":{"590":2}}],["resulttype",{"2":{"730":1}}],["resulttype=",{"2":{"726":1,"730":3}}],["result",{"2":{"441":1,"444":1,"458":5,"472":3,"496":1,"556":1,"958":2}}],["results",{"2":{"86":3,"87":3,"88":3,"89":3,"799":4}}],["rescale",{"2":{"556":6}}],["resize",{"2":{"441":3,"445":6,"556":1}}],["researchers",{"2":{"899":1}}],["research",{"0":{"899":1},"2":{"421":1,"891":1,"905":1}}],["reset",{"2":{"156":2,"571":2,"904":2}}],["res",{"2":{"84":2}}],["reshapes",{"2":{"98":1}}],["reshape",{"0":{"97":1,"98":1},"1":{"98":1,"99":1,"100":1,"101":1},"2":{"50":4,"89":1,"98":2,"110":1,"436":1,"437":1,"438":1,"445":3,"460":2,"484":2,"487":2,"499":4,"580":1,"649":2}}],["并确保库文件路径和头文件路径正确设置",{"2":{"822":1}}],["并管理各个进程之间的通信",{"2":{"822":1}}],["并自动添加",{"2":{"822":1}}],["并行",{"2":{"803":1}}],["并行的类型",{"0":{"800":1},"1":{"801":1,"802":1}}],["并行的实际案例",{"0":{"799":1}}],["并行的引入",{"0":{"795":1},"1":{"796":1,"797":1,"798":1,"799":1}}],["并行有啥用",{"0":{"798":1}}],["并行计算可以在不同的硬件架构上实现",{"2":{"799":1}}],["并行计算变得愈发重要",{"2":{"797":1}}],["并行计算",{"2":{"797":2}}],["并行运行与顺序运行不同数量的试验不会产生统计上不同的结果",{"2":{"401":1}}],["并尝试使用远程连接工具连接访问",{"2":{"735":1,"794":1}}],["并尝试通过反复查看各种超参数轴图来校准我们的直觉",{"2":{"374":1}}],["并保证程序按预期执行",{"2":{"676":1}}],["并构建一个计算图的表示形式",{"2":{"563":1}}],["并构建表示计算梯度的函数的图",{"2":{"471":1}}],["并生成高效的机器代码",{"2":{"560":1}}],["并理解其含义",{"2":{"550":1}}],["并接收里程碑点列表",{"2":{"549":1}}],["并通过gpu并行化显著提高了执行效率",{"2":{"859":1}}],["并通过底层网络协议",{"2":{"822":1}}],["并通过一次调用执行它们各自的连续step",{"2":{"548":1}}],["并通过额外的预训练阶段来适应新的结构",{"2":{"220":1,"306":1}}],["并一次性执行大块的计算",{"2":{"510":1}}],["并进行大块的计算",{"2":{"510":1}}],["并进行了1000次warmup",{"2":{"409":1}}],["并应用上述点",{"2":{"473":1}}],["并应用激活函数",{"2":{"444":1}}],["并可帮助您进行调试",{"2":{"470":1}}],["并返回变换后的张量",{"2":{"444":1}}],["并返回",{"2":{"441":1}}],["并找到最佳的学习率",{"2":{"405":1}}],["并非总是可以回滚到旧的实现",{"2":{"401":1}}],["并非",{"2":{"400":1}}],["并非所有的任务和网络都能从零中心激活函数中受益",{"2":{"120":1}}],["并只保存第一个设备的ema",{"2":{"394":1}}],["并回顾性地从中选择最佳检查点",{"2":{"392":1}}],["并仍然产生准确的估计",{"2":{"391":1}}],["并定期在训练和评估之间交替",{"2":{"390":1}}],["并像",{"2":{"385":1}}],["并尽可能地减少对最终长时间运行的影响",{"2":{"383":1}}],["并尽可能轻松地找到每项研究中最好的几次试验并检查它们的训练曲线",{"2":{"377":1}}],["并重新训练通过贝叶斯优化找到的最佳配置",{"2":{"379":1}}],["并重用其",{"2":{"338":1}}],["并决定了哪些超参数甚至应该被调整",{"2":{"379":1}}],["并最终选择不同的超参数值",{"2":{"378":1}}],["并偏向那些不会出现过拟合问题的配置",{"2":{"375":1}}],["并试图了解有多少点位于搜索空间的",{"2":{"374":1}}],["并允许每个冗余超参数有尽可能大的值域",{"2":{"371":1}}],["并允许任意大的上下文大小",{"2":{"327":1}}],["并设置",{"2":{"370":2}}],["并随着我们理解的深度不断更新我们的搜索空间",{"2":{"365":1}}],["并没有具体模板",{"2":{"969":1}}],["并没有显著更新",{"2":{"648":1}}],["并没有后来常见的relu函数等",{"2":{"245":1}}],["并没阻止学习到有效特征",{"2":{"348":1}}],["并响应",{"2":{"338":1}}],["并结合了一个缓存感知调度策略",{"2":{"337":1}}],["并具有易于使用的接口",{"2":{"335":1}}],["并避免频繁动态调整节点分区",{"2":{"329":1}}],["并减少了与",{"2":{"329":1}}],["并为长上下文prefill实现了分块管道并行性",{"2":{"329":1}}],["并在虚拟角色中实现高精度的面部表情再现",{"2":{"859":1}}],["并在每个进程中运行",{"2":{"822":1}}],["并在每次替换前确认",{"2":{"787":1}}],["并在",{"2":{"619":1}}],["并在后续的转换过程中进行类型检查",{"2":{"563":1}}],["并在模型的其他部分中进行访问",{"2":{"496":1}}],["并在读取时将其解包为不同的张量",{"2":{"472":1}}],["并在开始时延长恒定的lr期",{"2":{"385":1}}],["并在最终长时间训练后再进行验证和确认",{"2":{"383":1}}],["并在分桶定义的每个垂直切片中取最佳试验来近似绘制隔离图",{"2":{"376":1}}],["并在此过程中学到了很多东西",{"2":{"353":1}}],["并在现代神经网络继续保持显著特色",{"2":{"345":1}}],["并在过去两个月部署在chatbot",{"2":{"332":1}}],["并在调整期间考虑缓存重用利用率和slo要求违规等指标时使conductor的设计复杂化",{"2":{"329":1}}],["并在ring",{"2":{"329":1}}],["并在计算和通信之间取得最佳折衷来实现最佳性能",{"2":{"328":1}}],["并在gpu之间实现最佳负载平衡",{"2":{"328":1}}],["并在反向过程中再次收集kv",{"2":{"328":1}}],["并有助于跳过局部极小点",{"2":{"267":1}}],["并写出到hbm",{"2":{"226":1}}],["并将每个计算得到的坐标点向下取整后绘制出来",{"2":{"839":1}}],["并将结果返回给主进程",{"2":{"811":1}}],["并将结果reduce",{"2":{"226":1}}],["并将用作该组的优化选项",{"2":{"504":1}}],["并将与参数一起保存",{"2":{"493":1}}],["并将最后两个维度进行转置",{"2":{"445":1}}],["并将在不久的将来进行更改",{"2":{"444":1}}],["并将复现该论文中的模型作为起点",{"2":{"355":1}}],["并将其转换为一个可重放的跟踪模型",{"2":{"564":1}}],["并将其插入树中",{"2":{"338":1}}],["并将其写入",{"2":{"224":1,"311":1}}],["并将注意力计算的输出写回hbm",{"2":{"222":1,"314":1}}],["并将它们加载到快速的片上sram上",{"2":{"222":1,"314":1}}],["并将所有注意力操作融合到一个gpu内核中",{"2":{"222":1,"314":1}}],["并对输入块进行多次处理",{"2":{"222":1,"311":1}}],["并再次映射",{"2":{"208":1}}],["并与用户进行自然语言交互",{"2":{"188":1}}],["并提高系统的性能和效率",{"2":{"338":1}}],["并提高生成文本的语义质量",{"2":{"180":1}}],["并提出了一种新的激活函数",{"2":{"127":1}}],["并使用",{"2":{"472":1}}],["并使用上面讨论中选择的最佳检查点来将这个实验与baseline进行比较",{"2":{"409":1}}],["并使用验证误差作为评估指标",{"2":{"401":1}}],["并使用随机搜索来调整超参数",{"2":{"401":1}}],["并使用搜索算法在单个研究中对两种超参数的值进行采样",{"2":{"370":1}}],["并使用前一步的输出作为下一步的输入",{"2":{"167":1}}],["并使用索引来检索它们",{"2":{"113":1}}],["并且还能够包容他们",{"2":{"878":1}}],["并且改名为mybatis",{"2":{"721":1}}],["并且尽可能占满整个空间的位置",{"2":{"656":1}}],["并且通常来说会进行截断",{"2":{"643":1}}],["并且通过适当的调整",{"2":{"380":1}}],["并且对小众的语言也能生成高质量的翻译",{"2":{"621":1}}],["并且放弃了",{"2":{"619":1}}],["并且与完整的预训练相比",{"2":{"617":1}}],["并且几乎在所有",{"2":{"616":1}}],["并且中间的",{"2":{"609":1}}],["并且在两者上都实现了最优性能",{"2":{"621":1}}],["并且在执行过程中不会改变",{"2":{"559":1}}],["并且在设计中没有明确使用异步性和低精度",{"2":{"325":1}}],["并且用户没有指定任何与实现相关的",{"2":{"510":1}}],["并且所有参数都将使用动量",{"2":{"504":1}}],["并且所有的参数会原样传递给torch",{"2":{"496":1}}],["并且应包含一个",{"2":{"504":1}}],["并且接口足够通用",{"2":{"501":1}}],["并且如果被修改的输入的存储被其他张量引用",{"2":{"481":1}}],["并且如果表现最好的试验在该区域的边缘具有学习率",{"2":{"373":1}}],["并且您不打算在后续的自动求导记录的计算中使用在推断模式下创建的张量时",{"2":{"479":1}}],["并且输出会保持与自动求导图的关联",{"2":{"445":1}}],["并且这些不确定性可能存在着正则化效果",{"2":{"412":1}}],["并且这些tensor保留在gpu内存中以生成下一个token",{"2":{"333":1}}],["并且",{"2":{"411":1,"412":1}}],["并且搜索点更为分散",{"2":{"401":1}}],["并且计算成本很高",{"2":{"389":1}}],["并且计算效率是关键因素",{"2":{"385":1}}],["并且检查点足够频繁",{"2":{"381":1}}],["并且已经过充分采样",{"2":{"379":1}}],["并且我们是使用quasi",{"2":{"376":1}}],["并且我们无法进行大量相对独立的研究",{"2":{"370":1}}],["并且范围要足够小",{"2":{"367":2}}],["并且训练步数足够",{"2":{"357":1}}],["并且不应该被直接用于调整验证集性能",{"2":{"357":1}}],["并且能在新输入上泛化好的算法",{"2":{"340":1}}],["并且可以根据不同的输入数据进行灵活的控制流操作",{"2":{"559":1}}],["并且可以使用训练误差作为评估指标",{"2":{"401":1}}],["并且可以很容易地为各种感兴趣的模型执行训练和预测工作",{"2":{"354":1}}],["并且可以有效地控制模型的过拟合",{"2":{"341":1}}],["并且可以更有效地利用多个节点的处理能力",{"2":{"329":1}}],["并且可以在八个p100",{"2":{"193":1}}],["并且键",{"2":{"327":1}}],["并且也不直接存储这些项",{"2":{"287":1}}],["并且继续沿该方向移动",{"2":{"263":1}}],["并且梯度不会出现弥散现象",{"2":{"243":1}}],["并且使用的内存量与序列长度呈线性关系",{"2":{"222":1,"314":1}}],["并且需要加载的数据量减少了h倍",{"2":{"219":1,"305":1}}],["并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出",{"2":{"133":1}}],["并且保持每个图像实例之间的独立",{"2":{"88":1}}],["并不意味我们只能通过更长",{"2":{"380":1}}],["并不严谨",{"2":{"61":1}}],["并不影响结果",{"2":{"21":1}}],["并用膨胀率参数",{"2":{"60":1}}],["并用于分类",{"2":{"4":1}}],["并产生输出",{"2":{"24":1}}],["8gf",{"2":{"590":2}}],["86sj",{"2":{"584":1}}],["81",{"2":{"549":1}}],["8101",{"2":{"112":1}}],["800mf",{"2":{"590":2}}],["80",{"2":{"492":2,"533":1,"538":3}}],["8bit",{"2":{"433":1}}],["8倍的加速",{"2":{"322":1}}],["8us",{"2":{"217":1,"303":1}}],["88109∗0",{"2":{"45":2}}],["88109",{"2":{"45":4}}],["891090×",{"2":{"46":2}}],["891090",{"2":{"41":5,"45":9,"46":7}}],["891090out",{"2":{"41":1}}],["8",{"0":{"21":1,"58":1,"103":1,"104":1,"105":1,"106":1,"107":1,"128":1,"158":1,"192":1,"214":1,"215":1,"216":1,"253":1,"290":1,"291":1,"292":1,"318":1,"328":1,"442":1,"443":1,"444":1,"445":1,"457":1,"469":1,"542":1,"715":1,"762":1,"791":1,"812":1,"958":1},"1":{"104":1,"105":1,"106":1,"107":1,"215":1,"216":1,"291":1,"292":1,"443":1,"444":1,"445":1,"763":1,"792":1,"793":1},"2":{"45":1,"46":1,"47":1,"95":1,"99":1,"107":1,"111":3,"338":3,"409":1,"436":1,"497":1,"719":2,"726":2,"947":1}}],["70",{"2":{"939":1}}],["702",{"2":{"126":1}}],["702x",{"2":{"126":2}}],["78",{"2":{"904":1}}],["784",{"2":{"655":1,"904":3}}],["72",{"2":{"634":1,"635":1}}],["729",{"2":{"548":1,"549":1}}],["755",{"2":{"746":1}}],["75",{"2":{"590":1}}],["7bit",{"2":{"433":1}}],["7b展示了以5",{"2":{"408":1}}],["7b",{"2":{"408":1}}],["7b在nvidia",{"2":{"332":1}}],["7a",{"2":{"408":2}}],["7gb的空间",{"2":{"333":1}}],["768x768",{"2":{"608":1}}],["768",{"2":{"328":21}}],["77",{"2":{"223":1,"312":1}}],["7us和1",{"2":{"217":1,"303":1}}],["7x7",{"2":{"95":1}}],["7x",{"2":{"50":1}}],["7",{"0":{"20":1,"36":1,"50":1,"57":1,"102":1,"127":1,"141":1,"154":1,"155":1,"156":1,"157":1,"187":1,"188":1,"189":1,"190":1,"191":1,"213":1,"246":1,"247":1,"248":1,"249":1,"250":1,"251":1,"252":1,"286":1,"287":1,"288":1,"289":1,"317":1,"326":1,"327":1,"349":1,"441":1,"456":1,"468":1,"481":1,"541":1,"581":1,"622":1,"714":1,"758":1,"788":1,"811":1,"957":1},"1":{"155":1,"156":1,"157":1,"188":1,"189":1,"190":1,"191":1,"247":1,"248":1,"249":1,"250":1,"251":2,"252":2,"287":1,"288":1,"289":1,"327":1,"759":1,"760":1,"761":1,"789":1,"790":1},"2":{"41":1,"43":1,"44":3,"45":3,"46":1,"47":7,"50":3,"95":3,"107":1,"111":4,"294":1,"322":1,"338":1,"497":3,"620":1,"634":13}}],["不吃面经咋活",{"0":{"962":1}}],["不大于胃口",{"2":{"961":1}}],["不影响你正常理解算法思维",{"2":{"950":1}}],["不妨继续往下看看",{"2":{"948":1}}],["不妨选择他们的中点",{"2":{"844":1}}],["不放弃",{"2":{"880":1}}],["不放在",{"2":{"868":1}}],["不抛弃",{"2":{"880":1}}],["不解之言",{"0":{"879":1}}],["不愠",{"2":{"878":2}}],["不自觉的产物",{"2":{"878":1}}],["不然为何称他为",{"2":{"878":1}}],["不亦君子乎",{"2":{"877":1}}],["不亦乐乎",{"2":{"877":1}}],["不亦说乎",{"2":{"877":1,"878":1}}],["不吹嘘",{"2":{"875":1}}],["不拖拉",{"2":{"875":1}}],["不适用于共享内存架构",{"2":{"812":1}}],["不共享内存",{"2":{"805":1}}],["不让空闲",{"2":{"798":1}}],["不懂就问ai或者浏览器",{"2":{"794":1}}],["不保存更改",{"2":{"777":1}}],["不保存",{"2":{"777":1}}],["不保存退出",{"2":{"751":1}}],["不写的话不会提交到数据库",{"2":{"731":1,"732":1,"733":1}}],["不用抱怨这一切",{"2":{"878":1}}],["不用mybatis依旧可以做到",{"2":{"724":1}}],["不用担心它们之间的重叠",{"2":{"328":1}}],["不管是从中学的书本还是后来自己的钻研",{"2":{"878":1}}],["不管是单核单处理器",{"2":{"798":1}}],["不管",{"2":{"643":1}}],["不管一个给定的工作负载是否是计算约束",{"2":{"380":1}}],["不再依赖于动态图和python解释器",{"2":{"563":1}}],["不再对任何数据有所响应",{"2":{"122":1}}],["不仅仅是动态图",{"0":{"558":1}}],["不是也不是时间远",{"2":{"878":1}}],["不是亲戚朋友",{"2":{"878":1}}],["不是字典类型的话",{"2":{"508":1}}],["不是一个参数",{"2":{"493":1}}],["不能写错",{"2":{"726":1}}],["不能同时进入关于同一组共享变量的临界区域",{"2":{"678":1}}],["不能直接求",{"2":{"659":1}}],["不能跟别的类别的高斯中心离得太近",{"2":{"657":1}}],["不能为空",{"2":{"508":1}}],["不能看见未来的信息",{"2":{"216":1}}],["不满足这些属性的对象的示例包括集合",{"2":{"507":1}}],["不要对一件没有做过的事儿说没有意义",{"2":{"880":1}}],["不要过度分散注意力",{"2":{"831":1}}],["不要传递一个",{"2":{"504":1}}],["不要在训练中调整",{"2":{"381":1}}],["不需要单独设置参数类型",{"2":{"730":1}}],["不需要掌握",{"0":{"470":1},"1":{"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1}}],["不需要每次循环都进行缩放",{"2":{"321":1}}],["不释放",{"2":{"464":1}}],["不释放tensor的梯度",{"2":{"457":1}}],["不考虑学习率衰减的固定学习率",{"2":{"405":1}}],["不平衡的数据集",{"2":{"391":1}}],["不太可能完美迁移",{"2":{"384":1}}],["不太可能转移",{"2":{"384":1}}],["不值得这样做",{"2":{"378":1}}],["不值得部署",{"2":{"363":1}}],["不受计算限制",{"2":{"375":1}}],["不受其约束",{"2":{"89":1}}],["不幸运",{"2":{"375":1}}],["不幸的是",{"2":{"358":1,"371":1,"411":1,"473":1}}],["不可行",{"2":{"373":1,"408":1}}],["不可避免地",{"2":{"353":1}}],["不良的搜索空间边界和可接受的搜索空间边界示例",{"2":{"373":1}}],["不运行任何实验",{"2":{"359":1}}],["不做近似地完成超长",{"2":{"326":1}}],["不像adam",{"2":{"294":1}}],["不容易受到单个样本或噪声的影响",{"2":{"260":1}}],["不合理初始化的问题",{"0":{"236":1}}],["不断改进生产中使用的模型",{"2":{"365":1}}],["不断重复上述过程",{"2":{"184":1}}],["不断地将前一个时刻",{"2":{"168":1}}],["不一定全局最优",{"2":{"183":1}}],["不确定具体长度",{"2":{"165":1}}],["不过也算是基础了解pytorch吧",{"2":{"890":1}}],["不过我可以跟你说",{"2":{"878":1}}],["不过孔子先生更厉害",{"2":{"878":1}}],["不过这里有一个字需要特别强调",{"2":{"723":1}}],["不过这里采用了cfg",{"2":{"608":1}}],["不过",{"2":{"128":1,"510":1}}],["不重要",{"2":{"126":1}}],["不会影响梯度计算",{"2":{"452":1}}],["不会消失",{"2":{"122":1}}],["不会发生梯度消失问题",{"2":{"122":1}}],["不包含9",{"2":{"111":1}}],["不包含7",{"2":{"111":1}}],["不依赖minibatch",{"2":{"90":1}}],["不同商家之间的视野",{"0":{"875":1},"2":{"871":1}}],["不同情况的位置确定是如何的呢",{"2":{"844":1}}],["不同于常规位置编码对将",{"2":{"644":1}}],["不同于rnn",{"2":{"638":1}}],["不同stage的attention模块是固定attention",{"2":{"608":1}}],["不同实现与性能优化",{"0":{"510":1}}],["不同",{"2":{"328":1,"823":1}}],["不同优化算法效果对比",{"0":{"290":1},"1":{"291":1,"292":1}}],["不同维度的参数会得到相同的更新",{"2":{"237":1}}],["不同维度的两个tensor",{"2":{"108":1}}],["不同词汇是怎么流畅地组合成句子的",{"2":{"190":1}}],["不同的",{"2":{"878":1}}],["不同的线程可以并行执行",{"2":{"796":1}}],["不同的后缀名",{"2":{"516":1}}],["不同的优化器类之间其内容可能不同",{"2":{"509":1}}],["不同的学习率在不同的时间效果最好",{"2":{"397":1}}],["不同的随机初始化",{"2":{"378":1}}],["不同的模型架构可能允许更大的batch",{"2":{"358":1}}],["不同的输入样本有不同的均值和方差",{"2":{"87":1}}],["不同的训练参数",{"2":{"48":1}}],["不同参数l",{"2":{"60":1}}],["不同神经元的感知区域相互重叠从而覆盖整个视野",{"2":{"51":1}}],["不同点",{"0":{"19":1}}],["不光滑等不太好的性质",{"2":{"9":1}}],["数值微分法",{"0":{"838":1},"1":{"839":1,"840":1,"841":1,"842":1}}],["数量也为",{"2":{"609":1}}],["数量分别为",{"2":{"609":1}}],["数组",{"2":{"441":1,"708":1}}],["数学过程",{"0":{"933":1,"939":1,"943":1,"947":1}}],["数学挂钩",{"2":{"916":1}}],["数学表达式为",{"2":{"244":1}}],["数学表达为",{"2":{"244":1}}],["数学公式为",{"0":{"200":1}}],["数学公式",{"2":{"121":1}}],["数学模型",{"2":{"11":1}}],["数据可视化等众多领域都有广泛应用",{"2":{"858":1}}],["数据大小",{"2":{"823":1}}],["数据收集",{"2":{"808":1}}],["数据收集和抽样方差",{"2":{"378":1}}],["数据散播",{"2":{"808":1}}],["数据分析",{"2":{"797":1,"868":1}}],["数据取出时的封装",{"2":{"724":1}}],["数据持久功能大多是必不可少的组成部分",{"2":{"723":1}}],["数据持久化往往也就意味着将内存中的数据保存到磁盘上加以固化",{"2":{"723":1}}],["数据访问对象",{"2":{"723":1}}],["数据库的建立连接等等",{"2":{"724":1}}],["数据库优化",{"2":{"717":1}}],["数据库基础",{"0":{"709":1}}],["数据同步指一个数据集的多份拷贝一致以维护完整性",{"2":{"677":1}}],["数据生成",{"0":{"653":1}}],["数据压缩与数据生成的关系",{"0":{"654":1}}],["数据压缩也可以成为数据降维",{"2":{"652":1}}],["数据压缩",{"0":{"652":1}}],["数据压缩和数据生成",{"0":{"651":1},"1":{"652":1,"653":1,"654":1,"655":1,"656":1,"657":1}}],["数据准备",{"2":{"484":1,"497":1}}],["数据准备和预处理方面",{"2":{"18":1}}],["数据类型和标签等信息",{"2":{"806":1}}],["数据类型",{"2":{"445":1,"706":1,"708":1,"809":1}}],["数据类型转化为",{"2":{"445":1}}],["数据类型转化为float",{"2":{"443":1}}],["数据类型转化",{"0":{"433":1},"2":{"433":1}}],["数据未与训练进程存放在同一位置",{"2":{"387":1}}],["数据增强方法",{"2":{"384":1}}],["数据增强操作的模式和并行运算的顺序",{"2":{"378":1}}],["数据清理等基本工作已经完成",{"2":{"354":1}}],["数据清洗",{"2":{"18":1}}],["数据集上进行了预训练",{"2":{"620":1}}],["数据集下载",{"0":{"584":1},"2":{"613":1}}],["数据集增强",{"0":{"344":1}}],["数据集规模相对较小",{"2":{"341":1}}],["数据并行模式",{"2":{"811":1}}],["数据并行",{"2":{"328":1}}],["数据处理也异常繁琐",{"2":{"190":1}}],["数据",{"2":{"55":1,"484":1,"617":1}}],["数据标签",{"2":{"18":1}}],["相信通过以上简单的几个例子",{"2":{"948":1}}],["相信也会遇到那个跨越时空的的知己",{"2":{"878":1}}],["相信大家也能够理解我想说什么了",{"2":{"878":1}}],["相结合",{"2":{"616":1}}],["相同的",{"2":{"472":1}}],["相同的数据指针创建一个",{"2":{"445":1}}],["相同点",{"0":{"18":1}}],["相邻元素在空间上共享语义信息",{"2":{"348":1}}],["相较于hf",{"2":{"332":1}}],["相应地",{"2":{"328":1}}],["相当于",{"2":{"781":1}}],["相当于阻止了其跨度太大",{"2":{"269":1}}],["相当于是将卷积核转换为稀疏矩阵后",{"2":{"61":1}}],["相反",{"2":{"235":1,"338":1,"353":1}}],["相比sd",{"2":{"608":1}}],["相比原来的text",{"2":{"608":1}}],["相比于",{"2":{"510":1}}],["相比于adagrad",{"2":{"283":1}}],["相比于bgd",{"2":{"262":1}}],["相比于非零中心的激活函数",{"2":{"120":1}}],["相比之下",{"2":{"228":1,"318":1,"369":1,"401":1}}],["相比",{"2":{"125":1,"401":1}}],["相比较其他深度",{"2":{"51":1}}],["相互连接",{"2":{"117":1}}],["相对位置并没有完整建模每个输入的位置信息",{"2":{"642":1}}],["相对位置编码是由绝对位置编码启发而来",{"2":{"643":1}}],["相对位置编码起源于google的论文",{"2":{"643":1}}],["相对位置编码",{"0":{"642":1},"1":{"643":1,"644":1}}],["相对应的是",{"2":{"477":1}}],["相对快速",{"2":{"363":1}}],["相对于y0",{"2":{"659":1}}],["相对于",{"0":{"324":1}}],["相对于bgd需要存储整个训练数据集的梯度以及sgd需要存储单个样本的梯度",{"2":{"262":1}}],["相对于gpt",{"2":{"222":1,"314":1}}],["相对",{"2":{"74":1}}],["相关知识",{"0":{"910":1}}],["相关的工具",{"2":{"822":1}}],["相关性指的是调整结果与最终长时间运行之间的相似性",{"2":{"383":1}}],["相关性和彻底性",{"2":{"383":1}}],["相关",{"0":{"84":1,"124":1}}],["相关软件库",{"0":{"72":1},"1":{"73":1,"74":1,"75":1}}],["相关概念",{"0":{"1":1},"1":{"2":1,"3":1,"4":1,"5":1,"6":1}}],["6b",{"2":{"620":2}}],["6gf",{"2":{"590":2}}],["60",{"2":{"537":2,"619":1,"620":1}}],["6m",{"2":{"518":1}}],["6f",{"2":{"497":1}}],["6ni^",{"2":{"252":1}}],["6ni",{"2":{"252":1}}],["6nj+nj+1",{"2":{"245":1}}],["6倍的加速",{"2":{"222":1,"314":1}}],["6倍",{"2":{"222":1,"314":1}}],["671",{"2":{"128":1}}],["6732λ≈1",{"2":{"125":1}}],["6732",{"2":{"125":2}}],["6hardswish",{"2":{"127":1}}],["64×32×3×3=1843264",{"2":{"248":1}}],["6420",{"2":{"112":1}}],["64",{"2":{"63":1,"95":3,"227":1,"248":1,"249":1,"317":1,"328":16,"394":1,"497":5,"498":1,"500":1,"513":1,"580":4,"904":2}}],["662866",{"2":{"48":3}}],["6561",{"2":{"548":1}}],["6548",{"2":{"112":1}}],["6538",{"2":{"112":1}}],["653688",{"2":{"47":2}}],["653688w",{"2":{"47":1}}],["65",{"2":{"47":3,"50":2,"460":1}}],["6×0",{"2":{"41":2}}],["6",{"0":{"17":1,"18":1,"19":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"49":1,"56":1,"91":1,"97":1,"98":1,"99":1,"100":1,"101":1,"126":1,"140":1,"144":1,"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1,"182":1,"183":1,"184":1,"185":1,"186":1,"212":1,"228":1,"245":1,"281":1,"282":1,"283":1,"284":1,"285":1,"316":1,"325":1,"348":1,"440":1,"455":1,"467":1,"476":1,"477":1,"478":1,"479":1,"480":1,"496":1,"527":1,"528":1,"529":1,"530":1,"540":1,"580":1,"599":1,"607":1,"608":1,"609":1,"610":1,"621":1,"657":1,"702":1,"713":1,"734":1,"754":1,"785":1,"810":1,"829":1,"830":1,"831":1,"956":1},"1":{"18":1,"19":1,"31":1,"32":1,"33":1,"34":1,"35":1,"98":1,"99":1,"100":1,"101":1,"145":1,"146":1,"147":2,"148":2,"149":2,"150":2,"151":2,"152":1,"153":1,"183":1,"184":1,"185":1,"186":1,"283":1,"284":1,"285":1,"477":1,"478":1,"479":1,"480":1,"528":1,"529":1,"530":1,"608":1,"609":1,"755":1,"756":1,"757":1,"786":1,"787":1},"2":{"41":1,"46":1,"47":1,"50":3,"89":9,"107":1,"111":4,"112":2,"113":1,"123":3,"127":1,"196":1,"197":1,"245":2,"252":4,"338":2,"369":1,"407":1,"436":2,"440":1,"452":1,"460":1,"474":1,"497":1,"947":1}}],["第三句或许在未来我也能够书写进去",{"2":{"878":1}}],["第三句的",{"2":{"878":1}}],["第三层权重修改",{"2":{"29":1}}],["第三层计算",{"2":{"16":1}}],["第2种",{"2":{"734":1}}],["第1种",{"2":{"734":1}}],["第1000次迭代结果",{"2":{"48":1}}],["第100次迭代结果",{"2":{"48":1}}],["第10次迭代结果",{"2":{"48":1}}],["第几次循环",{"2":{"553":1}}],["第一个发射分数",{"2":{"632":1}}],["第一个模型继续按标准",{"2":{"619":1}}],["第一个子层是一个multi",{"2":{"196":1}}],["第一轮",{"0":{"384":1},"2":{"383":1}}],["第一层",{"2":{"49":1}}],["第一层求解",{"0":{"40":1}}],["第一层权重修改",{"2":{"29":1}}],["第一层计算",{"2":{"16":1}}],["第二句",{"2":{"878":1}}],["第二部分会详细讲解vim操作命令",{"2":{"750":1}}],["第二项",{"2":{"643":1}}],["第二轮",{"0":{"385":1},"2":{"383":1,"385":1}}],["第二个模型",{"2":{"619":1}}],["第二个聊天会话继续",{"2":{"338":1}}],["第二个子层是一个简单的",{"2":{"196":1}}],["第二个参数",{"2":{"52":1}}],["第二层",{"2":{"49":1}}],["第二层权重修改",{"2":{"29":1}}],["第二层计算",{"0":{"41":1},"2":{"16":1}}],["案例演示",{"2":{"827":1}}],["案例",{"0":{"566":1},"1":{"567":1,"568":1,"569":1},"2":{"15":1,"799":1}}],["水等效果",{"2":{"857":1}}],["水平分屏",{"2":{"790":1}}],["水管网络中",{"2":{"15":1}}],["水管网络的层数",{"2":{"15":1}}],["水流",{"2":{"15":1}}],["而每块饼干只能给一个小孩",{"2":{"951":1}}],["而你有",{"2":{"943":1}}],["而现在的教育体系和教育方式",{"2":{"917":1}}],["而我们也可以从中学到更多解决问题的思维方式",{"2":{"927":1}}],["而我们日常生活中做的很多事情",{"2":{"916":1}}],["而我们的思维方式中也经常蕴含着算法",{"2":{"916":1}}],["而我们的耐心和计算资源就成为了限制因素",{"2":{"383":1}}],["而正是这里所言",{"2":{"878":1}}],["而志于学",{"2":{"878":1}}],["而持久化的实现过程则大多通过各种关系数据库来完成",{"2":{"723":1}}],["而这跟计算机里的",{"2":{"919":1}}],["而这些共用资源又无法同时被多个线程访问的特性",{"2":{"682":1}}],["而这些并发进程必须有好的解决方案",{"2":{"681":1}}],["而这些模块在训练模式下可能表现不同",{"2":{"480":1}}],["而这一个f关于概率密度函数的",{"2":{"659":1}}],["而给出的数据可能是一个或多个随机数",{"2":{"653":1}}],["而数据经过降维以后",{"2":{"652":1}}],["而目前很火的",{"2":{"645":1}}],["而之前的",{"2":{"609":1}}],["而非用于实际的模型执行",{"2":{"562":1}}],["而非线性可分问题的数据集包含两种以上的类别",{"2":{"11":1}}],["而参数本身不会被保存",{"2":{"509":1}}],["而原地操作需要更改表示该操作的函数的所有输入的创建者",{"2":{"481":1}}],["而根节点是输出张量",{"2":{"471":1}}],["而虚部取负值",{"2":{"440":1}}],["而残差大大增加了训练参的敏感性",{"2":{"406":1}}],["而彻底性则指调整结果的详尽程度",{"2":{"383":1}}],["而对不同目标超参数值进行了不公平的比较",{"2":{"371":1}}],["而对于一些有明显的上下文特征的序列化输入",{"2":{"132":1}}],["而将",{"2":{"369":1}}],["而偏重于基本原理",{"2":{"353":1}}],["而序列长度具有极大的变化和不可预测性",{"2":{"333":1}}],["而key",{"2":{"327":1}}],["而无需重新开始整个训练过程",{"2":{"521":1}}],["而无需复制存储空间",{"2":{"496":1}}],["而无需进行任何模型架构更改",{"2":{"332":1}}],["而无需增加额外开销",{"2":{"327":1}}],["而无法达到全局最优解",{"2":{"261":1}}],["而其它方法要么很慢",{"2":{"292":1}}],["而其他的候选项会被淘汰",{"2":{"186":1}}],["而其他的候选项会被丢弃",{"2":{"186":1}}],["而adadelta只累加固定大小的项",{"2":{"287":1}}],["而具有小偏导的参数在学习率上有相对较小的下降",{"2":{"277":1}}],["而在较短的训练时间内得出的结论可能不能完全适用于长时间训练后的模型",{"2":{"383":1}}],["而在正向传播中只需要执行2次矩阵乘法",{"2":{"316":1}}],["而在bp的时候",{"2":{"237":1}}],["而在具体任务上进行微调",{"2":{"180":1}}],["而过小的初始值则相反",{"2":{"236":1}}],["而收敛结果实际上又很大程度取决于网络参数的最开始的初始化",{"2":{"235":1}}],["而模型的flops和参数随着模型维度的平方增加",{"2":{"219":1,"305":1}}],["而gqa",{"2":{"219":1,"305":1}}],["而gap对整个特征图求平均值",{"2":{"95":1}}],["而语言模型则侧重于学习一种语言内部的语法结构",{"2":{"190":1}}],["而后者",{"2":{"190":1}}],["而且不想了解编程",{"2":{"950":1}}],["而且需要管理员权限",{"2":{"889":1}}],["而且只是二十出头的我的理解",{"2":{"878":1}}],["而且在",{"2":{"878":1}}],["而且还要让这些商品的价值尽可能的大",{"2":{"967":1}}],["而且还",{"2":{"878":1}}],["而且有点搞笑",{"2":{"878":1}}],["而且维持成本也高",{"2":{"722":1}}],["而且没有现在的云原生",{"2":{"702":1}}],["而且没有联系感",{"2":{"698":1}}],["而且内容较为浅显",{"2":{"698":1}}],["而且时间和经济成本都非常高",{"2":{"617":1}}],["而且可以使用恒定的学习率更新策略来实现",{"2":{"382":1}}],["而且越错越离谱",{"2":{"177":1}}],["而且这个神经元有可能再也不会被任何数据激活",{"2":{"122":1}}],["而工程上通常使用luong",{"2":{"174":1}}],["而输出的y序列就是一段句子",{"2":{"164":1}}],["而不考虑未来的其他情况",{"2":{"929":1}}],["而不用反复思考",{"2":{"921":1}}],["而不一定考虑未来可能的影响",{"2":{"921":1}}],["而不原地操作只是分配新的对象并保留对旧计算图的引用",{"2":{"481":1}}],["而不会被自动求导记录",{"2":{"478":1}}],["而不需要重新运行任何实验",{"2":{"401":1}}],["而不必浪费大量的计算资源和时间在不优秀的超参数上",{"2":{"383":1}}],["而不仅仅是碰运气找到的配置",{"2":{"365":1}}],["而不敏感于其他",{"2":{"276":1}}],["而不能依赖",{"2":{"216":1}}],["而不是开始就借用别的人话",{"2":{"917":1}}],["而不是基于",{"2":{"609":1}}],["而不是",{"2":{"510":1,"723":1}}],["而不是仅仅一个算子",{"2":{"465":1}}],["而不是一个",{"2":{"441":1}}],["而不是使用验证误差",{"2":{"401":1}}],["而不是按时间间隔进行",{"2":{"390":1}}],["而不是10分钟评估一次",{"2":{"388":1}}],["而不是固定的时间间隔",{"2":{"388":1}}],["而不是受我们拥有多少训练数据或其他因素的限制",{"2":{"380":1}}],["而不是立即选择较小数量的隐藏层",{"2":{"375":1}}],["而不是降低验证集错误率",{"2":{"366":1}}],["而不是任何客观事实",{"2":{"353":1}}],["而不是二次关系",{"2":{"316":1}}],["而不是用",{"2":{"208":1}}],["而不是平移不变性",{"2":{"91":1}}],["而不向relu那样直接置0",{"2":{"126":1}}],["而relu函数简单",{"2":{"122":1}}],["而",{"2":{"122":1,"217":1,"303":1,"309":1,"337":1,"338":1,"380":1,"621":1,"648":1}}],["而layernorm对深度网络的某一层的所有神经元进行标准化操作",{"2":{"87":1}}],["而cuda正是英伟达开发的gpu的编程接口",{"2":{"74":1}}],["而所谓的",{"2":{"61":1}}],["而是一种人的本性",{"2":{"967":1}}],["而是一种可以帮助我们提高生活效率的工具",{"2":{"927":1}}],["而是优先满足容易被小饼干满足的小孩",{"2":{"960":1}}],["而是看到一个需要的东西就顺手放进购物车",{"2":{"921":1}}],["而是是一种发自内心的",{"2":{"878":1}}],["而是包装器",{"2":{"822":1}}],["而是在算attention的时候考虑当前位置与被attention的位置的相对距离",{"2":{"642":1}}],["而是直接将位置编码当作可训练参数",{"2":{"641":1}}],["而是采用v",{"2":{"608":1}}],["而是传递一个",{"2":{"504":1}}],["而是使用训练误差",{"2":{"401":1}}],["而是将别人预训练好的模型权重通过迁移学习应用到自己的模型中",{"2":{"617":1}}],["而是将节点中的每个与其相连的输入权值以1",{"2":{"347":1}}],["而是将其保留在基数树",{"2":{"337":1}}],["而是隐式地操作头部的索引来执行相同的计算",{"2":{"323":1}}],["而是保持在k个",{"2":{"186":1}}],["而是通过自己不停的尝试来学会某些技能",{"2":{"21":1}}],["而是机器自动提取的",{"2":{"19":1}}],["而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络",{"2":{"15":1}}],["凸域将可以形成任意的形状",{"2":{"14":1}}],["大概知道是个什么样的思想就行",{"2":{"975":1}}],["大概两小时",{"2":{"877":1}}],["大更新",{"0":{"867":1,"870":1,"873":1}}],["大家找找感觉能理解什么是",{"2":{"973":1}}],["大家对下面的这些原理和策略的证明可以暂时跳过",{"2":{"972":1}}],["大家想了解的话可以浏览器或者ai查一查贪心算法的严谨证明",{"2":{"972":1}}],["大家可能会觉得这不是显而易见的吗",{"0":{"935":1}}],["大家可以自己推导出对应点的坐标",{"2":{"844":1}}],["大家可以看到圆形隐藏层中包含了前面所有的颜色",{"2":{"142":1}}],["大家根据自己的领悟去理解即可",{"2":{"878":1}}],["大家再仔细想想",{"2":{"844":1}}],["大数据处理框架",{"2":{"802":1}}],["大规模并行计算",{"2":{"802":1}}],["大规模仿真等领域",{"2":{"797":1}}],["大规模数据上",{"2":{"616":1}}],["大致分为两个阶段",{"2":{"624":1}}],["大语言模型的快速发展对自然语言处理领域产生了革命性的影响",{"2":{"622":1}}],["大都采用自监督学习",{"2":{"616":1}}],["大于梯度截断的阈值",{"2":{"410":1}}],["大于max",{"2":{"409":1}}],["大于两层的",{"2":{"13":1}}],["大多数情况下特别是企业级应用",{"2":{"723":1}}],["大多数情况下人工神经网络能在外界信息的基础上改变内部结构",{"2":{"5":1}}],["大多数学习率调度器可以连续调用",{"2":{"533":1}}],["大多数函数将使用",{"2":{"473":1}}],["大多数深度学习框架都支持模型检查点",{"2":{"392":1}}],["大多数时候",{"2":{"366":1}}],["大多数自动搜索算法依赖于人工设计的搜索空间",{"2":{"365":1}}],["大多数超参数的最佳值对batch",{"2":{"361":1}}],["大小和操作",{"2":{"466":1}}],["大小一样大",{"2":{"390":1}}],["大小应该至少与用于训练的",{"2":{"390":1}}],["大小为",{"2":{"226":2}}],["大小",{"2":{"226":1,"953":1}}],["大量不可行点可能表示训练代码中存在错误",{"2":{"372":1}}],["大量的内存访问会导致较慢的实际执行时间",{"2":{"223":1,"312":1}}],["大量信号被刻意的屏蔽",{"2":{"123":1}}],["大量信号被刻意的屏蔽了",{"2":{"122":1}}],["大模型",{"2":{"702":1}}],["大模型榜单",{"2":{"622":1}}],["大模型概述",{"2":{"622":1}}],["大模型的爆发",{"0":{"622":1}}],["大模型推理加速利器",{"0":{"230":1,"231":1,"330":1,"331":1},"1":{"332":1,"333":1,"334":1,"335":1}}],["大模型加速利器",{"0":{"221":1,"310":1},"1":{"222":1,"223":1,"224":1,"225":1,"226":1,"227":1,"228":1,"311":1,"312":1,"313":1,"314":1,"315":1,"316":1,"317":1,"318":1,"319":1}}],["大模型神器",{"0":{"218":1,"304":1},"1":{"219":1,"305":1}}],["大脑同时被激活的神经元只有1",{"2":{"123":1}}],["大部分情况下",{"2":{"617":1}}],["大部分神经序列转导模型都有一个编码器",{"2":{"194":1}}],["大部分激活函数都是没有参数的",{"2":{"120":1}}],["大部分的activation",{"2":{"108":1}}],["每块饼干也有一个大小",{"2":{"951":1}}],["每块不超过预填块大小",{"2":{"329":1}}],["每条消息附带一个标签",{"2":{"809":1}}],["每条消息包含源进程id",{"2":{"806":1}}],["每条句子记录两条最佳路径",{"2":{"634":1}}],["每种模式有特定的功能和快捷键",{"2":{"774":1}}],["每经过",{"2":{"537":1}}],["每项研究中有多少试验是不可行",{"2":{"372":1}}],["每组元素对应的旋转角度",{"2":{"649":1}}],["每组实验都有一个特定的目标",{"2":{"372":1}}],["每组负责对相应的输入层进行卷积计算",{"2":{"57":1}}],["每轮实验都应该有一个明确的目标",{"2":{"367":2}}],["每步的资源消耗",{"2":{"360":1}}],["每步的时间应该是恒定的",{"2":{"358":1}}],["每步时间",{"2":{"358":1,"359":1}}],["每张卡计算一个",{"2":{"326":1}}],["每行最大值",{"2":{"322":1}}],["每次优先使用面值最大的硬币",{"2":{"946":1}}],["每次优化一个小目标",{"2":{"922":1}}],["每次先做最紧急的任务",{"2":{"942":1}}],["每次都选最佳",{"0":{"921":1}}],["每次都使用整个训练数据集的梯度相比",{"2":{"261":1}}],["每次运行",{"2":{"466":1}}],["每次设计新事物时",{"2":{"377":1}}],["每次试验的验证目标值通常应该是它在训练期间达到的最佳值",{"2":{"373":1}}],["每次更改模型或优化器时",{"2":{"358":1}}],["每次更新参数时",{"2":{"236":1}}],["每次参数更新时使用整个训练数据集的梯度",{"2":{"260":1}}],["每次利用梯度下降更新参数的时",{"2":{"236":1}}],["每次执行我们习惯上称值为一个时间步",{"2":{"135":1}}],["每一张图片名称",{"2":{"552":1}}],["每一个正向的函数",{"2":{"462":1}}],["每一维代表是某个词的概率",{"2":{"181":1}}],["每一步都能让当前的结果尽可能大",{"2":{"932":1}}],["每一步都做出当前最优的选择",{"2":{"929":1,"969":1}}],["每一步只增加少量时间",{"2":{"360":1}}],["每一步会选择k个候选项作为下一步的扩展",{"2":{"186":1}}],["每一步的开始",{"2":{"184":1}}],["每一步的预测结果",{"2":{"176":1}}],["每一步",{"2":{"179":1,"183":1}}],["每一层的神经元学到的东西都是一样的",{"2":{"237":1}}],["每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来",{"2":{"15":1}}],["每一层都有两个子层",{"2":{"196":1}}],["每一层都输出到上面的层",{"2":{"13":1}}],["每一层由许多个可以控制水流流向与流量的调节阀",{"2":{"15":1}}],["每个小孩最多只能分到一块饼干",{"2":{"951":1}}],["每个小孩都有一个对饼干大小的需求",{"2":{"951":1}}],["每个进程计算自己的部分和",{"2":{"827":1}}],["每个进程负责的部分大小",{"2":{"827":1}}],["每个进程处理数据的一部分",{"2":{"811":1}}],["每个进程执行相同的代码",{"2":{"806":1}}],["每个处理器有独立的内存",{"2":{"801":1}}],["每个文件权限用",{"2":{"745":1}}],["每个字词对应一行的标签分数",{"2":{"627":1}}],["每个输入",{"2":{"627":1}}],["每个标签",{"2":{"626":1}}],["每个标记的查询",{"2":{"328":1}}],["每个元素都有一个前继和后继元素",{"2":{"626":1}}],["每个循环迭代时",{"2":{"543":1}}],["每个循环将初始振幅缩小一半",{"2":{"543":1}}],["每个周期都会减小为上一个周期的",{"2":{"541":1}}],["每个训练周期的步数",{"2":{"544":1}}],["每个训练周期",{"2":{"541":1}}],["每个调度器都会按顺序应用在前一个调度器得到的学习率上",{"2":{"533":1}}],["每个参数组包含特定于优化器的元数据",{"2":{"509":1}}],["每个原地操作都需要重新构建计算图",{"2":{"481":1}}],["每个",{"2":{"409":1,"471":1,"504":1}}],["每个问题都有自己的特性和计算资源限制",{"2":{"371":1}}],["每个配置称为",{"2":{"370":1}}],["每个模型都有不同的超参数设置",{"2":{"355":1}}],["每个树边都带有一个标签",{"2":{"338":1}}],["每个节点维护一个引用计数器",{"2":{"338":1}}],["每个页面的大小等于一个token",{"2":{"338":1}}],["每个块包含一定数量的token的key",{"2":{"333":1}}],["每个块都是原始张量的视图",{"2":{"110":1}}],["每个gpu的激活内存占用也小了cp倍",{"2":{"328":1}}],["每个gpu仅对序列的一部分进行计算",{"2":{"328":1}}],["每个gpu处理4k个标记",{"2":{"328":1}}],["每个gpu在前向过程中仅存储一个序列块的kv",{"2":{"328":1}}],["每个主机负责query",{"2":{"327":1}}],["每个主机负责运行与其指定块相对应的块并行注意力外部循环的一个元素",{"2":{"327":1}}],["每个主机将键",{"2":{"327":1}}],["每个主机持有一个查询块",{"2":{"327":1}}],["每个主机通过同时将用于注意力计算的key",{"2":{"327":1}}],["每个非矩阵乘法flop的成本是矩阵乘法flop的16倍",{"2":{"320":1}}],["每个通大小为",{"2":{"249":1}}],["每个通道在每次前向调用时都会独立地被置零",{"2":{"114":1}}],["每个大小为",{"2":{"226":2}}],["每个block",{"2":{"226":3}}],["每个头只单独保留了一份",{"2":{"217":1,"303":1}}],["每个词之间的依赖关系",{"2":{"213":1}}],["每个组共享一个键头和值头",{"2":{"219":1,"305":1}}],["每个组",{"2":{"208":1}}],["每个self",{"2":{"202":1}}],["每个子层的输出是layernorm",{"2":{"196":1}}],["每个群组包含相似的文本",{"2":{"188":1}}],["每个时间步为何没有矩阵相乘呢",{"2":{"139":1}}],["每个特征图对应网络在输入数据中提取的一种特征",{"2":{"55":1}}],["每层的调节阀数量可以有不同的变化组合",{"2":{"15":1}}],["每层神经元与下层神经元全互连",{"2":{"13":1}}],["最优子结构性质",{"2":{"974":1}}],["最优",{"2":{"974":1}}],["最优学习率很容易随着下一次训练流程的改变而改变",{"2":{"369":1}}],["最新研究内容和成果",{"0":{"859":1}}],["最重要的一点",{"2":{"724":1}}],["最简单安装只要两个jar文件+配置几个sql映射文件就可以了",{"2":{"724":1}}],["最简单的理解",{"2":{"917":1}}],["最简单的解决方案通常是以不同的批次大小",{"2":{"358":1}}],["最简单的方法就是把encoder的最后一个隐状态赋值给context",{"2":{"170":1}}],["最简单的方法是将许多全连接层堆叠在一起",{"2":{"13":1}}],["最适合处理那些需要理解整个句子语义的任务",{"2":{"619":1}}],["最适合用于早期训练不稳定的情况",{"2":{"406":1}}],["最核心之处",{"2":{"552":1}}],["最直接的实现方式是对参数进行",{"2":{"510":1}}],["最直观的方法是将动量应用于缩放后的梯度",{"2":{"294":1}}],["最常用的方法已经得到支持",{"2":{"501":1}}],["最小学习率",{"2":{"545":1}}],["最小值",{"2":{"445":1}}],["最小化训练时间的batch",{"2":{"359":1}}],["最小化",{"2":{"256":1}}],["最好复制生成衰减方案的算法",{"2":{"399":1}}],["最好将您的基础策略设为自动生成尽可能多的图表",{"2":{"377":1}}],["最好的办法是把它拆解成多个小问题",{"2":{"924":1}}],["最好的学习率衰减方案是什么",{"0":{"397":1}}],["最好的试验是否具有与有问题的过度拟合一致的训练曲线",{"2":{"372":1}}],["最好的",{"2":{"369":1}}],["最好的切入角度就是",{"2":{"174":1}}],["最佳学习率处于可行的边缘",{"2":{"408":1}}],["最佳模型在验证集上的表现",{"2":{"393":1}}],["最佳检查点并不一定是最后一个检查点",{"2":{"392":1}}],["最佳",{"2":{"356":1,"365":1,"375":2,"380":1,"381":1,"921":1}}],["最近最少使用",{"2":{"338":1}}],["最近的研究提出了弹性序列并行性",{"2":{"329":1}}],["最近的大型语言模型的可用上下文长度正在迅速增加",{"2":{"329":1}}],["最近",{"2":{"329":1}}],["最高为2k",{"2":{"227":1,"317":1}}],["最早是出现在2019年谷歌的一篇论文",{"2":{"217":1,"303":1}}],["最大化了时间的利用率",{"2":{"943":1}}],["最大化验证集指标",{"2":{"367":1}}],["最大四位数的例子",{"0":{"930":1},"1":{"931":1,"932":1,"933":1,"934":1}}],["最大的搜索值不应超过max",{"2":{"409":1}}],["最大的问题是如何调整学习率衰减计划",{"2":{"383":1}}],["最大的那个序列作为最终结果",{"2":{"184":1}}],["最大的k个作为下一步的输入",{"2":{"184":1}}],["最大池化在每个池化窗口中选择最大的特征值作为输出",{"2":{"93":1}}],["最上点是此时间步的输出",{"2":{"172":1}}],["最经典的例子是",{"2":{"120":1}}],["最先进的gpu",{"0":{"78":1}}],["最后剩下的是",{"2":{"933":1}}],["最后综合这些信息",{"2":{"925":1}}],["最后综合考虑",{"2":{"183":1}}],["最后合起来看",{"2":{"924":1}}],["最后出门去上班",{"2":{"917":1}}],["最后我们直接用管理项目的账号去登录",{"2":{"889":1}}],["最后问我们是哪个学校的",{"2":{"875":1}}],["最后一个文件",{"2":{"789":1}}],["最后一个具有",{"2":{"634":1}}],["最后一个元素没有后继元素",{"2":{"626":1}}],["最后的生成的结果将会非常离谱",{"2":{"656":1}}],["最后的生成结果接近数字0",{"2":{"655":1}}],["最后的end",{"2":{"634":1}}],["最后的权重",{"2":{"48":1}}],["最后单词转移分数",{"2":{"632":1}}],["最后计算上述公式得到",{"2":{"606":1}}],["最后通过比较两个研究中的最优试验来比较这两个优化器",{"2":{"370":1}}],["最后将",{"2":{"226":1,"619":1}}],["最后将结果合并组合",{"2":{"57":1}}],["最后n个序列选哪个",{"2":{"186":1}}],["最后",{"2":{"150":1,"205":1,"219":1,"305":1,"353":1,"383":1,"390":1,"444":1}}],["最后再计算",{"2":{"648":1}}],["最后再softmax分类",{"2":{"95":1}}],["最后再进行合并",{"2":{"57":1}}],["最后得到结果",{"2":{"59":1}}],["最终完成了",{"2":{"943":1}}],["最终得到的结果是4321",{"2":{"934":1}}],["最终结果就是",{"2":{"933":1}}],["最终你就会发现自己离大目标越来越近了",{"2":{"922":1}}],["最终帮助你完成目标",{"2":{"917":1}}],["最终效果与createsuperuser一模一样",{"2":{"889":1}}],["最终我放弃了这种策略",{"2":{"889":1}}],["最终我们可以推出",{"2":{"249":1}}],["最终输入data",{"2":{"553":1}}],["最终",{"2":{"359":1,"366":1,"372":1,"619":1,"621":1,"646":1}}],["最终训练出更好的模型",{"2":{"357":1}}],["最终到达一个局部是凸碗的区域",{"2":{"283":1}}],["最终形式",{"2":{"34":1}}],["最终产生输出",{"2":{"24":1}}],["最快",{"2":{"26":2}}],["最初的激活函数是下图左所示的阶跃函数",{"2":{"9":1}}],["使系统的设计更清晰",{"2":{"724":1}}],["使它们能够重新计算您的模型",{"2":{"505":1}}],["使同时尽可能缩短评估时间",{"2":{"389":1}}],["使预测更极端",{"2":{"345":1}}],["使模型更加简洁且泛化性能更好",{"2":{"341":1}}],["使模型对输入图像中的特征位置变化更加鲁棒",{"2":{"92":1}}],["使sm的利用率尽量打满",{"2":{"324":1}}],["使矩阵乘法速度更快",{"2":{"320":1}}],["使网络各层的激活值和反向激活梯度的方差在传播过程中尽量保持一致",{"2":{"244":1}}],["使得尽可能多的小孩得到满足",{"2":{"952":1}}],["使得尽可能多的小孩能得到满足",{"2":{"951":1}}],["使得它有能力分辨不同位置的token",{"2":{"638":1}}],["使得自注意力层",{"2":{"619":1}}],["使得在超过10万个四面体的弹性体上实现实时高保真物理仿真成为可能",{"2":{"859":1}}],["使得在子类上调用的方法返回一个子类实例",{"2":{"441":1}}],["使得在处理大型数据集时更加可行",{"2":{"262":1}}],["使得验证误差最小",{"2":{"401":1}}],["使得",{"2":{"329":1}}],["使得参数更新更加稳定",{"2":{"267":1}}],["使得参数无法继续更新的问题",{"2":{"120":1}}],["使得网络不收敛",{"2":{"236":1}}],["使得网络更容易被优化",{"2":{"93":1}}],["使得以后不用人为设计激活函数了",{"2":{"127":1}}],["使其逐渐稳定并达到更好的性能状态",{"2":{"544":1}}],["使其不再与计算图相关联",{"2":{"452":1}}],["使其成为叶节点",{"2":{"441":1}}],["使其能够在找到凸碗状结构后快速收敛",{"2":{"283":1}}],["使其能处理更普遍的函数关系类型",{"2":{"13":1}}],["使其在参数更新时不产生效果",{"2":{"214":1}}],["使其分布一致",{"2":{"86":1}}],["使用两个指针",{"2":{"956":1}}],["使用最少的硬币",{"0":{"944":1},"1":{"945":1,"946":1,"947":1}}],["使用最多且最简单",{"2":{"835":1}}],["使用增量",{"2":{"838":1}}],["使用增加梯度方差",{"2":{"380":1}}],["使用以下命令将公钥复制到",{"2":{"827":1}}],["使用示例",{"2":{"822":1}}],["使用共享内存模型",{"2":{"802":1}}],["使用万能的map",{"2":{"730":1}}],["使用的人多",{"2":{"724":1}}],["使用特定任务的标注语料",{"2":{"616":1}}],["使用jit",{"2":{"564":1}}],["使用多项式函数来在给定的",{"2":{"542":1}}],["使用方法",{"0":{"532":1,"533":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1}}],["使用torch",{"2":{"496":1}}],["使用参数self",{"2":{"496":1}}],["使用运行时的均值和方差进行归一化",{"2":{"493":1}}],["使用运算符",{"2":{"441":1}}],["使用自动求导",{"2":{"481":1}}],["使用自动微分进行梯度计算仅在每个使用的基本函数都是可微分的情况下有效",{"2":{"473":1}}],["使用自产自销的策略",{"2":{"176":1}}],["使用retain",{"2":{"457":1}}],["使用从柯西分布中抽取的数字填充张量",{"2":{"445":1}}],["使用从伯努利分布中采样的样本",{"2":{"114":1}}],["使用与",{"2":{"445":1}}],["使用指定的大小",{"2":{"445":1}}],["使用指数衰减平均以丢弃遥远过去的历史",{"2":{"283":1}}],["使用内置的",{"2":{"441":1}}],["使用梯度截断",{"2":{"406":1}}],["使用梯度积累技术可以支持的更大的batch",{"2":{"358":1}}],["使用1000步的学习率预热可以解决这种特殊的不稳定情况",{"2":{"404":1}}],["使用2倍预算随机搜索作为baseline有多强大",{"2":{"401":1}}],["使用不同的评估指标来评估这些结果",{"2":{"401":1}}],["使用已经运行的实验中的数据来评估每一组超参数的训练误差",{"2":{"401":1}}],["使用可能更陡峭的",{"2":{"399":1}}],["使用一些简单的",{"2":{"399":1}}],["使用当前批次的均值和方差对激活值进行归一化",{"2":{"394":1}}],["使用比训练时更大的",{"2":{"388":1}}],["使用适当的性能分析工具来诊性能受限的输入管道",{"2":{"387":1}}],["使用性能分析工具并注意常见的一些问题",{"2":{"387":1}}],["使用较少的训练步数可以解决早期训练的不稳定性",{"2":{"384":1}}],["使用学习率预热",{"2":{"406":1}}],["使用学习率搜索算法来确定",{"0":{"382":1}}],["使用学习率衰减",{"2":{"375":1}}],["使用了一种双模型方法来解决这个问题",{"2":{"619":1}}],["使用了",{"2":{"492":1}}],["使用了数据增强技术",{"2":{"380":1}}],["使用了较小的batch",{"2":{"380":1}}],["使用黑盒优化工具来正确处理发散试验很重要",{"2":{"379":1}}],["使用严格的统计测试对有限验证集上估计的验证错误率进行比较是很好的",{"2":{"378":1}}],["使用isolation图检测更改是否有用",{"0":{"376":1}}],["使用更好的优化器或更好的学习率更新策略",{"2":{"381":1}}],["使用更多的验证数据",{"2":{"375":1}}],["使用更大batch",{"2":{"358":1}}],["使用常见的正则化技术减少过度拟合通常很简单",{"2":{"375":1}}],["使用成本",{"2":{"360":1}}],["使用如权重衰减等其他正则化策略能够防止这种情况",{"2":{"345":1}}],["使用softmax",{"2":{"345":1}}],["使用正则表达式应用的简单模式匹配变",{"2":{"344":1}}],["使用超过一个8x",{"2":{"329":1}}],["使用cp",{"2":{"328":1}}],["使用移动平均引入了一个新的超参数ρ",{"2":{"283":1}}],["使用预训练的weight",{"0":{"254":1}}],["使用先前生成的符号作为附加输入",{"2":{"194":1}}],["使用上一步的预测来作为下一步的输入吗",{"2":{"177":1}}],["使用隐藏状态来传递信息",{"2":{"156":1}}],["使用步长对张量进行切片",{"2":{"111":1}}],["使用gap代替全连接层",{"2":{"95":1}}],["使用batchnorm",{"2":{"86":1}}],["使用",{"2":{"58":1,"496":2,"609":1,"617":1,"624":2,"757":1,"787":1,"817":1,"822":1,"827":1}}],["使用感知机解决异非",{"2":{"11":1}}],["使用感知机解决或",{"2":{"11":1}}],["使用感知机解决与",{"2":{"11":1}}],["使用感知机解决线性可分问题",{"0":{"11":1}}],["使之成为一种颇具吸引力的深度学习结构",{"2":{"51":1}}],["从数字中选最大",{"0":{"930":1},"1":{"931":1,"932":1,"933":1,"934":1}}],["从数学计算上",{"2":{"61":1}}],["从哪里开始进行自动化",{"2":{"831":1}}],["从进程",{"2":{"811":1}}],["从光标位置向上查找",{"2":{"786":1}}],["从光标位置向下查找",{"2":{"786":1}}],["从图中我们可以看到随着相对距离的变大",{"2":{"648":1}}],["从图像生成文字",{"2":{"164":1}}],["从这个实现也可以看到",{"2":{"648":1}}],["从这些试验中",{"2":{"381":1}}],["从step",{"2":{"634":1}}],["从state",{"2":{"496":1}}],["从上图可以看到",{"2":{"624":1}}],["从自然语言理解",{"2":{"622":1}}],["从pytorch",{"2":{"550":1}}],["从功能上讲",{"2":{"480":1}}],["从访问",{"2":{"472":1}}],["从伯努利分布中绘制二进制随机数",{"2":{"445":1}}],["从numpy生成",{"0":{"430":1}}],["从此时开始",{"2":{"399":1}}],["从本质上讲",{"2":{"383":1}}],["从实验得出的结论可能对固定超参数的其他值无效",{"2":{"369":1}}],["从实验结果中获取经验",{"0":{"372":1},"1":{"373":1,"374":1,"375":1,"376":1,"377":1},"2":{"365":1}}],["从长远来看",{"2":{"366":1}}],["从长文本中提取关键信息",{"2":{"188":1}}],["从简单的配置开始",{"2":{"365":1}}],["从较小的模型开始",{"2":{"363":1}}],["从较慢的hbm加载到较快的sram中",{"2":{"224":1,"311":1}}],["从云供应商处计费",{"2":{"360":1}}],["从更简单的优化器开始会更可取",{"2":{"356":1}}],["从针对手头问题类型的最常用的优化器开始",{"2":{"356":1}}],["从研究论文附录中收集的技巧",{"2":{"353":1}}],["从8k到128k",{"2":{"329":1}}],["从context",{"0":{"329":1}}],["从ring",{"0":{"328":1}}],["从rnn",{"0":{"159":1},"1":{"160":1,"161":1,"162":1,"163":1,"164":1,"165":1}}],["从其他主机获取block的朴素方法会导致两个重要问题",{"2":{"327":1}}],["从前向传递中保存伪随机数生成器获取状态并在反向过程中重新生成dropout",{"2":{"316":1}}],["从训练开始时积累梯度平方会导致有效学习率过早和过量的减小",{"2":{"277":1}}],["从基础到凯明",{"2":{"255":1}}],["从hbm",{"2":{"226":1}}],["从hbm加载输入数据",{"2":{"226":1,"315":1}}],["从",{"0":{"609":1},"2":{"226":1,"383":1}}],["从多头模型生成多查询模型分为两个步骤",{"2":{"220":1,"306":1}}],["从mha转换为mqa将h个键和值头减少为单个键和值头",{"2":{"219":1,"305":1}}],["从非结构化文本中提取结构化信息",{"2":{"188":1}}],["从文本中识别和提取命名实体",{"2":{"188":1}}],["从机器学习到深度学习",{"0":{"187":1},"1":{"188":1,"189":1,"190":1,"191":1}}],["从理论上没有任何的问题",{"2":{"177":1}}],["从类别生成语音或音乐等",{"2":{"164":1}}],["从生物学上看",{"2":{"123":1}}],["从信号方面来看",{"2":{"122":1}}],["从而为后面的大胃口小孩保留更大的饼干",{"2":{"960":1}}],["从而为模型提供一个较好的起点",{"2":{"180":1}}],["从而能够满足更多小孩",{"2":{"955":1}}],["从而用最少的硬币达到目标",{"2":{"946":1}}],["从而简化计算",{"2":{"840":1}}],["从而实现并行计算",{"2":{"822":1}}],["从而实现并行处理并减少",{"2":{"329":1}}],["从而找到",{"2":{"822":1}}],["从而找到最优的实验",{"2":{"401":1}}],["从而使得上述关系成立",{"2":{"646":1}}],["从而使旧搜索更难重现",{"2":{"401":1}}],["从而提高模型的执行效率",{"2":{"560":1}}],["从而提高系统的整体性能和吞吐量",{"2":{"329":1}}],["从而改变其性质和硬度的过程",{"2":{"544":1}}],["从而节省了许多连续的内核调用",{"2":{"510":1}}],["从而生成了一个有向无环图",{"2":{"471":1}}],["从而影响模型对留出集的表现",{"2":{"391":1}}],["从而降低了每个示例的计算要求",{"2":{"390":1}}],["从而降低后续实验的复杂度",{"2":{"366":1}}],["从而导致i",{"2":{"387":1}}],["从而可以将它们嵌套在树形结构中",{"2":{"488":1}}],["从而可以加快迭代过程",{"2":{"176":1}}],["从而可能增加达到特定验证损失所需的训练步骤",{"2":{"380":1}}],["从而无法获得更高的学习率",{"2":{"373":1}}],["从而无法完成深度网络的训练",{"2":{"122":1}}],["从而增加完成研究的总体时间",{"2":{"385":1}}],["从而增加资源成本",{"2":{"371":1}}],["从而增加过拟合的可能性",{"2":{"341":1}}],["从而我们从实验中得出错误结论的风险也越高",{"2":{"369":1}}],["从而防止过拟合",{"2":{"346":1}}],["从而显著提高了效率",{"2":{"338":1}}],["从而显著提高吞吐量",{"2":{"334":1}}],["从而减少冗余的计算和内存占用",{"2":{"337":1}}],["从而避免冗余的内存和计算",{"2":{"337":1}}],["从而进一步提高了系统的性能和效率",{"2":{"329":1}}],["从而扩展了算法隐藏内存和指令发布延迟的能力",{"2":{"325":1}}],["从而支持高效的推理",{"2":{"308":1}}],["从而加速参数的更新过程",{"2":{"267":1}}],["从而加速参数更新",{"2":{"266":1}}],["从而在执行过程中获得更高的性能",{"2":{"559":1}}],["从而在注意力计算中获得了7",{"2":{"222":1,"314":1}}],["从而在搜索空间中找到可能性较高的序列",{"2":{"186":1}}],["从而逐步执行softmax归一化操作",{"2":{"222":1,"311":1}}],["从而多查询注意力在内存带宽和容量上都具有更激进的削减",{"2":{"219":1,"305":1}}],["从而大大减少",{"2":{"217":1,"303":1}}],["从而更好地理解和生成文本",{"2":{"180":1}}],["从而将细胞状态更新为神经网络认为相关的新值",{"2":{"149":1}}],["从而得到更好的准确性和泛化",{"2":{"128":1}}],["从而略微缓减了sigmoid",{"2":{"121":1}}],["从而对输入数据进行分类",{"2":{"117":1}}],["从而从给定的训练数据集生成更真实的新数据",{"2":{"21":1}}],["从索引1到索引8",{"2":{"111":1}}],["从索引2到索引6",{"2":{"111":1}}],["从感知机到深度神经网络",{"0":{"13":1},"1":{"14":1,"15":1}}],["从神经元到感知机",{"0":{"10":1},"1":{"11":1,"12":1}}],["多边形",{"2":{"857":1}}],["多机多处理机",{"2":{"801":1}}],["多线程编程",{"2":{"799":1}}],["多处理器系统和分布式系统",{"2":{"799":1}}],["多处理机",{"2":{"798":1}}],["多文件和多窗口操作",{"0":{"788":1},"1":{"789":1,"790":1}}],["多态",{"2":{"708":1}}],["多么的厉害",{"2":{"700":1}}],["多张量",{"2":{"510":1}}],["多维tensor",{"0":{"459":1}}],["多维离散的卷积公式演变如下",{"2":{"52":1}}],["多主机训练非常容易引入错误",{"2":{"395":1}}],["多主机管道的考虑因素",{"0":{"395":1}}],["多主机工作流的注意事项",{"2":{"351":1}}],["多tpu训练",{"2":{"360":1}}],["多年来一直致力于深度学习",{"2":{"353":1}}],["多用于全连接层",{"2":{"347":1}}],["多轮对话中的聊天历史",{"2":{"337":1}}],["多个进程参与的通信",{"2":{"806":1}}],["多个进程同时访问同一块内存区域",{"2":{"801":1}}],["多个进程同时处于临界区",{"2":{"681":1}}],["多个进程或线程需要共享访问",{"2":{"681":1}}],["多个进程或线程可能需要同时访问共享资源",{"2":{"676":1}}],["多个输出序列从相同的提示中生成",{"2":{"335":1}}],["多个仿射变换叠加仍是一个仿射变换",{"2":{"120":1}}],["多查询注意力",{"2":{"323":1}}],["多查询注意力和分组查询注意力",{"2":{"323":1}}],["多查询注意力的比较",{"2":{"219":1,"305":1}}],["多头的实现细节展示",{"0":{"211":1}}],["多对多的",{"2":{"190":1}}],["多对一",{"2":{"190":1}}],["多选几个作为候选",{"2":{"183":1}}],["多轴交换",{"2":{"101":1}}],["多少维的",{"2":{"65":1}}],["多层网络的有效训练方法长时间以来一直未知",{"2":{"29":1}}],["多层神经元解决非线性问题",{"2":{"12":1}}],["多元函数",{"2":{"26":1}}],["多分类问题的解决",{"2":{"14":1}}],["多次分割解决分线性",{"2":{"12":1}}],["如mpi",{"2":{"809":1}}],["如广播",{"2":{"806":1}}],["如天气预测",{"2":{"802":1}}],["如消息传递接口mpi",{"2":{"801":1}}],["如数字",{"2":{"796":1}}],["如数据竞争",{"2":{"676":1}}],["如磁盘",{"2":{"722":1}}],["如内存中的对象",{"2":{"722":1}}],["如cpu",{"2":{"680":1}}],["如论文中所述",{"2":{"543":1}}],["如学习率和权重衰减",{"2":{"509":1}}],["如共轭梯度",{"2":{"505":1}}],["如跟踪计算图",{"2":{"496":1}}],["如无梯度模式和推断模式",{"2":{"477":1}}],["如图像处理的多步操作等",{"2":{"811":1}}],["如图中10000步处展示的那样",{"2":{"408":1}}],["如图所示",{"2":{"170":1,"327":1}}],["如不用计算梯度之类的",{"2":{"390":1}}],["如100个epoch评估一次",{"2":{"388":1}}],["如减少磁盘空间占用",{"2":{"387":1}}],["如有必要",{"2":{"372":1,"466":1}}],["如神经网络",{"2":{"343":1}}],["如线性回归和逻辑回归可以使用简单",{"2":{"340":1}}],["如并行采样和beam",{"2":{"335":1}}],["如hopper中的fp8和blackwell中的fp4",{"2":{"325":1}}],["如上所述",{"2":{"226":1,"315":1}}],["如上图中h0和x1分别有一个箭头连接",{"2":{"160":1}}],["如上图所示",{"2":{"142":1,"202":1}}],["如上图",{"2":{"57":1}}],["如下文所述",{"2":{"369":1}}],["如下所示",{"2":{"225":1,"313":1}}],["如下图的架构",{"2":{"213":1}}],["如下图典型rnn",{"2":{"160":1}}],["如下图为膨胀率",{"2":{"60":1}}],["如下图为",{"2":{"58":1}}],["如下图",{"2":{"58":1}}],["如下图所示",{"2":{"14":1,"56":1,"142":1,"183":1,"208":1,"240":1,"337":1,"641":1}}],["如词性标注",{"2":{"188":1}}],["如文本摘要",{"2":{"188":1}}],["如关系抽取",{"2":{"188":1}}],["如人名",{"2":{"188":1}}],["如情感分类",{"2":{"188":1}}],["如机器翻译",{"2":{"188":1}}],["如机器翻译问题",{"2":{"173":1}}],["如机器翻译中",{"2":{"165":1}}],["如聊天机器人",{"2":{"167":1}}],["如输入一段文字判别它所属的类别",{"2":{"163":1}}],["如黑色和绿色区域",{"2":{"143":1}}],["如橙色区域",{"2":{"143":1}}],["如何用最少的硬币凑齐",{"2":{"945":1}}],["如何用尽量少的钱去尽量多的地方",{"2":{"937":1}}],["如何安排时间让你完成尽可能多的任务",{"2":{"941":1}}],["如何分配时间",{"0":{"940":1},"1":{"941":1,"942":1,"943":1}}],["如何组成最大的四位数",{"2":{"931":1}}],["如何组合在一起",{"2":{"140":1}}],["如何理解ta呢",{"2":{"878":1}}],["如何使用该站点",{"2":{"864":1}}],["如何使用torch",{"0":{"502":1},"1":{"503":1,"504":1,"505":1}}],["如何进行统一管理",{"2":{"853":1}}],["如何进行保存张量的打包",{"2":{"472":1}}],["如何确定下一个点是在右边还是右上角",{"2":{"844":1}}],["如何阅读该书",{"0":{"702":1}}],["如何有效和高效地利用这些模型",{"2":{"622":1}}],["如何将模型安全的交付",{"2":{"524":1}}],["如何backward",{"0":{"459":1}}],["如何判断两个tensor",{"2":{"437":1}}],["如何对学习率进行预热",{"0":{"409":1}}],["如何调试和缓解优化失败",{"0":{"404":1},"1":{"405":1,"406":1,"407":1,"408":1,"409":1,"410":1}}],["如何计算它是一个悬而未决的问题",{"2":{"359":1}}],["如何找到两个向量间的相关性",{"2":{"203":1}}],["如何解决这个问题呢",{"2":{"177":1}}],["如何解决这个问题并改进",{"2":{"173":1}}],["如何解决异或问题",{"0":{"12":1}}],["如完形填空",{"2":{"132":1}}],["如一个图像",{"2":{"132":1}}],["如relu",{"2":{"120":1}}],["如reshape",{"2":{"117":1}}],["如",{"2":{"87":1,"822":2}}],["如果当前饼干能满足当前孩子",{"2":{"957":1}}],["如果当前饼干可以满足孩子的胃口",{"2":{"956":1}}],["如果觉得枯燥无趣的话",{"2":{"948":1}}],["如果总是先处理不紧急的任务",{"2":{"942":1}}],["如果对于前面的介绍你还是不能够理解到",{"2":{"929":1}}],["如果对原图进行dropout正则化",{"2":{"348":1}}],["如果换a壳的话会花多少多少",{"2":{"875":1}}],["如果参数比较少",{"2":{"730":1}}],["如果参数过多",{"2":{"730":1}}],["如果还不清楚就问ai",{"2":{"702":1}}],["如果读到不太想读的地方可以先跳过",{"2":{"702":1}}],["如果每个椭圆离得特别远会发生什么",{"2":{"656":1}}],["如果生成过程中在坐标中取的点接近蓝色区域",{"2":{"655":1}}],["如果保留了原有数据的主要信息",{"2":{"652":1}}],["如果数据维度的输入",{"2":{"652":1}}],["如果想模仿原论文的行为",{"2":{"544":1}}],["如果返回了一个",{"2":{"509":1}}],["如果strict为true",{"2":{"496":1}}],["如果类中定义的成员被封装到python的普通数据类型中",{"2":{"492":1}}],["如果派生于",{"2":{"492":2}}],["如果它能够适用于您的用例",{"2":{"479":1}}],["如果该函数不是确定性映射",{"2":{"473":1}}],["如果该函数未定义",{"2":{"473":1}}],["如果该函数被定义",{"2":{"473":1}}],["如果该函数是凹函数",{"2":{"473":1}}],["如果该函数是凸函数",{"2":{"473":1}}],["如果该函数可微分",{"2":{"473":1}}],["如果该图展示的训练损失在稳步下降后突然上升",{"2":{"408":1}}],["如果让你设计一个工程的上数据结构来表示tensor",{"2":{"435":1}}],["如果您的模型依赖于诸如",{"2":{"480":1}}],["如果您无法避免在您的情况下使用这样的张量",{"2":{"479":1}}],["如果您已经签署过一次",{"2":{"423":1}}],["如果您以后需要切换到不同的batch",{"2":{"361":1}}],["如果有任何不正确的地方",{"2":{"422":1}}],["如果有无限的计算资源",{"2":{"369":1}}],["如果你看见代码部分比较头疼",{"2":{"950":1}}],["如果你盲目学习408的话",{"2":{"698":1}}],["如果你想获取相关通知",{"2":{"422":1}}],["如果你喜欢这本手册",{"2":{"422":1}}],["如果你要用gpu训练模型",{"2":{"75":1}}],["如果针对每个batch",{"2":{"412":1}}],["如果梯度范数",{"2":{"410":1}}],["如果稳定训练需要较长的warmup",{"2":{"409":1}}],["如果模型中尚未包含残差连接和归一化",{"2":{"406":1}}],["如果模型具有较大的容量",{"2":{"341":1}}],["如果怀疑模型受到早期训练不稳定的影响",{"2":{"405":1}}],["如果基于低差异序列的quasi",{"2":{"402":1}}],["如果quasi",{"2":{"401":1}}],["如果优化工具作为服务运行",{"2":{"401":1}}],["如果使用复杂的贝叶斯优化软件",{"2":{"401":1}}],["如果试验次数在25次以上",{"2":{"400":1}}],["如果试验次数在10到25次之间",{"2":{"400":1}}],["如果在蓝色和黑色交界处",{"2":{"655":1}}],["如果在连续",{"2":{"547":1}}],["如果在启用推断模式后遇到错误",{"2":{"479":1}}],["如果在需要梯度的张量上在",{"2":{"473":1}}],["如果在优化模型时遇到困难",{"2":{"404":1}}],["如果在一次研究中",{"2":{"400":1}}],["如果在模型中引入数据增强或dropout等正则化方法",{"2":{"381":1}}],["如果这种类型的验证错误敏感计划可以完全自动化",{"2":{"399":1}}],["如果这个时候继续以这样的方式更新参数",{"2":{"271":1}}],["如果这个情况发生了",{"2":{"122":1}}],["如果发生这种情况",{"2":{"399":1}}],["如果发现问题",{"2":{"372":1}}],["如果是计科或者编程相关人士",{"2":{"950":1}}],["如果是线性计划",{"2":{"385":1}}],["如果是这样",{"2":{"375":3}}],["如果学习率大于",{"2":{"405":1}}],["如果学习率过小",{"2":{"383":1}}],["如果学习过crf或者hmm",{"2":{"190":1}}],["如果训练误差",{"2":{"383":1}}],["如果训练过程以某种方式改进",{"2":{"381":1}}],["如果训练过程中",{"2":{"381":1}}],["如果训练吞吐量到某个batch",{"2":{"358":1}}],["如果搜索空间包含大量发散点",{"2":{"379":1}}],["如果目标超参数是",{"2":{"375":1}}],["如果目标超参数包括正则化参数",{"2":{"375":1}}],["如果任何最佳试验出现过拟合问题",{"2":{"375":1}}],["如果所有试验对于大于某个阈值的学习率都是不可行的",{"2":{"373":1}}],["如果最好的step总是出现在训练过程的最后的25",{"2":{"381":1}}],["如果最佳step总是出现在训练过程的前10",{"2":{"381":1}}],["如果最佳点聚集在搜索空间的边缘",{"2":{"373":1}}],["如果最终增加了训练时间",{"2":{"359":1}}],["如果从搜索空间中采样的最佳点靠近其边界",{"2":{"373":1}}],["如果不能满足",{"2":{"956":1}}],["如果不可能完美地拟合训练集",{"2":{"384":1}}],["如果不是",{"2":{"372":1}}],["如果不运行或者编译完整的训练程序",{"2":{"358":1}}],["如果研究的最佳点在一维或多维搜索空间的边界附近",{"2":{"372":1}}],["如果一项研究中的所有学习率都太小",{"2":{"382":1}}],["如果一开始选择了一个不必要的大训练步数",{"2":{"363":1}}],["如果一个模型在训练时只使用了",{"2":{"645":1}}],["如果一个新的超参数点",{"2":{"378":1}}],["如果一个节点的引用计数器为零",{"2":{"338":1}}],["如果一个函数满足输入改变",{"2":{"54":1}}],["如果将batch",{"2":{"360":1}}],["如果大batch",{"2":{"360":1}}],["如果增加batch",{"2":{"360":1}}],["如果增加",{"2":{"360":1}}],["如果没有合适的同步机制",{"2":{"676":1}}],["如果没有贝叶斯优化和其他高级黑盒优化方法方面的专业知识",{"2":{"401":1}}],["如果没有",{"2":{"358":1}}],["如果与上述情况不符",{"2":{"358":1}}],["如果与接近",{"2":{"149":1}}],["如果batch",{"2":{"358":1}}],["如果计算时间超过了传输key",{"2":{"327":1}}],["如果我们认为输入信息与位置信息应该是独立",{"2":{"644":1}}],["如果我们正在编译",{"2":{"509":1}}],["如果我们需要进行极其激进的梯度截断来处理我们的不稳定问题",{"2":{"410":1}}],["如果我们发现自己使用了非常激进的截断",{"2":{"410":1}}],["如果我们发现全损失梯度的",{"2":{"405":1}}],["如果我们尝试梯度截断并且不稳定问题仍然存在",{"2":{"410":1}}],["如果我们一开始的max",{"2":{"409":1}}],["如果我们使用自适应随机搜索来调参",{"2":{"401":1}}],["如果我们不关心分析时间",{"2":{"385":1}}],["如果我们不问这些问题",{"2":{"372":1}}],["如果我们能以某种方式延长训练时间或提高训练效率",{"2":{"380":1}}],["如果我们将搜索范围朝着这个方向扩大",{"2":{"373":1}}],["如果我们提出正确的问题",{"2":{"372":1}}],["如果我们决定根据这个实验将",{"2":{"369":1}}],["如果我们的计算资源只允许少量试验并行运行",{"2":{"401":1}}],["如果我们的实验目标涉及在两个或多个不同的优化器之间进行公平比较",{"2":{"369":1}}],["如果我们的目标是确定是否要加入权重衰减",{"2":{"376":1}}],["如果我们的目标是从",{"2":{"370":1}}],["如果我们的目标是",{"2":{"369":1}}],["如果我们要公平对比不同深度的模型",{"2":{"369":1}}],["如果我们试图一次添加多个特征或回答多个问题",{"2":{"367":1}}],["如果我们想最大化我们的最终效果",{"2":{"366":1}}],["如果我们相信方向敏感度在某种程度是轴对齐的",{"2":{"276":1}}],["如果我们跟踪一些额外的统计信息",{"2":{"226":1,"315":1}}],["如果存在多个值",{"2":{"473":1}}],["如果存在",{"2":{"260":1}}],["如果权值的初始值过大",{"2":{"236":2}}],["如果只有一个attention",{"2":{"210":1}}],["如果等每一个分支都遇到end才停的话",{"2":{"186":1}}],["如果传递了start",{"2":{"107":1}}],["如果传播的误差来自多个神经元",{"2":{"29":1}}],["如果可以运行的试验次数大于25次",{"2":{"400":1}}],["如果可以完美地拟合整个训练集",{"2":{"382":1}}],["如果可以的话",{"2":{"355":1}}],["如果可以使用一条线将数据集分为两个类别",{"2":{"11":1}}],["如果可能的话",{"2":{"98":1}}],["如果",{"2":{"50":1,"840":2}}],["x始终是加一",{"2":{"845":1}}],["x|∣δy∣",{"2":{"840":1}}],["x|",{"2":{"840":1}}],["xstep=​k​​1​​=​δy​​δx​​",{"2":{"840":1}}],["xstep=1k=δxδyxstep",{"2":{"840":1}}],["xstep=1xstep",{"2":{"840":1}}],["xstepx​i+1​​=x​i​​+xstep",{"2":{"840":1}}],["xshell",{"2":{"816":1}}],["x和y增长哪个更快",{"2":{"838":1}}],["xxx",{"2":{"766":1}}],["xchg指令",{"0":{"692":1}}],["x∣z",{"2":{"659":2}}],["x∣y",{"2":{"190":8}}],["xvf",{"2":{"768":1}}],["xv",{"2":{"649":4}}],["xq",{"2":{"649":19}}],["xmlstring",{"2":{"734":2}}],["xml中添加insert语句",{"2":{"731":1}}],["xml中添加select语句",{"2":{"730":1}}],["xml中的namespace改为为usermapper的路径",{"2":{"729":1}}],["xml配置文件",{"2":{"726":1}}],["xml数据文件中等等",{"2":{"722":1}}],["xml",{"2":{"721":1,"726":7,"727":3,"730":3,"731":1,"732":1,"733":1}}],["xm",{"2":{"646":4,"647":1}}],["xk",{"2":{"649":16}}],["xk+pkx",{"2":{"639":1}}],["xkx",{"2":{"639":1}}],["x几乎没有改变",{"2":{"608":1}}],["x0x",{"2":{"627":1}}],["x0",{"2":{"590":1,"627":1,"659":1,"840":1}}],["xpu",{"2":{"496":2}}],["x²",{"2":{"472":1}}],["x的梯度",{"2":{"452":1}}],["xor",{"2":{"443":3,"445":6}}],["x∼u",{"2":{"252":2}}],["xlm",{"2":{"619":9}}],["xlogy",{"2":{"445":4}}],["xl+1=f",{"2":{"249":1}}],["xl2",{"2":{"248":4}}],["xl",{"2":{"248":5,"612":1}}],["xl=f",{"2":{"248":1}}],["xlx",{"2":{"248":2}}],["xy",{"2":{"247":2}}],["xnx",{"2":{"646":1}}],["xn",{"2":{"247":1,"626":1,"627":1,"646":3}}],["xavier",{"0":{"245":1},"2":{"244":1}}],["x3c",{"2":{"441":5,"443":2,"460":1,"537":5,"538":3,"595":2,"726":43,"727":26,"730":10,"731":2,"732":2,"733":2,"734":6,"756":2,"823":2,"827":4,"888":3,"889":2,"957":2}}],["x3",{"2":{"160":1}}],["xjwv+ri",{"2":{"643":1}}],["xjwv+pjwv",{"2":{"643":1}}],["xjwk+ri",{"2":{"643":1}}],["xj",{"2":{"129":1}}],["xi+1=xi+xstepx",{"2":{"840":1}}],["xi+1",{"2":{"840":1}}],["xiwqwk⊤xj⊤+βi",{"2":{"644":1}}],["xiwq",{"2":{"643":1}}],["xix",{"2":{"626":1,"627":2}}],["xi",{"2":{"129":2,"225":1,"313":1,"627":1,"840":1}}],["x26",{"2":{"726":2,"770":2,"823":4,"827":6}}],["x27",{"2":{"244":1,"410":2}}],["x2可以看做是第二个单词",{"2":{"160":1}}],["x2",{"2":{"127":1,"160":1,"247":1,"590":1,"626":1,"635":5}}],["x2x",{"2":{"11":1}}],["x+3",{"2":{"127":3}}],["x+0",{"2":{"126":3}}],["x^",{"2":{"126":1,"225":14,"247":1,"313":14}}],["xφ",{"2":{"126":4}}],["x≤x",{"2":{"126":2}}],["xtx",{"2":{"137":1}}],["xt",{"2":{"50":1}}],["x=f",{"2":{"28":2}}],["x=",{"2":{"26":1,"626":3,"627":3}}],["x​i+1​​",{"2":{"840":1}}],["x​i​​w​q​​w​k​⊤​​x​j​⊤​​+β​i",{"2":{"644":1}}],["x​i​​w​q​​",{"2":{"643":1}}],["x​i​​",{"2":{"129":2,"225":1,"313":1,"626":1,"627":3,"840":1}}],["x​m​​",{"2":{"646":4,"647":1}}],["x​k​​+p​k​​",{"2":{"639":1}}],["x​k​​",{"2":{"639":1}}],["x​0​​",{"2":{"627":2,"840":1}}],["x​l+1​​=f",{"2":{"249":1}}],["x​l​2​​",{"2":{"248":4}}],["x​l​​=f",{"2":{"248":1}}],["x​l​​",{"2":{"248":7}}],["x​n​​",{"2":{"247":1,"626":1,"627":1,"646":4}}],["x​",{"2":{"225":14,"313":14}}],["x​t​​",{"2":{"137":1}}],["x​j​​w​v​​+r​i",{"2":{"643":1}}],["x​j​​w​v​​+p​j​​w​v​​",{"2":{"643":1}}],["x​j​​w​k​​+r​i",{"2":{"643":1}}],["x​j​​",{"2":{"129":1}}],["x​2​​",{"2":{"11":1,"247":1,"626":1}}],["x​1​​+⋯+x​n​​",{"2":{"247":1}}],["x​1​​",{"2":{"11":1,"247":1,"626":1,"627":1,"840":1}}],["x",{"2":{"11":1,"24":2,"26":16,"28":4,"50":17,"63":1,"86":13,"87":15,"88":11,"89":17,"99":3,"100":2,"101":2,"104":6,"106":3,"120":2,"121":17,"122":10,"123":6,"126":21,"127":8,"128":5,"129":3,"138":1,"161":3,"185":6,"190":17,"194":2,"196":3,"225":74,"226":5,"247":15,"248":22,"249":7,"252":1,"313":74,"315":1,"329":1,"359":1,"360":1,"373":1,"406":8,"427":5,"441":2,"443":1,"445":1,"451":2,"452":3,"453":5,"454":2,"456":9,"457":1,"472":7,"473":1,"474":6,"484":6,"487":14,"493":6,"495":2,"497":60,"498":23,"499":6,"500":35,"513":24,"556":5,"567":8,"571":2,"590":7,"626":7,"627":4,"635":6,"643":4,"644":4,"646":7,"647":5,"649":8,"659":18,"745":1,"777":1,"781":1,"840":17,"843":4,"904":8}}],["x1+⋯+xn",{"2":{"247":1}}],["x1可以看做是第一个单词",{"2":{"160":1}}],["x1",{"2":{"11":1,"160":1,"247":1,"590":2,"626":1,"627":1,"659":1,"840":1}}],["owing",{"2":{"899":1}}],["old",{"2":{"721":1,"753":2,"787":7}}],["oi=∑jai",{"2":{"643":2}}],["oio",{"2":{"226":2}}],["oor",{"2":{"634":6}}],["oom",{"2":{"328":1}}],["o+to",{"2":{"628":1}}],["observe",{"2":{"556":1}}],["object>",{"2":{"730":3}}],["objects",{"2":{"721":1}}],["objective",{"2":{"608":1}}],["object",{"2":{"556":3,"723":1,"724":1,"897":1}}],["obj",{"2":{"441":2}}],["os通过parallels",{"2":{"815":1}}],["os",{"2":{"552":2,"555":1}}],["over",{"2":{"633":2,"634":1}}],["override",{"2":{"443":2}}],["overload",{"2":{"443":34,"444":2,"445":347,"496":5,"509":2}}],["overview",{"2":{"302":1,"446":1,"447":1}}],["o延迟",{"2":{"387":1}}],["opt",{"2":{"539":1,"540":1,"542":1,"548":2,"549":3,"571":2}}],["options",{"0":{"504":1}}],["optional",{"2":{"440":6,"444":10,"445":188,"490":5,"496":14,"509":4,"590":1,"634":1}}],["optimizemigration",{"2":{"889":1}}],["optimizes",{"2":{"490":1}}],["optimize",{"2":{"302":1,"509":1,"904":1}}],["optimizers",{"2":{"671":1}}],["optimizer参数是正在使用的优化器实例",{"2":{"509":1}}],["optimizerposthook",{"2":{"509":1}}],["optimizerprehook",{"2":{"509":1}}],["optimizer=",{"2":{"369":4,"370":2}}],["optimizer",{"0":{"256":1,"301":1,"507":1,"508":1,"509":1},"2":{"274":3,"369":1,"484":3,"487":10,"496":1,"497":8,"500":3,"503":2,"505":6,"506":1,"508":7,"509":19,"522":3,"523":3,"533":7,"535":2,"536":1,"537":2,"538":2,"539":1,"540":1,"541":3,"542":1,"543":1,"544":3,"545":3,"546":4,"547":1,"548":1,"549":1,"567":3,"568":2,"671":1,"904":6}}],["optimization",{"2":{"281":1,"294":1,"302":3}}],["optim",{"0":{"501":1,"502":1,"506":1,"507":1,"508":1,"509":1,"532":1},"1":{"503":1,"504":1,"505":1,"507":1,"508":1,"509":1,"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1},"2":{"274":1,"484":1,"487":6,"497":6,"500":3,"501":2,"503":3,"506":1,"509":4,"513":2,"522":1,"523":1,"532":2,"533":3,"541":4,"543":2,"544":2,"545":4,"547":1,"568":1,"575":2,"904":3}}],["op",{"0":{"455":1}}],["operators",{"2":{"671":1}}],["operations",{"0":{"481":1},"2":{"444":1,"471":2,"481":1}}],["opengl",{"2":{"857":1}}],["openssh",{"2":{"816":1}}],["opensession",{"2":{"726":1}}],["openmpi",{"2":{"818":1}}],["openmp",{"2":{"802":1}}],["open",{"2":{"555":1,"794":1,"802":1,"822":2,"891":1}}],["opencv",{"2":{"552":1}}],["openai",{"2":{"126":1,"620":2}}],["o​​+t​o",{"2":{"628":1}}],["o​i​​=​j​∑​​a​i",{"2":{"643":1}}],["o​i​​=∑​j​​a​i",{"2":{"643":1}}],["o​i​​",{"2":{"226":2}}],["o​t​r​​​​",{"2":{"226":1}}],["o​t​​=w​oh​​s​t​​",{"2":{"138":1}}],["o​t​​",{"2":{"137":1}}],["o​1​​",{"2":{"226":1}}],["oh",{"2":{"138":1}}],["otimes⊗",{"2":{"648":1}}],["otro",{"2":{"226":1}}],["ot=wohsto",{"2":{"138":1}}],["oto",{"2":{"137":1}}],["other",{"2":{"99":1,"441":12,"443":61,"445":160,"469":2}}],["only",{"2":{"329":1,"440":1,"441":1,"632":2}}],["online",{"2":{"281":1,"901":1}}],["on",{"2":{"271":1,"444":1,"556":2,"581":6,"582":1,"590":3,"827":1,"895":1}}],["onecyclelr",{"0":{"544":1},"2":{"544":1}}],["one",{"2":{"186":1,"217":1,"303":1,"444":1,"544":3,"556":1,"595":7,"904":1}}],["onesided",{"2":{"445":1}}],["ones",{"2":{"113":1,"428":1,"429":1,"433":1,"445":3,"453":2,"454":1,"456":3,"459":3,"460":2,"493":1,"498":1,"511":1,"649":1}}],["onnxruntime",{"2":{"529":2,"570":1}}],["onnx",{"0":{"570":1},"2":{"115":1,"212":1,"497":2,"528":2,"529":4,"530":3,"570":8,"580":2}}],["onnection",{"2":{"8":1}}],["official",{"0":{"903":1},"2":{"903":1}}],["offering",{"2":{"897":1}}],["off",{"2":{"581":1}}],["offsets",{"2":{"444":1}}],["offset",{"2":{"63":1,"445":11}}],["of",{"0":{"892":1,"897":1,"898":1},"1":{"893":1,"894":1,"895":1,"896":1,"897":1,"899":1,"900":1,"901":1},"2":{"93":3,"94":3,"95":3,"106":1,"113":4,"122":1,"181":1,"217":1,"220":1,"227":1,"271":1,"302":1,"303":1,"306":1,"317":1,"335":1,"337":1,"440":2,"444":3,"446":1,"447":1,"497":2,"544":1,"546":1,"556":7,"581":1,"582":1,"585":1,"589":2,"590":4,"633":6,"634":4,"644":1,"671":1,"823":1,"891":2,"893":1,"895":3,"897":2,"901":1,"904":4}}],["o",{"2":{"48":1,"50":17,"83":1,"181":1,"209":2,"223":5,"224":1,"226":5,"311":1,"312":5,"358":1,"460":4,"621":3,"624":4,"628":6,"643":2,"774":1,"778":2,"822":2,"827":1,"959":3}}],["o=pv∈r​n×d​​",{"2":{"223":1,"312":1}}],["o=pv∈rn×d",{"2":{"223":1,"312":1}}],["o=",{"2":{"48":9}}],["outdim",{"2":{"445":1}}],["outer",{"2":{"327":1,"445":1,"649":1}}],["outo1",{"2":{"45":1}}],["outo1=11+e−neto1out",{"2":{"45":1}}],["outo1=11+e−neto1=11+e−2",{"2":{"41":1}}],["outo1out",{"2":{"44":1,"45":1}}],["outo2=0",{"2":{"41":1}}],["out​o1​",{"2":{"45":1}}],["out​o1​​=​1+e​−net​o1​​​​​​1​​",{"2":{"45":1}}],["out​o1​​=​1+e​−net​o1​​​​​​1​​=​1+e​−2",{"2":{"41":1}}],["out​o1​​",{"2":{"44":1,"45":1}}],["out​o2​​=0",{"2":{"41":1}}],["out​h1​​",{"2":{"44":1}}],["out​h1​​=​1+e​−net​h1​​​​​​1​​=​1+e​−2",{"2":{"40":1}}],["out​h3​​=0",{"2":{"40":1}}],["out​h2​​=0",{"2":{"40":1}}],["out",{"2":{"41":3,"44":6,"45":12,"46":21,"50":15,"245":1,"251":1,"445":7,"459":7,"460":4,"499":15,"500":2,"634":1,"649":5,"706":1,"726":1,"730":1,"731":1,"732":1,"733":1,"827":2,"893":1,"905":1}}],["outh1out",{"2":{"44":1}}],["outh1=11+e−neth1=11+e−2",{"2":{"40":1}}],["outh3=0",{"2":{"40":1}}],["outh2=0",{"2":{"40":1}}],["outputting",{"2":{"581":1}}],["output都是向量",{"2":{"198":1}}],["outputs",{"2":{"38":1,"335":1,"529":4,"546":2,"570":3,"904":2}}],["output",{"0":{"34":1},"2":{"50":1,"57":1,"80":1,"81":5,"83":2,"86":1,"87":5,"88":1,"89":1,"93":1,"94":1,"95":6,"114":1,"121":2,"122":2,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"150":1,"198":1,"319":1,"321":1,"440":2,"444":1,"445":3,"450":2,"453":1,"454":4,"456":8,"457":2,"458":3,"464":1,"468":2,"484":2,"487":8,"493":1,"494":4,"495":5,"497":10,"498":13,"500":32,"505":4,"513":2,"515":3,"518":1,"519":3,"523":3,"526":3,"533":4,"556":27,"567":3,"568":3,"569":3,"570":1,"580":7,"636":1,"649":1}}],["o2",{"2":{"38":2,"41":2,"45":1,"46":12,"50":4}}],["o1",{"2":{"38":2,"41":5,"44":9,"45":19,"46":12,"50":6,"226":1}}],["orm",{"2":{"709":1}}],["ormqr",{"2":{"445":1}}],["original",{"2":{"595":6}}],["orig",{"2":{"595":1}}],["ort",{"2":{"445":1,"570":9}}],["ordereddict",{"2":{"508":6}}],["order",{"2":{"441":1,"445":1}}],["organization",{"2":{"624":4,"628":5}}],["orgqr",{"2":{"445":1}}],["org",{"2":{"122":1,"402":1,"556":1,"583":1,"584":1,"721":1,"726":8,"799":1}}],["or",{"2":{"11":1,"443":3,"445":7,"460":1,"509":4,"556":2,"585":1,"586":1,"590":2,"626":1,"636":1,"895":2}}],["因变量是q与真实后验密度函数的",{"2":{"659":1}}],["因而对hw做归一化",{"2":{"88":1}}],["因为人的本性就是贪心的",{"2":{"975":1}}],["因为往上爬可能还有更高的",{"2":{"970":1}}],["因为只有一个小孩能得到满足",{"2":{"958":1}}],["因为doccano后端是采用django框架搭建的",{"2":{"887":1}}],["因为的的确确不知道",{"2":{"878":1}}],["因为进行了截断",{"2":{"643":1}}],["因为纯粹的attention模块是无法捕捉输入顺序的",{"2":{"638":1}}],["因为输出依赖于过去和当前的输入",{"2":{"616":1}}],["因为您使用的某个模块可能会在训练和评估模式下表现不同",{"2":{"480":1}}],["因为有时候它会被误解为这样的机制",{"2":{"480":1}}],["因为有时候深度学习虽然能有好的表现",{"2":{"19":1}}],["因为使用这些参数作为输入的计算在前向传播中不会被记录",{"2":{"475":1}}],["因为这将在inductor",{"2":{"509":1}}],["因为这将有助于您编写更高效",{"2":{"470":1}}],["因为这些小孩容易被小饼干满足",{"2":{"955":1}}],["因为这些方法在探索阶段有多种优势",{"2":{"370":1}}],["因为这些填充的位置",{"2":{"215":1}}],["因为这些神经元的输出值是未知的",{"2":{"29":1}}],["因为内存",{"2":{"464":1}}],["因为反向求梯度的",{"2":{"463":1}}],["因为最佳学习率恰好位于可行的边缘",{"2":{"408":1}}],["因为最佳的特定衰减方案将对许多其他超参数选择敏感",{"2":{"399":1}}],["因为贝叶斯优化没有机会观察先前试验的结果",{"2":{"401":1}}],["因为正是这种不均匀性才是一个好的优化算法所需要的",{"2":{"401":1}}],["因为采样空间已经变化",{"2":{"401":1}}],["因为预先指定了试验预算并保留了迄今为止看到的",{"2":{"392":1}}],["因为我们的耐心和计算资源有限",{"2":{"383":1}}],["因为网络权重可以无限制地增长",{"2":{"381":1}}],["因为生产模型可能不会像研究中那样在",{"2":{"375":1}}],["因为如果这些正则化参数的低强度设置导致有问题的过拟合是不足为奇的",{"2":{"375":1}}],["因为某些值恰好有更好的冗余超参数配置",{"2":{"371":1}}],["因为很难指定对应的搜索空间",{"2":{"370":1}}],["因为模型结构变化会影响服务和训练成本",{"2":{"369":1}}],["因为像",{"2":{"369":1}}],["因为实验固定了某些超参数",{"2":{"369":1}}],["因为新查询与现有节点不共享任何前缀",{"2":{"338":1}}],["因为可能的重用模式非常多样",{"2":{"337":1}}],["因为可以使用相同的操作和技术",{"2":{"327":1}}],["因为静态并行设置可能导致集群中利用率较低",{"2":{"329":1}}],["因为激活的内存占用呈线性增长",{"2":{"328":1}}],["因为系统等待接收必要的key",{"2":{"327":1}}],["因为每个高斯的中心部分因为被采样次数多必须特色鲜明",{"2":{"657":1}}],["因为每个试验都随机地在",{"2":{"375":1}}],["因为每个批次输入序列长度是不一样的也就是说",{"2":{"215":1}}],["因为每次使用的样本数量较少",{"2":{"262":1}}],["因为在评估期间不需要保持模型运行",{"2":{"390":1}}],["因为在每次参数更新步骤中需要计算整个数据集的梯度",{"2":{"260":1}}],["因为在测试时是单个图片测试",{"2":{"86":1}}],["因为前向传播的时候激活变换为",{"2":{"249":1}}],["因为他们的gradient相同",{"2":{"237":1}}],["因为kv",{"2":{"219":1,"305":1}}],["因为训练的时候每次我们是将target数据完整输入进decoder中地",{"2":{"216":1}}],["因为训练的时候并不是一个生成的过程",{"2":{"179":1}}],["因为它避免了将小饼干浪费在大胃口的小孩身上",{"2":{"960":1}}],["因为它避免了因滥用",{"2":{"411":1}}],["因为它统一但随机地探索给定的搜索空间",{"2":{"401":1}}],["因为它可以隐藏表面下发生的事情的重要细节",{"2":{"375":1}}],["因为它可以使用高度优化的矩阵乘法代码来实现",{"2":{"203":1}}],["因为它确保我们能相对均匀的采样目标超参数值",{"2":{"370":1}}],["因为它往往会对训练速度和内存使用产生巨大影响",{"2":{"369":1}}],["因为它",{"2":{"357":1}}],["因为它这得基于最近的结果和正在进行的研究",{"2":{"353":1}}],["因为它们一开始就不是反向图的一部分",{"2":{"475":1}}],["因为它们对于调试来说非常有价值",{"2":{"390":1}}],["因为它们与训练预算有特别强的相互作用",{"2":{"380":1}}],["因为它们往往与其他变化相互影响",{"2":{"369":1}}],["因为它们是最近最少使用的",{"2":{"338":1}}],["因为它们仅对kv使用一个或少量注意力头",{"2":{"328":1}}],["因为它们没有跨token的操作",{"2":{"328":1}}],["因为它对模型的性能有显著的影响",{"2":{"276":1}}],["因为它包含了两种以上的类别",{"2":{"11":1}}],["因为score函数的每一项都是负的",{"2":{"186":1}}],["因为没有任何的引导",{"2":{"177":1}}],["因为神经网络本来就是非凸的",{"2":{"120":1}}],["因为判别模型中结果取决于数据整体分布",{"2":{"88":1}}],["因为并不会完全还原到跟输入图像一样",{"2":{"61":1}}],["因此广泛用于大规模并行计算场景",{"2":{"805":1}}],["因此避免了共享内存架构中的竞争条件和数据一致性问题",{"2":{"805":1}}],["因此干脆就直接固定",{"2":{"648":1}}],["因此通常来说它不会改变原模型的稳定性",{"2":{"647":1}}],["因此任意偶数维的",{"2":{"647":1}}],["因此一些旨在重新创建和发布",{"2":{"620":1}}],["因此一般我们会设定一些规则",{"2":{"186":1}}],["因此也被称为自回归",{"2":{"620":1}}],["因此移除了",{"2":{"619":1}}],["因此迭代尝试不同的微调方案也更快",{"2":{"617":1}}],["因此被称为迁移学习",{"2":{"617":1}}],["因此该任务被称为遮盖语言建模",{"2":{"616":1}}],["因此该任务被称为因果语言建模",{"2":{"616":1}}],["因此如果用户没有指定特定的实现方式",{"2":{"510":1}}],["因此如何在这三个需求之间分配资源需要一定程度的领域专业知识",{"2":{"371":1}}],["因此您需要传递一个闭包",{"2":{"505":1}}],["因此当启动新试验时",{"2":{"401":1}}],["因此你可以在不重新运行实验的情况下",{"2":{"401":1}}],["因此请确保合适地标记它们",{"2":{"395":1}}],["因此这些",{"2":{"394":1}}],["因此这种类型的语言模型",{"2":{"176":1}}],["因此第一轮非常有用",{"2":{"384":1}}],["因此在当前点存在梯度",{"2":{"473":1}}],["因此在下一轮实验中添加一个或多个这些通常问题不大",{"2":{"375":1}}],["因此在决定是否包含它时",{"2":{"369":1}}],["因此固定权重衰减的强度来比较不同的模型大小",{"2":{"369":1}}],["因此需要一起重新调整",{"2":{"366":1}}],["因此它在模型的调试和开发过程中更具交互性和可读性",{"2":{"559":1}}],["因此它只代表作者在撰写本文时的观点",{"2":{"353":1}}],["因此它会继续学习越来越大的权重",{"2":{"345":1}}],["因此模型不会过度依赖某些神经元",{"2":{"346":1}}],["因此优化ttft至关重要",{"2":{"329":1}}],["因此不再有oom问题",{"2":{"328":1}}],["因此其键值缓存仅有",{"2":{"309":1}}],["因此xavier方法主要是围绕tanh激活函数可能存在的梯度爆炸或梯度消失进行的优化",{"2":{"245":1}}],["因此内存带宽通常不是主要瓶颈",{"2":{"219":1,"305":1}}],["因此具有单个键头和值头",{"2":{"219":1,"305":1}}],["因此我们建议避免使用它们",{"2":{"399":1}}],["因此我们建议在每轮调整中逐渐增加训练步数限制",{"2":{"383":1}}],["因此我们可以更确定哪些参数是最有可能在生产环境中表现良好的参数",{"2":{"383":1}}],["因此我们可以使用长度来对score函数进行细微的调整",{"2":{"186":1}}],["因此我们的",{"2":{"365":1}}],["因此我们拆分来自",{"2":{"338":1}}],["因此我们使用缩放的方法对大型",{"2":{"225":1,"313":1}}],["因此我们需要想一个办法",{"2":{"216":1}}],["因此有必要对transformer模型有一个全面认识",{"2":{"193":1}}],["因此有时也称为",{"2":{"9":1}}],["因此大家把这种方法称为teacher",{"2":{"178":1}}],["因此出现了rnn最重要的一种任务",{"2":{"165":1}}],["因此相对于lstm来说",{"2":{"156":1}}],["因此swish函数可以看作是线性函数和relu函数之间的光滑非线性插值结果",{"2":{"127":1}}],["因此单调性并不是硬性条件",{"2":{"120":1}}],["因此可以在未来的实验中固定住",{"2":{"366":1}}],["因此可以用于batchsize为1和rnn中对边长的输入sequence的normalize操作",{"2":{"87":1}}],["因此可以解决任何复杂的分类问题",{"2":{"14":1}}],["因此",{"2":{"61":1,"91":1,"120":1,"145":1,"173":1,"186":1,"190":1,"219":1,"223":1,"226":1,"235":1,"294":1,"305":1,"312":1,"315":1,"328":2,"333":1,"338":2,"355":1,"359":2,"361":1,"375":1,"377":1,"378":2,"383":1,"409":1,"411":1,"412":1,"423":1,"475":1,"492":1,"510":1,"616":1,"617":1,"648":1,"656":1,"959":1}}],["因此实际常用sigmoid函数作为激活函数",{"2":{"9":1}}],["简洁不废话",{"2":{"875":1}}],["简略",{"0":{"814":1},"1":{"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1}}],["简而言之",{"2":{"644":1}}],["简化编译过程",{"2":{"822":1}}],["简化了运行时调度和匹配",{"2":{"338":1}}],["简化伪代码",{"2":{"315":1}}],["简单总结一下",{"0":{"928":1}}],["简单易用",{"2":{"802":1}}],["简单易学",{"2":{"724":1}}],["简单的几个字",{"2":{"875":1,"880":1}}],["简单的一阶马尔可夫性假设可能不足以捕捉到完整的依赖关系",{"2":{"630":1}}],["简单的说就是先根据之前累积的梯度方向模拟下一步参数更新后的值",{"2":{"269":1}}],["简单",{"2":{"363":1,"875":1}}],["简单快速",{"2":{"183":1}}],["简单一点就是",{"2":{"145":1}}],["简单来说",{"2":{"11":1}}],["简述",{"0":{"160":1},"2":{"87":1,"88":1}}],["简介",{"0":{"68":1,"332":1,"703":1,"738":1},"1":{"69":1,"70":1,"704":1,"705":1,"706":1}}],["简称rl",{"2":{"21":1}}],["简称为深度神经网络",{"2":{"13":1}}],["简称神经网络",{"2":{"5":1}}],["lh",{"2":{"742":1}}],["lbrace",{"2":{"647":1}}],["lgamma",{"2":{"445":2}}],["lcm",{"2":{"445":2}}],["lc×l",{"2":{"249":1}}],["ls",{"2":{"740":2,"742":4,"746":1}}],["lshift",{"2":{"443":3}}],["lstsq",{"2":{"441":1}}],["lstm的核心概念是cell",{"2":{"145":1}}],["lstm适合于处理和预测时间序列中间隔和延迟非常长的重要事件",{"2":{"144":1}}],["lstm",{"0":{"144":1,"145":1,"146":1,"152":1,"153":1,"155":1},"1":{"145":1,"146":1,"147":2,"148":2,"149":2,"150":2,"151":2,"152":1,"153":1},"2":{"143":1,"144":1,"152":1,"616":1}}],["lu",{"2":{"441":4,"445":3}}],["luong",{"2":{"174":2,"192":2}}],["l​j​​",{"2":{"322":1,"323":1}}],["l​j​​=m​j​​+log",{"2":{"322":1,"323":1}}],["l^",{"2":{"322":2,"323":2}}],["lj",{"2":{"322":1,"323":1}}],["lj=mj+log",{"2":{"322":1,"323":1}}],["ldexp",{"2":{"445":2}}],["ld​c​​∗l",{"2":{"309":1}}],["ldots",{"2":{"181":1,"185":3,"209":1,"225":1,"313":1,"626":4,"627":4,"647":1}}],["llama",{"0":{"649":1,"663":1,"664":1,"665":1,"666":1},"2":{"332":1,"645":1,"671":1}}],["llm",{"2":{"337":4,"338":2}}],["llm的所有输入token产生它们的注意力key",{"2":{"333":1}}],["llm承诺从根本上改变我们在所有行业中使用人工智能的方式",{"2":{"332":1}}],["llm在处理长上下文",{"2":{"328":1}}],["ll",{"2":{"309":1}}],["lll",{"2":{"225":1,"313":1,"322":1}}],["l+1",{"2":{"249":2}}],["lmpi",{"2":{"822":1}}],["lm可以通过目标语言的语料进行训练",{"2":{"190":1}}],["lm",{"2":{"176":2,"177":1,"180":1,"190":1}}],["lt",{"2":{"120":1,"122":2,"328":1,"443":1,"445":4,"757":1,"784":1,"792":1,"836":2,"841":2,"853":6}}],["level",{"2":{"857":1}}],["leibler",{"2":{"659":1}}],["let",{"2":{"556":2}}],["less",{"2":{"445":8,"743":2}}],["lerp",{"2":{"445":4}}],["le",{"2":{"443":1,"445":4}}],["len维度的并行",{"2":{"324":1}}],["len",{"2":{"227":2,"317":2,"441":1,"497":6,"498":7,"499":15,"508":1,"529":2,"546":1,"552":4,"556":2,"567":3,"577":1,"595":4,"635":4,"649":12,"799":1,"957":2}}],["length的实验",{"2":{"383":1}}],["length时",{"2":{"383":1}}],["length",{"2":{"87":2,"326":5,"383":1,"444":1,"445":6,"499":5,"500":11,"632":5,"633":4,"634":9,"636":1,"799":1}}],["left",{"2":{"225":1,"248":1,"249":1,"313":1,"406":1,"410":2,"445":5,"556":4,"647":1}}],["leq",{"2":{"126":1}}],["leading",{"2":{"905":1}}],["leaf",{"2":{"445":1,"462":1}}],["least",{"2":{"337":1}}],["leakeyrelu",{"2":{"124":1}}],["leakyrelu",{"2":{"124":1,"487":2}}],["leaky",{"2":{"120":1,"124":2}}],["learn",{"2":{"891":1}}],["learnable",{"0":{"641":1},"2":{"86":2,"88":2}}],["learning",{"0":{"531":1,"534":1,"671":1},"2":{"4":3,"5":1,"21":1,"258":1,"271":1,"281":1,"289":1,"302":1,"337":1,"369":3,"370":2,"409":10,"421":1,"422":1,"497":2,"500":1,"503":1,"531":1,"541":1,"543":1,"544":1,"545":1,"585":2,"590":2,"616":2,"620":1,"636":1,"644":1,"671":3,"868":1,"874":2,"891":1,"896":1,"897":1,"899":1,"901":1,"904":1,"905":2}}],["ln的区别",{"2":{"87":1}}],["ln不依赖于batch的大小和输入sequence的深度",{"2":{"87":1}}],["ln中同层神经元输入拥有相同的均值和方差",{"2":{"87":1}}],["ln一般只用于rnn的场景下",{"2":{"87":1}}],["ln",{"2":{"87":4,"128":3}}],["liu",{"2":{"843":1,"856":1,"966":1}}],["limit=",{"2":{"581":1}}],["limits",{"2":{"381":1,"644":1}}],["literal",{"2":{"445":2}}],["libraries",{"0":{"897":1},"2":{"897":2}}],["library",{"2":{"75":1,"556":1,"843":1}}],["lib",{"2":{"436":1,"822":1}}],["like",{"2":{"429":3,"453":2,"456":3,"459":3,"556":1,"649":1,"734":2,"895":1,"897":2,"900":1}}],["lists",{"2":{"895":1}}],["listdir",{"2":{"552":1}}],["list",{"2":{"427":1,"440":1,"443":2,"445":22,"457":2,"508":4,"509":1,"529":4,"634":3,"726":4,"730":1,"734":2}}],["linux虚拟机系统",{"2":{"909":1}}],["linux等",{"2":{"833":1}}],["linux基础",{"2":{"832":1}}],["linux基础部分",{"0":{"735":1},"1":{"736":1,"737":1,"738":1,"739":1,"740":1,"741":1,"742":1,"743":1,"744":1,"745":1,"746":1,"747":1,"748":1,"749":1,"750":1,"751":1,"752":1,"753":1,"754":1,"755":1,"756":1,"757":1,"758":1,"759":1,"760":1,"761":1,"762":1,"763":1,"764":1,"765":1,"766":1,"767":1,"768":1,"769":1,"770":1,"771":1,"772":1,"773":1,"774":1,"775":1,"776":1,"777":1,"778":1,"779":1,"780":1,"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1,"788":1,"789":1,"790":1,"791":1,"792":1,"793":1},"2":{"868":1}}],["linux模块",{"0":{"832":1}}],["linux为主",{"2":{"827":1}}],["linux安装配置mpich",{"2":{"827":1}}],["linux环境",{"0":{"815":1}}],["linux",{"0":{"737":1},"1":{"738":1,"739":1,"740":1},"2":{"738":1,"743":1,"794":1,"827":5}}],["link",{"2":{"285":2,"289":1,"296":1,"300":1,"387":1,"470":1,"501":1,"532":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"551":1,"903":1}}],["lin等人提出使用全局平均池化global",{"2":{"95":1}}],["linearlr",{"0":{"540":1},"2":{"540":1}}],["linear",{"0":{"83":1,"125":1,"126":1},"2":{"83":1,"122":2,"124":3,"208":1,"328":2,"445":4,"456":3,"457":1,"484":8,"487":8,"489":3,"492":2,"494":3,"495":3,"497":4,"498":8,"499":6,"500":9,"513":2,"567":2,"649":3,"904":3}}],["l=2",{"2":{"60":1}}],["l=1",{"2":{"60":1}}],["l",{"2":{"40":2,"60":2,"248":60,"249":17,"319":1,"323":1,"338":1,"414":1,"415":1,"416":2,"417":2,"418":2,"419":3,"590":2,"608":1,"742":1,"746":1,"780":1,"790":1,"822":3}}],["l20031220",{"2":{"726":1}}],["l2",{"2":{"38":1,"405":3,"456":3,"457":1}}],["l1",{"2":{"38":1}}],["lam",{"2":{"802":1}}],["lambd",{"2":{"445":2}}],["lambda=lmbda",{"2":{"536":1}}],["lambda=",{"2":{"535":1}}],["lambda2",{"2":{"535":2}}],["lambda1",{"2":{"535":2}}],["lambdalr",{"0":{"535":1},"2":{"535":1}}],["lambdaλ",{"2":{"410":1}}],["lambda",{"2":{"125":1,"410":1,"457":1,"535":2,"536":1}}],["law",{"2":{"671":1}}],["laws",{"0":{"661":1}}],["laion2b",{"2":{"608":1}}],["launch",{"2":{"590":1}}],["latest",{"2":{"590":1}}],["latent",{"0":{"307":1,"598":1},"1":{"308":1,"309":1},"2":{"657":1}}],["landscape",{"2":{"905":1}}],["landmarks",{"2":{"556":20}}],["langle",{"2":{"646":1}}],["language",{"0":{"661":1},"2":{"176":1,"188":2,"190":2,"605":1,"616":3,"619":4,"620":1,"857":2,"896":1,"897":1,"899":1}}],["last",{"2":{"440":1,"499":1,"535":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"632":2,"634":2,"789":1}}],["largest",{"2":{"445":1}}],["large",{"0":{"662":1},"2":{"227":1,"317":1,"333":1,"544":1,"586":1,"590":2,"891":1,"901":1}}],["layout分页布局中",{"2":{"338":1}}],["layout",{"2":{"99":1,"440":2,"444":2,"445":18}}],["layers",{"0":{"460":1},"2":{"492":1,"498":6,"499":4,"500":9,"904":1}}],["layernorm等",{"2":{"328":1}}],["layernorm结束",{"2":{"328":1}}],["layernorm",{"0":{"87":1},"2":{"87":2,"89":1,"498":2,"499":2,"500":5}}],["layer",{"0":{"483":1,"488":1,"499":1},"1":{"484":1,"485":1},"2":{"13":2,"51":1,"87":2,"91":4,"117":2,"329":1,"456":3,"457":1,"498":3,"499":2,"500":5}}],["lable",{"2":{"50":4,"484":1,"487":2}}],["labeled",{"2":{"584":1}}],["labels",{"2":{"546":3,"552":5,"580":1,"904":2}}],["labeling",{"2":{"188":2,"613":2}}],["label",{"0":{"345":1},"2":{"29":1,"38":1,"50":13,"345":1,"454":2,"456":6,"457":2,"460":2,"484":2,"487":3,"552":4,"553":1,"635":5}}],["loop",{"2":{"581":1,"904":3}}],["loop的一个迭代",{"2":{"327":1}}],["locatebashlocate",{"2":{"765":1}}],["location=device",{"2":{"511":1,"519":1}}],["localhost",{"2":{"726":1}}],["locally",{"2":{"496":2}}],["local",{"2":{"496":4,"827":5}}],["loaddata",{"2":{"889":1}}],["loading",{"2":{"590":1}}],["loaded",{"2":{"569":2}}],["loader",{"2":{"497":13,"543":2,"544":3,"556":1,"577":1}}],["loads",{"2":{"509":1}}],["load",{"2":{"490":4,"496":5,"508":2,"509":13,"511":3,"515":3,"519":3,"523":4,"526":3,"568":1,"569":1}}],["lowering",{"2":{"509":1}}],["low",{"0":{"325":1}}],["logs",{"2":{"578":1}}],["logsumexp",{"2":{"445":2,"633":2}}],["logdir",{"2":{"578":1}}],["logdir=",{"2":{"578":2,"580":1}}],["logdet",{"2":{"445":1}}],["logging",{"2":{"497":1}}],["logits",{"2":{"454":1,"489":3}}],["logit",{"2":{"445":2}}],["logical",{"2":{"445":8}}],["logic",{"2":{"10":1}}],["logcumsumexp",{"2":{"445":2}}],["logaddexp2",{"2":{"445":1}}],["logaddexp",{"2":{"445":1}}],["log2",{"2":{"445":2}}],["log1p",{"2":{"445":2}}],["log10",{"2":{"445":2}}],["logp",{"2":{"185":2}}],["log",{"2":{"181":6,"185":2,"322":1,"323":1,"445":5,"473":2,"497":6,"513":1,"576":1,"577":1,"578":1,"579":1,"580":1,"581":1,"633":2,"772":3,"959":2}}],["long",{"0":{"144":1},"1":{"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1},"2":{"144":1,"443":1,"445":1,"632":1,"634":6}}],["longtensor",{"2":{"113":3,"632":1}}],["loss的特性有关",{"2":{"381":1}}],["loss且没有正则化项时",{"2":{"381":1}}],["loss函数",{"2":{"343":1}}],["loss关于权值参数的梯度很小",{"2":{"236":1}}],["loss=f",{"2":{"28":2}}],["loss",{"0":{"291":1,"577":1},"2":{"26":1,"28":2,"50":15,"274":1,"450":2,"454":5,"455":2,"456":15,"457":3,"460":3,"484":3,"487":9,"495":2,"497":13,"500":4,"505":7,"522":3,"523":2,"533":6,"546":2,"547":2,"567":7,"576":2,"577":4,"586":1,"904":10}}],["lr=initial",{"2":{"545":1}}],["lr=base​l​​r∗",{"2":{"542":1}}],["lr=baselr∗",{"2":{"542":1}}],["lr=1e",{"2":{"504":1}}],["lr=learning",{"2":{"500":1}}],["lr=args",{"2":{"497":2}}],["lr=0",{"2":{"274":1,"484":1,"487":6,"497":1,"503":2,"522":1,"523":1,"533":2,"541":1,"543":3,"544":2,"547":1,"568":1,"904":1}}],["lru",{"2":{"337":1,"338":3}}],["lr",{"0":{"532":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"548":1,"549":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1},"2":{"26":3,"50":3,"385":1,"399":4,"405":4,"497":5,"504":1,"532":2,"533":1,"535":1,"536":1,"537":5,"538":5,"539":7,"540":7,"541":3,"542":8,"543":1,"544":1,"545":10,"548":6,"549":6,"550":1,"585":1,"590":5,"671":1}}],["亦称",{"2":{"10":1}}],["输入services",{"2":{"913":1}}],["输入序列",{"2":{"626":1}}],["输入序列的长度就成了限制模型性能的瓶颈",{"2":{"173":1}}],["输入参数转为",{"2":{"508":1}}],["输入数据",{"2":{"484":1}}],["输入的tensor",{"2":{"464":1}}],["输入的视图",{"2":{"445":1}}],["输入管道性能受限的原因及干预措施与具体任务高度相关",{"2":{"387":1}}],["输入标记可能比输出标记大10到100倍",{"2":{"329":1}}],["输入到",{"2":{"171":1}}],["输入一段视频并判断它的类别等等",{"2":{"163":1}}],["输入一个句子判断其情感倾向",{"2":{"163":1}}],["输入和输出序列必须要是等长的",{"2":{"161":1}}],["输入门决定了从当前步骤中添加哪些相关信息",{"2":{"151":1}}],["输入门",{"0":{"148":1},"2":{"146":1}}],["输入time的时候",{"2":{"142":1}}],["输入中元素的顺序保持不变",{"2":{"107":1}}],["输入中最外层0是什么",{"2":{"55":1}}],["输入",{"0":{"953":1},"2":{"24":1,"55":2,"204":1,"580":1,"644":6}}],["输入层用于接受外界输入信号",{"2":{"10":1}}],["输出内容长度",{"2":{"799":1}}],["输出整理后的结果",{"2":{"799":1}}],["输出示例",{"2":{"746":1}}],["输出最终的运行时均值和方差",{"2":{"493":1}}],["输出当前批次的均值和方差",{"2":{"493":1}}],["输出张量",{"2":{"490":1}}],["输出长度进行抽样",{"2":{"332":1}}],["输出序列的累积损失越小",{"2":{"185":1}}],["输出序列长度m",{"2":{"165":1}}],["输出的context",{"2":{"171":1}}],["输出的值介于",{"2":{"147":1}}],["输出为tensor",{"2":{"452":1}}],["输出为一维的",{"2":{"441":1}}],["输出为value的加权和",{"2":{"198":1}}],["输出为",{"2":{"161":1}}],["输出结果就是隐藏状态",{"2":{"150":1}}],["输出门确定了下一个隐藏状态应该是什么样子",{"2":{"151":1}}],["输出门决定下一个隐藏状态应该是什么样子",{"2":{"150":1}}],["输出门",{"0":{"150":1},"2":{"146":1}}],["输出是相应的单词嵌入",{"2":{"113":1}}],["输出",{"0":{"954":1},"2":{"55":1,"111":3,"338":1,"958":1}}],["输出也以同样的方式改变这一性质",{"2":{"54":1}}],["输出有时被称作特征映射或特征图",{"2":{"52":1}}],["输出层",{"2":{"10":1}}],["输出值范围内",{"2":{"9":1}}],["ssh",{"2":{"827":9}}],["ssh扩展",{"2":{"816":1}}],["ssh工具",{"0":{"816":1}}],["ssh连接",{"2":{"794":1}}],["ssbashnetstat",{"2":{"760":1}}],["sspaddmm",{"2":{"445":1}}],["s3",{"2":{"613":1}}],["sd3",{"2":{"612":1}}],["sdxl",{"0":{"609":1,"611":1},"2":{"609":3,"610":1}}],["sd2",{"0":{"608":1}}],["sd",{"0":{"595":1,"596":1,"607":1,"609":1},"1":{"608":1,"609":1},"2":{"608":12,"609":1,"610":2}}],["skip",{"2":{"499":1,"581":1}}],["svd",{"2":{"445":2}}],["src",{"2":{"445":15,"482":1,"499":2,"500":19,"636":1}}],["sram",{"2":{"226":2,"315":1}}],["sysconfig",{"2":{"915":1}}],["syslog",{"2":{"772":2}}],["system",{"2":{"680":1,"706":1,"726":1,"730":1,"731":1,"732":1,"733":1,"894":1}}],["systems",{"2":{"188":1,"900":1}}],["symfloat",{"2":{"445":9}}],["symint",{"2":{"445":54}}],["sgn",{"2":{"445":2}}],["sglang",{"2":{"336":1,"337":2,"339":1}}],["sgdr",{"2":{"545":1,"546":1}}],["sgd能够在多个局部最小值之间进行搜索",{"2":{"261":1}}],["sgd的参数更新在每次迭代中都具有一定的随机性",{"2":{"261":1}}],["sgd的参数更新速度比bgd更快",{"2":{"261":1}}],["sgd每次仅使用单个样本或一小批样本的梯度进行参数更新",{"2":{"261":1}}],["sgd",{"0":{"261":1,"263":1,"272":1,"414":1},"1":{"264":1,"265":1,"266":1,"267":1,"273":1,"274":1},"2":{"26":1,"261":1,"262":2,"269":1,"270":1,"274":1,"356":3,"484":1,"487":2,"497":1,"503":1,"504":1,"533":2,"541":1,"543":1,"544":1,"545":1,"547":1,"568":1,"904":1}}],["sleep",{"2":{"904":1}}],["slow",{"2":{"496":1}}],["slogdet",{"2":{"445":2}}],["slo",{"2":{"329":1}}],["slice",{"0":{"109":1,"111":1},"1":{"110":1,"111":1},"2":{"111":4,"443":2,"445":1}}],["s翻倍",{"2":{"325":1}}],["s的50",{"2":{"320":1}}],["s^",{"2":{"244":2}}],["s​ij​​−m​ij​​",{"2":{"226":1}}],["s​ij​​",{"2":{"226":1}}],["s​ij​​=q​i​​k​j​t​​∈r​b​r​​×b​c​​​​",{"2":{"226":1}}],["s​t​​=σ",{"2":{"138":1}}],["s​t​​",{"2":{"137":1}}],["s=qk​⊤​​∈r​n×n​​",{"2":{"223":1,"312":1}}],["s=qk⊤∈rn×n",{"2":{"223":1,"312":1}}],["so",{"2":{"556":1,"633":3,"634":1,"896":1}}],["some",{"2":{"445":2,"556":1}}],["sorted",{"2":{"445":1}}],["sorted=true",{"2":{"441":1}}],["sort",{"2":{"445":9,"581":1,"957":2}}],["solution",{"2":{"441":1}}],["solve",{"2":{"441":3,"445":4}}],["softsign这三种激活函数",{"2":{"245":1}}],["softmax函数用于将一组实数转换为范围在",{"2":{"129":1}}],["softmax",{"0":{"129":1,"321":1},"2":{"129":5,"215":2,"223":1,"225":10,"226":3,"312":1,"313":11,"315":3,"319":1,"321":2,"345":1,"445":4,"497":2,"498":1,"499":1,"500":1,"513":1,"619":1,"643":1,"649":1}}],["source端",{"2":{"213":1}}],["source",{"2":{"190":1,"445":17,"823":1,"891":1}}],["small",{"2":{"590":2,"636":1}}],["smaller",{"2":{"227":1,"317":1,"556":1}}],["smm",{"2":{"445":1}}],["smoothing",{"0":{"345":1},"2":{"345":1}}],["smt的门槛也是很高的",{"2":{"190":1}}],["smt的主要思想就是从大量的数据中学习一个概率模型",{"2":{"190":1}}],["smt",{"0":{"190":1},"2":{"189":1,"190":1}}],["smi",{"2":{"71":1,"734":2}}],["shdocker",{"2":{"886":1}}],["shell",{"2":{"889":1}}],["shellavailable",{"2":{"889":1}}],["shell脚本",{"2":{"832":1}}],["shell01",{"2":{"671":1}}],["shellgit",{"2":{"592":1,"613":1,"636":1}}],["shecuder",{"2":{"550":1}}],["sh",{"2":{"584":1}}],["shufflenet",{"2":{"590":4}}],["shuffle=true",{"2":{"553":1,"568":1,"580":1}}],["shuffle",{"2":{"497":1}}],["shiftwidth=4",{"2":{"792":1}}],["shifts",{"2":{"445":1}}],["shift",{"2":{"445":8}}],["showmigrations",{"2":{"889":1}}],["show",{"2":{"590":1}}],["should",{"2":{"444":1,"547":1,"587":1}}],["shot",{"2":{"337":1,"620":1}}],["shorter",{"2":{"556":1}}],["short",{"0":{"144":1},"1":{"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1},"2":{"144":1,"445":1}}],["shader",{"2":{"857":2}}],["shallue",{"2":{"350":1,"357":1,"359":1,"363":1,"412":1,"421":1}}],["shazeer",{"2":{"308":1}}],["shared",{"2":{"322":1,"441":2}}],["share",{"2":{"217":1,"303":1,"335":1,"441":1,"496":1}}],["sharing",{"2":{"54":1}}],["shapes",{"2":{"530":1}}],["shaped",{"2":{"212":1}}],["shape",{"0":{"530":1},"2":{"55":1,"63":2,"86":1,"87":2,"88":1,"89":5,"248":2,"436":3,"439":1,"440":1,"445":3,"489":1,"498":4,"499":10,"515":2,"519":2,"523":2,"530":3,"556":2,"580":4,"595":4,"632":7,"633":10,"634":9,"649":8}}],["sx",{"2":{"138":1}}],["s型神经元",{"2":{"127":1}}],["s型激活函数分析",{"2":{"121":1}}],["scripts",{"2":{"915":1}}],["scripted",{"2":{"568":6}}],["script装饰器标记模型的函数时",{"2":{"563":1}}],["script通过静态分析和推断来捕获模型的计算图",{"2":{"563":1}}],["script",{"0":{"563":1,"568":1},"2":{"568":3}}],["scaling",{"0":{"661":1},"2":{"671":1}}],["scalars",{"2":{"576":1,"577":1}}],["scalar",{"0":{"576":1},"2":{"497":1,"576":5}}],["scale",{"2":{"445":1,"556":2}}],["scales",{"2":{"445":1}}],["scaled",{"0":{"125":1,"198":1},"1":{"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":1,"206":1},"2":{"215":1,"498":1,"500":1}}],["scatter在底层转换为环拓扑中的点对点通信",{"2":{"328":1}}],["scatter到kv的激活梯度",{"2":{"328":1}}],["scatter",{"2":{"328":2,"445":21,"634":1,"806":1,"808":1}}],["score评估自然语言",{"2":{"605":1}}],["score较高时",{"2":{"605":1}}],["score是指将文本和图像对输入到openai的clip",{"2":{"605":1}}],["scores",{"2":{"215":4,"498":4,"500":4,"633":2,"635":4,"649":5}}],["score往往就越小",{"2":{"186":1}}],["score",{"0":{"605":1,"635":1},"2":{"185":3,"205":1,"322":1,"605":1,"606":1,"627":1,"632":11,"633":22,"634":32}}],["sconcat等",{"2":{"117":1}}],["scheduling",{"2":{"531":1}}],["schedule=torch",{"2":{"581":1}}],["schedule",{"2":{"581":2,"585":1}}],["schedulers=",{"2":{"549":1}}],["scheduler2",{"2":{"533":2,"548":2,"549":2}}],["scheduler1",{"2":{"533":2,"548":2,"549":2}}],["scheduler",{"0":{"532":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"548":1,"549":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1},"2":{"497":3,"532":2,"533":5,"535":2,"536":2,"537":2,"538":2,"539":2,"540":2,"541":4,"542":2,"543":3,"544":3,"545":5,"546":6,"547":2,"548":2,"549":2,"671":1}}],["scheduled",{"0":{"179":1},"2":{"179":1}}],["scholar",{"2":{"126":1}}],["say",{"2":{"556":1}}],["saving",{"2":{"497":1}}],["saves",{"2":{"634":2}}],["saved",{"0":{"472":1},"2":{"458":1,"469":4,"472":8}}],["savedmodels",{"2":{"390":1}}],["save",{"2":{"458":1,"472":1,"496":1,"497":3,"511":2,"514":2,"518":2,"522":2,"525":3,"555":1,"568":1,"569":1,"634":1,"671":1}}],["same",{"2":{"445":1,"556":2,"595":1}}],["sample",{"2":{"546":3,"556":18,"633":2}}],["samples",{"2":{"113":1,"335":1,"445":1,"556":1,"595":10,"904":1}}],["sampling",{"0":{"179":1},"2":{"179":1,"335":1}}],["safer",{"2":{"556":1}}],["safe",{"2":{"313":1}}],["saturated",{"2":{"240":1}}],["saturation",{"2":{"120":1}}],["stick",{"2":{"556":1}}],["stdlib",{"2":{"827":1}}],["stdio",{"2":{"823":1,"827":1}}],["std",{"2":{"445":7}}],["stft",{"2":{"441":1}}],["stores",{"2":{"633":3,"634":1}}],["store",{"2":{"497":4,"895":1}}],["storage",{"2":{"436":1,"441":4,"443":2,"444":1,"445":15}}],["stochastic",{"0":{"261":1,"414":1},"2":{"261":1,"281":1,"294":1,"545":1,"546":1}}],["string",{"2":{"706":1,"726":3,"730":5}}],["strict",{"2":{"496":2}}],["strided",{"2":{"445":5}}],["strides",{"2":{"444":2}}],["stride=",{"2":{"80":2,"81":1,"93":1,"94":1}}],["stride=2",{"2":{"80":1,"81":3,"93":2,"94":2,"580":1}}],["stride",{"2":{"80":3,"81":2,"436":3,"445":8,"636":1}}],["stream",{"2":{"445":2}}],["stream=none",{"2":{"441":1}}],["str",{"2":{"440":1,"445":94,"490":4,"496":28,"508":1,"509":5,"581":1,"799":2}}],["struct等函数创建适合具体应用的数据类型",{"2":{"809":1}}],["struct",{"2":{"436":1,"468":1}}],["structure",{"0":{"219":1,"305":1}}],["strategy",{"0":{"338":1}}],["st=σ",{"2":{"138":1}}],["sts",{"2":{"137":1}}],["step4",{"2":{"497":1}}],["steplr",{"0":{"537":1},"2":{"497":2,"537":1}}],["steps来解决这个问题",{"2":{"409":1}}],["steps进行调优",{"2":{"409":1}}],["steps的5",{"2":{"409":1}}],["steps的值是10000",{"2":{"409":1}}],["steps的值是必要的",{"2":{"382":1}}],["steps的10",{"2":{"409":1}}],["steps的两倍就可以了",{"2":{"409":1}}],["steps的过程中",{"2":{"409":2}}],["steps的数值",{"2":{"381":1}}],["stepsd的起点n",{"2":{"382":1}}],["steps应该有一个确定的值可以完美地拟合训练集",{"2":{"382":1}}],["steps可能需要增加起始值",{"2":{"381":1}}],["steps选择初始候选值",{"2":{"381":1}}],["steps相关",{"2":{"381":1}}],["steps",{"0":{"382":1},"2":{"381":2,"382":1,"385":1,"409":7,"544":5}}],["step3",{"2":{"315":1}}],["step2",{"2":{"315":1,"497":1}}],["step1",{"2":{"315":1,"497":2}}],["step",{"2":{"111":2,"137":1,"216":1,"274":1,"445":2,"484":1,"487":2,"497":14,"500":1,"505":5,"508":3,"509":13,"533":6,"535":1,"536":1,"537":3,"538":1,"539":1,"540":1,"541":1,"542":1,"543":2,"544":3,"545":1,"546":6,"547":2,"548":1,"549":1,"567":1,"581":4,"893":2,"904":3}}],["stale",{"2":{"889":1}}],["stage3",{"2":{"609":1}}],["stage2",{"2":{"609":1}}],["stage",{"2":{"609":3}}],["stable",{"0":{"593":1,"600":1},"1":{"594":1,"595":1,"596":1,"597":1,"598":1,"599":1,"601":1,"602":1,"603":1},"2":{"445":3,"556":1,"612":1,"671":1}}],["stands",{"2":{"905":1}}],["standard",{"2":{"312":1,"703":1}}],["stan",{"2":{"420":1}}],["status",{"2":{"497":1,"799":7,"823":3}}],["staticfiles",{"2":{"889":1}}],["static",{"2":{"445":1,"559":1,"706":1,"726":3}}],["staticmethod",{"2":{"444":1,"458":2,"509":3}}],["statistical",{"2":{"189":1}}],["state是一个将参数id映射到相应参数状态字典的字典",{"2":{"509":1}}],["statedict",{"2":{"509":6}}],["states的哪些信息应该被丢弃和保留",{"2":{"147":1}}],["state",{"0":{"149":1},"2":{"145":1,"146":1,"160":1,"213":1,"441":1,"490":11,"493":1,"496":27,"508":9,"509":32,"514":1,"515":1,"522":4,"523":4}}],["state可以在处理序列的过程中携带相关信息",{"2":{"145":1}}],["state充当传输高速公路",{"2":{"145":1}}],["state和其各种gates",{"2":{"145":1}}],["startproject",{"2":{"889":1}}],["startapp",{"2":{"889":1}}],["starts",{"2":{"585":1}}],["started",{"2":{"581":1,"586":1}}],["starting",{"2":{"581":1}}],["start",{"2":{"107":1,"445":7,"540":1,"581":1,"590":2,"632":2,"633":2,"634":2,"799":1,"827":5}}],["stack",{"0":{"103":1,"105":1},"1":{"104":1,"105":1,"106":1,"107":1},"2":{"105":1}}],["swagger",{"2":{"889":1}}],["swap指令",{"0":{"692":1}}],["swapped",{"2":{"556":1}}],["swap",{"2":{"556":2}}],["swapdims",{"2":{"445":2}}],["swapaxes",{"2":{"445":2}}],["swaps",{"2":{"99":1}}],["swish函数退化成relu函数",{"2":{"127":1}}],["swish函数退化成线性函数",{"2":{"127":1}}],["swish",{"0":{"127":1},"2":{"127":7}}],["switch",{"0":{"90":1},"2":{"706":1}}],["sn是一种覆盖特征图张量各个维度来计算统计信息的归一化方法",{"2":{"90":1}}],["s",{"0":{"121":1},"2":{"87":2,"121":1,"127":1,"138":3,"181":1,"223":6,"226":2,"228":1,"312":6,"318":1,"320":2,"327":1,"444":2,"445":3,"497":1,"556":6,"584":1,"586":1,"753":1,"787":5,"827":1,"891":1,"895":1,"896":1,"897":1,"904":2,"953":2,"956":2,"957":4,"958":2}}],["semaphore",{"2":{"682":1}}],["semantic",{"2":{"188":1}}],["sendtestemail",{"2":{"889":1}}],["send配合使用",{"2":{"808":1}}],["send和mpi",{"2":{"806":1}}],["send",{"2":{"581":1,"808":1,"823":1}}],["sentiment",{"2":{"188":1,"897":1}}],["sentence",{"2":{"87":2,"181":1,"619":1}}],["see",{"2":{"556":2}}],["seed",{"2":{"454":1,"456":3,"487":1,"497":4,"590":5}}],["serializetostring",{"2":{"529":1}}],["server",{"2":{"802":1}}],["server的最新技术水平",{"2":{"332":1}}],["servlet",{"2":{"710":1}}],["service",{"2":{"387":1}}],["sessions",{"2":{"889":1}}],["session中",{"2":{"570":1}}],["session",{"2":{"529":6,"570":3,"726":7,"730":3,"731":4,"732":4,"733":4}}],["second",{"2":{"454":1,"581":1}}],["sections",{"2":{"445":5}}],["seamless",{"2":{"444":1}}],["search获得较好的结果",{"0":{"403":1}}],["search很简单",{"2":{"401":1}}],["search遍历中的最佳点位于搜索空间的边界",{"2":{"401":1}}],["search以一致且数据上可重现的方式运行",{"2":{"401":1}}],["search可以被认为是",{"2":{"401":1}}],["search而不是更复杂的黑盒优化算法",{"0":{"401":1}}],["search的实现",{"0":{"402":1}}],["search的非自适应性质使得我们可以基于最终验证误差",{"2":{"401":1}}],["search的优势包括",{"2":{"401":1}}],["search的优化方式不再适用",{"2":{"379":1}}],["search的操作步骤如下",{"2":{"184":1}}],["search搜索",{"2":{"378":1}}],["search算法不可用",{"2":{"402":1}}],["search算法",{"2":{"370":1}}],["search算法通过这种方式在保持一定搜索广度的同时",{"2":{"186":1}}],["search过程",{"2":{"186":1}}],["search会根据某种评估指标",{"2":{"186":1}}],["search方法",{"2":{"183":1}}],["search",{"0":{"182":1,"184":1,"186":1},"1":{"183":1,"184":1,"185":1,"186":1},"2":{"127":2,"184":1,"335":1,"337":1,"376":1,"401":3}}],["setpwd",{"2":{"732":1}}],["setup",{"2":{"613":2}}],["sets",{"2":{"507":1}}],["setstate",{"2":{"441":1,"496":1,"509":1}}],["settings",{"2":{"497":1}}],["setattr",{"2":{"492":2,"496":1}}],["setitem",{"2":{"443":1}}],["set",{"0":{"691":1},"2":{"217":1,"303":1,"445":3,"453":2,"474":1,"490":2,"496":3,"497":1,"509":1,"581":1,"590":2,"633":1,"634":1,"726":1,"732":1,"792":3,"904":1}}],["selectlike",{"2":{"734":4}}],["selectlist",{"2":{"726":1}}],["select语句有很多属性可以详细配置每一条sql语句",{"2":{"730":1}}],["select标签是mybatis中最常用的标签之一",{"2":{"730":1}}],["select>",{"2":{"726":1,"730":3,"734":2}}],["selectuserbynp2",{"2":{"730":3}}],["selectuserbynp",{"2":{"730":2}}],["selectuserbyid",{"2":{"730":3,"732":1}}],["selectuser",{"2":{"726":5,"730":1}}],["select",{"0":{"730":1},"2":{"445":6,"726":2,"730":6,"734":4}}],["self",{"0":{"202":1,"207":1},"1":{"208":1,"209":1,"210":1,"211":1},"2":{"193":1,"196":1,"213":2,"337":1,"441":55,"443":76,"444":27,"445":743,"469":2,"472":3,"487":23,"490":2,"492":1,"493":21,"494":4,"495":5,"496":73,"497":40,"498":52,"499":60,"500":88,"508":10,"509":26,"513":15,"539":1,"540":1,"542":1,"548":2,"549":3,"552":24,"556":15,"567":15,"581":1,"595":2,"616":1,"619":1,"632":4,"633":4,"634":10,"643":1,"645":1,"647":2,"648":2,"649":9,"904":9}}],["selu",{"0":{"125":1},"2":{"125":3}}],["seqlen",{"2":{"649":3}}],["seq​t​​=t​i−person",{"2":{"628":1}}],["seqt=ti−person",{"2":{"628":1}}],["seq",{"2":{"227":2,"317":2,"326":1,"489":2,"498":7,"499":3,"500":11,"632":7,"633":5,"634":12,"635":1,"636":1,"649":12}}],["seq2seq结构呢",{"2":{"173":1}}],["seq2seq结构不再要求输入和输出序列有相同的时间长度",{"2":{"168":1}}],["seq2seq主要由一个编码器和一个解码器组成",{"2":{"167":1}}],["seq2seq将输入序列转换为输出序列",{"2":{"167":1}}],["seq2seq也能广泛地应用到各种不同的技术上",{"2":{"167":1}}],["seq2seq",{"0":{"159":1,"166":1,"167":1,"168":1,"172":1,"173":1,"174":1,"175":1,"181":1},"1":{"160":1,"161":1,"162":1,"163":1,"164":1,"165":1,"169":1,"170":1,"171":1,"172":1,"174":1,"176":1,"177":1,"178":1,"179":1,"180":1},"2":{"167":1,"170":1,"616":1,"621":3,"636":2,"671":1}}],["sequentiallr",{"0":{"549":1},"2":{"549":1}}],["sequential",{"2":{"444":1,"489":2,"499":1}}],["sequences",{"2":{"444":1,"633":2}}],["sequence",{"0":{"216":1},"2":{"135":1,"167":3,"188":1,"214":1,"216":1,"327":1,"329":1,"333":1,"445":44,"613":2,"616":2,"634":5}}],["sequenze",{"0":{"102":1}}],["separate",{"2":{"89":2}}],["separable",{"0":{"59":1}}],["sqlsequencereset",{"2":{"889":1}}],["sqlsessionfactorybuilder",{"2":{"726":2}}],["sqlsessionfactory",{"2":{"726":5}}],["sqlsession",{"2":{"726":3,"730":1,"731":1,"732":1,"733":1}}],["sqlmigrate",{"2":{"889":1}}],["sqlflush",{"2":{"889":1}}],["sql中取的值即可",{"2":{"730":1}}],["sql语句编写的时候",{"2":{"730":1}}],["sql语句返回值类型",{"2":{"730":1}}],["sqlcreate",{"2":{"726":1}}],["sql和代码的分离",{"2":{"724":1}}],["sql写在xml里",{"2":{"724":1}}],["squeezenet1",{"2":{"590":2}}],["squeeze",{"2":{"445":10}}],["squashmigrations",{"2":{"889":1}}],["squashing",{"2":{"9":1}}],["squad",{"2":{"636":2}}],["square",{"2":{"80":3,"81":2,"91":2,"93":2,"94":2,"95":1,"282":2,"445":2,"556":2}}],["sqrt",{"2":{"86":1,"87":2,"88":1,"89":1,"108":2,"126":1,"200":1,"206":1,"215":1,"245":5,"252":4,"417":1,"418":2,"419":2,"445":2,"473":3,"493":1,"498":1,"500":1,"595":14,"606":1,"649":1}}],["sprintboot",{"0":{"714":1}}],["spring",{"0":{"712":1,"713":1},"2":{"718":1}}],["speech",{"2":{"897":2}}],["speed",{"2":{"586":1}}],["specialized",{"2":{"897":1}}],["special",{"2":{"895":1}}],["specified",{"2":{"81":1,"490":1,"904":1}}],["spec",{"2":{"441":1}}],["sp仍然需要频繁的跨节点通信",{"2":{"329":1}}],["sp仍然导致mfu比仅使用单节点tp时更差",{"2":{"329":1}}],["sp仅拆分dropout和layernorm激活的序列",{"2":{"328":1}}],["sp",{"2":{"328":1,"329":2,"790":1}}],["split",{"0":{"109":1,"110":1},"1":{"110":1,"111":1},"2":{"110":2,"440":1,"441":4,"445":13,"498":1,"499":1,"500":1,"790":1}}],["spark",{"2":{"802":1}}],["sparse",{"2":{"54":1,"441":2,"444":12,"445":18}}],["spatially",{"0":{"59":1}}],["space",{"0":{"598":1},"2":{"47":20,"333":1,"344":1,"633":1,"657":1}}],["side",{"2":{"556":1}}],["significant",{"2":{"905":1}}],["signal",{"2":{"581":1}}],["signbit",{"2":{"445":1}}],["sign",{"2":{"445":2}}],["signed",{"2":{"445":1}}],["sigma",{"2":{"126":1,"138":1,"445":1,"606":2}}],["sigmoid函数复杂",{"2":{"122":1}}],["sigmoid函数在",{"2":{"122":1}}],["sigmoid等",{"2":{"117":1}}],["sigmoid",{"2":{"50":8,"120":1,"121":12,"127":1,"147":1,"148":3,"150":2,"240":1,"445":2,"450":1,"456":3,"457":1,"460":2,"484":2,"487":1}}],["sinusoidal",{"0":{"640":1},"2":{"640":1,"648":3}}],["sinh",{"2":{"445":2}}],["since",{"2":{"571":1,"587":1}}],["sinc",{"2":{"445":2}}],["sin",{"2":{"441":1,"445":2,"571":1,"640":1,"649":2}}],["single",{"0":{"588":1},"2":{"89":1,"217":1,"303":1,"497":1,"590":1}}],["site",{"2":{"436":1}}],["simplifies",{"2":{"897":1}}],["simplenn",{"2":{"904":3}}],["simple",{"2":{"556":2,"891":1,"901":1,"904":3}}],["simsekl",{"2":{"381":1}}],["sim",{"2":{"245":2,"248":1,"249":1,"251":2,"252":3}}],["sij−mij",{"2":{"226":1}}],["sij",{"2":{"226":1}}],["sij=qikjt∈rbr×bcs",{"2":{"226":1}}],["sizes",{"2":{"441":2,"445":6}}],["size会影响最大可实现的验证性能",{"2":{"412":1}}],["size会在训练算法中引入更多的不确定性",{"2":{"412":1}}],["size进行单独调优的时候是最重要的",{"2":{"412":1}}],["size影响最强烈的那些超参数",{"2":{"412":1}}],["size单独调优",{"2":{"412":1}}],["size单独调整它们",{"2":{"361":1}}],["size重新调整所有内容可能会很困难",{"2":{"361":1}}],["size交互最强烈的超参数是优化器超参数",{"2":{"361":1}}],["size敏感",{"2":{"361":1}}],["size需要重新调整大多数超参数",{"0":{"361":1}}],["size需要升级硬件",{"2":{"360":1}}],["size增加一倍",{"2":{"360":1}}],["size可能更容易过度拟合",{"2":{"412":1}}],["size可能会增加资源消耗",{"2":{"360":1}}],["size可能会减少资源消耗",{"2":{"360":1}}],["size可能不会改变资源消耗",{"2":{"360":1}}],["size相同的硬件上运行",{"2":{"360":1}}],["size有很大的前期成本",{"2":{"360":1}}],["size有关",{"2":{"360":1}}],["size以最小化资源消耗",{"0":{"360":1}}],["size以最小化训练时间",{"0":{"359":1}}],["size就没有意义了",{"2":{"359":1}}],["size将小于临界batch",{"2":{"359":1}}],["size仍可能通过减少所需的训练步数来提供有意义的加速",{"2":{"359":1}}],["size与效果预算进行比较只会涉及到完美缩放的范围",{"2":{"359":1}}],["size时请记住",{"2":{"361":1}}],["size时",{"2":{"359":1}}],["size时重新调整所有相关超参数",{"2":{"359":1}}],["size取决于数据集",{"2":{"359":1}}],["size通常需要重新开始调整过程",{"2":{"361":1}}],["size通常可以减少总步骤数",{"2":{"360":1}}],["size通常是最大的batch",{"2":{"359":1}}],["size通常会产生一些开销",{"2":{"359":1}}],["size通常会减少训练时间",{"2":{"357":1}}],["size不会再使训练步数减少",{"2":{"359":1}}],["size不应该被当作验证集性能的可调超参数",{"2":{"357":1}}],["size在临界值之前",{"2":{"359":1}}],["size翻倍可能会使训练步数减半",{"2":{"359":1}}],["size越大",{"2":{"359":1}}],["size之间的验证集性能差异通常会消失",{"2":{"412":1}}],["size之间并没有明确的关系",{"2":{"357":1}}],["size之后就不再增加",{"2":{"358":1}}],["size的大小时",{"2":{"412":1}}],["size的选择造成什么影响",{"0":{"362":1}}],["size的每一步都可以在与小batch",{"2":{"360":1}}],["size的所有好处都假定训练吞吐量增加",{"2":{"358":1}}],["size的增加",{"2":{"358":1}}],["size的同时对各个维度统计有很好的鲁棒性",{"2":{"90":1}}],["size加倍",{"2":{"358":1}}],["size并估计训练吞吐量",{"0":{"358":1}}],["size来直接提高验证集性能",{"0":{"412":1},"2":{"357":2}}],["size都能获得相同的最终性能",{"2":{"357":1}}],["size让资源消耗增加",{"2":{"357":1}}],["size是决定训练时间和计算资源消耗的关键因素",{"2":{"357":1}}],["size是较为理想的数值",{"2":{"357":1}}],["size决定训练速度",{"2":{"357":1}}],["size为1",{"2":{"328":1}}],["size为k",{"2":{"184":1}}],["size=7",{"2":{"580":1}}],["size=64",{"2":{"580":1}}],["size=10",{"2":{"568":1}}],["size=1",{"2":{"497":1}}],["size=",{"2":{"328":1}}],["size=k",{"2":{"184":1}}],["size=32",{"2":{"553":1}}],["size=30",{"2":{"537":1}}],["size=3",{"2":{"93":1,"94":1}}],["size=input",{"2":{"81":1}}],["size较小时",{"2":{"86":1}}],["size",{"2":{"63":2,"81":4,"83":1,"84":2,"95":3,"99":7,"101":2,"106":2,"113":1,"215":1,"226":1,"227":1,"317":1,"328":1,"338":1,"358":9,"359":4,"361":1,"362":2,"375":1,"380":1,"388":1,"390":3,"412":1,"440":1,"441":2,"443":2,"444":5,"445":75,"497":8,"498":11,"499":24,"500":25,"537":1,"556":32,"567":1,"588":1,"589":2,"590":7,"632":13,"633":17,"634":23,"636":1,"649":7,"765":1,"808":1,"823":4,"827":8,"904":1}}],["sudo",{"2":{"763":1,"770":3,"817":6}}],["sure",{"2":{"595":1}}],["such",{"2":{"582":1,"897":1,"899":1,"900":1}}],["succsessfully",{"2":{"526":1}}],["successfully",{"2":{"50":1,"529":1,"530":1}}],["superglue",{"2":{"619":1,"621":1}}],["supervised",{"2":{"616":1}}],["super",{"2":{"487":2,"490":1,"493":1,"494":1,"495":1,"497":2,"498":4,"499":3,"500":5,"513":1,"544":1,"567":1,"649":1,"904":1}}],["supports",{"2":{"897":1}}],["support",{"2":{"441":1,"843":1,"905":1}}],["sutton",{"2":{"420":1}}],["subcommands",{"2":{"889":1}}],["subclass",{"2":{"444":1,"445":1}}],["subfolders",{"2":{"584":1}}],["submodule",{"2":{"496":1}}],["subtract",{"2":{"445":4}}],["sublayer",{"2":{"196":1}}],["subgradient",{"2":{"120":1,"281":1}}],["sub",{"2":{"108":1,"443":1,"445":2,"455":4,"456":2}}],["summary",{"2":{"671":1}}],["summarywriter",{"0":{"575":1},"2":{"497":2,"575":2,"576":1,"577":1,"579":1,"580":1}}],["summarization",{"2":{"188":1}}],["sum",{"2":{"8":1,"50":4,"112":3,"129":1,"181":1,"185":1,"225":1,"313":1,"322":1,"323":1,"445":5,"450":1,"495":1,"497":3,"567":1,"632":1,"633":7,"634":1,"635":3,"643":3,"827":13}}],["挤压函数",{"2":{"9":1}}],["然后从剩下的",{"2":{"933":1}}],["然后去可能的地方一个个找",{"2":{"920":1}}],["然后去审视自己",{"2":{"878":1}}],["然后换衣服",{"2":{"917":1}}],["然后重新启动就好啦",{"2":{"914":1}}],["然后添加我们创建的这些管理员",{"2":{"889":1}}],["然后查看manage",{"2":{"889":1}}],["然后给了我们一个方案",{"2":{"875":1}}],["然后拿到电脑",{"2":{"875":1}}],["然后以各种说法说那些风险啊什么的",{"2":{"875":1}}],["然后带入直线的一般式方程",{"2":{"844":1}}],["然后按",{"2":{"792":1}}],["然后使用",{"2":{"757":1}}],["然后经过神经网络",{"2":{"653":1}}],["然后训练一段时间后发现",{"2":{"648":1}}],["然后对每个",{"2":{"648":1}}],["然后对矩阵进行转置操作",{"2":{"440":1}}],["然后论文中提出了一个满足上述关系的",{"2":{"646":1}}],["然后继续微调",{"2":{"641":1}}],["然后要求",{"2":{"621":1}}],["然后运用",{"2":{"619":1}}],["然后让模型进行重构来进行预训练",{"2":{"619":1}}],["然后微调它",{"2":{"617":1}}],["然后在没有任何先验知识的情况下开始训练",{"2":{"617":1}}],["然后在laion5b的高分辨率数据集以512x512尺寸训练194",{"2":{"608":1}}],["然后在更新后的位置再求梯度",{"2":{"269":1}}],["然后计算这两个特征向量集合的均值",{"2":{"606":1}}],["然后计算它们之间的余弦相似度",{"2":{"605":1}}],["然后可以重复地执行编译后的图形",{"2":{"559":1}}],["然后扩展到大量训练步骤将导致在过小的步骤上进行大部分训练",{"2":{"384":1}}],["然后创建另一项研究",{"2":{"370":1}}],["然后发送剩余的提示",{"2":{"338":1}}],["然后我们沿水平位置排列的key",{"2":{"327":1}}],["然后将模拟后的位置处梯度替换动量方法中的当前位置梯度",{"2":{"269":1}}],["然后将结果转回实数域",{"2":{"649":1}}],["然后将结果写回到hbm",{"2":{"226":1,"315":1}}],["然后将结果组合起来",{"2":{"226":1,"315":1}}],["然后将结果作为一个特征向量输出到下一层",{"2":{"95":1}}],["然后相对于这些块计算注意力输出",{"2":{"224":1,"311":1}}],["然后进行层标准化",{"2":{"197":1}}],["然后选择概率或得分最高的k个候选项",{"2":{"186":1}}],["然后综合这k×v个score的结果",{"2":{"184":1}}],["然后输入给下一步",{"2":{"183":1}}],["然后一步步将输出序列解码出来",{"2":{"171":1}}],["然后再去拿",{"2":{"921":1}}],["然后再从最大学习率退火到远低于初始学习率的最小学习率",{"2":{"544":1}}],["然后再设置为",{"2":{"478":1}}],["然后再把source端的得到的self",{"2":{"213":1}}],["然后再由解码器",{"2":{"168":1}}],["然后再作为下一个层的输入",{"2":{"120":1}}],["然后",{"2":{"148":1,"149":1,"150":1,"444":1,"503":1,"621":1}}],["然后每个group内做归一化",{"2":{"89":1}}],["然后传播到每一层的隐藏单元",{"2":{"24":1}}],["然后通过激活函数",{"2":{"8":1}}],["然而也不会有相聚甚远的情况",{"2":{"657":1}}],["然而有些模型则可能需要4万次以上的训练",{"2":{"409":1}}],["然而一些常见的批归一化实现不同步这些ema",{"2":{"394":1}}],["然而现在每次遍历都需要保存一次",{"2":{"319":1}}],["然而缺失了修正因子",{"2":{"294":1}}],["然而这是有弊端的",{"2":{"238":1}}],["然而我们遇到的大部分问题序列都是不等长的",{"2":{"165":1}}],["然而其论文迄今为止在",{"2":{"126":1}}],["然而传统的sigmoid",{"2":{"123":1}}],["然而",{"2":{"9":1,"120":1,"219":1,"228":1,"261":1,"277":1,"305":1,"318":1,"327":1,"329":2,"332":1,"369":1,"372":1,"375":1,"380":1,"391":1,"401":2,"630":1,"916":1}}],["对孩子的胃口和饼干大小进行排序",{"2":{"957":1}}],["对孩子的胃口数组",{"2":{"956":1}}],["对了",{"2":{"878":1}}],["对面寝室都好久没充电费了",{"2":{"878":1}}],["对博客部分做了重构",{"2":{"862":1}}],["对你有什么启发",{"2":{"853":1}}],["对这块感兴趣的可以自己了解了解",{"2":{"822":1}}],["对这三个要求的任何一个进行改进都需要增加试验次数",{"2":{"371":1}}],["对人工智能也不大清楚",{"2":{"697":1}}],["对相对位置进行了一个",{"2":{"644":1}}],["对第三个标签的分数预测为",{"2":{"627":1}}],["对第二个标签的分数预测为",{"2":{"627":1}}],["对第一个标签的分数预测为",{"2":{"627":1}}],["对one",{"2":{"544":1}}],["对模型的保存和加载有影响吗",{"2":{"516":1}}],["对模块的所有参数",{"2":{"475":1}}],["对前向传播进行装饰",{"2":{"496":1}}],["对您的模型的影响完全取决于您模型中使用的具体模块以及它们是否定义了任何训练模式特定的行为",{"2":{"480":1}}],["对用户不可知",{"2":{"463":1}}],["对我们当前正在学习的地方做一个定位",{"2":{"674":1,"695":1}}],["对我们用户是可见的",{"2":{"462":1}}],["对我们需要更新梯度的tensor",{"2":{"456":1}}],["对它的数据进行了更新",{"2":{"456":1}}],["对z进行操作",{"2":{"452":1}}],["对输入",{"2":{"445":1}}],["对输出的更改会反映在",{"2":{"445":1}}],["对外api接口",{"0":{"445":1}}],["对",{"2":{"443":3,"620":1,"643":1}}],["对子类进行包装",{"2":{"441":1}}],["对象关系映射",{"2":{"724":1}}],["对象将定义一个单独的参数组",{"2":{"504":1}}],["对象使用除法操作符",{"2":{"443":1}}],["对象进行赋值操作时触发",{"2":{"443":1}}],["对象进行真值测试",{"2":{"443":1}}],["对象用作整数索引",{"2":{"443":1}}],["对象所属的模块",{"2":{"441":1}}],["对象所在的设备信息并返回",{"2":{"441":1}}],["对象",{"2":{"441":2,"472":1,"496":1}}],["对象重新转换为具有指定维度大小的多维",{"2":{"441":1}}],["对象中",{"2":{"441":1}}],["对象转换为",{"2":{"441":3}}],["对象的可迭代对象",{"2":{"504":2}}],["对象的元素或子集",{"2":{"443":1}}],["对象的属性和方法列表",{"2":{"441":1}}],["对象的哈希操作",{"2":{"441":1}}],["对象的维度名称",{"2":{"441":3}}],["对象的维度顺序以匹配指定的顺序",{"2":{"441":1}}],["对象的维度命名",{"2":{"441":1}}],["对象的维度",{"2":{"441":1}}],["对象可迭代",{"2":{"441":1}}],["对该项目的贡献必须附有贡献者许可协议",{"2":{"423":1}}],["对搜索空间以及应该从搜索空间中采样数量做出概括性陈述是非常困难的",{"2":{"400":1}}],["对冗余超参数的搜索空间进行足够密集的采样",{"2":{"371":1}}],["对flashattention算法进行了调整",{"2":{"320":1}}],["对rnn",{"2":{"282":1}}],["对梯度的调节太大",{"2":{"280":1}}],["对每个参数组的学习率进行衰减",{"2":{"538":1}}],["对每个序列的得分",{"2":{"186":1}}],["对每层l",{"2":{"249":1}}],["对称失效",{"2":{"237":1}}],["对称性可以提高网络的稳定性和泛化能力",{"2":{"120":1}}],["对称性",{"2":{"120":1}}],["对各个节点的权重",{"2":{"233":1}}],["对话系统",{"2":{"188":1}}],["对话生成等",{"2":{"188":2}}],["对候选项进行排序",{"2":{"186":1}}],["对给定的上下文进行下一个单词或字符的预测",{"2":{"176":1,"188":1}}],["对激活函数的研究一直没有停止过",{"2":{"128":1}}],["对负半轴引入软饱和以代替置",{"2":{"125":1}}],["对线性层的输出用",{"2":{"120":1}}],["对张量进行切片",{"2":{"111":1}}],["对nhw做归一化",{"2":{"86":1}}],["对比度",{"2":{"344":1}}],["对比图",{"0":{"291":1}}],["对比",{"0":{"155":1},"2":{"85":1}}],["对那个维度分组",{"2":{"57":2}}],["对于光照",{"2":{"857":1}}],["对于最大位移方向",{"2":{"838":1}}],["对于终生学习来说这些简单了解即可",{"2":{"831":1}}],["对于终生学习来说",{"2":{"831":1}}],["对于应用系统而言",{"2":{"723":1}}],["对于计科同学的话",{"2":{"702":1}}],["对于相对位置编码来说",{"2":{"642":1}}],["对于transformer模型来说",{"2":{"638":1}}],["对于tm的学习",{"2":{"190":1}}],["对于没有元数据的状态字典",{"2":{"496":1}}],["对于没有经验的用户来说",{"2":{"401":1}}],["对于矩阵",{"2":{"440":1}}],["对于复数",{"2":{"440":2}}],["对于你",{"2":{"423":1}}],["对于不可微分的函数的梯度计算",{"0":{"473":1}}],["对于不适合问题的问题或其他消息",{"2":{"422":1}}],["对于不平衡的数据集",{"2":{"391":1}}],["对于使用例如100倍",{"2":{"409":1}}],["对于早期和中期训练中不稳定情况都有好处",{"2":{"406":1}}],["对于此工作量可能约为",{"2":{"403":1}}],["对于具有非常成熟建模和调整的工作流以及非常长且昂贵的生产训练运行的团队来说",{"2":{"385":1}}],["对于余弦衰减",{"2":{"385":1}}],["对于这种训练式的绝对位置编码",{"2":{"641":1}}],["对于这一切",{"2":{"384":1}}],["对于这样长的上下文请求",{"2":{"329":1}}],["对于某些类型的超参数",{"2":{"384":1}}],["对于当前问题",{"2":{"369":1}}],["对于给定的值x∈",{"2":{"659":1}}],["对于给定的词语",{"2":{"620":1}}],["对于给定的目标",{"2":{"369":1}}],["对于给定的模型和优化器",{"2":{"358":1}}],["对于每一项研究",{"2":{"375":1}}],["对于每次上线",{"2":{"365":1}}],["对于每个参数的梯度进行平方并相加后再取平方根的过程",{"2":{"405":1}}],["对于每个类别只有少量样本的数据集",{"2":{"391":1}}],["对于每个batch",{"2":{"358":1}}],["对于每个请求",{"2":{"329":1}}],["对于所有可行的batch",{"2":{"359":1}}],["对于所有列索引均大于行索引的块",{"2":{"322":1}}],["对于一些你觉得很浅显的内容",{"2":{"702":1}}],["对于一些机器学习任务",{"2":{"344":1}}],["对于一份文档而言",{"2":{"411":1}}],["对于一个目标超参数配置",{"2":{"371":1}}],["对于一个由",{"2":{"369":1}}],["对于一个序列",{"2":{"216":1}}],["对于短期上下文预填没有明显的开销",{"2":{"329":1}}],["对于任何主机i",{"2":{"327":1}}],["对于那些确保行索引严格小于列索引的块",{"2":{"322":1}}],["对于训练深度神经网络模型而言",{"2":{"277":1}}],["对于大序列长度约占一半的块",{"2":{"322":1}}],["对于大规模系统和大型数据集",{"2":{"260":1}}],["对于大型图像处理有出色表现",{"2":{"51":1}}],["对于向量",{"2":{"225":1,"313":1}}],["对于gpt2",{"2":{"223":1,"312":1}}],["对于很大的",{"2":{"206":1}}],["对于",{"2":{"120":1,"369":1,"409":1,"441":1,"472":1,"648":1}}],["对于卷积",{"2":{"54":1}}],["对应到我们当前任务就是输入文本序列",{"2":{"627":1}}],["对应向后兼容很重要",{"2":{"490":1}}],["对应的另一个方向",{"2":{"838":1}}],["对应的tags",{"2":{"634":1}}],["对应的数据类型",{"2":{"496":1}}],["对应的输出的计算",{"2":{"204":2}}],["对应的导函数",{"2":{"121":1}}],["对应公式如下",{"2":{"124":1}}],["对应图像和导函数图像为",{"2":{"122":1}}],["对应一个权重和bias",{"2":{"87":1}}],["对应经典的神经网络",{"2":{"51":1}}],["对应于神经元抑制",{"2":{"9":1}}],["对应于神经元兴奋",{"2":{"9":1}}],["对复杂任务来说",{"2":{"15":1}}],["对手写数字的分类",{"2":{"11":1}}],["对资料进行表征学习的算法",{"2":{"4":1}}],["0δy=y​1​​−y​0​​",{"2":{"840":1}}],["0δx=x​1​​−x​0​​",{"2":{"840":1}}],["06",{"2":{"671":1}}],["0～7",{"2":{"644":1}}],["0的基础上放开了限制",{"2":{"608":1}}],["00",{"2":{"627":1}}],["000步数",{"2":{"608":4}}],["000步",{"2":{"608":2}}],["00025",{"2":{"542":1}}],["00075",{"2":{"542":1}}],["00050",{"2":{"542":1}}],["0005",{"2":{"537":1,"538":1}}],["0001",{"2":{"500":1,"503":1}}],["005",{"2":{"537":1,"538":1}}],["0011",{"2":{"479":1}}],["001",{"2":{"50":1,"284":1,"450":1,"457":1,"522":1,"523":1,"542":2,"545":1}}],["0f​",{"2":{"843":1}}],["0f",{"2":{"497":2}}],["0或1",{"2":{"445":1}}],["081",{"2":{"548":1}}],["08",{"2":{"445":2,"671":1,"868":1}}],["03",{"0":{"728":1,"872":1},"1":{"729":1,"730":1,"731":1,"732":1,"733":1,"734":1,"873":1,"874":1},"2":{"671":1,"832":1,"873":3,"874":2}}],["03m",{"2":{"608":1}}],["0375",{"2":{"540":1}}],["03125",{"2":{"540":1}}],["03200中建议来实现移位的",{"2":{"402":1}}],["030866",{"2":{"46":3}}],["0e",{"2":{"248":1}}],["04",{"2":{"671":1,"832":1}}],["04375",{"2":{"540":1}}],["0403",{"2":{"456":1}}],["0405",{"2":{"456":1}}],["044715x​3​​",{"2":{"126":1}}],["044715x3",{"2":{"126":1}}],["044715",{"2":{"126":1}}],["049019",{"2":{"48":3}}],["05",{"2":{"445":2,"537":2,"538":2,"539":2,"540":2,"671":1,"873":3,"874":1}}],["05灵敏度改进听起来很令人兴奋",{"2":{"391":1}}],["0507",{"2":{"125":3}}],["05201",{"2":{"122":1}}],["025",{"2":{"539":4,"540":1}}],["02",{"0":{"725":1},"1":{"726":1,"727":1},"2":{"50":1,"460":2,"627":1,"671":1,"832":1,"871":1}}],["022971",{"2":{"48":3}}],["07",{"2":{"671":1,"867":1,"871":1}}],["0722",{"2":{"456":1}}],["073889",{"2":{"48":3}}],["078064=0",{"2":{"47":3}}],["078064",{"2":{"45":3}}],["09",{"2":{"548":1,"671":1,"868":2}}],["094534",{"2":{"47":3}}],["097049∗0",{"2":{"45":2}}],["097049",{"2":{"45":4}}],["0=0",{"2":{"45":1}}],["0139069",{"2":{"47":3}}],["011204",{"2":{"46":3}}],["01−0",{"2":{"41":2,"45":4,"46":2}}],["01",{"0":{"720":1},"1":{"721":1,"722":1,"723":1,"724":1},"2":{"26":1,"38":1,"41":1,"45":2,"46":1,"50":3,"239":4,"240":3,"280":1,"460":1,"484":1,"487":1,"503":1,"533":2,"543":1,"544":1,"568":1,"585":2,"627":1,"832":1,"904":1}}],["0",{"0":{"120":1,"132":1,"501":1},"1":{"121":1,"122":1},"2":{"9":3,"26":1,"38":2,"40":5,"41":12,"45":14,"46":8,"47":16,"48":39,"50":32,"86":3,"87":1,"88":1,"89":2,"98":1,"100":1,"101":1,"104":1,"112":10,"113":3,"120":3,"121":7,"122":11,"123":3,"124":3,"125":1,"127":1,"129":1,"147":2,"148":2,"149":1,"215":2,"239":7,"240":6,"245":3,"248":4,"249":4,"251":6,"264":1,"280":1,"284":2,"328":1,"403":1,"404":1,"406":1,"415":2,"416":2,"417":3,"418":4,"419":4,"421":1,"430":1,"433":2,"434":3,"444":1,"445":34,"450":6,"452":1,"455":2,"456":23,"457":6,"460":18,"468":1,"473":2,"474":9,"484":2,"487":5,"493":8,"497":12,"498":4,"499":3,"500":4,"504":1,"508":2,"509":1,"513":2,"522":1,"529":1,"535":1,"536":1,"537":4,"538":4,"539":7,"540":7,"542":9,"545":3,"546":2,"548":6,"549":6,"552":2,"556":4,"567":6,"570":2,"580":4,"585":3,"588":3,"589":2,"590":4,"595":2,"605":3,"608":5,"613":1,"627":3,"632":3,"633":1,"634":4,"635":3,"636":1,"649":4,"719":1,"726":5,"746":1,"780":1,"823":1,"827":5,"836":1,"840":11,"841":2,"862":1,"904":2,"957":2}}],["fgf",{"2":{"646":1}}],["f​q",{"2":{"647":1}}],["f​q​​",{"2":{"646":1}}],["f​g​​",{"2":{"646":1}}],["f​k​​",{"2":{"646":2}}],["f​2​​",{"2":{"248":2}}],["fkf",{"2":{"646":1}}],["fk",{"2":{"646":1}}],["fq",{"2":{"646":1,"647":1}}],["f1",{"0":{"635":1},"2":{"635":2}}],["fx图是一种中间表示形式",{"2":{"562":1}}],["fx图是一种基于符号执行的图表示",{"2":{"562":1}}],["fx图本身并不能直接运行",{"2":{"562":1}}],["fx图",{"2":{"562":1}}],["fx",{"0":{"562":1},"2":{"562":1}}],["foo",{"2":{"734":2}}],["foo2",{"2":{"571":2}}],["folders",{"2":{"585":2,"588":1,"589":2}}],["folder",{"2":{"552":1,"585":2,"588":1,"589":2}}],["fortran",{"2":{"822":1}}],["forth",{"2":{"581":1}}],["foreach",{"2":{"510":8}}],["force",{"2":{"445":1}}],["forcing",{"0":{"178":1},"2":{"178":2}}],["forall",{"2":{"244":2,"245":2}}],["forget",{"2":{"147":1}}],["format=torch",{"2":{"445":2}}],["format",{"2":{"50":1,"441":3,"444":1,"445":12,"497":2,"567":1}}],["for",{"0":{"661":1},"2":{"26":1,"50":3,"113":1,"226":4,"227":1,"281":1,"294":1,"317":1,"334":1,"335":1,"441":1,"444":2,"454":4,"456":3,"458":1,"460":1,"472":1,"484":1,"487":2,"493":1,"496":2,"497":6,"498":2,"499":2,"500":5,"508":1,"510":5,"529":2,"533":5,"535":1,"536":1,"537":2,"538":2,"539":2,"540":2,"541":1,"542":2,"543":3,"544":2,"545":1,"546":3,"547":1,"548":2,"549":2,"553":1,"556":4,"567":2,"571":1,"576":1,"581":2,"585":3,"586":1,"587":1,"590":4,"616":1,"632":2,"633":6,"634":5,"635":1,"706":1,"726":1,"799":3,"823":1,"827":1,"889":1,"891":3,"897":4,"900":1,"904":3,"905":1}}],["forward函数",{"2":{"488":1}}],["forward",{"0":{"315":1,"322":1},"2":{"24":1,"315":1,"458":1,"463":1,"487":2,"490":7,"493":1,"494":2,"495":1,"496":8,"497":2,"498":7,"499":12,"500":11,"513":1,"567":1,"649":1,"904":2}}],["ff",{"2":{"498":11,"500":16}}],["fft",{"2":{"445":1}}],["fc3",{"2":{"904":2}}],["fc",{"2":{"498":2,"499":2,"500":4}}],["fc2",{"2":{"497":4,"498":2,"500":2,"513":2,"567":2,"904":2}}],["fc1",{"2":{"497":4,"498":2,"500":2,"513":2,"567":2,"904":2}}],["fmod",{"2":{"445":4}}],["fmin",{"2":{"445":1}}],["fmax",{"2":{"445":1}}],["fweights",{"2":{"445":1}}],["fn是否为空",{"2":{"468":1}}],["fn",{"2":{"274":1,"440":2,"454":2,"462":2,"465":2,"468":2,"469":1,"471":1,"472":8,"475":2,"494":2,"495":2,"496":6,"505":2,"533":2}}],["favored",{"2":{"905":1}}],["far",{"2":{"633":2,"634":1}}],["factor",{"2":{"585":1}}],["factor=0",{"2":{"539":1,"540":1,"548":1,"549":1}}],["facebook",{"2":{"891":1,"900":1}}],["face",{"2":{"556":1}}],["faces",{"2":{"556":2}}],["facelandmarksdataset",{"2":{"556":1}}],["faq",{"2":{"556":1}}],["fake",{"2":{"552":1,"567":1,"590":1}}],["false",{"2":{"444":5,"445":102,"453":2,"462":1,"464":1,"465":1,"472":1,"474":2,"475":2,"477":1,"480":1,"490":4,"493":1,"496":8,"509":5,"580":1,"635":1}}],["fail",{"2":{"427":1}}],["fan",{"2":{"251":2}}],["fastest",{"2":{"590":1}}],["faster",{"0":{"320":1},"1":{"321":1,"322":1,"323":1,"324":1},"2":{"229":1,"895":1}}],["fastai",{"2":{"544":1}}],["fast",{"0":{"325":1},"2":{"217":1,"303":1,"544":1,"616":1,"891":1}}],["f^",{"2":{"248":2}}],["f2",{"2":{"248":2,"635":2}}],["fields",{"2":{"899":1}}],["field",{"0":{"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"905":1}}],["fid值",{"2":{"606":1}}],["fid首先用",{"2":{"606":1}}],["fidelity",{"2":{"606":1}}],["fid可以衡量生成图像的逼真度",{"2":{"606":1}}],["fid",{"0":{"606":1},"2":{"606":5}}],["filtering>",{"2":{"727":2}}],["filtering>false",{"2":{"727":2}}],["filename",{"2":{"776":2,"790":4}}],["file2",{"2":{"743":2,"789":1}}],["file1",{"2":{"743":5,"789":1}}],["file=",{"2":{"556":1}}],["file",{"2":{"509":1,"552":2,"746":4,"748":3,"749":2,"751":1,"765":2}}],["fill",{"2":{"215":1,"445":18,"498":1,"499":1,"500":1}}],["findcontentchildren",{"2":{"957":1,"958":1}}],["findstatic",{"2":{"889":1}}],["findbashfind",{"2":{"765":1}}],["find",{"2":{"634":1,"765":1,"893":1}}],["finalize",{"2":{"808":1,"823":1,"827":1}}],["finally",{"2":{"499":1}}],["final",{"2":{"498":1,"500":1}}],["finished",{"2":{"450":1}}],["finetuning",{"2":{"220":1,"306":1}}],["fine",{"2":{"220":1,"306":1,"616":2}}],["fixed",{"2":{"556":1}}],["fix",{"2":{"445":2}}],["first",{"2":{"329":1,"454":1,"459":1,"581":1,"632":1,"633":2,"634":1,"789":1}}],["figure",{"2":{"328":1,"373":1,"403":1,"404":1,"405":1,"407":1,"408":4,"409":1,"410":1}}],["flexibility",{"2":{"897":1,"899":1,"905":1}}],["flexible",{"2":{"891":1}}],["flush",{"2":{"579":1,"889":1}}],["flipud",{"2":{"445":1}}],["fliplr",{"2":{"445":1}}],["flip",{"2":{"441":1,"445":2}}],["floor",{"2":{"445":4,"634":1}}],["floordiv",{"2":{"441":1,"443":1}}],["float等",{"2":{"809":1}}],["float32",{"2":{"444":1,"460":1,"484":1,"487":1,"498":1,"500":1}}],["float",{"2":{"443":3,"445":35,"460":2,"487":1,"496":2,"498":1,"499":1,"500":1,"509":4,"632":1,"649":6,"706":1}}],["float16",{"2":{"433":1}}],["floating",{"2":{"381":1,"445":1}}],["floattensor",{"2":{"113":2,"595":3,"634":1}}],["flops",{"2":{"322":1}}],["flash",{"0":{"224":1,"227":1,"229":1,"314":1,"317":1},"2":{"227":2,"317":2,"326":2}}],["flashattention3",{"0":{"325":1}}],["flashattention在节省内存方面可以达到10",{"2":{"316":1}}],["flashattention避免了需要存储大型中间值",{"2":{"316":1}}],["flashattention1",{"0":{"315":1,"316":1,"319":1},"2":{"310":1,"316":1,"321":1}}],["flashattention2",{"2":{"229":1,"320":1,"321":1}}],["flashattention不需要将大型的𝑁×𝑁注意力矩阵读取和写入hbm",{"2":{"222":1,"314":1}}],["flashattention获得了加速",{"2":{"222":1,"314":1}}],["flashattention通过q矩阵的块循环",{"2":{"222":1,"314":1}}],["flashattention通过k和v矩阵的块循环",{"2":{"222":1,"314":1}}],["flashattention使用切片技术",{"2":{"222":1,"314":1}}],["flashattention",{"0":{"221":1,"310":1,"320":1},"1":{"222":1,"223":1,"224":1,"225":1,"226":1,"227":1,"228":1,"311":1,"312":1,"313":1,"314":1,"315":1,"316":1,"317":1,"318":1,"319":1,"321":1,"322":1,"323":1,"324":1},"2":{"223":1,"226":1,"228":1,"229":1,"312":1,"315":2,"325":1}}],["flatten",{"0":{"103":1,"107":1},"1":{"104":1,"105":1,"106":1,"107":1},"2":{"107":2,"445":4,"497":2,"499":1,"513":1,"595":2,"649":2}}],["future",{"2":{"497":1,"513":1}}],["fused",{"2":{"510":5}}],["fuse",{"2":{"226":1,"315":1}}],["fullconnect",{"2":{"487":3}}],["full",{"2":{"111":2,"444":1,"445":1,"487":7,"490":3,"496":6,"634":1,"904":1}}],["func",{"2":{"441":1,"509":1}}],["functional",{"2":{"454":1,"497":1,"498":1,"499":1,"500":1,"513":1,"567":1}}],["function的值在其最小值附近震荡",{"2":{"236":1}}],["function相对于权值参数的梯度值很大",{"2":{"236":1}}],["functions",{"0":{"96":1},"2":{"127":1,"442":1,"556":1,"671":1}}],["function",{"2":{"8":1,"9":1,"52":1,"120":1,"122":1,"441":12,"454":2,"458":1,"465":1,"472":1,"487":2,"490":1,"494":1,"495":1,"497":1,"509":2,"513":1,"904":1}}],["fun",{"0":{"469":1},"2":{"26":2,"530":1,"799":1}}],["friendliness",{"2":{"905":1}}],["fréchet",{"2":{"606":1}}],["freqs",{"2":{"649":17}}],["frequency",{"2":{"590":1}}],["freq",{"2":{"590":1}}],["frexp",{"2":{"445":2}}],["freeport",{"2":{"588":1,"589":2}}],["free",{"2":{"177":1,"891":1}}],["fro",{"2":{"441":1}}],["frostig",{"2":{"420":1}}],["from",{"2":{"99":1,"113":1,"430":9,"436":1,"441":1,"444":1,"445":2,"496":1,"497":3,"541":1,"555":4,"556":5,"575":3,"584":1,"616":1,"633":1,"634":2,"726":1,"730":3,"733":1,"734":2,"827":2,"891":1}}],["framework",{"0":{"904":1},"2":{"718":1,"889":1,"905":1}}],["framework进行增强",{"2":{"327":1}}],["frac",{"2":{"28":1,"40":2,"41":4,"44":5,"45":11,"46":19,"47":1,"121":4,"126":2,"127":2,"129":1,"181":1,"190":2,"200":1,"206":1,"225":2,"226":4,"244":2,"245":3,"248":6,"249":2,"251":2,"252":5,"313":2,"345":2,"410":1,"417":1,"418":2,"419":2,"445":2,"542":1,"545":2,"546":2,"640":2,"659":1,"840":4}}],["f",{"2":{"26":1,"28":3,"50":2,"215":1,"225":13,"245":2,"248":2,"313":13,"406":3,"451":2,"454":4,"459":3,"473":1,"487":1,"493":2,"497":13,"498":3,"499":1,"500":4,"511":1,"513":6,"515":1,"519":1,"545":1,"644":1,"646":3,"649":1,"765":1,"772":1,"799":6,"904":1}}],["fetching",{"2":{"799":1}}],["fetched",{"2":{"799":1}}],["fetch",{"2":{"799":1}}],["feed",{"2":{"498":3,"499":2,"500":6,"529":1}}],["feedforward",{"0":{"0":1,"39":1},"1":{"40":1,"41":1},"2":{"6":2,"13":2,"24":1,"498":3,"500":4,"671":1}}],["few",{"2":{"337":1,"620":1}}],["features",{"0":{"892":1},"1":{"893":1,"894":1,"895":1,"896":1,"897":1},"2":{"493":1}}],["feature",{"2":{"4":1,"52":1,"55":1}}],["在你所处的位置",{"2":{"970":1}}],["在预算内购买到更多的商品",{"2":{"967":1}}],["在预热的时候",{"2":{"410":1}}],["在有限的预算下",{"2":{"938":1}}],["在有疑问的时候",{"2":{"381":1}}],["在虚拟机里重新start网络或者重新启动虚拟机",{"2":{"913":1}}],["在虚拟角色的面部动画方面",{"2":{"859":1}}],["在物理主机开启nat和dhcp服务",{"0":{"913":1}}],["在现在这个繁杂而又急躁的社会",{"2":{"880":1}}],["在3d环境中检测物体的相互碰撞",{"2":{"857":1}}],["在坐标系上绘制点",{"2":{"840":1}}],["在安装",{"2":{"822":1}}],["在同步通信中",{"2":{"807":1}}],["在同时进行的前提下",{"2":{"797":1}}],["在win10网络中将vm8的网络手动设置成规范格式",{"2":{"915":1}}],["在windows环境中进行高性能计算",{"2":{"802":1}}],["在windows平台上实现的mpi",{"2":{"802":1}}],["在warmup",{"2":{"409":1}}],["在可视模式中选中文本",{"2":{"792":1}}],["在分屏间切换",{"2":{"790":1}}],["在分析一组给定的实验以朝着最初的目标取得进展之前",{"2":{"372":1}}],["在普通模式中输入",{"2":{"786":1}}],["在普通模式中按",{"2":{"784":1}}],["在光标前粘贴",{"2":{"782":1}}],["在光标前插入",{"2":{"778":1}}],["在光标后粘贴",{"2":{"782":1}}],["在光标后插入",{"2":{"778":1}}],["在文件之间切换",{"2":{"789":1}}],["在文件中查找",{"2":{"749":1}}],["在文本中注入噪声",{"2":{"344":1}}],["在java代码中添加sql通配符",{"2":{"734":1}}],["在接口方法中",{"2":{"730":1}}],["在接口方法的参数前加",{"2":{"730":1}}],["在usermapper接口中添加对应的方法",{"2":{"731":1}}],["在usermapper",{"2":{"730":1,"731":1}}],["在usermapper中添加对应方法",{"2":{"730":1}}],["在生活中",{"2":{"722":1,"926":1}}],["在多核环境或集群中",{"2":{"822":1}}],["在多道程序环境下",{"2":{"681":1}}],["在多个进程上运行同一个",{"2":{"822":1}}],["在多个基准上取得了最优性能",{"2":{"621":1}}],["在多个多语言",{"2":{"619":1}}],["在操作系统中",{"2":{"676":1}}],["在y0",{"2":{"659":1}}],["在变分推断中",{"2":{"659":1}}],["在解决上面问题后",{"2":{"656":1}}],["在解码器",{"2":{"168":1}}],["在经过一系列数学研究后",{"2":{"654":1}}],["在vmware虚拟化工具中把对应的nat网络手动设置成一样的信息",{"2":{"915":1}}],["在vae中",{"2":{"654":1}}],["在vllm中",{"2":{"333":1}}],["在数据生成过程中要输入一些数进去",{"2":{"654":1}}],["在数学中",{"2":{"225":1,"313":1}}],["在基于",{"2":{"624":1}}],["在性能上可以媲美较小版本的",{"2":{"620":1}}],["在内存占用减少",{"2":{"619":1}}],["在内部处理计算的方式",{"2":{"476":1}}],["在内部",{"2":{"471":1,"472":1}}],["在流行的",{"2":{"619":1}}],["在绝大部分情况下",{"2":{"617":1}}],["在自己任务上获得优秀性能所需的时间和计算成本都可以很小",{"2":{"617":1}}],["在自回归解码过程中",{"2":{"333":1}}],["在翻译任务上超过了之前最优秀的循环神经网络模型",{"2":{"616":1}}],["在翻译时",{"2":{"190":1}}],["在512x512模型基础上用图像分辨率大于768x768的子集继续训练",{"2":{"608":1}}],["在improved",{"2":{"608":4}}],["在linux虚拟机里定制对应网络号",{"2":{"915":1}}],["在laion2b",{"2":{"608":1}}],["在llama",{"2":{"333":1}}],["在pytorch中",{"2":{"562":1}}],["在pagedattention中",{"2":{"334":1}}],["在动态图中",{"2":{"559":1}}],["在静态图中",{"2":{"559":1}}],["在使用linux系统的虚拟机过程中",{"2":{"908":1}}],["在使用方法的时候",{"2":{"730":1}}],["在使用批次进行训练后",{"2":{"543":1,"544":1}}],["在使用quasi",{"2":{"401":1}}],["在适用的情况下",{"2":{"510":1}}],["在参数组未指定时使用",{"2":{"507":1}}],["在未覆盖它们的组中生效",{"2":{"504":1}}],["在极少数情况下",{"2":{"496":1}}],["在极端训练预算限制下",{"2":{"384":1}}],["在torch",{"2":{"496":1}}],["在设置完self的state",{"2":{"496":1}}],["在设计一项研究或一系列研究时",{"2":{"371":1}}],["在设计新一轮实验时",{"2":{"369":1}}],["在module属性设置过程中插入自己的逻辑",{"2":{"496":1}}],["在访问不存在的属性时被调用",{"2":{"496":1}}],["在forward",{"2":{"496":1}}],["在模块上注册一个前向传播钩子",{"2":{"496":1}}],["在模块上注册一个前向传播预钩子",{"2":{"496":1}}],["在模块上注册一个反向传播钩子",{"2":{"496":2}}],["在模块上注册一个反向传播",{"2":{"496":1}}],["在模型微调期间需要冻结预训练模型的某些部分",{"2":{"475":1}}],["在模型训练期间收集的指标可能是离线评估的代理",{"2":{"389":1}}],["在梯度计算之后执行的钩子函数",{"2":{"490":1}}],["在梯度计算之前执行的钩子函数",{"2":{"490":1}}],["在子类上进行赋值之前",{"2":{"488":1}}],["在评估模型",{"2":{"480":1}}],["在退出推断模式后",{"2":{"479":1}}],["在初始化参数时避免了在原地更新初始化的参数时的自动求导跟踪",{"2":{"478":1}}],["在执行训练更新时",{"2":{"478":1}}],["在无梯度模式下",{"2":{"478":2}}],["在启动训练之前",{"2":{"471":1}}],["在正向的时候自动生成",{"2":{"465":1}}],["在c++",{"2":{"455":1}}],["在cnn中ln规范化效果不如bn",{"2":{"87":1}}],["在dag",{"2":{"447":1}}],["在decoder端",{"2":{"176":1}}],["在不更改训练工作流其他细节的情况下",{"2":{"412":1}}],["在大多数情况下",{"2":{"411":1,"481":1}}],["在发布一篇研究论文的时候",{"2":{"411":1}}],["在发布使用此类衰减方案的结果之前",{"2":{"399":1}}],["在贝叶斯机器学习中",{"2":{"411":1}}],["在整个工作量的范围中并不存在真正意义上的标准值",{"2":{"409":1}}],["在整个学习过程中自动适应这些学习率是有道理的",{"2":{"276":1}}],["在样本学习中可以以",{"2":{"409":1}}],["在哪里可以找到quasi",{"0":{"402":1}}],["在高并行机制中击败",{"2":{"401":1}}],["在实际的深度学习超参数调优条件下",{"2":{"401":1}}],["在实践中",{"2":{"334":1,"344":1}}],["在实践中dot",{"2":{"203":1}}],["在实践中人们发现",{"2":{"177":1}}],["在许多调优试验并行运行时特别高效",{"2":{"401":1}}],["在优化过程中",{"2":{"397":1}}],["在日志记录",{"2":{"395":1}}],["在测试模式中使用的指数移动平均",{"2":{"394":1}}],["在更多的训练数据上",{"2":{"619":1}}],["在更改批大小或主机数量时会有一些棘手的细节",{"2":{"394":1}}],["在更复杂的情况下",{"2":{"370":1}}],["在电子表格中跟踪实验结果有助于我们解决各种建模问题",{"2":{"393":1}}],["在跟踪不同的实验时",{"2":{"393":1}}],["在稀有类别样本上的表现往往会有噪音",{"2":{"391":1}}],["在构建采样数据集时",{"2":{"391":1}}],["在线评估是最佳标准",{"2":{"389":1}}],["在线评估",{"2":{"389":1}}],["在固定步长间隔进行评估",{"2":{"388":1}}],["在较少的训练步骤上调整开根号衰减",{"2":{"384":1}}],["在较佳的超参数上进行少量长时间的训练来得到最终模型",{"2":{"383":1}}],["在短时间和不完整训练中找到的超参数在增加训练长度后仍然是好选择的保证是没有的",{"2":{"384":1}}],["在调用",{"2":{"509":2}}],["在调用torch",{"2":{"509":2}}],["在调用self上的state",{"2":{"509":1}}],["在调用模块的load",{"2":{"496":1}}],["在调整学习率衰减计划时的一个常见问题是使用了太小的学习率",{"2":{"383":1}}],["在调优过程中的许多抉择",{"2":{"354":1}}],["在搜索中最快达到完美训练的实验所需的步数就是我们对",{"2":{"382":1}}],["在没有数据增强和正则化的情况下运行恒定的学习率搜索",{"2":{"382":1}}],["在其他两种模式中",{"2":{"477":1}}],["在其他应用中",{"2":{"378":1}}],["在其他情况下",{"2":{"365":1}}],["在采用一个候选变化之前",{"2":{"378":1}}],["在试验中",{"2":{"375":1}}],["在检查训练曲线时",{"2":{"375":1}}],["在上述代码中",{"2":{"472":1}}],["在上面的内容中",{"2":{"409":1}}],["在上面的示例中",{"2":{"369":1}}],["在上图中用红色",{"2":{"373":1}}],["在某个维度上",{"2":{"373":1}}],["在某些实际问题中",{"2":{"630":1}}],["在某些深度学习模型上效果不错",{"2":{"277":1}}],["在某些情况下",{"2":{"120":3,"365":1,"369":1,"372":1,"383":1}}],["在进行调整时",{"2":{"383":2}}],["在进行调整时要在两个方面进行平衡",{"2":{"383":1}}],["在进行一项研究后",{"2":{"371":1}}],["在进行训练之前",{"2":{"86":1}}],["在当前行上方插入新行",{"2":{"778":1}}],["在当前行下方插入新行",{"2":{"778":1}}],["在当前行行尾插入",{"2":{"778":1}}],["在当前行行首插入",{"2":{"778":1}}],["在当前搜索空间中",{"2":{"371":1}}],["在当前轮次实验中取固定值的参数",{"2":{"369":1}}],["在足够大的搜索空间上调整冗余超参数",{"2":{"371":1}}],["在探索结束后",{"2":{"370":1}}],["在探索阶段",{"2":{"370":1}}],["在最简单的情况下",{"2":{"370":1}}],["在各种优化器超参数",{"2":{"369":1}}],["在各种任务中",{"2":{"193":1}}],["在此阶段",{"2":{"369":1}}],["在特定位置添加批标准化是否有帮助",{"2":{"369":1}}],["在比较目标超参数的不同值时",{"2":{"369":1}}],["在添加花哨的衰减方案之前以恒定的学习率开始",{"2":{"363":1}}],["在项目开始时选择batch",{"2":{"361":1}}],["在项目的初始阶段",{"2":{"356":1}}],["在开始超参数调整之前",{"2":{"363":1}}],["在开始一个新项目时",{"2":{"355":1}}],["在开始调优之前",{"2":{"354":1}}],["在开发",{"2":{"337":1}}],["在准备创建此文档时",{"2":{"353":1}}],["在学习过程中",{"2":{"346":1}}],["在学习了lm和tm这两个模型之后",{"2":{"190":1}}],["在句子中随机交换任意两个单词",{"2":{"344":1}}],["在步骤",{"2":{"338":9}}],["在连续批处理",{"2":{"338":1}}],["在涉及多个",{"2":{"337":1}}],["在涉及需要从其他主机获取块的key",{"2":{"327":1}}],["在并行采样中",{"2":{"335":1}}],["在注意力计算过程中",{"2":{"333":1}}],["在我们的系统中",{"2":{"338":1}}],["在我们的实验中",{"2":{"332":1}}],["在我们的github存储库中",{"2":{"332":1}}],["在我们算法的两阶段版本中",{"2":{"325":1}}],["在gpt中已经添加了cp支持",{"2":{"328":1}}],["在反向计算中重新计算激活可以避免oom",{"2":{"328":1}}],["在反向传播过程",{"2":{"475":1}}],["在反向传播过程时",{"2":{"121":1}}],["在反向传播期间检索它们",{"2":{"472":1}}],["在反向传播中应用reduce",{"2":{"328":1}}],["在反向传播中",{"2":{"323":1}}],["在图形学中",{"2":{"858":1}}],["在图1中",{"2":{"328":1}}],["在图中",{"2":{"327":1}}],["在图像分类任务上获得了远远超过其他参赛者的结果",{"2":{"122":1}}],["在计算机科学中",{"2":{"680":1}}],["在计算前向传播时",{"2":{"471":1}}],["在计算注意力时",{"2":{"327":1}}],["在计算其query",{"2":{"327":1}}],["在计算块并行注意力和前馈时",{"2":{"327":1}}],["在计算损失的时候",{"2":{"181":1}}],["在将输入序列分布到不同主机时",{"2":{"327":1}}],["在将多头检查点转换为gqa检查点时",{"2":{"219":1,"305":1}}],["在单核单处理器的环境下",{"2":{"799":1}}],["在单卡内部做的分块优化扩展到多卡上",{"2":{"326":1}}],["在单个训练步骤中计算得出",{"2":{"29":1}}],["在异步块级gemm下隐藏softmax",{"2":{"325":1}}],["在第一次实验中",{"2":{"401":1}}],["在第一轮调参中",{"2":{"384":1}}],["在第2",{"2":{"316":1}}],["在第3",{"2":{"223":1,"312":1}}],["在推理过程中",{"2":{"309":1}}],["在adam",{"2":{"294":1}}],["在凸优化背景中",{"2":{"277":1}}],["在批量梯度下降中",{"2":{"260":1}}],["在0点处导数值为1",{"2":{"245":1}}],["在2010年提出的",{"2":{"244":1}}],["在后几层中",{"2":{"239":1}}],["在神经网络中",{"2":{"237":1}}],["在常见的序列长度",{"2":{"227":1,"317":1}}],["在芯片上更新",{"2":{"226":1}}],["在芯片上计算",{"2":{"226":2}}],["在每个序列的末尾",{"2":{"634":1}}],["在每个标签",{"2":{"628":1}}],["在每个训练步骤中只有被遮盖掉词语的表示会得到更新",{"2":{"619":1}}],["在每个训练周期之前更新学习率",{"2":{"541":1}}],["在每个阶段",{"2":{"619":1,"620":1,"621":1}}],["在每个周期内进行训练",{"2":{"545":1}}],["在每个块中",{"2":{"222":1,"314":1}}],["在每一轮中",{"2":{"385":1}}],["在每一步中",{"2":{"194":1}}],["在每一步选择k个候选项时",{"2":{"186":1}}],["在每一步",{"2":{"184":1}}],["在每一步的预测时",{"2":{"178":1}}],["在每次迭代训练中",{"2":{"346":1}}],["在每次参数更新时",{"2":{"266":1}}],["在外循环",{"2":{"222":1,"314":1}}],["在前面讲解过",{"2":{"655":1}}],["在前向传播期间保存张量",{"2":{"472":1}}],["在前向传播过程中",{"2":{"472":1,"475":1}}],["在前向传播中存储了softmax归一化因子",{"2":{"222":1,"311":1}}],["在前馈神经网络最后",{"2":{"29":1}}],["在于",{"2":{"191":1}}],["在sql语句中拼接通配符",{"2":{"734":1}}],["在sql的配置文件中",{"2":{"733":1}}],["在smt中具体怎么解码",{"2":{"190":1}}],["在self上生成state",{"2":{"509":1}}],["在search结束之后",{"2":{"186":1}}],["在seq2seq的训练过程中",{"2":{"179":1}}],["在seq2seq结构中",{"2":{"168":1}}],["在之前图中",{"2":{"181":1}}],["在encoder",{"2":{"173":1}}],["在",{"2":{"126":1,"216":1,"220":1,"240":1,"306":1,"387":1,"402":1,"403":1,"404":1,"473":1,"616":2,"620":1,"624":1,"633":1,"634":1,"648":1,"799":1,"827":3,"878":1}}],["在深度学习领域",{"2":{"353":1}}],["在深度学习时代之前",{"2":{"190":1}}],["在深度学习时代",{"2":{"189":1}}],["在深度学习中",{"2":{"123":1,"256":1,"531":1}}],["在深度学习发展初期",{"2":{"121":1}}],["在一个进程或节点中创建待发送的信息",{"2":{"796":1}}],["在一般的条件随机场",{"2":{"630":1}}],["在一定模型下",{"2":{"123":1}}],["在一群猫和狗中",{"2":{"11":1}}],["在负数部分",{"2":{"122":1}}],["在该比赛中",{"2":{"122":1}}],["在非线性激活函数的作用下数据分布进行再映射",{"2":{"120":1}}],["在几何中",{"2":{"120":1}}],["在新轴上拼接tensor",{"2":{"105":1}}],["在给定的维度上拼接给定的序列张量",{"2":{"104":1}}],["在卷积神经网络训练初期",{"2":{"95":1}}],["在卷积核里面的元素之间插入空格来",{"2":{"60":1}}],["在训练期间记录下未截断梯度范数",{"2":{"410":1}}],["在训练结束时",{"2":{"392":1}}],["在训练后期",{"2":{"375":1}}],["在训练的时候",{"2":{"177":1}}],["在训练和推理时有何不同",{"2":{"86":1}}],["在训练过程中记录全损失梯度的",{"2":{"405":1}}],["在训练过程中常使用预训练的语言模型来初始化decoder的参数",{"2":{"180":1}}],["在训练过程中",{"2":{"24":1,"114":1,"180":1,"235":1}}],["在输入的第",{"2":{"639":1}}],["在输入层上应用深度卷积",{"2":{"58":1}}],["在输入张量中",{"2":{"55":1}}],["在这一点上",{"2":{"379":1}}],["在这种情况下",{"2":{"276":1,"335":1,"341":1,"370":1,"372":1,"380":2,"381":1,"390":1,"394":1,"407":1,"496":1,"544":1}}],["在这种背景下",{"2":{"95":1}}],["在这里",{"2":{"220":1,"306":1,"472":1}}],["在这项工作中论文提出transformer",{"2":{"193":1}}],["在这本书中我们遵循把两种运算都叫做卷积的这个传统",{"2":{"52":1}}],["在这个时候",{"2":{"379":1}}],["在这个例子中",{"2":{"52":1}}],["在这个模型中",{"2":{"8":1}}],["在概念上",{"2":{"471":1}}],["在概念",{"2":{"18":1}}],["在机器学习和深度学习中",{"2":{"258":1}}],["在机器学习和认知科学领域",{"2":{"5":1}}],["在机器学习中",{"2":{"4":1,"340":1}}],["这年代",{"0":{"962":1}}],["这并不是遥不可及的复杂理论",{"2":{"927":1}}],["这并不是一款由谷歌官方所支持的产品",{"2":{"422":1}}],["这其实就是一种分步解决问题的方式",{"2":{"922":1}}],["这其实跟电脑在成千上万的文件里找某个文件的过程类似",{"2":{"920":1}}],["这其实是一种生活中的排序方式",{"2":{"919":1}}],["这其实也是内外循环置换这个总体思想配套的改进措施",{"2":{"324":1}}],["这部经典和最近孔老夫子以及王阳明先生带给我太多太多宝贵的东西",{"2":{"880":1}}],["这部经典影片我现在每隔两年左右会看一遍",{"2":{"880":1}}],["这周周天继续看完了剩下的内容",{"2":{"880":1}}],["这段路往往是很孤单的",{"2":{"878":1}}],["这真的让现在的我很是敬佩",{"2":{"878":1}}],["这完全有可能",{"2":{"878":1}}],["这或许是",{"2":{"875":1}}],["这项技术能够捕捉微小的表情变化",{"2":{"859":1}}],["这大大简化了编译过程",{"2":{"822":1}}],["这大大减少了网络消耗并提高了mfu",{"2":{"329":1}}],["这本书只是让你宏观地感受计算机本身",{"2":{"702":1}}],["这本书呢是日本作者写的一本关于计算机的基础知识",{"2":{"696":1}}],["这点女生可能比男生更有经验",{"2":{"967":1}}],["这点再次让我真正觉得孔子值得被称为",{"2":{"878":1}}],["这点很重要",{"2":{"878":1}}],["这点说完我就觉得他应该赚这份钱",{"2":{"875":1}}],["这点在我们的课堂上是比较缺失的",{"2":{"699":1}}],["这点对于计科考研党来说比较好",{"2":{"698":1}}],["这篇笔记我们讲讲书本中的信号量机制pv操作之",{"2":{"695":1}}],["这篇笔记我们讲讲进程协作之间的进程同步",{"2":{"674":1}}],["这篇论文的第一个思路是基于多个",{"2":{"220":1,"306":1}}],["这构成了相对位置编码的一般做法",{"2":{"638":1}}],["这构成了绝对位置编码的一般做法",{"2":{"638":1}}],["这对于处理文本摘要等需要捕获长距离依赖的任务特别有用",{"2":{"621":1}}],["这对于减少长上下文输入的总体处理时间",{"2":{"329":1}}],["这三种实现方式的性能排序为",{"2":{"510":1}}],["这三个必要条件",{"2":{"371":1}}],["这非常有用",{"2":{"504":2}}],["这非常有益",{"2":{"357":1}}],["这用于注册一个不被视为模型参数的缓冲区",{"2":{"493":1}}],["这正是允许使用任意的",{"2":{"471":1}}],["这只是允许我们使用和重新分配您的贡献作为项目的一部分",{"2":{"423":1}}],["这只适用于未来不会有这种特定工作需求的情况",{"2":{"379":1}}],["这至少比",{"2":{"409":1}}],["这会导致出现缓慢但稳定的训练",{"2":{"405":1}}],["这才会是问题",{"2":{"405":1}}],["这表明应该更改搜索空间边界",{"2":{"401":1}}],["这表明我们处于",{"2":{"375":1}}],["这表明我们在",{"2":{"375":1}}],["这允许训练作业对计算实例中断具有弹性",{"2":{"392":1}}],["这通常需要对数据进行抽样以进行定期评估",{"2":{"391":1}}],["这通过cp倍减少了计算和通信",{"2":{"328":1}}],["这与log",{"2":{"381":1}}],["这实际上优化了冗余超参数",{"2":{"375":1}}],["这有时需要重新参数化搜索空间",{"2":{"372":1}}],["这有助于生成正确的计算图",{"2":{"563":1}}],["这有助于生成更准确",{"2":{"180":1}}],["这有助于在梯度方向上形成更大的动量",{"2":{"266":1}}],["这有助于加快模型的收敛速度",{"2":{"180":1}}],["这有助于保留整体特征信息",{"2":{"94":1}}],["这不就是希望吗",{"2":{"880":1}}],["这不就是向量乘以了一个旋转矩阵吗",{"2":{"646":1}}],["这不是我夸大",{"2":{"878":1}}],["这不是官方认证的",{"2":{"350":1}}],["这不会降低在低学习率下的性能",{"2":{"404":1}}],["这不一定对应线上模型的实际上线",{"2":{"365":1}}],["这包括指定",{"2":{"363":1}}],["这称为完美缩放",{"2":{"359":1}}],["这称之为前向传播",{"2":{"24":1}}],["这在项目的初始阶段尤其重要",{"2":{"356":1}}],["这在训练的时候有效",{"2":{"216":1}}],["这份文件是在我们试图实现我们自己的深度学习方法时产生的",{"2":{"353":1}}],["这份手册是为谁准备的",{"0":{"352":1},"2":{"351":1}}],["这导致几乎最佳的内存利用率",{"2":{"334":1}}],["这导致更好的",{"2":{"329":1}}],["这基于流水线的加速方法已在训练系统中得到探讨",{"2":{"329":1}}],["这降低了mfu并与网络资源竞争以在节点之间传输kvcache",{"2":{"329":1}}],["这将导致在反向传播过程中引发错误",{"2":{"473":1}}],["这将导致大约1",{"2":{"322":1}}],["这将不会导致额外的通信成本",{"2":{"327":1}}],["这将违背减少内存成本的初衷",{"2":{"327":1}}],["这两个",{"2":{"878":1}}],["这两个参数是用来学习的参数",{"2":{"86":1}}],["这两种模型在实践中体现出极好的性能",{"2":{"653":1}}],["这两点我们在第一部分中已给出详细说明",{"2":{"324":1}}],["这意味着每个进程都有自己的独立内存空间",{"2":{"805":1}}],["这意味着维特比算法中的局部最优性原理仅考虑前一个时刻的最优路径",{"2":{"630":1}}],["这意味着",{"2":{"504":1}}],["这意味着cp被禁用",{"2":{"328":1}}],["这意味着对于每一行",{"2":{"322":1}}],["这意味着在下一步扩展时",{"2":{"186":1}}],["这使得模型可以灵活地用于",{"2":{"621":1}}],["这使得训练效率提高了",{"2":{"619":1}}],["这使得这些采样方法在llm服务中变得实用",{"2":{"335":1}}],["这使得在部署过程中需要频繁的即时可扩展性的情况下具有挑战性",{"2":{"329":1}}],["这使得在训练和推理过程中上下文大小的扩展零开销",{"2":{"327":1}}],["这使得算法能够更好地平衡快速收敛和避免震荡之间的权衡",{"2":{"262":1}}],["这使得mini",{"2":{"262":1}}],["这使得sgd在大规模数据集上具有优势",{"2":{"261":1}}],["这使得其对噪声有一些鲁棒性",{"2":{"125":1}}],["这被称作是",{"2":{"254":1}}],["这也就是说",{"2":{"401":1}}],["这也成为日后kaiming初始化提出的原因",{"2":{"245":1}}],["这也是该领域的一个活跃研究领域",{"2":{"406":1}}],["这也是我根本不想去深入了解这个技术的原因",{"2":{"190":1}}],["这也是为什么大家都说深度学习的可解释性很差",{"2":{"19":1}}],["这同样导致了gradient太小",{"2":{"240":1}}],["这就像",{"2":{"921":1}}],["这就限制了大模型在处理长文本或多轮对话等任务时的效果",{"2":{"645":1}}],["这就可能存在问题",{"2":{"375":1}}],["这就导致loss",{"2":{"236":1}}],["这就是数据压缩过程我们所要考虑的问题",{"2":{"654":1}}],["这就是为什么叫做旋转位置编码的原因",{"2":{"646":1}}],["这就是一个生活中的",{"2":{"917":1}}],["这就是一个语言模型",{"2":{"190":1}}],["这就是一直沿用至今的",{"2":{"8":1}}],["这就是",{"2":{"143":1,"924":1}}],["这就是高斯误差函数名称的由来",{"2":{"126":1}}],["这避免了反复从hbm读取和写入输入和输出的操作",{"2":{"226":1,"315":1}}],["这需要在内存中布置fp32累加器块和fp8操作数矩阵的不同布局一致性要求",{"2":{"325":1}}],["这需要",{"2":{"223":1,"312":1}}],["这比从hbm中读取中间注意力矩阵的标准方法更快",{"2":{"222":1,"311":1}}],["这代表了一个有利的权衡",{"2":{"219":1,"305":1}}],["这里会有一些贪心策略的选择",{"2":{"972":1}}],["这里这样说不太严谨",{"2":{"972":1}}],["这里讲的",{"2":{"967":1}}],["这里吧前面说的i和j换成了child和cookie",{"2":{"957":1}}],["这里不做记录",{"2":{"909":1}}],["这里不多赘述",{"2":{"677":1}}],["这里只会记录一些使用过程中的问题",{"2":{"908":1}}],["这里只考虑了0",{"2":{"853":1}}],["这里展示create",{"2":{"889":1}}],["这里我不再过多表达",{"2":{"917":1}}],["这里我把相关的知识和解决方案大概写一写",{"2":{"908":1}}],["这里我用我的远程win系统给大家演示",{"2":{"888":1}}],["这里我借用刘崇军老师给说说的话",{"2":{"831":1}}],["这里汇集了我的日常思考",{"2":{"881":1}}],["这里有人会去解读",{"2":{"878":1}}],["这里就不展示了",{"2":{"889":1}}],["这里就引出了一个关键问题",{"2":{"844":1}}],["这里就拿单核单处理器简单演示",{"2":{"799":1}}],["这里主要讲解mpi实现分布式消息传递",{"2":{"796":1}}],["这里简单提一下",{"2":{"677":1}}],["这里其实不是椭圆",{"2":{"655":1}}],["这里面",{"2":{"646":1}}],["这里可能对应着很多条不同的路径",{"2":{"624":1}}],["这里可能存在无穷大",{"2":{"473":1}}],["这里的",{"2":{"878":2}}],["这里的向量都是指行向量",{"2":{"643":1}}],["这里的高分辨率数据集是图像尺寸在1024x1024以上",{"2":{"608":1}}],["这里的计算不会被跟踪梯度",{"2":{"474":2}}],["这里的重点就在于这个",{"2":{"185":1}}],["这里至少有两种类型的不稳定的训练任务值得需要进行区分",{"2":{"405":1}}],["这里假设",{"2":{"249":1}}],["这里",{"2":{"194":1,"223":1,"312":1}}],["这里保留训练时的均值和方差",{"2":{"86":1}}],["这是本专题的基本大纲",{"2":{"966":1}}],["这是由这四个数字能构成的最大四位数",{"2":{"934":1}}],["这是贪心算法的基本策略",{"2":{"932":1}}],["这是无价的",{"2":{"880":1}}],["这是很难做到的",{"2":{"878":1}}],["这是所谓的",{"2":{"878":1}}],["这是做人的基本",{"2":{"878":1}}],["这是大多数优化器支持的简化版本",{"2":{"505":1}}],["这是最终手段",{"2":{"406":1}}],["这是一种不用于禁用梯度计算的方法",{"2":{"474":1}}],["这是一种受操作系统中虚拟内存和分页",{"2":{"333":1}}],["这是一份在线文档",{"2":{"422":1}}],["这是一个可能变化的实现细节",{"2":{"472":1}}],["这是一个很好的",{"2":{"401":1}}],["这是一个开放性问题",{"2":{"397":1}}],["这是一个用于快速llm推理和服务的开源库",{"2":{"332":1}}],["这是一项核心技术",{"2":{"332":1}}],["这是在推理阶段的第一个应用",{"2":{"329":1}}],["这是因为训练模型的时间越长",{"2":{"383":1}}],["这是因为较小的数据集可能无法很好地捕捉到真实数据的复杂性",{"2":{"341":1}}],["这是因为现代gpu具有专门的计算单元",{"2":{"320":1}}],["这是因为在反向传播中需要在sram中保持更多的值来执行5次矩阵乘法",{"2":{"316":1}}],["这是因为如果把parameters初始化",{"2":{"237":1}}],["这是否意味着decoder模型学到了一些通用的知识呢",{"2":{"180":1}}],["这是电脑硬件中所对应的一个软件",{"2":{"73":1}}],["这和神经科学的研究不太相符",{"2":{"123":1}}],["这可能需要更强的正则化和",{"2":{"412":1}}],["这可能表明模型参数在某一时刻发生了非常大的变化",{"2":{"405":1}}],["这可能会很棘手",{"2":{"481":1}}],["这可能会成为问题",{"2":{"405":1}}],["这可能会增加训练时间并增加计算资源的需求",{"2":{"383":1}}],["这可能会干扰我们比较目标超参数的不同值的能力",{"2":{"375":1}}],["这可能会导致训练时间较长",{"2":{"260":1}}],["这可能不适用",{"2":{"375":1}}],["这可能导致sgd在搜索空间中陷入局部最小值",{"2":{"261":1}}],["这可能对某些任务和网络架构更有利",{"2":{"120":1}}],["这可以告诉我们该如何选择梯度",{"2":{"405":1}}],["这可以将吞吐量提高高达2",{"2":{"335":1}}],["这可以很容易地与计算重叠",{"2":{"329":1}}],["这可以看作是一种选择性梯度检查点的形式",{"2":{"228":1,"318":1}}],["这可以造成网络的稀疏性",{"2":{"122":1}}],["这一算法优化了碰撞检测和矩阵计算公式",{"2":{"859":1}}],["这一步对应的就是发射分数",{"2":{"627":1}}],["这一术语拥有一种更加精确的含义",{"2":{"411":1}}],["这一最流行的llm库以及huggingface文本生成推理",{"2":{"332":1}}],["这一属性源自这样一个事实",{"2":{"327":1}}],["这一突破被认为是深度学习在计算机视觉领域的重要里程碑",{"2":{"122":1}}],["这一模型也可以使用反向传播算法进行训练",{"2":{"51":1}}],["这时我们想到了变分法",{"2":{"659":1}}],["这时应该使用贝叶斯优化工具来自动找到最佳超参数配置",{"2":{"379":1}}],["这时的decoder就是一个语言模型",{"2":{"176":1}}],["这时候它也会出现饱和的现象",{"2":{"120":1}}],["这时使用group",{"2":{"86":1}}],["这些技术的进步为游戏",{"2":{"859":1}}],["这些技术增加了代码复杂性的下届或额外的计算",{"2":{"375":1}}],["这些都是目前最前沿的技术之一",{"2":{"858":1}}],["这些工具可以",{"2":{"822":1}}],["这些方案还不能对cpu的速度和数目做出任何的假设",{"2":{"681":1}}],["这些方法的专家能够获得良好的结果",{"2":{"401":1}}],["这些发射分数",{"2":{"624":1}}],["这些标签向量将被作为发射分数传入crf中",{"2":{"624":1}}],["这些强大的模型在各种",{"2":{"622":1}}],["这些变化使得可以用更少的参数训练更大的模型",{"2":{"619":1}}],["这些改变显著地提高了模型的性能",{"2":{"619":1}}],["这些语言模型虽然可以对训练过的语言产生统计意义上的理解",{"2":{"616":1}}],["这些语句可以在每次迭代时改变图的整体形状和大小",{"2":{"471":1}}],["这些具有开创性的工作促成了两个著名",{"2":{"616":1}}],["这些优化包括常量折叠",{"2":{"560":1}}],["这些调度器在优化过程中按顺序调用",{"2":{"549":1}}],["这些钩子函数将在调用self的state",{"2":{"496":1}}],["这些钩子函数将被传入以下参数",{"2":{"496":1}}],["这些钩子函数可以原地修改state",{"2":{"496":1}}],["这些模式可以影响",{"2":{"476":1}}],["这些模式在",{"2":{"337":1}}],["这些推荐有帮于证明我们创建更多这样的内容是合理的",{"2":{"422":1}}],["这些东西对于每个batch",{"2":{"412":1}}],["这些填充的数据可以被赋予零的权重",{"2":{"390":1}}],["这些问题可以通过在固定步长间隔进行评估来更容易地检测到",{"2":{"390":1}}],["这些试验会产生分歧或得到非常糟糕的结果",{"2":{"373":1}}],["这些搜索空间往往非常重要",{"2":{"365":1}}],["这些总是可以在以后添加",{"2":{"363":1}}],["这些指标应该尽可能地代表在部署环境中测量的内容",{"2":{"354":1}}],["这些专家也很乐意承认他们所做的一些事情可能没有充分的理由",{"2":{"353":1}}],["这些策略被统称为正则化",{"2":{"340":1}}],["这些查询共享相同的少样本示例",{"2":{"338":1}}],["这些请求包括两个聊天会话",{"2":{"338":1}}],["这些kv",{"2":{"338":1}}],["这些程序在当前系统中处理得很差",{"2":{"337":1}}],["这些cached",{"2":{"333":1}}],["这些序列并行性方法利用了注意力运算的结合特性",{"2":{"329":1}}],["这些序列形的数据就不太好用原始的神经网络处理了",{"2":{"160":1}}],["这些操作不需要与其他主机进行通信",{"2":{"327":1}}],["这些权重能够被提取出来",{"2":{"254":1}}],["这些位置",{"2":{"215":1}}],["这些位置的概率就会接近0",{"2":{"215":1}}],["这些任务代表了nlp领域中的一些核心问题和应用",{"2":{"188":1}}],["这些门可以在训练过程中学习哪些信息是需要保留或遗忘的",{"2":{"145":1}}],["这些门是不同的神经网络",{"2":{"145":1}}],["这些算子通过张量",{"2":{"117":1}}],["这些层之间存在着多层的非线性转换关系",{"2":{"117":1}}],["这些输入信号通过带权重的连接",{"2":{"8":1}}],["这样你可以保证时间用在最重要最紧急的事情上",{"2":{"942":1}}],["这样你就能去",{"2":{"939":1}}],["这样你就可以找到最优的超参数组合",{"2":{"401":1}}],["这样看来",{"2":{"878":1}}],["这样便于实现多个子任务并行执行",{"2":{"810":1}}],["这样就可以利用",{"2":{"646":1}}],["这样就导致负的梯度在这个relu被置零",{"2":{"122":1}}],["这样一来",{"2":{"643":1}}],["这样只需要调整控制符就可以生成多样化的文本",{"2":{"620":1}}],["这样我们就可以放心采样进行数据生成",{"2":{"656":1}}],["这样我们就可以根据这个规律去抽取样本进行生成",{"2":{"654":1}}],["这样我们就可以更好的了解模型的性能和限制",{"2":{"383":1}}],["这样我们就得到了新的细胞状态",{"2":{"149":1}}],["这样我们更有信心相信",{"2":{"371":1}}],["这样我们从实验中得出的结论就不会受到固定超参数的限定",{"2":{"369":1}}],["这样实验才能真正朝着目标取得进展",{"2":{"367":2}}],["这样使得整个模型更具有鲁棒性",{"2":{"348":1}}],["这样形成一整块整块",{"2":{"348":1}}],["这样做的好处是丰富了图片的背景",{"2":{"344":1}}],["这样神经网络就可以对权重参数w不停地迭代更新",{"2":{"233":1}}],["这样虽然可以提升推理的速度",{"2":{"220":1,"306":1}}],["这样的数量级进行尝试",{"2":{"409":1}}],["这样的好处在于",{"2":{"401":1}}],["这样的构件可以轻松地在评估完成后进行即时模型检查",{"2":{"390":1}}],["这样的目标没有什么意义",{"2":{"369":1}}],["这样的话",{"2":{"215":1}}],["这样的神经网络结构通常称为多层前馈神经网络",{"2":{"13":1}}],["这样",{"2":{"186":1,"383":1,"932":1}}],["这样会导致训练时的累积损失太大",{"2":{"177":1}}],["这样训练非常困难",{"2":{"177":1}}],["这样可以确保大饼干用于更大胃口的小孩",{"2":{"955":1}}],["这样可以尽快减少剩下的钱",{"2":{"946":1}}],["这样可以尽早让模型进入工作状态",{"2":{"355":1}}],["这样可以让我们在短时间内完成更多的事情",{"2":{"926":1}}],["这样可以让你在有限的时间内完成更多的事情",{"2":{"919":1}}],["这样可以更灵活地处理变长序列数据",{"2":{"559":1}}],["这样可以在有限的时间和资源内获得最大的理解",{"2":{"383":1}}],["这样可以提高学习的精度",{"2":{"122":1}}],["这样可以很好的模拟人脑神经元工作的原理",{"2":{"122":1}}],["这样与batchsize无关",{"2":{"89":1}}],["这个点就是全局最优解",{"2":{"970":1}}],["这个小山峰是最高的",{"2":{"970":1}}],["这个词",{"2":{"916":1}}],["这个在孔子看来是很重要的一件事",{"2":{"878":1}}],["这个维修的话会怎么怎么样",{"2":{"875":1}}],["这个层面应该具有一个较为清晰和严格的逻辑边界",{"2":{"723":1}}],["这个变分表示了函数y",{"2":{"659":1}}],["这个设计的思路其实也很直观",{"2":{"644":1}}],["这个转移分数矩阵是crf中的一个可学习的参数矩阵",{"2":{"628":1}}],["这个微调的过程只需要很少的数据",{"2":{"617":1}}],["这个improved",{"2":{"608":1}}],["这个跟踪模型可以在后续的推理过程中重复使用",{"2":{"564":1}}],["这个脚本是模型的静态表示形式",{"2":{"563":1}}],["这个方法在torch",{"2":{"496":1}}],["这个函数已被弃用",{"2":{"496":1}}],["这个函数决定了哪些值将被更新",{"2":{"148":1}}],["这个上下文管理器使得在不必临时将张量设置为",{"2":{"478":1}}],["这个torch",{"2":{"463":1}}],["这个tensor",{"2":{"462":1}}],["这个grad",{"2":{"457":1}}],["这个说法",{"2":{"411":1}}],["这个术语来表示学习率",{"2":{"411":1}}],["这个阈值的大小与工作量有关",{"2":{"410":1}}],["这个计划会将学习率从0提升到某个稳定的",{"2":{"409":1}}],["这个问题与变分推断遇到的几乎一样",{"2":{"658":1}}],["这个问题没有办法笼统地回答",{"2":{"403":1}}],["这个问题在应用于注意力矩阵的其他逐元素操作时会变得更加严重",{"2":{"223":1,"312":1}}],["这个名字派生自短语",{"2":{"294":1}}],["这个过程跟计算机里的时间复杂度分析很相似",{"2":{"926":1}}],["这个过程其实就是一种简单的逻辑推理",{"2":{"925":1}}],["这个过程不仅需要海量的训练数据",{"2":{"617":1}}],["这个过程也被称为",{"2":{"220":1,"306":1}}],["这个过程我们可以看到",{"2":{"142":1}}],["这个score代表了当前到第t步的输出序列的一个综合得分",{"2":{"185":1}}],["这个特殊标记",{"2":{"181":1}}],["这个projection层",{"2":{"181":1}}],["这个context",{"2":{"170":1}}],["这个模型目前没有开源",{"2":{"620":1}}],["这个模型最初设计用于改进机器翻译技术",{"2":{"167":1}}],["这个模块经常被用来存储单词嵌入",{"2":{"113":1}}],["这个非线性函数被称为激活函数",{"2":{"120":1}}],["这个图就是我们常说的深度学习网络图",{"2":{"117":1}}],["这个差异",{"2":{"29":1}}],["这个目标值可以在训练数据集中找到",{"2":{"29":1}}],["这个水管网络有许多层",{"2":{"15":1}}],["这种贪心策略能够保证最多的小孩得到满足",{"2":{"960":1}}],["这种简单的选择方式虽然看起来随意",{"2":{"921":1}}],["这种行为也可以看作是一种",{"2":{"920":1}}],["这种行为称之为",{"2":{"237":1}}],["这种决策方式本质上就是我们在生活中对任务的优先级进行排序",{"2":{"919":1}}],["这种远不是距离远",{"2":{"878":1}}],["这种强烈的感觉或许会让你顿时感到无比欣慰",{"2":{"878":1}}],["这种见习是自然而然的",{"2":{"878":1}}],["这种老板会不成功吗",{"2":{"875":1}}],["这种过程充满挑战",{"2":{"858":1}}],["这种现象被称作进程互斥",{"2":{"678":1}}],["这种情况下",{"2":{"630":1}}],["这种情况有可能会被mish改变",{"2":{"128":1}}],["这种迁移学习的好处是",{"2":{"617":1}}],["这种迁移学习的思想使得使用预训练语言模型来初始化decoder参数成为一种有效的策略",{"2":{"180":1}}],["这种编译过程可以包括静态类型推断",{"2":{"560":1}}],["这种减小学习率的过程类似于金属冶炼中的加热和冷却过程",{"2":{"544":1}}],["这种更好的运行时性能伴随着一个缺点",{"2":{"479":1}}],["这种误差会造成优化效果变差",{"2":{"401":1}}],["这种考虑很少是一个实际的问题",{"2":{"391":1}}],["这种策略自20",{"2":{"345":1}}],["这种设计使得系统能够高效地利用内存",{"2":{"338":1}}],["这种",{"2":{"338":1}}],["这种数据结构使得前缀搜索",{"2":{"337":1}}],["这种数学运算",{"2":{"51":1}}],["这种内存效率的提升非常有益",{"2":{"334":1}}],["这种进一步的分解会导致动态调整每个组中节点数量的问题",{"2":{"329":1}}],["这种重叠机制适用于我们方法的正向和反向传递",{"2":{"327":1}}],["这种随机性也有助于sgd跳出局部最小值并继续搜索更好的解",{"2":{"261":1}}],["这种掩码结合将输出嵌入偏移一个位置",{"2":{"197":1}}],["这种模式适合有集中管理需求的任务分解",{"2":{"811":1}}],["这种模式简单高效",{"2":{"801":1}}],["这种模式我们称之为free",{"2":{"176":1}}],["这种模型架构避免循环并完全依赖于attention机制来绘制输入和输出之间的全局依赖关系",{"2":{"193":1}}],["这种attention机制都与循环网络一起使用",{"2":{"193":1}}],["这种对应关系可以是一对一",{"2":{"190":1}}],["这种做法过程简单",{"2":{"189":1}}],["这种做法使得全连接层参数很多",{"2":{"95":1}}],["这种greedy的方式",{"2":{"183":1}}],["这种预训练",{"2":{"180":1}}],["这种操作的目的就是为了使得训练过程更容易",{"2":{"178":1}}],["这种1",{"2":{"164":1}}],["这种结构通常用来处理序列分类问题",{"2":{"163":1}}],["这种池化方法通常在网络最后",{"2":{"95":1}}],["这种方式适用于需要确保消息到达的情景",{"2":{"807":1}}],["这种方式带来的开销是我们无法忍受的",{"2":{"190":1}}],["这种方式很可能",{"2":{"183":1}}],["这种方式摒弃了网络中大量的冗余信息",{"2":{"93":1}}],["这种方法称为",{"2":{"179":1}}],["这种方法比起正式的逻辑学推理演算更具有优势",{"2":{"5":1}}],["这种关系能否用公式来表达",{"2":{"55":1}}],["这种技术适用于所有网络层",{"2":{"29":1}}],["这种架构通常称为多层感知机",{"2":{"13":1}}],["将大问题划分成若干小问题",{"2":{"974":1}}],["将大块的计算融合成一个内核",{"2":{"510":1}}],["将它放在千位",{"2":{"933":1}}],["将它们的内存使用量降低了高达55",{"2":{"335":1}}],["将它们应用到我们正在面对的问题上",{"2":{"254":1}}],["将它们加载到sram",{"2":{"222":1,"314":1}}],["将它们连接",{"2":{"208":1}}],["将did",{"2":{"845":1}}],["将公钥复制到",{"2":{"827":1}}],["将各进程的数据聚合为一个单一结果",{"2":{"808":1}}],["将各进程的数据收集到一个进程中",{"2":{"808":1}}],["将不同的数据片段分发给各个进程",{"2":{"808":1}}],["将不会改变",{"2":{"360":1}}],["将状态码和内容存储到结果字典中",{"2":{"799":1}}],["将消息发送给另一个进程或节点",{"2":{"796":1}}],["将文件权限改为所有者可读写执行",{"2":{"746":1}}],["将文本集合分成不同的群组",{"2":{"188":1}}],["将文本分为不同的类别或标签",{"2":{"188":1}}],["将usermapper",{"2":{"729":1}}],["将上面案例中的接口userdao改名为usermapper",{"2":{"729":1}}],["将上式化简为",{"2":{"248":1}}],["将业务逻辑和数据访问逻辑分离",{"2":{"724":1}}],["将水果做成罐头的方法也是",{"2":{"722":1}}],["将鲜肉冷藏",{"2":{"722":1}}],["将接口和",{"2":{"721":1}}],["将图片进行某种编码",{"2":{"655":1}}],["将原来的三维空间投影到方差最大且线性无关的两个方向或者说将原矩阵进行单位正交基变换以保留最大的信息量",{"2":{"652":1}}],["将原始预测值转换为类别概率",{"2":{"129":1}}],["将原始数据转换成为能够被机器学习来有效开发的一种形式",{"2":{"4":1}}],["将2维推广到任意维度",{"2":{"647":1}}],["将可处理的文本长度从大多数模型的",{"2":{"621":1}}],["将输入的数据进行放大",{"2":{"653":1}}],["将输入句子通过遮盖词语",{"2":{"621":1}}],["将输入分割成块",{"2":{"222":1,"311":1}}],["将基于海量数据获得的统计理解能力应用于我们的任务",{"2":{"617":1}}],["将在",{"2":{"616":1}}],["将模型转换为script模式",{"2":{"568":1}}],["将模块的状态保存到包含模块状态但不包含其子模块状态的destination字典中",{"2":{"496":1}}],["将动态操作转换为优化的静态内核",{"2":{"560":1}}],["将动量加入rmsprop",{"2":{"294":1}}],["将学习率调度器的列表链接在一起",{"2":{"548":1}}],["将初始振幅按",{"2":{"543":1}}],["将初始学习率设置为",{"2":{"537":1,"538":1,"539":1,"540":1,"541":1,"542":1}}],["将初始学习率设置为lr",{"2":{"535":1,"536":1}}],["将每个进程的部分和加到总和中",{"2":{"827":1}}],["将每个位置的最佳idx记录下来",{"2":{"634":1}}],["将每个参数组的学习率通过线性变化的小乘法因子进行衰减",{"2":{"540":1}}],["将每个参数组的学习率按一个小的常数因子进行衰减",{"2":{"539":1}}],["将每个参数组的学习率按",{"2":{"537":1,"541":1}}],["将每个参数组的学习率乘以指定函数中给定的因子",{"2":{"536":1}}],["将每个参数组的学习率设置为初始学习率乘以给定函数",{"2":{"535":1}}],["将每一步的损失求和",{"2":{"181":1}}],["将使用参数self和state",{"2":{"509":1}}],["将使用参数self调用该钩子",{"2":{"509":1}}],["将param",{"2":{"508":1}}],["将参数",{"2":{"496":1}}],["将参数和缓冲区从state",{"2":{"496":1}}],["将参数和缓冲区转成tensor",{"2":{"496":1}}],["将参数和缓冲区转成指定的数据类型",{"2":{"496":1}}],["将参数和缓冲区移动到指定的设备",{"2":{"496":2}}],["将执行",{"2":{"496":1}}],["将创建并返回一个ordereddict",{"2":{"496":1}}],["将来版本中",{"2":{"496":1}}],["将所有",{"2":{"621":1}}],["将所有参数和缓冲区转换为",{"2":{"496":1}}],["将所有模型参数和缓冲区移动到",{"2":{"496":3}}],["将tensor",{"2":{"443":1}}],["将底层存储移动到共享内存",{"2":{"441":1}}],["将张量从创建它的计算图中分离",{"2":{"441":1}}],["将张量分割成多个块",{"2":{"110":1}}],["将被调用",{"2":{"441":1}}],["将数据和目标转换为tensor类型",{"2":{"567":1}}],["将数据拉回到正态分布",{"2":{"86":1}}],["将数值从0提升到",{"2":{"409":1}}],["将总批大小与用于计算批归一化统计数据的样本数量分离对于批次大小的比较特别有用",{"2":{"394":1}}],["将超参数分为三类",{"2":{"368":1}}],["将深化理解置于短期收益之上可以帮助我们",{"2":{"366":1}}],["将取决于每步的消耗如何变化",{"2":{"360":1}}],["将batch",{"2":{"359":2}}],["将优化器超参数视为冗余参数是有意义的",{"2":{"356":1}}],["将此部分梯度然后跟之前累积下来的梯度值矢量相加",{"2":{"269":1}}],["将module",{"2":{"496":2}}],["将m",{"2":{"226":1}}],["将ℓ分割为",{"2":{"226":1}}],["将output的矩阵",{"2":{"226":1}}],["将",{"2":{"225":1,"226":4,"313":1,"443":1,"508":1,"620":1,"633":1,"644":1,"647":1,"648":1}}],["将多头检查点转换为多查询检查点",{"2":{"220":1,"306":1}}],["将键值缓存",{"2":{"219":1,"305":1}}],["将查询头分成g个组",{"2":{"219":1,"305":1}}],["将softmax函数推向具有极小梯度的区域",{"2":{"206":1}}],["将一条消息发送给所有进程",{"2":{"808":1}}],["将一个tensor",{"2":{"441":1}}],["将一个tm任务转化成tm+lm两种任务",{"2":{"190":1}}],["将一种语言的文本翻译成另一种语言的文本",{"2":{"188":1}}],["将context",{"2":{"171":1}}],["将向量转换成输出序列",{"2":{"167":1}}],["将值压缩在",{"2":{"148":1}}],["将相关信息传递到整个序列链的末端",{"2":{"145":1}}],["将句子逐时间步输入到rnn中",{"2":{"142":1}}],["将错误率降低到了当时的最低水平",{"2":{"122":1}}],["将前馈网络写成矩阵形式",{"0":{"49":1}}],["将猫分离出来",{"2":{"11":1}}],["将与神经元的阀值进行比较",{"2":{"8":1}}],["将神经元抽象为数学概念上的的简单模型",{"2":{"8":1}}],["年代就已经被使用",{"2":{"345":1}}],["年即被人提出",{"2":{"126":1}}],["年",{"2":{"8":1,"21":1,"57":1,"122":2,"616":1}}],["png",{"2":{"843":1}}],["ps",{"2":{"755":1,"757":1}}],["psbashps",{"2":{"755":1}}],["pseudo",{"2":{"312":1}}],["pub",{"2":{"827":1}}],["public",{"2":{"706":1,"726":6,"730":1,"731":1,"732":1,"733":1}}],["putty",{"2":{"816":1}}],["put",{"2":{"89":1,"445":4,"730":2}}],["p117",{"2":{"695":1}}],["pvp",{"2":{"643":1}}],["pmax",{"2":{"643":2}}],["pmin",{"2":{"643":2}}],["pjwvp",{"2":{"643":1}}],["pjwkp",{"2":{"643":1}}],["pk",{"2":{"640":4,"643":1}}],["pkp",{"2":{"639":2}}],["p​1​​",{"2":{"840":1}}],["p​0​​",{"2":{"840":1}}],["p​i​​w​q​​w​k​⊤​​p​j​⊤​​",{"2":{"644":1}}],["p​ij​​v​j​​",{"2":{"226":1}}],["p​ij​​=exp",{"2":{"226":1}}],["p​v​​",{"2":{"643":1}}],["p​max​​",{"2":{"643":2}}],["p​min​​",{"2":{"643":2}}],["p​j​​w​v​​",{"2":{"643":1}}],["p​j​​w​k​​",{"2":{"643":1}}],["p​k",{"2":{"640":4}}],["p​k​​",{"2":{"639":2,"643":1}}],["people",{"2":{"613":1,"891":1}}],["person",{"2":{"624":4,"628":8}}],["persistent=false",{"2":{"493":1}}],["persistent",{"2":{"490":3,"493":1,"496":1}}],["performance",{"2":{"587":1}}],["perfetto",{"2":{"387":1}}],["per",{"0":{"504":1},"2":{"445":3,"544":3,"577":1,"590":1,"636":1}}],["permute",{"0":{"97":1,"101":1},"1":{"98":1,"99":1,"100":1,"101":1},"2":{"101":1,"117":1,"438":1,"445":2,"634":1}}],["perceptron",{"2":{"6":1,"10":1,"13":1}}],["pwd=",{"2":{"732":1}}],["pwd=86sj",{"2":{"584":1}}],["pwd",{"2":{"726":1,"730":7,"731":2,"732":1}}],["pwatermark",{"2":{"608":1}}],["plot",{"0":{"576":1,"577":1}}],["player",{"2":{"905":1}}],["playbook",{"2":{"353":1,"421":2,"422":1}}],["plain",{"2":{"721":1}}],["place操作的适用性",{"2":{"481":1}}],["place",{"0":{"481":1},"2":{"481":1,"496":2}}],["pd",{"2":{"552":1,"555":1}}],["pth",{"2":{"514":1,"515":1}}],["pt",{"2":{"497":1,"511":1,"518":1,"519":2,"525":2,"526":1,"568":2,"569":2}}],["ptr",{"2":{"430":6,"436":6,"445":1}}],["p的概率清0",{"2":{"347":1}}],["phong着色",{"2":{"857":1}}],["phase",{"2":{"544":1}}],["physical",{"2":{"335":1,"444":1,"445":2}}],["phi",{"2":{"126":3}}],["p2p",{"2":{"326":1}}],["pp",{"2":{"328":1}}],["ppt",{"2":{"285":1}}],["ppl",{"2":{"217":1,"303":1}}],["p=",{"2":{"441":1}}],["p=softmax",{"2":{"223":2,"312":2}}],["p=0",{"2":{"114":1}}],["p^",{"2":{"181":2}}],["p根据老师的提示来预测",{"2":{"179":1}}],["pid",{"2":{"757":1}}],["pid>",{"2":{"756":2}}],["piwqwk⊤pj⊤p",{"2":{"644":1}}],["pip",{"2":{"573":1,"583":1}}],["pipeline",{"0":{"329":1},"2":{"329":1,"811":1}}],["pil",{"2":{"555":3}}],["pillow",{"2":{"552":1}}],["pieces",{"2":{"499":1}}],["pickle",{"2":{"496":2,"509":2}}],["picklable",{"2":{"496":1}}],["pingbashping",{"2":{"759":1}}],["pinverse",{"2":{"445":1}}],["pin",{"2":{"445":9,"497":1}}],["pinned",{"2":{"445":1}}],["pivots",{"2":{"445":1}}],["pivot=true",{"2":{"441":1}}],["pijvjp",{"2":{"226":1}}],["pij=exp",{"2":{"226":1}}],["pi",{"2":{"126":1,"545":1,"546":1}}],["pitts",{"2":{"8":1}}],["portion",{"2":{"827":3}}],["pojo",{"2":{"726":2,"730":3,"731":1,"732":1}}],["popularity",{"2":{"899":1}}],["popular",{"2":{"582":1,"891":1,"896":1}}],["pope等人",{"2":{"219":1,"305":1}}],["polar",{"2":{"649":1}}],["policy",{"2":{"509":1}}],["polynomiallr",{"0":{"542":1},"2":{"542":1}}],["polygamma",{"2":{"445":2}}],["polyak",{"2":{"263":1}}],["possible",{"2":{"633":6,"634":2}}],["positioned",{"2":{"905":1}}],["positional",{"2":{"500":4,"590":1}}],["positions",{"2":{"499":2,"634":1}}],["position",{"0":{"638":1},"1":{"639":1,"640":1,"641":1,"642":1,"643":1,"644":1,"645":1,"646":1,"647":1,"648":1,"649":1},"2":{"499":2,"634":1,"643":1,"645":3}}],["positive",{"2":{"441":1,"445":1}}],["posinf",{"2":{"445":2}}],["pos",{"2":{"441":1}}],["postgresql",{"2":{"709":1}}],["post",{"2":{"409":2,"441":1,"490":2,"496":1,"508":3,"509":3}}],["power=1",{"2":{"542":1}}],["powerlr",{"2":{"542":1}}],["power",{"2":{"445":5,"542":1}}],["pow",{"2":{"441":3,"443":1,"445":4,"452":1,"459":1,"472":2}}],["points",{"2":{"445":1}}],["pointer",{"2":{"436":2}}],["point",{"2":{"381":1,"445":2}}],["pointwise",{"0":{"108":1},"2":{"120":1,"226":3,"439":1}}],["pooled",{"2":{"726":1}}],["pool2d",{"2":{"497":1,"513":1}}],["pool",{"2":{"93":2,"94":2,"338":1,"497":2}}],["pooling",{"0":{"92":1,"93":1,"95":1},"1":{"93":1,"94":1,"95":1},"2":{"51":1,"92":1,"95":1}}],["package",{"2":{"770":2}}],["packages",{"2":{"436":1}}],["pan",{"2":{"584":1}}],["pandas",{"2":{"555":1}}],["pattern",{"2":{"749":3}}],["patience",{"2":{"547":1}}],["path",{"2":{"529":4,"552":4,"585":1,"590":4,"634":1,"636":1,"822":2,"857":1}}],["patch",{"2":{"509":3}}],["patches",{"2":{"490":1}}],["padded",{"2":{"445":1}}],["padding=3",{"2":{"580":1}}],["padding=1",{"2":{"81":2}}],["padding=",{"2":{"80":2,"81":1}}],["padding",{"0":{"215":1},"2":{"55":1,"80":2,"81":1,"113":5,"214":1,"215":1,"216":1,"444":1,"445":1}}],["pad",{"2":{"444":1,"634":4}}],["paging",{"2":{"333":1}}],["paged",{"2":{"338":1}}],["pagedattention是vllm的核心技术",{"2":{"335":1}}],["pagedattention跟踪物理块的引用计数并实现写时复制机制",{"2":{"335":1}}],["pagedattention中的不同序列可以通过将它们的逻辑块映射到相同的物理块来共享块",{"2":{"335":1}}],["pagedattention通过其block",{"2":{"335":1}}],["pagedattention还有另一个关键优势",{"2":{"335":1}}],["pagedattention内核能够高效地识别和获取这些块",{"2":{"333":1}}],["pagedattention将每个序列的kv",{"2":{"333":1}}],["pagedattention允许在非连续的内存空间中存储连续的key和value",{"2":{"333":1}}],["pagedattention",{"0":{"333":1},"2":{"231":1,"331":1,"333":1,"334":1}}],["pageattention的内存共享大大减少了复杂采样算法",{"2":{"335":1}}],["pages",{"2":{"335":1}}],["page",{"0":{"231":1,"331":1},"1":{"332":1,"333":1,"334":1,"335":1},"2":{"231":1,"331":1}}],["passing",{"2":{"806":1}}],["passwd",{"2":{"763":1}}],["password",{"2":{"726":1,"888":2,"889":2}}],["passed",{"2":{"556":1}}],["pass",{"0":{"322":1,"323":1},"2":{"497":1,"904":3}}],["paper说学习率衰减计划也能转移",{"2":{"384":1}}],["paper",{"2":{"232":1,"339":1,"614":2}}],["parse",{"2":{"497":1}}],["parser",{"2":{"497":13}}],["particularly",{"2":{"905":1}}],["partitioned",{"2":{"333":1}}],["partitioning",{"0":{"320":1},"1":{"321":1,"322":1,"323":1,"324":1},"2":{"229":1}}],["partial",{"2":{"28":2,"44":10,"45":8,"46":38,"47":2,"244":4}}],["para",{"2":{"514":2,"515":2}}],["parallelism",{"0":{"320":1,"329":1},"1":{"321":1,"322":1,"323":1,"324":1},"2":{"229":1,"329":2}}],["parallel",{"0":{"328":1,"329":1,"587":1},"1":{"588":1,"589":1},"2":{"190":1,"326":1,"327":1,"328":3,"335":1,"496":1,"590":3,"797":1}}],["param参数",{"2":{"733":1}}],["param中设置的值即可",{"2":{"730":1}}],["param属性",{"2":{"730":1}}],["params的可迭代对象转换为",{"2":{"508":1}}],["params",{"2":{"484":2,"496":1,"504":3,"506":1,"507":1,"508":4,"509":2,"556":1}}],["parametric",{"2":{"124":1}}],["parametertype=",{"2":{"730":1,"731":1,"732":1,"733":1}}],["parametertype",{"2":{"730":1}}],["parameter参数",{"2":{"508":1}}],["parameters",{"0":{"233":1,"492":1},"2":{"86":2,"88":2,"233":1,"274":1,"484":2,"487":6,"490":2,"492":1,"496":5,"497":3,"500":1,"503":1,"504":2,"522":1,"523":1,"533":2,"541":1,"543":1,"544":1,"545":1,"547":1,"556":1,"568":1,"904":3}}],["parameter",{"0":{"485":1,"504":1},"2":{"27":1,"54":1,"475":1,"490":1,"492":1,"496":7,"500":1,"503":1,"504":1,"508":1}}],["param",{"2":{"86":6,"496":1,"508":11,"509":9,"515":2,"545":1,"730":2}}],["py的api还有一个create",{"2":{"889":1}}],["py内容",{"2":{"889":1}}],["py和数据分析",{"2":{"873":1}}],["pyi",{"2":{"436":1}}],["py∣x",{"2":{"190":1}}],["py∣xp",{"2":{"190":1}}],["pytroch",{"2":{"431":1,"436":1}}],["pytorch代码编译成优化内核",{"2":{"565":1}}],["pytorch会生成一个独立的可运行脚本",{"2":{"563":1}}],["pytorch会进行类型推断",{"2":{"563":1}}],["pytorch会对模型函数进行静态分析",{"2":{"563":1}}],["pytorch会执行以下步骤来进行捕获",{"2":{"563":1}}],["pytorch在保存时对张量进行了打包",{"2":{"472":1}}],["pytorch有一个内置的微分引擎",{"2":{"463":1}}],["pytorch中就是通过",{"2":{"468":1}}],["pytorch中",{"0":{"532":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1},"2":{"462":1}}],["pytorch中有三个相似的矩阵操作",{"2":{"84":1}}],["pytorch实现",{"0":{"300":1}}],["pytorch",{"0":{"67":1,"68":1,"70":1,"71":1,"272":1,"281":1,"285":1,"289":1,"296":1,"446":1,"449":1,"450":1,"456":1,"470":1,"483":1,"557":1,"558":1,"582":1,"890":1,"891":1,"892":1,"898":1,"902":1},"1":{"69":1,"70":1,"273":1,"274":1,"447":1,"448":1,"450":1,"451":1,"452":1,"453":1,"454":1,"455":1,"456":1,"457":1,"458":1,"459":1,"460":1,"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1,"484":1,"485":1,"558":1,"559":1,"560":1,"891":1,"892":1,"893":2,"894":2,"895":2,"896":2,"897":2,"898":1,"899":2,"900":2,"901":2,"902":1,"903":2,"904":2,"905":1},"2":{"69":1,"80":1,"81":1,"83":1,"86":1,"87":1,"88":1,"89":1,"93":1,"94":1,"95":1,"98":1,"99":1,"100":1,"101":1,"104":1,"106":1,"107":1,"108":1,"110":1,"113":1,"114":1,"115":1,"121":2,"122":1,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"215":1,"285":1,"289":1,"296":1,"300":1,"431":2,"436":3,"440":2,"446":3,"447":2,"448":1,"456":1,"462":1,"463":1,"470":1,"472":3,"476":1,"479":1,"483":1,"497":1,"532":1,"535":1,"536":2,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"551":1,"556":2,"572":2,"583":2,"590":2,"636":1,"671":10,"868":1,"891":2,"893":1,"894":1,"895":1,"896":1,"897":3,"899":1,"900":1,"901":1,"903":1,"904":1,"905":2}}],["pythong",{"2":{"958":1}}],["pythongard",{"2":{"457":1}}],["pythonpath=",{"2":{"613":1,"636":1}}],["pythondata",{"2":{"544":1}}],["pythondef",{"2":{"87":1,"88":1,"89":1,"215":1,"433":1,"434":1,"436":1,"441":1,"443":1,"445":1,"450":1,"453":1,"454":1,"455":1,"456":1,"460":1,"484":1,"489":1,"511":1,"514":1,"515":1,"519":1,"522":1,"523":1,"525":1,"526":1,"529":1,"530":1,"568":1,"569":1,"570":1,"576":1,"579":1,"580":1,"595":1,"633":1,"634":1,"635":1,"957":1}}],["pythonlmbda",{"2":{"536":1}}],["pythonscheduler",{"2":{"533":1,"546":2}}],["pythonself",{"2":{"508":1}}],["pythonoptim",{"2":{"504":1}}],["pythonoptimizer",{"2":{"503":1,"533":2,"543":1,"547":1}}],["pythonfrom",{"2":{"497":1,"513":1,"553":1,"555":1}}],["pythonfor",{"2":{"457":1,"505":2}}],["pythonclass",{"2":{"487":2,"552":1}}],["python3",{"2":{"436":1,"613":1}}],["pythonm",{"2":{"114":1,"121":1,"122":1,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1}}],["pythont",{"2":{"107":1}}],["pythonx",{"2":{"99":1,"100":1,"101":1,"104":1,"106":1,"451":1,"472":2,"474":1}}],["pythona",{"2":{"98":1,"105":1,"108":1,"110":1,"112":5}}],["pythoninp",{"2":{"459":1}}],["pythoninput",{"2":{"89":1}}],["pythonimport",{"2":{"80":1,"81":1,"83":1,"84":1,"86":1,"87":1,"93":1,"94":1,"95":1,"111":1,"121":1,"274":1,"427":1,"428":1,"429":1,"440":1,"444":1,"452":1,"493":1,"494":1,"495":1,"498":1,"499":1,"500":1,"528":1,"541":1,"545":1,"575":1,"799":1,"904":1}}],["pythonnvidia",{"2":{"71":1}}],["python",{"0":{"896":1,"957":1},"2":{"26":1,"50":1,"86":1,"88":1,"113":1,"328":1,"427":1,"430":1,"440":2,"441":1,"444":2,"458":1,"471":1,"472":1,"474":1,"476":1,"490":1,"492":1,"496":1,"509":1,"535":1,"537":1,"538":1,"539":1,"540":1,"542":1,"548":1,"549":1,"552":1,"556":1,"567":1,"571":1,"577":1,"578":1,"581":1,"613":2,"632":1,"636":1,"649":1,"799":1,"888":2,"889":3,"896":1,"901":1}}],["py",{"2":{"50":1,"585":3,"586":2,"588":1,"589":2,"590":1,"613":3,"636":1,"868":1,"887":1,"888":2,"889":3}}],["practice",{"2":{"556":1}}],["present",{"2":{"856":1}}],["prev",{"2":{"789":1}}],["precompute",{"2":{"649":2}}],["precision2",{"2":{"635":2}}],["precision",{"0":{"325":1},"2":{"444":1,"635":2}}],["preprocessing",{"2":{"556":1}}],["prepend",{"2":{"445":1,"496":4,"509":4}}],["pred",{"2":{"497":3,"635":3}}],["prediction",{"2":{"608":1,"619":1}}],["predicted",{"2":{"567":2}}],["predict",{"2":{"176":1,"635":1}}],["prefix=",{"2":{"496":2}}],["prefix和keep",{"2":{"496":1}}],["prefix",{"2":{"496":8}}],["prefill",{"2":{"329":1}}],["prefetch",{"2":{"387":1}}],["pre",{"2":{"220":1,"306":1,"490":11,"496":6,"508":3,"509":3,"590":1,"605":1,"897":3}}],["prelu",{"2":{"120":2,"124":3,"445":1}}],["pretrained=false",{"2":{"579":1}}],["pretrained",{"2":{"113":2,"590":2,"616":1}}],["providing",{"2":{"897":1}}],["provides",{"2":{"587":1,"897":1}}],["projects",{"2":{"889":1,"897":1}}],["projection",{"2":{"444":1}}],["programming",{"2":{"896":1}}],["program",{"2":{"822":6}}],["prometheus",{"2":{"716":1}}],["promote",{"2":{"605":1}}],["prompt",{"2":{"335":1,"620":1}}],["prof",{"2":{"581":4}}],["profile",{"2":{"509":3,"581":2}}],["profileractivity",{"2":{"581":2}}],["profiler的入口点",{"2":{"509":1}}],["profiler",{"2":{"387":1,"581":9}}],["probable",{"2":{"634":1}}],["probability",{"2":{"497":1}}],["problem",{"2":{"122":1}}],["produces",{"2":{"634":1}}],["production",{"2":{"383":1}}],["product形式",{"2":{"211":1}}],["product",{"0":{"198":1},"1":{"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":1,"206":1},"2":{"203":2,"206":1,"215":1,"498":1,"500":1}}],["prod",{"2":{"445":3,"595":14}}],["properties",{"2":{"727":2}}],["property",{"2":{"441":1,"726":4}}],["propagation",{"0":{"42":1},"1":{"43":1,"44":1,"45":1,"46":1},"2":{"24":2,"28":1,"282":1,"671":1}}],["proto",{"2":{"441":2}}],["processor",{"2":{"496":1}}],["processes",{"2":{"335":1,"590":1}}],["process",{"2":{"334":1,"335":1,"509":1,"529":1,"827":1,"895":1}}],["processing",{"0":{"587":1},"1":{"588":1,"589":1},"2":{"74":2,"496":1,"587":1,"590":1,"897":2}}],["pros",{"2":{"302":1}}],["private",{"2":{"726":4}}],["primary",{"2":{"726":1}}],["prime",{"2":{"45":1,"244":3,"249":1}}],["priority",{"2":{"441":1}}],["printed",{"2":{"904":1}}],["printing",{"2":{"904":1}}],["printf",{"2":{"823":1,"827":2}}],["printstacktrace",{"2":{"726":1}}],["println",{"2":{"706":1,"726":1,"730":1,"731":1,"732":1,"733":1}}],["print",{"2":{"26":3,"50":8,"83":1,"111":3,"427":1,"428":2,"429":1,"430":6,"436":14,"440":1,"450":1,"451":2,"452":1,"453":3,"454":4,"456":6,"459":3,"460":1,"472":4,"484":1,"487":4,"489":1,"493":2,"494":5,"495":5,"497":3,"498":2,"500":2,"511":2,"513":1,"515":1,"519":1,"523":1,"526":2,"529":1,"530":1,"541":1,"545":1,"553":1,"555":1,"556":1,"567":1,"568":1,"569":1,"570":1,"571":1,"580":2,"581":1,"590":2,"799":6,"904":2,"958":1}}],["p神经元",{"2":{"10":1}}],["p",{"0":{"8":1},"2":{"8":1,"126":1,"181":17,"185":2,"190":30,"215":5,"223":4,"226":2,"228":1,"248":1,"312":4,"318":1,"445":9,"509":2,"581":2,"590":2,"606":9,"626":9,"639":1,"640":3,"643":5,"644":3,"659":17,"753":1,"782":2,"840":2}}],["神经机器翻译",{"2":{"189":1}}],["神经元输出",{"2":{"245":1}}],["神经元处于饱和状态",{"2":{"240":1}}],["神经元坏死问题",{"2":{"130":1}}],["神经元坏死",{"2":{"124":1}}],["神经元坏死现象",{"2":{"122":1}}],["神经元只对输入信号的少部分选择性响应",{"2":{"123":1}}],["神经元之间不存在同层连接",{"2":{"13":1}}],["神经元接收到的总输入值",{"2":{"8":1}}],["神经元接收到来自",{"2":{"8":1}}],["神经元",{"0":{"8":1},"2":{"10":1}}],["神经元模型",{"0":{"7":1},"1":{"8":1,"9":1},"2":{"8":1}}],["神经网络研究员早就意识到学习率肯定是难以设置的超参数之一",{"2":{"276":1}}],["神经网络需要用数据来训练",{"2":{"254":1}}],["神经网络模型一般依靠随机梯度下降进行模型训练和参数更新",{"2":{"235":1}}],["神经网络案例展示",{"0":{"37":1}}],["神经网络训练流程概述",{"0":{"24":1}}],["神经网络通过将线性分类器进行组合叠加",{"2":{"14":1}}],["神经网络通常是通过一个基于数学统计学类型的学习方法",{"2":{"5":1}}],["神经网络由大量的人工神经元联结进行计算",{"2":{"5":1}}],["mpiexec",{"2":{"822":1}}],["mpirun",{"2":{"822":2,"827":1}}],["mpif90",{"2":{"822":1}}],["mpi环境",{"0":{"818":1},"1":{"819":1,"820":1,"821":1,"822":1}}],["mpi还允许用户定义结构化数据类型",{"2":{"809":1}}],["mpi支持多种基础数据类型",{"2":{"809":1}}],["mpi支持两种基本的通信模式",{"2":{"807":1}}],["mpi传递消息时需要明确数据类型和标签",{"2":{"809":1}}],["mpi标准中包含了一系列函数",{"2":{"808":1}}],["mpi提供多种集体通信模式",{"2":{"806":1}}],["mpi使用消息传递",{"2":{"806":1}}],["mpi使用这个id来标识进程并确定数据传输的目标",{"2":{"806":1}}],["mpi使用分布式内存模型",{"2":{"805":1}}],["mpi程序通常启动多个进程",{"2":{"806":1}}],["mpi适用于需要跨多个节点运行的任务",{"2":{"805":1}}],["mpi的优势和劣势",{"0":{"812":1}}],["mpi的数据类型和消息标签",{"0":{"809":1}}],["mpi的基本使用",{"0":{"823":1},"1":{"824":1,"825":1,"826":1,"827":1}}],["mpi的基本函数",{"0":{"808":1}}],["mpi的基本原理",{"0":{"803":1},"1":{"804":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"813":1}}],["mpi的通信模式",{"0":{"807":1}}],["mpi的架构",{"0":{"805":1}}],["mpi中的常见通信模式",{"0":{"811":1}}],["mpi中的默认通信域是mpi",{"2":{"810":1}}],["mpi中",{"2":{"802":1}}],["mpi是一个标准化的接口",{"2":{"802":1}}],["mpi实现",{"2":{"799":1}}],["mpic++",{"2":{"822":1}}],["mpich",{"2":{"794":1,"802":1,"818":1,"822":2}}],["mpicc",{"2":{"766":1,"822":3}}],["mpi",{"2":{"794":2,"801":1,"802":6,"806":4,"808":11,"809":1,"822":24,"823":15,"827":19}}],["mpi并行计算",{"0":{"794":1},"1":{"795":1,"796":1,"797":1,"798":1,"799":1,"800":1,"801":1,"802":1,"803":1,"804":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"813":1,"814":1,"815":1,"816":1,"817":1,"818":1,"819":1,"820":1,"821":1,"822":1,"823":1,"824":1,"825":1,"826":1,"827":1,"828":1,"829":1,"830":1,"831":1},"2":{"832":1,"868":1}}],["mps",{"2":{"445":1,"497":6}}],["mkdir",{"2":{"742":2}}],["mkldnn",{"2":{"445":2}}],["md文件更新",{"2":{"868":1}}],["mdr",{"2":{"648":1}}],["mdwqxm",{"2":{"647":1}}],["mdwq",{"2":{"647":1}}],["m−n",{"2":{"646":4}}],["m2m",{"2":{"621":2}}],["myid",{"2":{"823":3}}],["mydir",{"2":{"768":1}}],["mydataset",{"2":{"552":1,"567":1,"568":1}}],["mytest",{"2":{"726":1}}],["mybatis笔记",{"2":{"868":1}}],["mybatisutils",{"2":{"726":2,"730":1,"731":1,"732":1,"733":1}}],["mybatis第一个程序",{"0":{"725":1},"1":{"726":1,"727":1}}],["mybatis不会对应用程序或者数据库的现有设计强加任何影响",{"2":{"724":1}}],["mybatis的优点",{"2":{"724":1}}],["mybatis就是帮助程序猿将数据存入数据库中",{"2":{"724":1}}],["mybatis官方文档",{"2":{"721":1}}],["mybatis简介",{"0":{"720":1},"1":{"721":1,"722":1,"723":1,"724":1}}],["mybatis框架",{"0":{"719":1},"1":{"720":1,"721":1,"722":1,"723":1,"724":1,"725":1,"726":1,"727":1,"728":1,"729":1,"730":1,"731":1,"732":1,"733":1,"734":1}}],["mybatis",{"0":{"711":1},"2":{"718":1,"721":8,"724":1,"726":9}}],["mysql",{"2":{"709":1,"719":2,"726":2}}],["mysql基础",{"2":{"709":1}}],["my",{"2":{"556":1,"742":5,"822":6}}],["mymodel",{"2":{"495":3,"567":2,"568":1,"569":1,"570":1}}],["mymodule",{"2":{"493":2,"494":2}}],["much",{"2":{"897":1}}],["mu",{"2":{"606":6}}],["must",{"2":{"498":1,"500":1}}],["mult",{"2":{"546":2}}],["multiprocessing",{"2":{"588":1,"589":2,"590":2}}],["multiplicativelr",{"0":{"536":1},"2":{"536":1}}],["multiply",{"2":{"445":4,"499":1}}],["multiple",{"0":{"588":1,"589":1},"2":{"335":1,"498":1,"500":1}}],["multisteplr",{"0":{"538":1},"2":{"533":1,"538":1}}],["multinomial",{"2":{"445":1}}],["multiheadattention",{"2":{"498":3,"499":3,"500":5}}],["multihead",{"2":{"209":2}}],["multi",{"0":{"207":1,"212":1,"213":1,"214":1,"217":1,"303":1,"307":1,"587":1},"1":{"208":1,"209":1,"210":1,"211":1,"215":1,"216":1,"308":1,"309":1,"588":1,"589":1},"2":{"13":1,"210":1,"217":2,"220":2,"303":2,"306":2,"337":1,"587":1,"590":2}}],["multilayer",{"2":{"6":1,"13":2}}],["mul",{"2":{"108":1,"443":1,"445":2,"455":1,"457":1}}],["mvapich",{"2":{"802":1}}],["mvc",{"0":{"713":1}}],["mvlgamma",{"2":{"445":2}}],["mv",{"2":{"445":1,"743":2}}],["msc并回车进入到",{"2":{"913":1}}],["ms",{"2":{"802":1}}],["msgs",{"2":{"496":1}}],["msort",{"2":{"445":1}}],["mseloss",{"2":{"44":1,"484":1,"487":1}}],["mh",{"2":{"440":1}}],["mha",{"2":{"217":2,"303":2,"308":1}}],["m0=0",{"2":{"418":1,"419":1}}],["m0=0v",{"2":{"417":1}}],["mfu",{"2":{"329":1}}],["m^",{"2":{"322":1,"323":1}}],["mlm",{"2":{"619":6,"621":1}}],["mla仅需缓存",{"2":{"309":1}}],["mla的性能优于mha",{"2":{"308":1}}],["mla",{"0":{"307":1,"308":1,"309":1},"1":{"308":1,"309":1},"2":{"308":1}}],["mlperf1",{"2":{"227":1,"317":1}}],["mlp中的神经网络层相对应",{"2":{"117":1}}],["mlp",{"0":{"460":1},"2":{"6":1,"13":1,"239":1,"328":1}}],["m​d​​",{"2":{"648":1}}],["m​d​​w​q​​x​m​​",{"2":{"647":1}}],["m​d​​w​q",{"2":{"647":1}}],["m​t+1​​=β​1​​m​t​​+",{"2":{"418":1,"419":1}}],["m​t+1​​=γm​t​​+​√​v​t+1​​+ϵ​​​​​η​t​​​​∇l",{"2":{"417":1}}],["m​t​r​​​​",{"2":{"226":1}}],["m​0​​=0",{"2":{"417":1,"418":1,"419":1}}],["m​i​​l​i​​",{"2":{"319":1}}],["m​ij​​=rowmax",{"2":{"226":1}}],["m​1​​",{"2":{"226":1}}],["m1",{"2":{"226":1}}],["m4d",{"2":{"226":1}}],["mqa",{"0":{"217":1,"303":1},"2":{"217":6,"220":2,"303":6,"306":2,"308":1,"323":1,"328":1}}],["mtn",{"2":{"580":1}}],["mt+1=β1mt+",{"2":{"418":1,"419":1}}],["mt+1=γmt+ηtvt+1+ϵ∇l",{"2":{"417":1}}],["mtrm",{"2":{"226":1}}],["mt",{"2":{"188":1,"440":1}}],["m≠n时",{"2":{"165":1}}],["migrate",{"2":{"889":1}}],["microsoft",{"2":{"802":1}}],["milestones",{"2":{"538":1}}],["milestones=",{"2":{"533":1,"538":1,"549":1}}],["milim",{"2":{"319":1}}],["mistakes",{"2":{"893":1}}],["missing",{"2":{"496":1}}],["misc",{"2":{"421":1}}],["mish函数在曲线上几乎所有点上的平滑度都很高",{"2":{"128":1}}],["mish",{"0":{"128":1},"2":{"120":1,"128":6}}],["mixup就是将两张图像进行mix操作",{"2":{"344":1}}],["mij=rowmax",{"2":{"226":1}}],["middle",{"2":{"457":1}}],["mid",{"2":{"185":2,"190":7,"457":1,"626":2,"659":6}}],["minus",{"2":{"595":7}}],["min=min",{"2":{"545":1}}],["minlength",{"2":{"445":1}}],["minist",{"2":{"497":1}}],["minimum",{"2":{"445":1}}],["mini",{"0":{"262":1},"2":{"262":7,"590":1}}],["min",{"2":{"112":2,"226":1,"445":23,"545":3,"546":2,"547":1,"643":2}}],["moe",{"0":{"668":1}}],["mobilenet",{"2":{"590":3}}],["most",{"2":{"556":1,"634":1}}],["mosaic",{"2":{"344":1}}],["move",{"2":{"584":1}}],["movedim",{"2":{"445":2}}],["moveaxis",{"2":{"445":2}}],["moves",{"2":{"441":1}}],["mohammad",{"2":{"420":1}}],["mooncake",{"2":{"329":2}}],["moments",{"2":{"294":1}}],["momentum=0",{"2":{"274":1,"487":1,"497":1,"503":1,"504":1,"533":2,"543":1,"544":1,"547":1}}],["momentum",{"0":{"263":1,"415":1},"1":{"264":1,"265":1,"266":1,"267":1},"2":{"86":4,"269":1,"270":1,"271":1,"356":1,"369":5,"370":3,"406":1,"590":3}}],["modified",{"2":{"509":2}}],["modle",{"2":{"488":1}}],["mode=",{"2":{"634":1}}],["mode",{"0":{"477":1,"479":1},"2":{"445":11,"476":2,"479":1,"496":2,"571":1,"671":1}}],["modelargs",{"2":{"649":1}}],["model的实例化",{"2":{"487":1}}],["models",{"0":{"661":1},"2":{"444":1,"528":1,"579":3,"580":1,"585":1,"891":1,"895":1,"896":1,"897":2,"899":1}}],["model",{"0":{"194":1,"460":1,"662":1},"2":{"208":1,"209":4,"274":4,"480":5,"487":13,"490":1,"495":3,"497":17,"498":29,"500":42,"503":1,"504":4,"505":2,"511":3,"514":2,"515":3,"518":3,"519":3,"522":4,"523":6,"525":7,"526":3,"528":3,"529":6,"530":4,"533":4,"541":3,"543":1,"544":1,"545":1,"547":1,"567":2,"568":11,"569":9,"570":4,"571":8,"580":6,"582":1,"585":2,"590":3,"616":1,"635":1,"636":1,"671":2,"893":1,"894":1,"904":6}}],["modeling",{"2":{"176":1,"188":1,"616":2,"619":2}}],["mod",{"2":{"443":1}}],["module环境问题",{"2":{"873":1}}],["modulelist",{"2":{"498":1,"499":1,"500":2}}],["module=false",{"2":{"496":1}}],["modules",{"2":{"489":2,"490":1,"492":1,"496":2}}],["moduledemo",{"2":{"487":3}}],["module",{"0":{"480":1,"482":1,"489":1,"490":1,"491":1,"496":1},"1":{"492":1,"493":1,"494":1,"495":1,"496":1},"2":{"87":1,"89":1,"113":1,"441":1,"474":1,"475":2,"480":2,"487":3,"488":1,"490":1,"492":2,"493":7,"494":7,"495":4,"496":24,"497":3,"498":4,"499":3,"500":5,"513":1,"567":1,"649":1,"671":1,"904":1}}],["monotonic",{"2":{"120":1}}],["messages",{"2":{"772":1}}],["message",{"2":{"590":1,"806":1}}],["member的api",{"2":{"889":1}}],["member",{"2":{"889":3}}],["members",{"2":{"496":2}}],["memo",{"2":{"441":1,"496":1}}],["memory的次数",{"2":{"324":1}}],["memory",{"0":{"144":1},"1":{"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1},"2":{"99":1,"144":1,"319":1,"322":1,"326":1,"333":2,"441":2,"445":21,"496":1,"497":1}}],["median",{"2":{"445":6}}],["met",{"2":{"436":1}}],["metavar=",{"2":{"497":7}}],["metadata还可以包含assign",{"2":{"496":1}}],["metadata为空",{"2":{"496":1}}],["metadata参数",{"2":{"496":1}}],["metadata",{"2":{"496":3}}],["metaclass",{"2":{"440":2}}],["metaclass=",{"2":{"440":1}}],["meta",{"2":{"436":6,"445":1}}],["methods",{"2":{"281":1,"302":1}}],["method",{"2":{"5":1,"289":1,"294":1,"440":1,"458":1,"556":2}}],["mechanics",{"2":{"302":1,"446":1}}],["meaning",{"2":{"893":1}}],["means",{"2":{"106":1}}],["mean",{"2":{"86":10,"87":4,"88":3,"89":3,"91":2,"112":3,"282":2,"445":5,"493":20}}],["mm",{"2":{"84":1,"445":1,"460":1,"526":2}}],["mm是用于两个二维矩阵乘法的函数",{"2":{"84":1}}],["making",{"2":{"891":1,"895":1,"905":1}}],["makes",{"2":{"893":1,"894":1}}],["makemigrations",{"2":{"889":1}}],["makemessages",{"2":{"889":1}}],["make",{"2":{"444":1,"580":2,"595":1,"897":1}}],["master",{"2":{"811":1}}],["masking",{"2":{"322":1}}],["mask步骤",{"2":{"215":1}}],["masked",{"2":{"215":1,"444":1,"445":8,"498":1,"499":1,"500":1,"616":2,"619":1}}],["mask=none",{"2":{"215":1,"498":3,"500":6}}],["mask",{"0":{"214":1,"215":1,"216":1},"1":{"215":1,"216":1},"2":{"214":4,"215":3,"216":2,"316":1,"444":3,"445":9,"498":6,"499":7,"500":8,"632":9,"633":4,"634":11,"635":2}}],["maven静态资源过滤问题",{"2":{"727":1}}],["maven",{"2":{"719":2}}],["made",{"2":{"556":1}}],["mac为子",{"2":{"827":1}}],["mac",{"2":{"815":1,"827":3}}],["mac安装虚拟机linux系统",{"2":{"815":1}}],["macos系统略有区别",{"2":{"909":1}}],["macos安装配置openmpi",{"2":{"827":1}}],["macos",{"2":{"497":1,"827":5}}],["machine",{"2":{"188":1,"189":2,"302":1,"705":1,"897":1}}],["maybe",{"2":{"496":1}}],["manage",{"2":{"887":1,"888":2,"889":2}}],["manually",{"2":{"894":1}}],["manual",{"2":{"456":3,"487":1,"497":1,"590":1}}],["many",{"2":{"227":1,"317":1,"497":1,"897":1}}],["mariet",{"2":{"420":1}}],["max=total",{"2":{"545":1}}],["maxnorm",{"2":{"445":2}}],["maximum",{"2":{"445":1,"634":1}}],["maxpool2d",{"2":{"93":2}}],["max",{"0":{"93":1,"382":1},"2":{"112":2,"123":3,"225":1,"313":1,"323":1,"381":1,"382":1,"385":1,"445":23,"497":2,"499":2,"500":7,"513":1,"542":1,"543":1,"544":1,"545":2,"546":1,"567":1,"605":1,"636":1,"643":2,"649":1}}],["map的",{"2":{"730":1}}],["mapper>",{"2":{"726":1}}],["mapper",{"2":{"726":8,"730":3,"731":2,"732":3,"733":2,"734":2}}],["mappers>",{"2":{"726":2}}],["mapping",{"2":{"496":1,"724":1}}],["map2",{"2":{"445":1}}],["map",{"2":{"52":1,"55":1,"441":2,"445":1,"511":1,"519":1,"730":7}}],["matched",{"2":{"556":2}}],["matches",{"2":{"444":1}}],["matmal",{"2":{"445":1}}],["matmul等算子如何设置weight和act",{"2":{"465":1}}],["matmul是通用的矩阵乘法函数",{"2":{"84":1}}],["matmul",{"0":{"84":1},"2":{"50":2,"84":1,"117":1,"215":2,"443":1,"444":1,"445":2,"450":1,"453":2,"454":1,"456":3,"457":1,"460":1,"467":1,"498":2,"500":2,"649":2}}],["mathcal",{"2":{"414":1,"415":1,"416":2,"417":2,"418":2,"419":3}}],["mathbf",{"2":{"223":6,"312":6,"605":4}}],["mathbb",{"2":{"209":4,"223":3,"312":3}}],["math",{"2":{"215":1,"649":1,"894":1}}],["mathrm",{"2":{"122":1}}],["mat2",{"2":{"84":4,"444":2,"445":4}}],["mat1",{"2":{"84":2,"444":2,"445":1}}],["matrix",{"2":{"50":2,"205":1,"440":1,"445":2,"499":1}}],["main",{"2":{"26":1,"50":1,"444":1,"497":3,"498":1,"500":1,"578":1,"585":3,"586":2,"588":1,"589":2,"590":1,"613":1,"706":1,"727":2,"823":1,"827":1}}],["mnasnet1",{"2":{"590":2}}],["mnasnet0",{"2":{"590":2}}],["mnist",{"2":{"497":5,"511":1,"514":1,"515":1,"518":1,"519":2,"522":1,"525":1,"555":1,"580":2}}],["mn",{"2":{"29":1}}],["mcculloch",{"2":{"8":1}}],["m",{"0":{"8":1,"165":1},"2":{"8":1,"50":2,"80":4,"81":3,"83":4,"86":3,"88":3,"89":4,"93":3,"94":3,"95":7,"114":1,"121":3,"122":4,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"165":1,"194":1,"225":22,"226":10,"227":1,"313":22,"315":1,"317":1,"322":1,"417":4,"418":3,"419":3,"497":1,"578":1,"590":2,"646":11,"647":11,"648":1}}],["5再取整",{"2":{"841":1}}],["5plus数据集上采用cfg以512x512尺寸训练595",{"2":{"608":1}}],["5plus数据集上采用cfg以512x512尺寸训练225",{"2":{"608":1}}],["5plus数据集上继续以512x512尺寸训练195",{"2":{"608":1}}],["5plus数据集上laion2b",{"2":{"608":1}}],["5plus数据集上以512x512尺寸训练515",{"2":{"608":1}}],["59049",{"2":{"548":1}}],["5905",{"2":{"112":1}}],["5bit",{"2":{"433":1}}],["5倍",{"2":{"332":1}}],["5us",{"2":{"217":1,"303":1}}],["512",{"2":{"196":1,"227":1,"317":1,"489":4,"621":1,"645":2}}],["511881",{"2":{"48":3}}],["5745",{"2":{"112":1}}],["5x7",{"2":{"95":1}}],["50的特定配置",{"2":{"376":1}}],["5080",{"2":{"112":1}}],["5027",{"2":{"112":1}}],["50",{"2":{"80":1,"81":1,"93":1,"94":1,"376":1,"403":1,"410":1,"444":1,"939":1}}],["50182",{"2":{"48":3}}],["5y",{"2":{"50":1}}],["5596",{"2":{"112":1}}],["55",{"2":{"50":1,"460":1}}],["557448",{"2":{"47":3}}],["553629",{"2":{"47":3}}],["5∗0",{"2":{"47":2}}],["5×0",{"2":{"41":2}}],["5",{"0":{"6":1,"16":1,"29":1,"35":1,"48":1,"55":1,"76":1,"77":1,"78":1,"90":1,"96":1,"125":1,"139":1,"143":1,"151":1,"181":1,"207":1,"208":1,"209":1,"210":1,"211":1,"226":1,"242":1,"243":1,"244":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":2,"281":1,"315":1,"320":1,"321":1,"322":1,"323":1,"324":1,"347":1,"439":1,"454":1,"466":1,"475":1,"491":1,"492":1,"493":1,"494":1,"495":1,"524":1,"525":1,"526":1,"539":1,"571":1,"579":1,"598":1,"604":1,"605":1,"606":1,"620":1,"630":1,"631":1,"632":1,"633":1,"634":1,"635":1,"656":1,"701":1,"712":1,"733":1,"750":1,"751":1,"752":1,"753":1,"784":1,"809":1,"824":1,"825":1,"826":1,"827":1,"897":1,"905":1,"915":1,"928":1,"948":1,"955":1},"1":{"77":1,"78":1,"208":1,"209":1,"210":1,"211":1,"243":1,"244":1,"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"321":1,"322":1,"323":1,"324":1,"492":1,"493":1,"494":1,"495":1,"496":1,"525":1,"526":1,"605":1,"606":1,"632":1,"633":1,"634":1,"635":1,"751":1,"752":1,"753":1,"827":1},"2":{"40":1,"41":1,"46":1,"47":2,"50":8,"80":2,"81":1,"84":2,"86":1,"87":3,"88":1,"89":1,"95":1,"101":1,"107":1,"110":1,"111":3,"112":2,"113":3,"264":1,"320":1,"328":1,"338":1,"369":1,"405":1,"427":1,"428":3,"433":1,"434":1,"436":1,"440":1,"441":1,"445":2,"450":1,"451":6,"453":2,"454":2,"455":2,"456":9,"459":1,"460":4,"472":2,"474":1,"484":2,"487":2,"493":2,"494":1,"497":6,"511":2,"513":1,"539":1,"540":1,"567":2,"580":2,"590":3,"595":2,"608":2,"619":1,"636":1,"682":1,"694":1,"726":1,"731":1,"733":1,"748":4,"841":1,"943":1,"945":1,"947":1}}],["也希望我们能够互相成长",{"2":{"928":1}}],["也没必要解释说哪个是内在的哪个是外在的",{"2":{"878":1}}],["也没有bn层",{"2":{"246":1}}],["也不是为了体现我有多么多么厉害",{"2":{"878":1}}],["也不存在跨层连接",{"2":{"13":1}}],["也是不对的",{"2":{"878":1}}],["也是正确建立人生价值观和世界观的起点",{"2":{"878":1}}],["也是node的实例",{"2":{"468":1}}],["也非常具有成就感",{"2":{"858":1}}],["也就意味着",{"2":{"723":1}}],["也就是局部最优",{"2":{"970":1}}],["也就是最大位移方向",{"2":{"840":1}}],["也就是某一时刻不允许多个进程同时访问",{"2":{"681":1}}],["也就是一种特殊的共享资源",{"2":{"681":1}}],["也就是后验",{"2":{"659":1}}],["也就是所谓的",{"2":{"617":1,"723":1}}],["也就是预期的长时间训练",{"2":{"383":1}}],["也就是dropblock的由来",{"2":{"348":1}}],["也就是说",{"2":{"161":1,"196":1,"366":1,"391":1,"411":1,"616":1,"678":1,"723":1}}],["也就是说网络必须拥有一定的记忆能力",{"2":{"132":1}}],["也就是说通过统计学的方法",{"2":{"5":1}}],["也就是",{"2":{"122":1,"409":1}}],["也就是用链式法则以网络每层的权重为变量计算损失函数的梯度",{"2":{"25":1}}],["也许是",{"2":{"723":1}}],["也许这些超参数是最能保证转移的选择",{"2":{"384":1}}],["也会因为内存的容量限制不能一直呆在内存中",{"2":{"722":1}}],["也被称为自编码",{"2":{"619":1}}],["也被称为是感知机的功能层",{"2":{"10":1}}],["也能让我们更加有信心相信搜索流程能够找到好的冗余超参数配置",{"2":{"371":1}}],["也同时减少了所需的训练步数",{"2":{"359":1}}],["也使llm服务变得负担得起",{"2":{"332":1}}],["也采用了这个",{"2":{"572":1}}],["也采用了",{"2":{"294":1}}],["也对应了pytorch里面的kaiming初始化只要传卷积核的参数进去就行了",{"2":{"248":1}}],["也称为链接调度器",{"2":{"533":1}}],["也称为xavier条件",{"2":{"244":1}}],["也称为切片",{"2":{"222":1,"311":1}}],["也称为深度学习模型图",{"2":{"117":1}}],["也很简单",{"2":{"216":1}}],["也可能是某个隐藏层的输出",{"2":{"202":1}}],["也可以不是2维",{"2":{"655":1}}],["也可以将超过512的位置向量随机初始化",{"2":{"641":1}}],["也可以直接置为none",{"2":{"496":1}}],["也可以返回一个新的state",{"2":{"496":1}}],["也可以在模块级别使用",{"2":{"475":1}}],["也可以帮助我们优先考虑下一步采取什么行动",{"2":{"375":2}}],["也可以解决oom问题",{"2":{"328":1}}],["也可以对所有的隐状态做变换",{"2":{"170":1}}],["也可以称之为seq2seq模型",{"2":{"165":1}}],["也可以用来提取全局上下文信息",{"2":{"95":1}}],["也有双向的",{"0":{"153":1}}],["也避免出现梯度爆炸问题",{"2":{"130":1}}],["也即卷积核变成只有一个数字",{"2":{"56":1}}],["也叫element",{"2":{"108":1}}],["也叫做卷积神经网络",{"2":{"51":1}}],["也叫作前馈神经网络",{"2":{"6":1}}],["也学习如何提取特征",{"2":{"4":1}}],["通俗讲解",{"0":{"970":1}}],["通俗地讲就是具备学习功能",{"2":{"5":1}}],["通用格式onnx的保存",{"0":{"527":1},"1":{"528":1,"529":1,"530":1}}],["通信域定义了进程组及其作用范围",{"2":{"810":1}}],["通信域",{"0":{"810":1}}],["通信",{"2":{"808":1}}],["通信模型",{"2":{"806":1}}],["通信与块级注意力和前馈计算重叠",{"2":{"327":1}}],["通信互相传递",{"2":{"326":1}}],["通道",{"2":{"65":1}}],["通道表示不同的特征图",{"2":{"55":1}}],["通道的概念",{"2":{"55":1}}],["通常不会一下子就完成所有目标",{"2":{"922":1}}],["通常和mpi",{"2":{"808":1}}],["通常称为rank",{"2":{"806":1}}],["通常假设当前时刻的状态只与前一个时刻的状态相关",{"2":{"630":1}}],["通常我们会使用线性链crf来建模ner任务",{"2":{"626":1}}],["通常需要提供示例输入来触发模型的执行并捕获跟踪",{"2":{"564":1}}],["通常用于调试和打印模块的可读表示",{"2":{"496":1}}],["通常是一个字典",{"2":{"496":1}}],["通常是一个softmax神经网络层",{"2":{"181":1}}],["通常会影响验证集的性能",{"2":{"412":1}}],["通常将其传递给优化器",{"2":{"496":1}}],["通常将",{"2":{"409":1}}],["通常建议将数据文件在多台主机之间进行分片",{"2":{"395":1}}],["通常表明训练工作流中存在错误",{"2":{"375":1}}],["通常来说",{"2":{"357":1}}],["通常被称为kv",{"2":{"333":1}}],["通常被认为对超参数的选择相当鲁棒",{"2":{"294":1}}],["通常",{"2":{"329":1,"353":1,"359":1,"373":1,"376":1,"390":1,"423":1,"493":1}}],["通常情况下最优学习率和模型结构有关",{"2":{"369":1}}],["通常情况下",{"2":{"223":1,"312":1,"378":1,"510":1}}],["通常都是极其复杂的",{"2":{"190":1}}],["通常指代以斜坡函数及其变种为代表的非线性函数",{"2":{"122":1}}],["通常叫做输入",{"2":{"52":1}}],["通常缩写为mlp",{"2":{"13":1}}],["通过贪心算法",{"2":{"943":1}}],["通过贪心思维",{"2":{"934":1}}],["通过这种方法",{"2":{"938":1}}],["通过理解和掌握这种思维方式",{"2":{"928":1}}],["通过不断排查发现",{"2":{"883":1}}],["通过编程的方式实现艺术的效果",{"2":{"858":1}}],["通过映射图像纹理增加物体表面的细节",{"2":{"857":1}}],["通过计算端点之间的增量差值",{"2":{"840":1}}],["通过安装",{"2":{"822":1}}],["通过调用系统的",{"2":{"822":1}}],["通过调整模型的参数来最小化损失函数",{"2":{"258":1}}],["通过mpi",{"2":{"809":1}}],["通过密码和名字查询用户",{"2":{"730":1}}],["通过提供dao层",{"2":{"724":1}}],["通过sql语句可以满足操作数据库的所有需求",{"2":{"724":1}}],["通过文档和源代码",{"2":{"724":1}}],["通过框架可以减少重复代码",{"2":{"724":1}}],["通过随机遮盖掉输入中的文本片段进行预训练",{"2":{"621":1}}],["通过扩大原始模型和训练集创造了",{"2":{"620":1}}],["通过根据上文预测下一个单词的预训练任务",{"2":{"620":1}}],["通过三处变化使得",{"2":{"619":1}}],["通过升级训练数据来改进多语言预训练",{"2":{"619":1}}],["通过修改预训练方案可以进一步提高性能",{"2":{"619":1}}],["通过预测文本中被遮盖的词语和判断一个文本是否跟随另一个来进行预训练",{"2":{"619":1}}],["通过微调可以激发出模型在预训练过程中获得的知识",{"2":{"617":1}}],["通过微调参数使模型适用于新任务",{"2":{"617":1}}],["通过逐步调整学习率来",{"2":{"544":1}}],["通过trace",{"2":{"525":1}}],["通过wrapper的方式给step方法加补丁",{"2":{"509":1}}],["通过名称获取",{"2":{"496":1}}],["通过名称获取parameter",{"2":{"496":1}}],["通过名称获取子模块",{"2":{"496":1}}],["通过查阅代码解决",{"2":{"485":1}}],["通过连续性在当前点定义梯度",{"2":{"473":1}}],["通过从根节点到叶节点追溯这个图",{"2":{"471":1}}],["通过自举",{"2":{"403":1}}],["通过网络读取训练数据时可能会发生这种情况",{"2":{"387":1}}],["通过网络的层级传播梯度时",{"2":{"120":1}}],["通过运行更多的短时间的实验",{"2":{"383":1}}],["通过减少周期之间的时间并允许并行运行更多实验来提高调整效率",{"2":{"363":1}}],["通过把确切分类目标从0",{"2":{"345":1}}],["通过首先淘汰叶子节点",{"2":{"338":1}}],["通过",{"2":{"337":1,"445":1,"468":1,"621":1}}],["通过简单地在命令行中设置context",{"2":{"328":1}}],["通过cp",{"2":{"328":1}}],["通过跨卡的",{"2":{"326":1}}],["通过结合低秩键值联合压缩",{"2":{"308":1}}],["通过考虑历史梯度的方向和幅度",{"2":{"267":1}}],["通过考虑历史梯度的平均方向",{"2":{"266":1,"267":1}}],["通过积累历史梯度信息",{"2":{"267":1}}],["通过对l",{"2":{"248":1}}],["通过存储输出o和softmax归一化统计信息",{"2":{"228":1,"318":1}}],["通过在序列开头添加特殊的",{"2":{"620":1}}],["通过在预训练期间使用知识蒸馏",{"2":{"619":1}}],["通过在输入块q",{"2":{"316":1}}],["通过在将每个块的输出乘以正确的归一化因子之前进行缩放并将它们相加",{"2":{"224":1,"311":1}}],["通过在特定区域内对特征进行",{"2":{"92":1}}],["通过以上过程我们发现其中涉及的原理",{"2":{"190":1}}],["通过设置大量的翻译规则",{"2":{"189":1}}],["通过初始化decoder参数",{"2":{"180":1}}],["通过使用线性扩展的稀疏注意力形式",{"2":{"621":1}}],["通过使用更大的数据集进行预训练",{"2":{"620":1}}],["通过使用",{"2":{"387":1,"496":1}}],["通过使用之前在大数据集上经过训练的预训练模型",{"2":{"254":1}}],["通过使用预训练模型初始化decoder的参数",{"2":{"180":2}}],["通过使用批归一化等技术",{"2":{"120":1}}],["通过门向细胞状态添加或移除信息",{"2":{"145":1}}],["通过上面的例子",{"2":{"143":1}}],["通过将学习率减小2",{"2":{"547":1}}],["通过将",{"2":{"493":1,"616":1}}],["通过将数据的生产者和消费者分割为单独的warp",{"2":{"325":1}}],["通过将这些值转换为介于",{"2":{"148":1}}],["通过将正负值均匀分布在激活函数的输出范围内",{"2":{"120":1}}],["通过将输入张量重塑为一维张量来对其进行扁平化",{"2":{"107":1}}],["通过将卷积核进行翻转",{"2":{"61":1}}],["通过添加驱动程序计算机中的硬件就能正常的工作",{"2":{"73":1}}],["通过统计学的标准数学方法我们能够得到大量的可以用函数来表达的局部结构空间",{"2":{"5":1}}],["通过学习大量数据来提取特征和模式",{"2":{"4":1}}],["特效等功能",{"2":{"857":1}}],["特别适用于需要高性能的计算应用",{"2":{"802":1}}],["特别的前面的一部分",{"2":{"699":1}}],["特别是数学相关的",{"2":{"972":1}}],["特别是如果有许多张量引用相同的存储",{"2":{"481":1}}],["特别是如果它们在设计时未考虑神经网络超参数调整",{"2":{"401":1}}],["特别是在实时模拟和虚拟人物表情渲染等技术上取得了显著突破",{"2":{"859":1}}],["特别是在光线追踪和蒙特卡洛方法中",{"2":{"857":1}}],["特别是在调整学习率衰减计划时",{"2":{"380":1}}],["特别是在llms的异常特征的情况下",{"2":{"325":1}}],["特别是在存在噪声或不稳定梯度的情况下",{"2":{"266":1}}],["特别是在迭代次数较少的情况下",{"2":{"261":1}}],["特别是处理高曲率",{"2":{"263":1}}],["特别是当训练数据较少时",{"2":{"180":1}}],["特别是大脑",{"2":{"5":1}}],["特定项目或工作流的偶然案例研究",{"2":{"353":1}}],["特征图上",{"2":{"348":1}}],["特征维度较高和模型复杂度较高等情况下容易出现",{"2":{"341":1}}],["特征维度较高",{"2":{"341":1}}],["特征学习",{"2":{"4":1}}],["特点",{"0":{"266":1,"279":1},"2":{"260":1,"261":1,"262":1,"802":6}}],["或许",{"2":{"878":1}}],["或许以后也会另有看法",{"2":{"878":1}}],["或许你会哭",{"2":{"878":1}}],["或许有些人这辈子都不会感悟到",{"2":{"878":1}}],["或许有同学会疑问啥是系统资源",{"2":{"680":1}}],["或许现在我是这种理解",{"2":{"878":1}}],["或许与先前的各位大师有所矛盾",{"2":{"876":1}}],["或许我看的视角有点片面",{"2":{"875":1}}],["或hlsl",{"2":{"857":1}}],["或响应",{"2":{"796":1}}],["或注解来配置和映射原生信息",{"2":{"721":1}}],["或线程",{"2":{"683":1}}],["或是让你在忙碌的生活中找到些许放松的时光",{"2":{"881":1}}],["或是资源",{"2":{"680":1}}],["或是带噪声的梯度",{"2":{"263":1}}],["或前nbset大",{"2":{"634":1}}],["或通用性进行了优化",{"2":{"510":1}}],["或等效地使用",{"2":{"480":1}}],["或当输入为",{"2":{"473":1}}],["或副本",{"2":{"441":1}}],["或在交互式环境中直接输入",{"2":{"441":1}}],["或在某些时候",{"2":{"380":1}}],["或你的雇主",{"2":{"423":1}}],["或额外的正则化技术",{"2":{"412":1}}],["或中期训练中出现的不稳定性",{"2":{"410":1}}],["或异常高的损失值的试验",{"2":{"408":1}}],["或其他非自适应搜索算法",{"2":{"401":1}}],["或其他变化",{"2":{"378":1}}],["或恒定学习率",{"2":{"399":1}}],["或用于",{"2":{"387":1}}],["或甚至验证误差",{"2":{"383":1}}],["或全部",{"2":{"376":1}}],["或使用polyak平均法",{"2":{"375":1}}],["或采取其他一些纠正措施",{"2":{"372":1}}],["或抽样更多试验",{"2":{"372":1}}],["或研究组",{"2":{"372":1}}],["或一系列研究",{"2":{"370":1}}],["或一个固定超参数",{"2":{"369":1}}],["或烘烤不必要的并发症",{"2":{"363":1}}],["或计算节点间的同步",{"2":{"358":1}}],["或至少接近恒定的",{"2":{"358":1}}],["或至少接近加倍",{"2":{"358":1}}],["或具有固定",{"2":{"356":1}}],["或看到出错",{"2":{"353":1}}],["或更小的恒定学习率",{"2":{"399":1}}],["或更好地调整现有的正则化参数",{"2":{"375":1}}],["或更本源的",{"2":{"326":1}}],["或更常用的lstm",{"2":{"167":1}}],["或内存加载",{"2":{"325":1}}],["或最大化",{"2":{"256":1,"258":1}}],["或微调",{"2":{"220":1,"306":1}}],["或者其他编辑器",{"2":{"889":1}}],["或者存储在磁盘文件中",{"2":{"722":1}}],["或者读到不清楚的地方回头去看前面提到的这一部分内容",{"2":{"702":1}}],["或者握手使得达成协议或者使得操作序列有序",{"2":{"677":1}}],["或者说密码",{"2":{"654":1}}],["或者一个分布",{"2":{"653":1}}],["或者直接安装",{"2":{"613":1}}],["或者可选择返回一个新的",{"2":{"509":1}}],["或者可选择返回一个新的state",{"2":{"509":1}}],["或者训练数据没有被适当地打乱",{"2":{"390":1}}],["或者更普遍的由于训练数据生成过程而产生的方差",{"2":{"378":1}}],["或者因为违反某些隐式约束而根本无法运行",{"2":{"372":1}}],["或者我们也可以将激活函数作为一个冗余超参数和深度一起调优",{"2":{"369":1}}],["或者我们接受实验得到的最优深度的仅在某个激活函数上有效",{"2":{"369":1}}],["或者我们不希望它们",{"2":{"369":1}}],["或者",{"2":{"358":1,"369":1,"370":1,"371":1,"381":1,"422":1,"794":1,"878":1,"948":1}}],["或者在收敛到最小值前在某个局部的极小值收敛了",{"2":{"236":1}}],["或者改进模型的性能",{"2":{"220":1,"306":1}}],["或者已经积累了n条已完成的句子",{"2":{"186":1}}],["或者下一时刻的输出要依赖于上一时刻的输出",{"2":{"133":1}}],["或者为空",{"2":{"104":1}}],["或者多层感知机",{"2":{"6":1}}],["或称膨胀卷积",{"2":{"60":1}}],["或",{"0":{"27":1},"2":{"9":1,"13":1,"27":1,"369":1,"370":1,"375":1,"389":1,"473":1,"507":1,"509":1,"621":2,"759":1,"760":1,"777":1,"782":1,"784":2,"786":1,"790":2,"822":4}}],["或类神经网络",{"2":{"5":1}}],["或表征学习",{"2":{"4":1}}],["azure",{"2":{"716":1}}],["aws",{"2":{"716":1}}],["aweights",{"2":{"445":1}}],["a​i",{"2":{"643":1}}],["aesthetics",{"2":{"608":5}}],["axes",{"2":{"556":2}}],["axis1",{"2":{"445":2}}],["axis0",{"2":{"445":2}}],["axis",{"2":{"445":1,"556":2}}],["axis=",{"2":{"86":2,"87":2,"88":2,"89":2}}],["audio",{"2":{"897":4}}],["aux",{"2":{"755":1,"757":1}}],["augmentation",{"2":{"556":1}}],["authtoken",{"2":{"889":1}}],["auth",{"2":{"889":1}}],["author",{"2":{"421":1}}],["autonomous",{"2":{"900":1}}],["automatically",{"2":{"894":1}}],["automatic",{"0":{"894":1}}],["automated",{"2":{"127":1}}],["autoindent",{"2":{"792":1}}],["autogard模块才会填充一个新的图",{"2":{"466":1}}],["autogradmeta",{"2":{"468":1}}],["autograd是什么",{"0":{"468":1}}],["autograd",{"0":{"446":1,"450":1,"456":1,"470":1,"481":1,"894":1},"1":{"447":1,"448":1,"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1,"478":1,"479":1,"480":1,"481":1},"2":{"440":1,"446":3,"447":1,"448":1,"450":2,"456":3,"463":3,"470":1,"476":1,"481":1,"671":1,"894":1}}],["auto",{"0":{"462":1,"467":1},"2":{"616":2,"619":1,"620":1}}],["autocast",{"2":{"444":1}}],["abcdef",{"2":{"726":1}}],["above",{"2":{"556":2}}],["absolute",{"2":{"445":2}}],["abs",{"2":{"122":1,"402":1,"441":2,"443":1,"445":4}}],["ai图像生成",{"2":{"858":1}}],["aigc等内容",{"2":{"702":1}}],["ai自学之路",{"2":{"672":1}}],["ai时代的算法学习",{"0":{"672":1}}],["ai",{"2":{"496":1,"616":1,"643":1,"873":1,"874":1,"891":2,"899":1}}],["ainslie等人",{"2":{"308":1}}],["after",{"2":{"459":1,"499":1,"547":1,"581":1,"904":1}}],["affine",{"2":{"120":1}}],["affine=true",{"2":{"88":1}}],["affine=false",{"2":{"86":1}}],["among",{"2":{"899":1}}],["amounts",{"2":{"891":1}}],["am",{"2":{"823":1}}],["aminmax",{"2":{"445":2}}],["amin",{"2":{"445":1}}],["amp",{"2":{"225":2,"402":1,"726":2,"868":1}}],["apt",{"2":{"770":3,"817":4}}],["apache",{"2":{"726":4}}],["append",{"2":{"445":1,"457":1,"529":1,"799":1}}],["applied",{"2":{"556":1}}],["applications",{"2":{"891":1,"905":1}}],["application",{"0":{"898":1},"1":{"899":1,"900":1,"901":1},"2":{"444":1,"843":1}}],["apply",{"2":{"445":1,"458":2,"471":1,"496":2,"556":1,"649":2}}],["appropriate",{"2":{"585":1}}],["approach",{"2":{"444":1}}],["approx",{"2":{"125":2,"126":2}}],["api处于原型阶段",{"2":{"444":1}}],["api",{"2":{"442":1,"444":1,"468":1,"703":1,"717":1,"889":1}}],["aa",{"2":{"440":2,"457":2}}],["a10g",{"2":{"332":1}}],["a100",{"2":{"78":1,"320":1,"332":1}}],["age",{"2":{"706":1}}],["agi",{"2":{"622":1}}],["agarwal为其他联合研究制作的几个分析图的一些实验数据",{"2":{"420":1}}],["agagrad会累加所有历史梯度的平方",{"2":{"287":1}}],["ag",{"2":{"328":11,"763":1}}],["academic",{"2":{"905":1}}],["across",{"2":{"897":1}}],["active",{"2":{"905":1}}],["active=2",{"2":{"581":2}}],["activities=",{"2":{"581":1}}],["activating",{"2":{"89":1}}],["activation2",{"2":{"487":2}}],["activation1",{"2":{"487":2}}],["activation",{"0":{"96":1,"120":1,"457":1},"1":{"121":1,"122":1},"2":{"8":1,"27":1,"116":1,"120":1,"122":1,"127":1,"131":1,"444":1,"462":1,"671":1}}],["activate",{"2":{"87":1}}],["action=",{"2":{"497":4}}],["act",{"2":{"484":4,"487":4}}],["acylic",{"2":{"447":1}}],["acosh",{"2":{"445":2}}],["acos",{"2":{"445":2}}],["account",{"2":{"889":2}}],["according",{"2":{"509":1}}],["access",{"2":{"723":1}}],["accelerated",{"0":{"268":1},"1":{"269":1,"270":1,"271":1}}],["accuracy",{"0":{"577":1},"2":{"497":1,"567":1,"576":2,"586":1}}],["accurate",{"0":{"325":1}}],["accumulation",{"2":{"904":1}}],["accumulator",{"2":{"468":1}}],["accumulate",{"2":{"441":1,"444":1,"445":4,"454":1}}],["a的词是跟b的词怎么对应的",{"2":{"190":1}}],["a∣y",{"2":{"190":2}}],["atanh",{"2":{"445":2}}],["atan2",{"2":{"445":2}}],["atan",{"2":{"445":2}}],["atol",{"2":{"445":3}}],["at",{"2":{"422":1,"585":1,"633":1,"634":3,"895":1}}],["attetion",{"2":{"647":1}}],["attenion",{"2":{"205":1}}],["attentions",{"2":{"671":1}}],["attention的实现过程中每层至少需要一次跨节点通信",{"2":{"329":1}}],["attention的输出",{"2":{"202":1}}],["attention或striped",{"2":{"329":1}}],["attention计算原理一样",{"2":{"214":1}}],["attention加入到target端得到的attention中",{"2":{"213":1}}],["attention首先分别在source端和target端进行自身的attention",{"2":{"213":1}}],["attention与传统的attention机制非常的不同",{"2":{"213":1}}],["attention允许模型的不同表示子空间联合关注不同位置的信息",{"2":{"210":1}}],["attention可以描述为将query和一组",{"2":{"198":1}}],["attention子层",{"2":{"197":1}}],["attention机制",{"2":{"196":1}}],["attention机制已经成为序列建模和转导模型不可或缺的一部分",{"2":{"193":1}}],["attention堆叠和point",{"2":{"194":1}}],["attention来计算输入和输出表示而不使用序列对齐rnn或卷积的转导模型",{"2":{"193":1}}],["attention",{"0":{"173":1,"174":1,"193":1,"198":1,"202":1,"207":1,"212":1,"213":1,"214":1,"217":1,"218":1,"224":1,"227":1,"229":1,"231":1,"303":1,"304":1,"307":1,"314":1,"317":1,"320":1,"325":1,"328":1,"331":1},"1":{"174":1,"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":1,"206":1,"208":1,"209":1,"210":1,"211":1,"215":1,"216":1,"219":1,"305":1,"308":1,"309":1,"321":1,"322":1,"323":1,"324":1,"332":1,"333":1,"334":1,"335":1},"2":{"174":3,"192":2,"193":2,"197":1,"200":2,"205":1,"206":1,"209":1,"213":2,"215":2,"217":2,"220":2,"227":2,"229":1,"231":1,"303":2,"306":2,"312":1,"317":2,"322":1,"326":7,"327":1,"328":2,"331":1,"339":2,"498":2,"499":7,"500":4,"608":1,"609":1,"616":1,"619":1,"635":2,"643":1,"645":1,"647":1,"648":2,"649":2}}],["attn",{"2":{"215":5,"498":10,"500":18}}],["atrous",{"0":{"60":1}}],["advance",{"2":{"905":1}}],["adopt",{"2":{"901":1}}],["admin需要添加名称和密码",{"2":{"889":1}}],["admin",{"2":{"889":5}}],["adjoint",{"2":{"445":1}}],["adam优化器的beta等",{"2":{"369":1}}],["adamw",{"0":{"298":1},"1":{"299":1,"300":1},"2":{"487":1}}],["adam",{"0":{"293":1,"400":1,"418":1},"2":{"294":5,"356":5,"369":4,"370":2,"400":1,"406":1,"487":1,"497":1,"500":1,"503":1,"522":1,"523":1}}],["adadelta",{"0":{"286":1},"1":{"287":1,"288":1,"289":1},"2":{"287":1,"289":1,"292":1,"487":1,"497":1}}],["adaptive",{"2":{"281":1,"289":1,"294":1}}],["adaptiveavgpool2d",{"2":{"95":3,"497":1}}],["adagrad",{"0":{"275":1,"277":1,"278":1},"1":{"276":1,"277":1,"278":1,"279":1,"280":1,"281":1},"2":{"277":3,"283":2,"287":1,"292":1,"487":1}}],["adduser",{"2":{"731":3}}],["added",{"2":{"632":2,"904":1}}],["adds",{"2":{"496":1}}],["addcmul",{"2":{"445":2}}],["addcdiv",{"2":{"445":2}}],["addmm",{"2":{"444":1}}],["address",{"2":{"827":3}}],["addr",{"2":{"436":2,"759":1}}],["additive",{"2":{"203":1,"206":2}}],["add",{"2":{"108":1,"117":1,"441":2,"443":1,"445":7,"496":3,"497":12,"499":1,"508":1,"509":1,"576":5,"577":1,"579":2,"580":3,"595":1,"889":1}}],["avg",{"2":{"497":2,"577":2}}],["avgpool2d",{"2":{"94":2}}],["avoid",{"2":{"441":1,"904":1}}],["available",{"2":{"434":1,"497":2,"511":1,"581":2}}],["averages",{"2":{"581":1}}],["averaged",{"2":{"577":1}}],["average",{"0":{"95":1},"2":{"95":1,"497":1}}],["averagepooling",{"0":{"94":1}}],["algorithm",{"2":{"634":1}}],["algorithms",{"2":{"302":2}}],["always",{"2":{"490":1,"496":1,"587":1}}],["along",{"2":{"445":1}}],["align",{"2":{"441":2,"445":3}}],["alignment",{"2":{"190":1}}],["al",{"2":{"277":1,"357":1,"359":1,"363":1,"381":1,"412":1}}],["albert",{"2":{"126":1,"619":2}}],["alphas",{"2":{"595":5}}],["alpha",{"2":{"125":1,"406":1,"418":1,"419":1,"444":2,"445":13,"595":14}}],["allclose",{"2":{"445":1}}],["allows",{"2":{"556":1,"581":1,"891":1}}],["allow",{"2":{"444":1}}],["allreduce",{"2":{"439":1}}],["all",{"0":{"193":1},"2":{"89":1,"217":1,"255":1,"303":1,"328":3,"444":1,"445":3,"462":1,"537":1,"538":1,"539":1,"540":1,"542":1,"548":1,"549":1,"590":1,"616":1,"633":4,"634":1}}],["also",{"2":{"81":1,"262":1,"586":1,"905":1}}],["alexnet",{"2":{"57":1,"582":1,"585":3,"590":1}}],["artifactid>mysql",{"2":{"726":1}}],["artifactid>mybatis",{"2":{"726":1}}],["artifactid>",{"2":{"726":2}}],["artificial",{"2":{"5":1,"891":1}}],["arr",{"2":{"634":3}}],["arrays",{"2":{"895":1}}],["array",{"2":{"50":11,"225":2,"313":2,"430":6,"436":6,"441":5}}],["archive",{"2":{"768":4}}],["architectures",{"2":{"582":1}}],["architecture",{"0":{"194":1},"2":{"74":1,"585":1,"590":1}}],["arch",{"2":{"590":4}}],["arctanh",{"2":{"445":2}}],["arctan2",{"2":{"445":2}}],["arctan",{"2":{"445":2}}],["arcsinh",{"2":{"445":2}}],["arcsin",{"2":{"445":3}}],["arccosh",{"2":{"445":2}}],["arccos",{"2":{"445":2}}],["are",{"2":{"333":1,"338":1,"447":1,"556":3,"571":1,"894":1,"895":3,"897":1,"904":1}}],["arena和vicuna",{"2":{"332":1}}],["around",{"2":{"227":1,"317":1}}],["argc",{"2":{"827":2}}],["argv",{"2":{"823":2,"827":2}}],["argparse",{"2":{"497":2,"513":1}}],["argwhere",{"2":{"445":1}}],["argmin",{"2":{"445":1}}],["argmax​y​​p",{"2":{"190":1}}],["argmax",{"2":{"190":2,"445":1,"497":1}}],["argmaxyp",{"2":{"190":1}}],["argsort",{"2":{"445":3}}],["args",{"2":{"443":1,"445":1,"490":1,"496":6,"497":12,"509":4,"556":2,"649":1,"706":1,"823":2}}],["args=",{"2":{"441":1,"799":1}}],["arguments",{"2":{"590":2}}],["argumentparser",{"2":{"497":1}}],["argument",{"2":{"81":1,"497":11}}],["arxiv",{"2":{"122":1,"402":1,"617":1}}],["arange",{"2":{"98":1,"110":1,"112":1,"499":1,"632":3,"634":1,"649":2}}],["asia",{"2":{"859":1}}],["asinh",{"2":{"445":2}}],["asin",{"2":{"445":2}}],["asdfgh",{"2":{"732":1}}],["ast",{"2":{"562":1}}],["aspect",{"2":{"556":1}}],["assuming",{"2":{"535":1,"537":1,"538":1,"539":1,"540":1,"542":1,"548":1,"549":1}}],["assert",{"2":{"498":1,"499":1,"500":1,"529":1,"556":3}}],["assign",{"2":{"496":1}}],["assistant",{"2":{"338":1}}],["asarray",{"2":{"441":1}}],["asynchrony",{"0":{"325":1}}],["as",{"2":{"50":1,"80":1,"81":2,"83":1,"86":1,"87":1,"93":1,"94":1,"95":1,"121":1,"262":1,"441":1,"445":14,"493":1,"494":1,"495":1,"497":4,"498":2,"499":2,"500":3,"513":3,"541":1,"545":2,"555":2,"556":1,"570":1,"575":3,"579":1,"581":1,"582":1,"585":1,"595":1,"649":6,"799":1,"893":1,"897":1,"899":1,"900":1,"904":2,"905":2}}],["a",{"0":{"460":1},"2":{"36":1,"50":5,"83":1,"89":1,"98":1,"99":4,"105":1,"108":1,"110":2,"112":6,"113":1,"190":1,"217":1,"252":4,"255":1,"294":1,"303":1,"334":1,"335":1,"338":2,"427":1,"440":8,"441":2,"444":4,"445":1,"451":2,"456":2,"457":3,"496":1,"497":1,"555":2,"556":8,"571":3,"576":1,"581":2,"585":4,"586":1,"588":1,"589":2,"590":2,"633":2,"634":1,"643":4,"644":1,"742":1,"774":1,"778":2,"843":1,"891":2,"894":1,"895":1,"896":1,"901":1,"904":6,"905":2}}],["analyzer",{"2":{"839":1}}],["analysis",{"2":{"188":1,"897":2}}],["answers",{"2":{"636":1}}],["answer",{"2":{"636":1}}],["answering",{"2":{"188":1,"636":1}}],["annotations",{"2":{"552":2}}],["anns",{"2":{"5":1}}],["angle",{"2":{"445":1}}],["any",{"2":{"440":1,"443":41,"444":1,"445":6,"496":21,"508":2,"509":6}}],["anil",{"2":{"420":1}}],["an",{"2":{"81":1,"113":1,"122":1,"289":1,"302":1,"508":1,"556":1}}],["and",{"0":{"35":1,"220":1,"306":1,"320":1,"325":2,"331":1,"577":1,"599":1,"691":1},"1":{"321":1,"322":1,"323":1,"324":1,"332":1,"333":1,"334":1,"335":1},"2":{"8":1,"11":1,"80":6,"81":3,"99":1,"217":1,"226":1,"227":1,"229":1,"271":1,"281":1,"294":1,"302":1,"303":1,"317":1,"333":2,"356":1,"421":4,"440":1,"441":11,"443":3,"445":7,"490":1,"497":2,"499":1,"509":3,"556":7,"581":3,"582":1,"584":2,"585":6,"586":1,"588":1,"589":2,"590":1,"595":2,"632":1,"633":3,"634":2,"730":2,"891":3,"893":1,"895":1,"896":2,"897":9,"899":1,"900":2,"901":2,"904":5,"905":2,"957":1}}],["4321",{"2":{"933":1}}],["47",{"2":{"671":1}}],["46",{"2":{"671":1}}],["4644",{"2":{"112":1}}],["44",{"2":{"671":1}}],["42",{"2":{"671":1}}],["41",{"2":{"671":1}}],["4f",{"2":{"497":1,"500":1,"567":1}}],["408的前置知识或者学后补充",{"2":{"696":1}}],["408知识点",{"2":{"833":1}}],["408知识",{"0":{"673":1},"2":{"868":1}}],["4096",{"2":{"621":1}}],["40",{"2":{"619":1,"671":1}}],["400mf",{"2":{"590":2}}],["4000",{"2":{"26":1}}],["40gb",{"2":{"332":1}}],["4倍的挂钟速度提升",{"2":{"316":1}}],["494",{"2":{"128":1}}],["4x",{"2":{"50":1}}],["48972",{"2":{"48":3}}],["45",{"2":{"50":1,"86":1,"88":1,"460":1,"671":1}}],["458137",{"2":{"47":2}}],["458137w",{"2":{"47":1}}],["453383",{"2":{"47":3}}],["4−0",{"2":{"47":2}}],["4×0",{"2":{"41":2}}],["4",{"0":{"5":1,"13":1,"14":1,"15":1,"28":1,"34":1,"47":1,"54":1,"72":1,"73":1,"74":1,"75":1,"89":1,"92":1,"93":1,"94":1,"95":1,"101":1,"107":1,"124":1,"138":1,"142":1,"150":1,"153":1,"175":1,"176":1,"177":1,"178":1,"179":1,"180":1,"186":1,"191":1,"198":1,"199":1,"200":1,"201":1,"202":1,"203":1,"204":1,"205":2,"206":2,"211":1,"225":1,"238":1,"239":1,"240":1,"241":1,"250":1,"251":1,"252":1,"272":1,"273":1,"274":1,"279":1,"297":1,"310":1,"311":1,"312":1,"313":1,"314":2,"315":1,"316":1,"317":1,"318":1,"319":1,"324":1,"335":1,"346":1,"430":1,"435":1,"436":1,"437":1,"438":1,"453":1,"465":1,"470":1,"471":1,"472":1,"473":1,"474":2,"475":1,"476":1,"477":1,"478":1,"479":1,"480":2,"481":1,"490":1,"495":1,"516":1,"521":1,"522":1,"523":1,"538":1,"550":1,"554":1,"555":1,"565":1,"570":1,"578":1,"585":1,"597":1,"600":1,"601":1,"602":1,"603":1,"619":1,"623":1,"624":1,"625":1,"626":1,"627":1,"628":1,"629":2,"630":1,"635":1,"649":1,"655":1,"660":1,"666":1,"674":1,"679":1,"680":1,"681":1,"682":1,"693":1,"695":2,"700":1,"711":1,"724":1,"732":1,"747":1,"779":1,"799":1,"808":1,"815":1,"816":1,"817":1,"818":2,"819":2,"820":2,"821":2,"822":3,"842":1,"847":1,"852":1,"896":1,"902":1,"903":1,"904":1,"912":1,"913":1,"914":1,"922":1,"927":1,"934":1,"944":1,"945":1,"946":1,"947":1,"954":1,"975":1},"1":{"14":1,"15":1,"73":1,"74":1,"75":1,"93":1,"94":1,"95":1,"176":1,"177":1,"178":2,"179":2,"180":1,"199":1,"200":1,"201":1,"202":2,"203":2,"204":2,"205":2,"206":1,"239":1,"240":1,"241":1,"251":1,"252":1,"273":1,"274":1,"311":1,"312":1,"313":1,"314":1,"315":1,"316":1,"317":1,"318":1,"319":1,"436":1,"437":1,"438":1,"439":1,"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":2,"478":2,"479":2,"480":2,"481":1,"522":1,"523":1,"555":1,"556":1,"586":1,"587":1,"588":1,"589":1,"590":1,"601":1,"602":1,"603":1,"624":1,"625":1,"626":2,"627":2,"628":2,"629":1,"630":3,"675":1,"676":1,"677":1,"678":1,"679":1,"680":2,"681":2,"682":2,"683":1,"684":1,"685":1,"686":1,"687":1,"688":1,"689":1,"690":1,"691":1,"692":1,"693":1,"694":1,"748":1,"749":1,"780":1,"781":1,"782":1,"783":1,"819":2,"820":2,"821":2,"822":2,"903":1,"904":1,"913":1,"914":1,"945":1,"946":1,"947":1},"2":{"26":1,"41":1,"46":1,"47":2,"50":4,"80":2,"81":1,"84":4,"89":2,"98":1,"99":4,"106":2,"107":1,"108":1,"110":1,"111":4,"112":10,"113":4,"122":1,"167":1,"226":2,"338":3,"356":1,"404":1,"427":1,"428":3,"430":1,"433":1,"434":1,"436":1,"440":1,"441":1,"450":2,"455":1,"459":1,"460":1,"474":1,"484":1,"487":3,"497":2,"498":1,"500":1,"518":1,"539":1,"540":1,"542":1,"548":1,"549":1,"568":1,"570":2,"590":2,"608":1,"609":1,"655":1,"681":1,"694":1,"822":2,"827":1,"868":1,"931":1,"933":2,"943":1}}],["识别不稳定的训练任务",{"0":{"405":1}}],["识别错误的搜索空间边界",{"0":{"373":1}}],["识别目标超参数",{"0":{"369":1}}],["识别",{"2":{"4":1}}],["它都是最高的",{"2":{"970":1}}],["它其实是我们每个人生活中的一部分",{"2":{"928":1}}],["它其实也是一种思维方式",{"2":{"923":1}}],["它也是我们日常生活的助手",{"2":{"927":1}}],["它也许最好被看作结合rmsprop",{"2":{"294":1}}],["它就在我们身边",{"2":{"928":1}}],["它就是一种解决问题的规则和步骤",{"2":{"916":1}}],["它就像一个初始化于该碗状结构的adagrad",{"2":{"283":1}}],["它广泛应用于科学计算",{"2":{"797":1}}],["它负责将字节码转化为机器码并执行",{"2":{"705":1}}],["它存在的目的是有效的防止竞争条件又能保证最大化使用共享数据",{"2":{"681":1}}],["它不会改变向量的模长",{"2":{"647":1}}],["它不是随机将隐含层节点的输出清0",{"2":{"347":1}}],["它仅仅是在attention矩阵的基础上加一个可训练的偏置项而已",{"2":{"644":1}}],["它表示当前位置的标签",{"2":{"628":1}}],["它指示了当前的输入",{"2":{"627":1}}],["它会检查函数中的各种操作符和模块",{"2":{"563":1}}],["它会引入计算延迟",{"2":{"327":1}}],["它适用于具有固定结构和无需动态控制流的模型",{"2":{"559":1}}],["它以一种动态的方式表示模型的计算过程",{"2":{"559":1}}],["它以一种静态的方式表示模型的结构和计算逻辑",{"2":{"559":1}}],["它接受一个可链接的学习率调度器列表",{"2":{"548":1}}],["它决定了在每次参数更新中应用的梯度下降的步长",{"2":{"531":1}}],["它决定了要丢弃哪些信息以及要添加哪些新信息",{"2":{"156":1}}],["它包含两个条目",{"2":{"509":1}}],["它包含对模块参数和缓冲区的引用",{"2":{"496":1}}],["它返回两个列表",{"2":{"496":1}}],["它允许对子图进行细粒度的梯度计算排除",{"2":{"475":1}}],["它支持任何计算图的梯度自动计算",{"2":{"463":1}}],["它应该具有以下的签名",{"2":{"509":2}}],["它应该具有以下签名",{"2":{"509":4}}],["它应该足够大",{"2":{"391":1}}],["它应用激活函数",{"2":{"444":1}}],["它能够生成篇幅较长且语义连贯的文本",{"2":{"620":1}}],["它能够在给定搜索空间内生成",{"2":{"402":1}}],["它能够更快地朝着梯度下降的方向移动",{"2":{"267":1}}],["它能加快搜索",{"2":{"401":1}}],["它通过跟踪模型的输入和输出",{"2":{"564":1}}],["它通过利用循环神经网络",{"2":{"167":1}}],["它通常有以下列",{"2":{"393":1}}],["它明显比上面的东西弱",{"2":{"384":1}}],["它对搜索空间的统一探索使得对结果以及它们可能对搜索空间提出的建议的推理变得更容易",{"2":{"401":1}}],["它对具有更多正则化的配置更偏爱",{"2":{"375":1}}],["它对某些值进行掩盖",{"2":{"214":1}}],["它在提出时横扫了整个",{"2":{"619":1}}],["它在前向传播和反向传播中都起作用",{"2":{"475":1}}],["它在两种算法中的作用相似",{"2":{"369":1}}],["它在每次参数更新时使用一小批次的样本来计算梯度和更新参数",{"2":{"262":1}}],["它被特别强调是因为我们在调整超参数方面遇到了困难",{"2":{"353":1}}],["它被归零的概率会升高",{"2":{"126":1}}],["它淘汰来自第二个聊天会话的所有节点",{"2":{"338":1}}],["它作为一种空间高效的替代方案",{"2":{"338":1}}],["它使系统能够更多地将序列进行批处理",{"2":{"334":1}}],["它自然适用于短期和长期上下文",{"2":{"329":1}}],["它们的作用是",{"2":{"822":1}}],["它们的梯度将作为计算需要",{"2":{"475":1}}],["它们提供了以下几种关键工具",{"2":{"822":1}}],["它们采用不同的预训练目标在不同的数据集上进行训练",{"2":{"616":1}}],["它们将被用作默认值",{"2":{"504":1}}],["它们不是任何先验分布的参数",{"0":{"411":1}}],["它们是当前研究中非常活跃的领域",{"2":{"401":1}}],["它们通常具有足够的相关性",{"2":{"384":1}}],["它们通常不会以任何方式影响前向传递或梯度的计算成本",{"2":{"369":1}}],["它们很少是目标超参数",{"2":{"369":1}}],["它们比具有动量的",{"2":{"356":1}}],["它们彼此交换kv",{"2":{"328":1}}],["它们需要更小的kv缓存",{"2":{"308":1}}],["它同时将key",{"2":{"327":1}}],["它提出并综合了三个新想法",{"2":{"325":1}}],["它只是一个非正式的描述语",{"2":{"381":1}}],["它只在每个流水线阶段的边界需要跨节点通信",{"2":{"329":1}}],["它只需存储每个小批量样本的梯度",{"2":{"262":1}}],["它只有两个门",{"2":{"156":1}}],["它有潜力收敛到全局最优解",{"2":{"260":1}}],["它从数据中获得信息",{"2":{"254":1}}],["它是很多成功人士用来处理繁琐事务的秘诀",{"2":{"924":1}}],["它是指通过分析",{"2":{"923":1}}],["它是指多进程存在时必须互斥访问的资源",{"2":{"681":1}}],["它是",{"2":{"703":1}}],["它是唯一可以生效的",{"2":{"477":1}}],["它是最陡下降方向",{"2":{"473":1}}],["它是深度学习从业者经常采用的优化方法之一",{"2":{"282":1}}],["它是由",{"2":{"244":1}}],["它是网络的记忆单元",{"2":{"137":1}}],["它常用于编程语言中表示变量的初始化或赋值操作",{"2":{"225":1,"313":1}}],["它常用于多类分类问题中",{"2":{"129":1}}],["它可以带来一定的远程衰减性",{"2":{"648":1}}],["它可以通过两种方式使用",{"2":{"505":1}}],["它可以在较少的内存访问次数下计算精确的注意力",{"2":{"222":1,"311":1}}],["它可以是为了适应新的任务或结构",{"2":{"220":1,"306":1}}],["它可以建模依赖关系而不考虑其在输入或输出序列中的距离",{"2":{"193":1}}],["它关联单个序列的不同位置以计算序列的表示",{"2":{"193":1}}],["它把那些需要大量人力的工作都吃掉了",{"2":{"191":1}}],["它把可能在较大范围内变化的输入值挤压到",{"2":{"9":1}}],["它的配置和select标签差不多",{"2":{"731":1,"732":1,"733":1}}],["它的灵活性更大",{"2":{"642":1}}],["它的存在能够帮助我们显示地去建模标签之间的转移关系",{"2":{"628":1}}],["它的值是",{"2":{"369":1}}],["它的吞吐量比huggingface",{"2":{"332":1}}],["它的思路类似于把",{"2":{"326":1}}],["它的核心思想是",{"2":{"244":1,"929":1}}],["它的平均值会削弱这个信息",{"2":{"210":1}}],["它的意思就是在两种语言a和b之间",{"2":{"190":1}}],["它的导数在",{"2":{"120":1}}],["它的人工神经元可以响应一部分覆盖范围内的周围单元",{"2":{"51":1}}],["它由多个神经网络层",{"2":{"117":1}}],["它将参数组合成一个多张量",{"2":{"510":1}}],["它将被用于加载到优化器中",{"2":{"509":1}}],["它将结果使用",{"2":{"444":1}}],["它将是一个副本",{"2":{"98":1}}],["它将输入值映射为输出值",{"2":{"9":1}}],["它模拟了人脑神经元之间的相互连接和信息传递方式",{"2":{"4":1}}],["它避免了手动提取特征的麻烦",{"2":{"4":1}}],["是孩子和饼干数量的较大值",{"2":{"959":1}}],["是做出来的",{"2":{"880":1}}],["是那些热爱生命并且勇往直前的人",{"2":{"880":1}}],["是理解的关键",{"2":{"878":1}}],["是很客观的",{"2":{"878":1}}],["是图形学中将3d图形转化为2d图像的关键技术",{"2":{"857":1}}],["是固定的",{"2":{"844":1}}],["是用于运行",{"2":{"822":1}}],["是用来排序的",{"2":{"445":1}}],["是因为这些工具都是为开发和执行",{"2":{"822":1}}],["是因为文本生成类任务还没这么火热",{"2":{"217":1,"303":1}}],["是进程的唯一标识",{"2":{"806":1}}],["是整个文件系统的起点",{"2":{"738":1}}],["是论文",{"2":{"645":1}}],["是选择可训练式的还是三角函数式的",{"2":{"643":1}}],["是位置向量的维度",{"2":{"640":1}}],["是线性序列",{"2":{"626":1}}],["是第一个可以在",{"2":{"621":1}}],["是第一个在",{"2":{"619":1}}],["是第一个基于",{"2":{"619":1}}],["是第t步的输出",{"2":{"137":1}}],["是有开销的",{"2":{"571":1}}],["是有输入的",{"2":{"462":1}}],["是两种不同的计算图表示形式",{"2":{"559":1}}],["是具有与之相关联的反向图的张量",{"2":{"475":1}}],["是view的base",{"2":{"468":1}}],["是个数字",{"2":{"468":1}}],["是个flag",{"2":{"468":1}}],["是个node实例",{"2":{"468":1}}],["是需要计算权重并保存梯度的",{"2":{"465":1}}],["是否是层层深入的关系我们先不去探讨",{"2":{"878":1}}],["是否是同一个tensor",{"2":{"437":1}}],["是否处于训练模式",{"2":{"490":1}}],["是否生成模块的补丁列表",{"2":{"490":1}}],["是否全为",{"2":{"444":1}}],["是否有任何试验显示过拟合",{"2":{"375":1}}],["是我们在用作迭代调优过程的一部分时优于更高级的黑盒优化工具",{"2":{"401":1}}],["是我们的llm推理和服务引擎背后的核心技术",{"2":{"335":1}}],["是非常重要的",{"2":{"395":1}}],["是不同的张量对象",{"2":{"472":1}}],["是不同的条件超参数",{"2":{"369":1}}],["是不是很符合人的本性",{"2":{"967":1}}],["是不是",{"2":{"462":1}}],["是不是就完事儿了呢",{"2":{"190":1}}],["是更好的选择吗",{"2":{"369":1}}],["是使用尽可能大的batch",{"2":{"359":1}}],["是将本来依赖于二元坐标",{"2":{"643":1}}],["是将四张图片进行随机裁剪",{"2":{"344":1}}],["是将序列",{"2":{"167":1}}],["是必要的",{"2":{"329":1}}],["是注意力的变体",{"2":{"323":1}}],["是下投影矩阵",{"2":{"309":1}}],["是键",{"2":{"309":1}}],["是另一种学习率自适应的优化算法",{"2":{"294":1}}],["是对",{"2":{"287":1}}],["是对多层人工神经网络进行梯度下降的算法",{"2":{"25":1}}],["是介于批量梯度下降",{"2":{"262":1}}],["是损失函数j关于参数θ的梯度向量",{"2":{"258":1}}],["是上一层通过relu得到的",{"2":{"248":1}}],["是赋值符号",{"2":{"225":1,"313":1}}],["是头维度",{"2":{"223":1,"312":1}}],["是序列长度",{"2":{"223":1,"312":1}}],["是指每次做选择时",{"2":{"921":1}}],["是指在并发环境中",{"2":{"681":1}}],["是指将具有多头注意力的语言模型转换为具有多查询注意力的模型",{"2":{"220":1,"306":1}}],["是指对已有的模型进行进一步的训练",{"2":{"220":1,"306":1}}],["是为了使得",{"2":{"216":1}}],["是每帧的声音信号",{"2":{"160":1}}],["是同一份数据吗",{"2":{"138":1}}],["是前馈神经网络在处理序列数据时的一种自然推广",{"2":{"132":1}}],["是在原来的sd模型的基础上增加了clip的image",{"2":{"608":1}}],["是在relu",{"2":{"123":1}}],["是在同一时间工作的",{"2":{"122":1}}],["是沿着那个轴进行split",{"2":{"110":1}}],["是torch",{"2":{"104":1}}],["是split",{"2":{"104":1}}],["是cnn",{"2":{"92":1}}],["是一组电脑",{"2":{"796":1}}],["是一款优秀的持久层框架",{"2":{"721":1}}],["是一个被先贤们整理好的册子",{"2":{"878":1}}],["是一个由vitepress构建的静态网页",{"2":{"856":1,"860":1}}],["是一个半自动化的orm框架",{"2":{"724":1}}],["是一个正交矩阵",{"2":{"647":1}}],["是一个实现各种优化算法的包",{"2":{"501":1}}],["是一个很复杂的问题",{"2":{"481":1}}],["是一个很好的选择",{"2":{"410":1}}],["是一个标志",{"2":{"475":1}}],["是一个方法",{"2":{"441":1}}],["是一个用于深层神经网络的gpu加速库",{"2":{"75":1}}],["是一种很正常很常见的事情",{"2":{"878":1}}],["是一种中间表示形式",{"2":{"562":1}}],["是一种用于评估生成图像质量的度量标准",{"2":{"606":1}}],["是一种用于在不同深度学习框架之间交换数据的标准化格式",{"2":{"441":2}}],["是一种用于初始化神经网络权重的方法",{"2":{"244":1}}],["是一种数据结构",{"2":{"338":1}}],["是一种在序列长度维度上的并行化方案",{"2":{"328":1}}],["是一种被证明的技术",{"2":{"325":1}}],["是一种基于随机采样的梯度下降优化算法",{"2":{"261":1}}],["是一种基本的梯度下降优化算法",{"2":{"260":1}}],["是一种常用的优化算法",{"2":{"258":1}}],["是一种attention机制",{"2":{"193":1}}],["是一种时间循环神经网络",{"2":{"144":1}}],["是一种人工神经网络中常用的激励函数",{"2":{"122":1}}],["是一种前馈神经网络",{"2":{"51":1}}],["是一种专门用来处理具有类似网格结构的数据的神经网络",{"2":{"51":1}}],["是一种深度学习架构",{"2":{"21":1}}],["是一种能有效的处理序列数据的算法",{"2":{"21":1}}],["是一种自适应系统",{"2":{"5":1}}],["是一种模仿生物神经网络",{"2":{"5":1}}],["是一种以人工神经网络为架构",{"2":{"4":1}}],["是nvidia打造的针对深度神经网络的加速库",{"2":{"75":1}}],["是显卡的核心芯片",{"2":{"74":1}}],["是由子层本身实现的函数",{"2":{"196":1}}],["是由nvidia推出的通用并行计算架构",{"2":{"74":1}}],["是由两层神经元组成的结构",{"2":{"10":1}}],["是增大了计算量还是减小了计算量",{"2":{"55":1}}],["是几维的",{"2":{"55":1}}],["是",{"2":{"54":1,"703":1,"705":1}}],["是典型的深度学习模型",{"2":{"6":1}}],["是学习一个特征的技术的集合",{"2":{"4":1}}],["是机器学习的分支",{"2":{"4":1}}],["英语",{"2":{"4":1,"5":1,"25":1,"144":1,"680":2,"797":1}}],["nurl",{"2":{"799":1}}],["null",{"2":{"726":3}}],["numel",{"2":{"445":1}}],["num",{"2":{"445":3,"493":1,"497":1,"498":19,"499":2,"500":27,"541":1,"581":1,"632":1,"633":14,"634":16,"636":1,"904":4}}],["numbers",{"2":{"556":1,"895":1}}],["number",{"2":{"443":11,"444":2,"445":125,"468":1,"497":1,"556":2,"590":4,"901":1,"904":2}}],["numpy2",{"2":{"430":1}}],["numpy",{"2":{"50":1,"86":1,"430":17,"436":3,"437":1,"441":2,"445":1,"556":5,"570":2,"575":1}}],["n−m​d​​w​k​​x​n​​",{"2":{"647":1}}],["n−mdwkxnq",{"2":{"647":1}}],["nbest",{"2":{"634":23}}],["nbsp",{"2":{"4":16,"5":24,"6":8,"8":8,"9":8,"10":8,"11":8,"13":16,"14":8,"15":8,"18":8,"24":8,"25":8,"29":24,"36":8,"44":7,"51":40,"52":16,"54":16,"55":8,"56":8,"57":16,"58":24,"59":16,"60":8,"61":8,"65":8,"73":8,"74":8,"75":8,"89":8,"91":8,"92":8,"93":16,"94":8,"95":24,"98":8,"99":8,"100":8,"101":8,"102":8,"104":8,"105":8,"106":8,"107":8,"108":8,"110":8,"113":8,"114":8,"117":24,"120":56,"121":8,"122":16,"123":16,"124":8,"125":8,"126":8,"127":8,"128":16,"129":8,"130":8,"132":24,"133":16,"142":16,"143":16,"144":8,"145":8,"147":8,"148":8,"149":8,"150":8,"156":32,"160":16,"161":8,"163":8,"164":24,"165":16,"167":16,"168":16,"170":16,"171":8,"172":8,"173":8,"174":24,"176":16,"177":8,"178":8,"179":8,"180":24,"181":24,"183":24,"184":16,"185":16,"186":24,"188":8,"190":48,"191":16,"193":40,"194":16,"196":8,"197":8,"198":8,"202":8,"203":8,"206":8,"208":8,"210":8,"213":16,"214":8,"215":16,"216":16,"217":24,"219":32,"220":8,"222":16,"223":24,"224":16,"225":24,"226":16,"227":8,"228":8,"230":8,"233":16,"235":16,"236":24,"237":8,"238":8,"239":16,"240":16,"243":8,"244":8,"245":40,"246":8,"248":88,"249":16,"256":8,"258":8,"260":8,"261":8,"262":8,"263":8,"269":16,"271":8,"276":8,"277":16,"283":16,"287":8,"292":8,"294":8,"303":24,"305":32,"306":8,"308":16,"311":24,"312":24,"313":24,"314":8,"315":16,"316":24,"317":24,"318":8,"320":8,"321":8,"323":8,"325":8,"326":16,"327":16,"328":48,"329":48,"330":8,"332":24,"333":16,"334":16,"335":32,"337":16,"338":24,"340":8,"341":16,"343":8,"344":8,"345":8,"346":16,"347":8,"348":8,"470":8,"471":24,"472":48,"473":8,"474":8,"475":48,"476":8,"477":16,"478":24,"479":40,"480":32,"481":32,"492":8,"501":8,"503":16,"504":32,"505":24,"507":32,"510":24,"531":16,"559":36,"560":18,"562":9,"563":36,"564":9,"565":9,"605":8,"606":24,"609":16,"616":64,"617":48,"618":8,"619":32,"620":32,"621":24,"622":8,"624":32,"626":32,"627":24,"628":24,"630":8,"638":8,"639":8,"640":24,"641":24,"642":8,"643":40,"644":48,"645":16,"646":40,"647":32,"648":32,"652":16,"653":24,"654":16,"655":16,"656":8,"657":8,"658":8,"659":24}}],["nsp",{"2":{"619":3}}],["nsecond",{"2":{"459":1}}],["nccl",{"2":{"587":1,"588":1,"589":2}}],["ncall",{"2":{"459":1}}],["nhql",{"2":{"499":1}}],["nkhd",{"2":{"499":1}}],["nqhd",{"2":{"499":1}}],["nlg",{"2":{"621":3}}],["nlu",{"2":{"619":2,"621":3,"622":1}}],["nlhd",{"2":{"499":1}}],["nll",{"2":{"497":2}}],["nlp面经",{"0":{"964":1}}],["nlp",{"0":{"187":1,"188":1},"1":{"188":1,"189":1,"190":1,"191":1},"2":{"87":1,"126":1,"160":1,"171":1,"188":1,"344":1,"616":2,"619":2,"622":2,"671":4,"897":1}}],["ntest",{"2":{"497":1}}],["nt",{"2":{"444":1}}],["nr",{"2":{"440":2,"468":2}}],["n=num",{"2":{"326":1}}],["n=k×k×cn=k",{"2":{"248":1}}],["n=1024",{"2":{"223":1,"312":1}}],["ni+1var",{"2":{"245":1}}],["nivar",{"2":{"245":1}}],["n​d​​w​k​​x​n​​",{"2":{"647":1}}],["n​i+1​​var",{"2":{"245":1}}],["n​i​​var",{"2":{"245":1}}],["n​2​​d​2​​m​−1​​",{"2":{"227":1,"317":1}}],["n​2​​",{"2":{"223":1,"312":1,"621":1}}],["ndwkxn",{"2":{"647":1}}],["ndimension",{"2":{"445":1}}],["ndim",{"2":{"440":1}}],["ndarrays",{"2":{"556":1}}],["ndarray",{"2":{"430":7,"436":1,"441":1}}],["nd×n",{"2":{"248":1}}],["nd+n​2​​",{"2":{"227":1,"317":1}}],["nd+n2",{"2":{"227":1,"317":1}}],["nd",{"2":{"227":1,"317":1,"436":5}}],["n^2d^2m^",{"2":{"227":1,"317":1}}],["n^",{"2":{"223":1,"227":1,"312":1,"317":1,"621":1}}],["n2d2m−1",{"2":{"227":1,"317":1}}],["n2",{"2":{"223":1,"312":1,"621":1}}],["n×d",{"2":{"223":2,"224":2,"311":2,"312":2}}],["nmt就是这样",{"2":{"191":1}}],["nmt",{"0":{"191":1},"2":{"189":1}}],["n的结构可以处理的问题有",{"2":{"164":1}}],["nat服务未开启",{"2":{"911":1}}],["nat模式",{"2":{"910":1}}],["natural",{"2":{"897":1}}],["narrow",{"2":{"445":3}}],["nabla",{"2":{"414":1,"415":1,"416":2,"417":2,"418":2,"419":3}}],["nadam",{"0":{"419":1},"2":{"356":1}}],["nado",{"2":{"350":1,"421":1}}],["nag",{"0":{"268":1},"1":{"269":1,"270":1,"271":1},"2":{"270":1}}],["nansum",{"2":{"445":1}}],["nanquantile",{"2":{"445":2}}],["nanmedian",{"2":{"445":5}}],["nanmean",{"2":{"445":1}}],["nan",{"2":{"122":1,"379":1,"408":1,"445":6,"473":2}}],["name>",{"2":{"734":2}}],["name=",{"2":{"726":4,"732":1}}],["namespace=",{"2":{"726":1}}],["namespace",{"0":{"729":1},"2":{"726":1}}],["names=",{"2":{"441":1}}],["names",{"2":{"440":1,"441":7,"445":7,"734":2}}],["named",{"2":{"188":1,"496":5}}],["name",{"2":{"26":1,"50":1,"496":8,"497":1,"498":1,"500":1,"529":7,"570":1,"578":1,"636":2,"726":1,"730":2,"731":2,"732":1,"765":1,"770":2}}],["nostatic",{"2":{"889":1}}],["noisy",{"2":{"595":2}}],["noiser",{"0":{"599":1}}],["noise",{"2":{"381":1,"595":3}}],["now",{"2":{"556":1}}],["node0",{"2":{"589":2}}],["nodes",{"0":{"589":1},"2":{"590":1}}],["node",{"0":{"588":1},"2":{"440":1,"468":1,"589":2,"590":5,"823":1}}],["norouzi",{"2":{"420":1}}],["norm3",{"2":{"500":2}}],["norm2",{"2":{"498":2,"499":2,"500":4}}],["norm1",{"2":{"498":2,"499":2,"500":4}}],["normal",{"2":{"445":2}}],["normalizer",{"2":{"633":1}}],["normalize",{"2":{"497":1,"580":1}}],["normalized",{"2":{"86":2,"87":2,"88":2,"89":2,"445":1,"493":2}}],["normalization对小batchsize效果差",{"2":{"89":1}}],["normalization",{"0":{"85":1,"88":1,"89":1},"1":{"86":1,"87":1,"88":1,"89":1,"90":1,"91":1},"2":{"91":4,"499":1,"585":1}}],["norm相当于白化",{"2":{"406":1}}],["norm代替",{"2":{"394":1}}],["norm通常可以用layer",{"2":{"394":1}}],["norm采用固定值的batch",{"2":{"362":1}}],["norm会对batch",{"0":{"362":1}}],["norm",{"0":{"90":1,"91":1},"2":{"87":2,"91":2,"362":1,"394":3,"406":1,"441":2}}],["norm可能得到的效果会更好",{"2":{"86":1}}],["no",{"2":{"113":1,"369":1,"444":1,"453":2,"455":1,"456":2,"462":1,"473":1,"474":2,"476":1,"497":5}}],["nonzero",{"2":{"443":1,"445":7}}],["none",{"2":{"87":4,"95":1,"215":2,"443":9,"444":10,"445":234,"490":1,"493":3,"496":17,"498":1,"499":1,"500":1,"509":23,"552":1,"570":1,"590":1,"634":2,"799":1}}],["non",{"2":{"80":2,"81":1,"93":1,"94":1,"444":1,"445":7,"490":2,"496":5,"581":1}}],["notes",{"2":{"556":1}}],["note",{"2":{"421":1,"504":1,"547":1,"556":1,"586":1}}],["not",{"2":{"11":1,"99":1,"106":1,"215":2,"333":1,"441":11,"445":8,"497":2,"498":1,"499":1,"500":1,"508":1,"556":2,"726":1}}],["nnz",{"2":{"444":1}}],["nn",{"0":{"480":1,"482":1,"483":1,"484":1,"489":1,"490":1,"491":1,"496":1},"1":{"484":1,"485":1,"492":1,"493":1,"494":1,"495":1,"496":1},"2":{"80":5,"81":6,"83":3,"86":2,"87":3,"88":2,"89":3,"93":4,"94":4,"95":5,"113":4,"114":1,"121":4,"122":2,"123":1,"124":3,"125":2,"126":1,"127":1,"128":1,"129":1,"454":1,"467":1,"474":1,"475":3,"478":1,"480":2,"482":1,"483":1,"484":6,"487":12,"488":1,"489":6,"492":3,"493":3,"494":4,"495":4,"496":4,"497":23,"498":17,"499":21,"500":29,"513":10,"567":4,"568":1,"575":2,"580":1,"649":1,"904":7}}],["nns",{"2":{"5":1}}],["nvidia公司提供的gpu并行计算框架",{"2":{"802":1}}],["nvidia",{"0":{"72":1},"1":{"73":1,"74":1,"75":1},"2":{"69":1,"73":1,"320":1}}],["np",{"2":{"50":17,"86":4,"87":3,"88":3,"89":4,"430":6,"436":1,"556":2,"575":1,"576":2,"822":1,"827":1}}],["n",{"0":{"162":2,"163":1,"164":1,"165":1},"2":{"8":1,"50":2,"83":3,"161":2,"165":1,"181":1,"194":2,"223":8,"226":4,"228":2,"239":3,"240":3,"245":11,"247":2,"248":4,"249":3,"251":2,"252":4,"309":2,"312":8,"315":1,"318":2,"326":1,"382":1,"392":2,"436":2,"445":5,"459":3,"487":1,"497":5,"499":13,"576":8,"581":1,"590":15,"616":1,"626":4,"627":2,"646":11,"647":5,"748":2,"786":2,"789":1,"823":1,"827":8,"959":6}}],["neo",{"2":{"620":2}}],["next",{"2":{"580":1,"581":2,"619":1,"632":4,"633":6,"634":10}}],["nextafter",{"2":{"445":2}}],["nelement",{"2":{"445":1}}],["nestedtensor",{"2":{"444":1}}],["nestedtensors",{"2":{"444":1}}],["nested",{"2":{"444":9,"445":1}}],["nesterov",{"0":{"268":1,"416":1},"1":{"269":1,"270":1,"271":1},"2":{"269":1,"356":1,"369":4,"370":2}}],["ne",{"2":{"443":1,"445":4}}],["negative",{"2":{"445":2}}],["neginf",{"2":{"445":2}}],["neg",{"2":{"441":2,"443":1,"444":1,"445":4}}],["neq",{"2":{"248":1}}],["newuser",{"2":{"763":2}}],["newfile",{"2":{"743":1}}],["new>",{"2":{"441":3}}],["new",{"2":{"226":4,"441":1,"445":14,"511":2,"555":1,"556":20,"581":1,"726":1,"730":1,"731":1,"753":2,"787":7,"893":1,"896":1,"899":1}}],["needed",{"2":{"894":1}}],["needs",{"2":{"499":1}}],["need",{"0":{"193":1},"2":{"217":1,"255":1,"303":1,"333":1,"556":4,"616":1}}],["ner",{"0":{"623":1},"1":{"624":1,"625":1,"626":1,"627":1,"628":1,"629":1,"630":1},"2":{"162":1,"188":1,"613":2}}],["netstat",{"2":{"760":1}}],["net的前世今生与核心知识",{"2":{"610":1}}],["net1",{"2":{"497":3}}],["netron",{"2":{"212":1}}],["neto1net",{"2":{"44":1}}],["neto1=w7×outh1+w9×outh2+w11×outh3+b2∗1net",{"2":{"45":1}}],["neto1=w7×outh1+w9×outh2+w11×outh3+b2×1net",{"2":{"41":1}}],["neto1=0",{"2":{"41":1}}],["net​o1​​",{"2":{"44":1}}],["net​o1​​=w​7​​×out​h1​​+w​9​​×out​h2​​+w​11​​×out​h3​​+b​2​​∗1",{"2":{"45":1}}],["net​o1​​=w​7​​×out​h1​​+w​9​​×out​h2​​+w​11​​×out​h3​​+b​2​​×1",{"2":{"41":1}}],["net​o1​​=0",{"2":{"41":1}}],["net​h1​​=0",{"2":{"40":1}}],["net​h1​​=w​1​​×l​1​​+w​2​​×l​2​​+b​1​​∗1",{"2":{"40":1}}],["net",{"2":{"40":1,"41":1,"44":2,"45":9,"46":8,"50":5,"460":4,"462":1,"497":2,"513":2,"514":1,"515":1,"518":1,"522":1,"523":1,"525":1,"546":1,"579":2,"584":2,"613":1}}],["neth1=0",{"2":{"40":1}}],["neth1=w1×l1+w2×l2+b1∗1net",{"2":{"40":1}}],["network提取真实数据和生成数据的特征向量",{"2":{"606":1}}],["networks",{"2":{"543":1,"544":1,"556":1}}],["network",{"0":{"0":1,"132":1},"2":{"5":2,"6":2,"13":2,"24":1,"51":3,"75":1,"132":1,"167":1,"498":1,"500":2,"671":3,"904":3,"915":1}}],["neural",{"0":{"0":1,"132":1,"661":1},"2":{"5":2,"6":1,"13":2,"24":1,"51":2,"75":1,"132":1,"167":1,"189":1,"543":1,"544":1,"556":1,"671":2,"904":3}}],["3e",{"2":{"636":1}}],["31",{"2":{"636":1}}],["3101",{"2":{"456":1}}],["3所示那样",{"2":{"403":1}}],["384",{"2":{"328":8,"636":1}}],["3=1843264×32×3×3=18432",{"2":{"248":1}}],["3节",{"2":{"176":1}}],["34",{"2":{"126":1}}],["348993",{"2":{"47":2}}],["348993w",{"2":{"47":1}}],["3rd",{"2":{"99":1}}],["3081",{"2":{"497":1}}],["300",{"2":{"460":1,"576":1}}],["30",{"2":{"83":2,"487":3,"533":1,"535":1,"537":2,"538":3,"584":1,"585":1,"619":1,"671":1,"726":2,"868":1,"939":1}}],["3306",{"2":{"726":1}}],["3330",{"2":{"112":1}}],["33",{"2":{"80":3,"81":2}}],["3d场景需要经过投影转化为2d图像",{"2":{"857":1}}],["3d图形渲染",{"2":{"857":1}}],["3d卷积核有三个维度",{"2":{"65":1}}],["3d",{"0":{"65":1}}],["32x4d",{"2":{"590":1}}],["32x8d",{"2":{"590":1}}],["32gf",{"2":{"590":2}}],["3270",{"2":{"112":1}}],["32",{"2":{"63":2,"93":1,"94":1,"248":4,"328":12,"444":1,"497":2,"500":1,"513":2,"590":2,"904":3}}],["323201",{"2":{"48":3}}],["3x1",{"2":{"59":1}}],["3x3",{"2":{"59":1}}],["396402",{"2":{"48":3}}],["391829",{"2":{"41":2}}],["391829e",{"2":{"41":1}}],["375711",{"2":{"48":3}}],["379850",{"2":{"48":3}}],["360968",{"2":{"47":5}}],["360968w",{"2":{"47":1}}],["360968=0",{"2":{"46":3}}],["35​​​​1​​=0",{"2":{"40":1}}],["35=0",{"2":{"40":1}}],["35",{"2":{"40":4,"47":3,"50":2,"86":1,"88":1,"460":1,"939":2}}],["35net",{"2":{"40":1}}],["35×1=2",{"2":{"40":2}}],["3",{"0":{"4":1,"10":1,"11":1,"12":1,"27":1,"33":1,"42":1,"43":1,"44":1,"45":1,"46":1,"53":1,"71":1,"75":1,"85":1,"86":1,"87":1,"88":2,"89":1,"90":1,"91":1,"95":1,"100":1,"106":1,"119":1,"123":1,"134":1,"135":1,"136":1,"137":2,"138":1,"139":1,"140":1,"141":1,"149":1,"152":1,"157":1,"164":1,"165":1,"171":1,"172":1,"173":1,"174":1,"180":1,"185":1,"190":1,"195":1,"196":1,"197":1,"201":1,"204":1,"210":1,"224":1,"237":1,"241":1,"249":1,"262":1,"267":1,"268":1,"269":1,"270":1,"271":2,"278":1,"285":1,"289":1,"296":1,"307":1,"308":1,"309":1,"313":1,"323":1,"334":1,"342":1,"343":1,"344":1,"345":2,"346":1,"347":1,"348":1,"349":1,"429":1,"432":1,"433":1,"434":1,"438":1,"445":1,"452":1,"461":1,"462":1,"463":1,"464":2,"465":1,"466":1,"467":1,"468":1,"469":1,"473":1,"479":1,"489":1,"494":1,"505":1,"509":1,"510":1,"515":1,"517":1,"518":1,"519":1,"520":2,"530":1,"534":1,"535":1,"536":1,"537":2,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"553":1,"560":1,"564":1,"566":1,"567":1,"568":1,"569":2,"574":1,"575":1,"576":1,"577":2,"584":1,"593":1,"594":1,"595":1,"596":2,"597":1,"598":1,"599":1,"615":1,"616":1,"617":1,"618":2,"619":1,"620":1,"621":1,"622":1,"628":1,"634":1,"638":1,"639":1,"640":1,"641":1,"642":1,"643":1,"644":1,"645":2,"646":2,"647":2,"648":3,"649":2,"654":1,"665":1,"678":1,"682":1,"688":1,"689":1,"690":1,"691":1,"692":2,"693":1,"694":1,"699":1,"710":1,"723":1,"729":1,"730":1,"731":2,"732":1,"733":1,"734":1,"744":1,"753":1,"778":1,"798":1,"804":1,"807":1,"813":1,"817":1,"821":1,"826":1,"827":1,"831":1,"841":1,"843":1,"844":1,"845":1,"846":2,"847":1,"848":1,"849":1,"850":1,"851":2,"852":1,"853":1,"887":1,"888":1,"889":1,"895":1,"898":1,"899":1,"900":1,"901":2,"911":1,"921":1,"923":1,"924":1,"925":1,"926":2,"933":1,"939":1,"940":1,"941":1,"942":1,"943":2,"947":1,"953":1,"971":1,"972":1,"973":1,"974":2},"1":{"11":1,"12":1,"43":1,"44":1,"45":1,"46":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1,"174":1,"196":1,"197":1,"202":1,"203":1,"204":1,"205":1,"269":1,"270":1,"271":1,"308":1,"309":1,"343":1,"344":1,"345":1,"346":1,"347":1,"348":1,"349":1,"433":1,"434":1,"462":1,"463":1,"464":1,"465":1,"466":1,"467":1,"468":1,"469":1,"518":1,"519":1,"520":1,"567":1,"568":1,"569":1,"575":1,"576":1,"577":1,"594":1,"595":1,"596":1,"597":1,"598":1,"599":1,"616":1,"617":1,"618":1,"619":1,"620":1,"621":1,"622":1,"639":1,"640":2,"641":2,"642":1,"643":2,"644":2,"645":1,"646":3,"647":3,"648":3,"649":3,"690":1,"691":1,"692":1,"693":1,"745":1,"746":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"827":1,"844":1,"845":1,"846":1,"847":1,"849":1,"850":1,"851":1,"852":1,"888":1,"889":1,"899":1,"900":1,"901":1,"924":1,"925":1,"926":1,"941":1,"942":1,"943":1,"972":1,"973":1,"974":1},"2":{"46":1,"47":1,"50":1,"58":3,"65":1,"80":4,"81":4,"84":5,"86":2,"87":2,"88":2,"89":5,"93":2,"94":2,"98":1,"99":2,"100":1,"101":1,"104":1,"105":2,"106":2,"107":1,"111":3,"113":10,"121":1,"124":1,"126":1,"129":1,"137":1,"248":5,"249":2,"325":1,"338":2,"339":1,"363":1,"369":1,"383":1,"403":1,"427":2,"428":3,"429":1,"430":2,"434":1,"436":2,"441":1,"450":2,"452":1,"453":3,"454":3,"455":1,"457":1,"460":2,"474":2,"484":3,"487":3,"489":1,"497":6,"504":2,"513":2,"528":1,"539":1,"540":1,"542":1,"548":1,"549":1,"556":1,"579":1,"580":2,"590":3,"608":1,"609":2,"620":6,"681":1,"694":1,"719":1,"721":2,"726":5,"822":1,"868":1,"904":1,"931":1,"933":3,"939":1,"943":3,"947":2,"958":1}}],["241207",{"2":{"908":1}}],["241125",{"2":{"907":1}}],["241111",{"2":{"907":1}}],["241108",{"2":{"875":1}}],["241013",{"2":{"907":1}}],["24年最新版本的有一些bug",{"2":{"883":1}}],["240910",{"2":{"868":1,"883":1}}],["24",{"2":{"671":1,"904":1}}],["246422",{"2":{"47":3}}],["22",{"2":{"671":1,"867":1,"868":1}}],["224",{"2":{"528":2,"556":3,"579":2,"580":2}}],["2i​​",{"2":{"640":1}}],["2i​​=sin",{"2":{"640":1}}],["2i+12i",{"2":{"640":2}}],["2i+1​​",{"2":{"640":1}}],["2i+1​​=cos",{"2":{"640":1}}],["2i+1p",{"2":{"640":1}}],["2i+1",{"2":{"640":2}}],["2i+1=cos",{"2":{"640":1}}],["2i",{"2":{"640":3}}],["2i=sin",{"2":{"640":1}}],["2x",{"2":{"609":2}}],["2x2",{"2":{"404":1}}],["2为初始权重",{"2":{"608":3}}],["2gf",{"2":{"590":2}}],["2f",{"2":{"567":1}}],["2fanout",{"2":{"251":1}}],["2fanin",{"2":{"251":1}}],["27",{"2":{"546":1,"671":1}}],["2d",{"2":{"440":2}}],["2^",{"2":{"418":1,"419":1}}],["2v",{"2":{"417":1,"418":1,"419":1,"862":1}}],["2var",{"2":{"247":2,"248":1}}],["23",{"2":{"403":1,"671":1,"719":1,"726":1,"868":2}}],["232×3×3",{"2":{"248":1}}],["2β​2​​",{"2":{"400":1}}],["2倍",{"2":{"335":1}}],["2算法",{"2":{"325":1}}],["2算法遵循简化的同步模型",{"2":{"325":1}}],["2以利用这些硬件特性",{"2":{"325":1}}],["2节的方程中",{"2":{"316":1}}],["2节中回顾了hopper在这些方向上提供的功能",{"2":{"325":1}}],["2节中",{"2":{"223":1,"312":1}}],["21",{"2":{"671":1,"868":3}}],["212",{"2":{"252":1}}],["214925",{"2":{"48":3}}],["26",{"2":{"546":1,"671":1,"868":1}}],["264×3×3",{"2":{"249":1}}],["262855",{"2":{"48":3}}],["2+",{"2":{"248":1}}],["2+var",{"2":{"247":1}}],["2+12",{"2":{"41":1}}],["2nin+nout",{"2":{"245":1}}],["2nd",{"2":{"99":1}}],["2b数据集上训练的clip",{"2":{"608":1}}],["2b",{"2":{"225":1,"313":1}}],["2在pytorch实现的注意力机制",{"2":{"222":1,"314":1}}],["2上最高可达7",{"2":{"222":1,"314":1}}],["2π",{"2":{"126":1}}],["29",{"2":{"671":1}}],["2959",{"2":{"112":1}}],["299497",{"2":{"47":3}}],["200",{"2":{"576":2}}],["20倍",{"2":{"316":1}}],["2025",{"0":{"872":1},"1":{"873":1,"874":1}}],["2024中获得国际认可",{"2":{"859":1}}],["2024",{"0":{"866":1,"869":1},"1":{"867":1,"868":1,"870":1,"871":1},"2":{"856":1,"875":1,"877":2,"880":1}}],["20241112173201855",{"2":{"843":2}}],["2023",{"2":{"308":1,"421":1}}],["2022",{"2":{"219":1,"305":1}}],["2035",{"2":{"112":1}}],["20",{"2":{"80":1,"81":1,"83":3,"86":1,"87":1,"88":1,"89":1,"93":1,"94":1,"114":1,"487":2,"500":1,"533":2,"546":3,"671":1,"726":1,"939":2,"947":1}}],["2013年11月迁移到github",{"2":{"721":1}}],["2018",{"2":{"357":1,"359":1,"363":1,"412":1}}],["2019",{"2":{"308":1}}],["2014",{"2":{"294":1}}],["2011",{"2":{"277":1}}],["2016",{"2":{"126":1}}],["2010年这个项目由apache",{"2":{"721":1}}],["2010s",{"2":{"189":1}}],["2010",{"2":{"122":1}}],["2012",{"2":{"57":1,"122":1,"283":1,"402":1}}],["2017年",{"2":{"127":1}}],["2017",{"2":{"21":1,"308":1,"616":1}}],["28=784维",{"2":{"652":1}}],["28",{"2":{"63":4,"489":4,"497":2,"515":2,"518":2,"519":2,"523":2,"525":2,"526":2,"652":1,"655":2,"671":1,"945":1,"947":1}}],["2y",{"2":{"50":1}}],["25开始",{"2":{"880":1}}],["256",{"2":{"497":3,"556":4,"590":1}}],["25",{"2":{"50":1,"121":1,"460":1,"497":1,"513":1,"522":1,"671":1,"706":1,"868":1,"871":1,"904":2,"947":1}}],["2=outo1",{"2":{"45":1}}],["2=11+e−net−1",{"2":{"45":1}}],["2=1+e−net−1",{"2":{"45":1}}],["2=0",{"2":{"41":1}}],["2−1∗−1+0=−",{"2":{"45":1}}],["2extract",{"2":{"584":1}}],["2e",{"2":{"45":1}}],["2",{"0":{"3":1,"7":1,"8":1,"9":2,"12":1,"15":1,"19":1,"25":1,"26":1,"32":1,"39":1,"40":1,"41":2,"45":1,"46":1,"52":1,"64":1,"68":1,"69":1,"70":2,"74":1,"78":1,"81":1,"82":1,"83":1,"84":2,"87":1,"94":1,"99":1,"105":1,"111":1,"118":1,"122":1,"133":1,"136":1,"146":1,"147":1,"148":2,"149":1,"150":1,"151":1,"156":1,"161":1,"162":1,"163":2,"164":1,"166":1,"167":1,"168":2,"169":2,"170":3,"171":2,"172":1,"177":1,"178":1,"179":2,"184":1,"189":1,"194":1,"197":1,"200":1,"202":1,"203":2,"204":1,"205":1,"209":1,"216":1,"220":1,"223":1,"229":1,"234":1,"235":1,"236":1,"240":1,"244":1,"248":1,"252":1,"259":1,"260":1,"261":2,"262":1,"263":1,"264":1,"265":2,"266":2,"267":1,"270":1,"274":1,"277":1,"284":1,"288":1,"292":1,"295":1,"300":1,"304":1,"305":1,"306":2,"309":1,"312":1,"320":1,"322":1,"333":1,"338":1,"341":1,"344":1,"428":1,"431":1,"434":1,"437":1,"444":1,"448":1,"449":1,"450":1,"451":2,"452":1,"453":1,"454":1,"455":1,"456":1,"457":1,"458":1,"459":1,"460":1,"463":1,"472":1,"478":1,"485":1,"486":1,"487":1,"488":2,"493":1,"504":1,"506":1,"507":1,"508":2,"509":1,"512":1,"513":1,"514":2,"515":1,"516":1,"519":1,"523":1,"526":1,"529":1,"532":1,"533":1,"536":1,"552":1,"559":1,"561":1,"562":1,"563":2,"564":1,"565":1,"568":1,"573":1,"576":1,"583":1,"592":1,"595":1,"602":1,"603":1,"606":1,"609":1,"614":1,"617":1,"625":1,"626":1,"627":2,"628":1,"629":1,"630":1,"633":1,"637":1,"641":1,"642":1,"643":1,"644":2,"647":2,"653":1,"658":1,"659":1,"664":1,"677":1,"681":1,"683":1,"684":1,"685":2,"686":2,"687":3,"688":2,"689":1,"690":1,"691":2,"692":1,"693":1,"698":1,"706":1,"709":1,"722":1,"726":1,"727":2,"730":1,"741":1,"752":1,"775":1,"797":1,"801":1,"802":2,"806":1,"813":1,"816":1,"820":1,"825":1,"830":1,"836":1,"837":1,"838":2,"839":2,"840":3,"841":2,"842":2,"843":1,"844":1,"845":2,"846":1,"847":1,"848":1,"849":1,"850":2,"851":1,"852":1,"879":1,"886":1,"889":1,"892":1,"893":1,"894":2,"895":1,"896":1,"897":1,"900":1,"904":1,"910":1,"914":1,"918":1,"919":1,"920":2,"921":1,"922":1,"925":1,"932":1,"936":1,"937":1,"938":2,"939":1,"942":1,"946":1,"952":1,"968":1,"969":1,"970":2,"973":1},"1":{"8":1,"9":1,"40":1,"41":1,"69":1,"70":1,"83":1,"84":1,"147":1,"148":1,"149":1,"150":1,"151":1,"162":1,"163":1,"164":1,"169":2,"170":2,"171":2,"172":2,"178":1,"179":1,"235":1,"236":1,"260":1,"261":1,"262":1,"264":1,"265":1,"266":1,"267":1,"305":1,"321":1,"322":1,"323":1,"324":1,"450":1,"451":1,"452":1,"453":1,"454":1,"455":1,"456":1,"457":1,"458":1,"459":1,"460":1,"487":1,"488":1,"507":1,"508":1,"509":1,"513":1,"514":1,"515":1,"516":1,"533":1,"534":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1,"550":1,"562":1,"563":1,"564":1,"565":1,"626":1,"627":1,"628":1,"630":1,"643":1,"644":1,"659":1,"684":1,"685":1,"686":3,"687":3,"688":3,"689":1,"690":2,"691":2,"692":2,"693":2,"742":1,"743":1,"776":1,"777":1,"837":1,"838":1,"839":3,"840":3,"841":3,"842":3,"843":1,"844":2,"845":2,"846":2,"847":2,"848":1,"849":2,"850":2,"851":2,"852":2,"893":1,"894":1,"895":1,"896":1,"897":1,"919":1,"920":1,"921":1,"922":1,"937":1,"938":1,"939":1,"969":1,"970":1},"2":{"11":1,"26":4,"40":4,"41":6,"45":8,"46":1,"47":2,"50":20,"80":4,"81":2,"84":1,"86":2,"87":2,"88":2,"89":3,"93":2,"94":2,"98":3,"99":3,"100":1,"101":2,"104":1,"105":2,"106":1,"107":1,"110":2,"111":5,"112":1,"113":5,"114":1,"121":3,"122":2,"123":1,"124":3,"125":2,"126":4,"127":2,"128":1,"129":1,"137":1,"161":2,"181":1,"185":2,"215":1,"223":1,"225":23,"227":2,"229":1,"245":3,"247":4,"248":21,"249":2,"251":2,"252":1,"312":1,"313":23,"317":2,"328":1,"338":1,"339":1,"356":1,"358":1,"363":1,"369":1,"376":1,"401":1,"402":1,"405":1,"418":2,"419":2,"427":2,"428":2,"429":1,"430":1,"433":1,"434":1,"436":2,"440":2,"443":1,"444":1,"445":3,"450":4,"452":2,"455":1,"456":2,"457":1,"459":1,"460":5,"472":1,"474":4,"484":10,"487":9,"497":4,"498":7,"499":1,"500":6,"504":2,"509":1,"513":1,"539":1,"540":1,"542":1,"545":1,"546":1,"548":1,"549":2,"552":1,"556":4,"567":2,"576":1,"589":2,"590":2,"606":5,"608":8,"609":1,"613":1,"619":1,"620":5,"621":1,"626":2,"633":1,"634":10,"635":3,"636":1,"640":4,"646":1,"647":7,"648":4,"649":11,"655":1,"671":1,"680":1,"694":1,"726":2,"822":1,"862":1,"868":1,"931":1,"933":4,"943":2,"947":1,"958":1}}],["1ystep=1",{"2":{"840":1}}],["1的直线进行讲解",{"2":{"836":1}}],["1mb",{"2":{"765":1}}],["1为什么要提出",{"0":{"676":1}}],["1为初始权重",{"2":{"608":1}}],["17",{"2":{"868":1}}],["1750",{"2":{"620":1}}],["1706",{"2":{"402":1}}],["1是在sd",{"2":{"608":1}}],["1时",{"2":{"535":1,"536":1}}],["1bit",{"2":{"433":2}}],["1^",{"2":{"418":1,"419":1}}],["1β​1​​",{"2":{"400":2}}],["1中的图表显示错误率",{"2":{"373":1}}],["1中提供了对mha",{"2":{"308":1}}],["1层的输出来求",{"2":{"248":1}}],["1和1附近的gradient都接近0",{"2":{"240":1}}],["1或1附近",{"2":{"240":1}}],["1k",{"2":{"227":1,"317":1}}],["1表示单个组",{"2":{"219":1,"305":1}}],["1e20",{"2":{"499":1}}],["1e9",{"2":{"215":2}}],["1e",{"2":{"86":1,"87":2,"88":1,"89":1,"445":5,"493":1,"504":3,"590":1,"635":6}}],["164",{"2":{"904":1}}],["16gf",{"2":{"590":2}}],["1603",{"2":{"122":1}}],["16",{"2":{"80":4,"81":8,"89":1,"93":1,"94":1,"99":1,"114":1,"248":2,"328":29,"579":1,"590":2,"634":13,"635":1}}],["1dk",{"2":{"206":1}}],["1d",{"2":{"65":1}}],["131",{"2":{"622":1}}],["1307",{"2":{"497":1}}],["13b中",{"2":{"333":1}}],["13b在nvidia",{"2":{"332":1}}],["13",{"0":{"65":1,"114":1,"230":1,"339":1,"547":1},"2":{"671":1,"867":1,"868":1,"874":1,"877":1}}],["18",{"2":{"63":1,"871":1}}],["1xstep=1",{"2":{"840":1}}],["1x3",{"2":{"59":1}}],["1x1",{"0":{"56":1},"2":{"56":2,"58":3,"404":1}}],["14模型",{"2":{"608":1}}],["14",{"0":{"66":1,"115":1,"231":1,"548":1},"2":{"50":5,"497":1,"580":4,"608":1,"671":1}}],["19",{"2":{"868":1}}],["19ugnloisklj9ibwbzfgldw",{"2":{"584":1}}],["1964",{"2":{"263":1}}],["1990s",{"2":{"189":1}}],["1992",{"2":{"112":1}}],["1950s",{"2":{"189":1}}],["198211",{"2":{"47":2}}],["198211w",{"2":{"47":1}}],["1943",{"2":{"8":2}}],["1−​max​epochs​​​​epoch​​",{"2":{"542":1}}],["1−epochmaxepochs",{"2":{"542":1}}],["1−β​2​​",{"2":{"418":1,"419":1}}],["1−β​1​​",{"2":{"418":1,"419":2}}],["1−β2",{"2":{"418":1,"419":1}}],["1−β1",{"2":{"418":1,"419":2}}],["1−ρ",{"2":{"417":2}}],["1−sigmoid",{"2":{"121":2}}],["1−0",{"2":{"46":2}}],["1−out​o2​​",{"2":{"46":1}}],["1−out​o1​​",{"2":{"44":1,"45":2,"46":1}}],["1−outo2",{"2":{"46":1}}],["1−outo1",{"2":{"44":1,"45":2,"46":1}}],["123456",{"2":{"726":1,"730":1}}],["127",{"2":{"588":1}}],["12nl^var",{"2":{"249":1}}],["12nlvar",{"2":{"248":1}}],["1264",{"2":{"112":1}}],["128gf",{"2":{"590":1}}],["128",{"2":{"58":1,"83":1,"227":1,"317":1,"328":1,"444":2,"497":7,"498":1,"500":1,"513":2,"556":1,"622":1,"636":1,"904":2}}],["12",{"0":{"62":1,"63":1,"64":1,"113":1,"229":1,"302":1,"336":1,"337":1,"338":1,"546":1,"771":1},"1":{"63":1,"64":1,"337":1,"338":1,"772":1},"2":{"45":1,"47":1,"81":2,"252":1,"622":1,"636":1,"671":1,"868":1,"870":1,"871":1}}],["1+",{"2":{"545":1}}],["1+cos",{"2":{"545":2,"546":3}}],["1+tanh",{"2":{"126":2}}],["1+e​x​​",{"2":{"128":1}}],["1+e​−net​​",{"2":{"45":3}}],["1+ex",{"2":{"128":1}}],["1+e−net",{"2":{"45":3}}],["1+e^",{"2":{"40":2,"41":2,"45":6,"128":1}}],["1+0=",{"2":{"45":1}}],["118",{"2":{"904":1}}],["110",{"2":{"621":1}}],["11",{"0":{"61":1,"112":1,"131":1,"221":1,"222":1,"223":1,"224":1,"225":1,"226":1,"228":1,"301":1,"331":1,"332":1,"333":1,"334":1,"335":1,"460":1,"545":1,"769":1,"869":1,"961":1},"1":{"222":1,"223":1,"224":1,"225":1,"226":1,"227":1,"228":1,"332":1,"333":1,"334":1,"335":1,"770":1,"870":1,"871":1},"2":{"41":1,"45":2,"47":1,"50":5,"671":1,"867":1,"868":2,"870":3,"871":6,"875":2,"877":1,"880":1}}],["1024",{"2":{"492":1}}],["10bit",{"2":{"433":1}}],["105",{"2":{"409":1}}],["104",{"2":{"409":1}}],["103",{"2":{"409":1}}],["10倍",{"2":{"547":1}}],["10倍大小的",{"2":{"409":1}}],["10倍的峰值学习率来训练模型中产生的训练损失是如何通过双重检查的",{"2":{"408":1}}],["10x7",{"2":{"95":1}}],["100kb",{"2":{"227":1,"317":1}}],["100",{"2":{"50":2,"80":1,"81":1,"86":3,"88":3,"403":1,"430":1,"445":2,"456":3,"457":1,"460":1,"484":1,"487":2,"497":2,"533":1,"535":1,"536":1,"537":1,"538":1,"539":1,"540":1,"542":1,"545":1,"548":1,"549":1,"552":2,"567":3,"620":1,"621":3,"939":1}}],["100000",{"2":{"827":1}}],["10000",{"2":{"649":1}}],["10000^",{"2":{"640":2}}],["1000",{"2":{"48":1,"50":1,"497":1,"500":2}}],["1000次时对应的权重为",{"2":{"48":1}}],["1019206​​​​1​​=0",{"2":{"41":1}}],["1019206=0",{"2":{"41":1}}],["1019206",{"2":{"41":3}}],["1019206net",{"2":{"41":1}}],["10",{"0":{"60":1,"109":1,"110":1,"111":1,"130":1,"218":1,"219":1,"220":1,"255":1,"298":1,"299":1,"300":1,"330":1,"459":1,"544":1,"717":1,"767":1,"866":1,"960":1},"1":{"110":1,"111":1,"219":1,"299":1,"300":1,"768":1,"867":1,"868":1},"2":{"40":1,"45":1,"47":1,"50":1,"84":4,"87":1,"89":2,"95":2,"110":1,"111":2,"113":3,"409":1,"428":1,"460":1,"484":1,"487":3,"489":1,"492":1,"493":1,"494":2,"495":2,"497":3,"498":1,"500":1,"513":1,"522":1,"543":1,"544":1,"547":1,"552":1,"555":1,"567":2,"568":1,"569":2,"570":2,"571":4,"585":1,"590":1,"609":2,"635":6,"671":1,"853":2,"867":4,"868":18,"877":2,"904":2,"945":1,"947":1}}],["1572",{"2":{"456":1}}],["15",{"0":{"116":1,"232":1,"549":1},"2":{"40":1,"50":1,"445":1,"460":1,"671":1,"877":1,"939":2}}],["15×10+0",{"2":{"40":2}}],["1×5+0",{"2":{"40":2}}],["1",{"0":{"1":1,"2":2,"3":1,"4":1,"5":1,"6":1,"8":1,"11":1,"14":1,"18":1,"23":1,"24":2,"25":1,"31":1,"38":1,"40":1,"43":1,"44":2,"45":1,"51":1,"63":1,"67":1,"69":1,"73":1,"77":1,"79":1,"80":2,"81":1,"83":1,"86":1,"93":1,"98":1,"104":1,"110":1,"117":1,"121":1,"135":1,"145":1,"147":1,"155":1,"159":1,"160":2,"161":1,"162":2,"163":2,"164":2,"165":1,"167":1,"169":1,"174":1,"176":1,"178":1,"183":1,"188":1,"193":1,"196":1,"199":1,"202":1,"208":1,"215":1,"219":1,"222":1,"233":1,"235":1,"236":1,"239":1,"243":1,"247":1,"251":1,"257":1,"258":2,"259":1,"260":2,"261":1,"262":1,"264":1,"269":1,"273":1,"276":1,"283":1,"287":1,"291":1,"294":1,"299":1,"303":1,"305":1,"308":1,"311":1,"314":1,"321":1,"327":1,"332":1,"337":1,"340":1,"343":1,"426":1,"427":2,"428":1,"429":1,"430":1,"433":1,"436":1,"443":1,"446":1,"447":2,"448":1,"450":1,"462":1,"471":1,"477":1,"483":1,"484":2,"485":1,"487":1,"492":1,"497":1,"502":1,"503":2,"504":1,"505":1,"507":1,"511":1,"513":1,"518":1,"522":1,"525":1,"528":1,"533":1,"535":1,"551":1,"555":1,"557":1,"558":2,"559":1,"560":1,"562":1,"567":1,"572":1,"575":1,"582":1,"591":1,"594":1,"601":1,"605":1,"608":1,"613":1,"616":1,"624":1,"626":1,"632":1,"636":1,"639":1,"640":2,"641":1,"643":1,"646":1,"651":1,"652":2,"653":1,"654":1,"655":1,"656":1,"657":1,"659":1,"663":1,"674":1,"675":1,"676":1,"677":1,"678":1,"679":1,"680":2,"681":1,"682":1,"684":1,"686":1,"690":1,"697":1,"705":1,"708":1,"721":2,"722":1,"723":1,"724":1,"726":1,"729":1,"737":1,"751":1,"774":1,"796":2,"797":1,"798":1,"799":1,"801":1,"804":1,"805":1,"815":1,"819":1,"824":1,"827":1,"829":1,"835":1,"837":1,"839":1,"844":1,"849":1,"877":1,"878":2,"879":1,"884":1,"885":2,"886":1,"887":1,"888":2,"889":1,"891":1,"893":1,"899":1,"903":1,"909":1,"913":1,"917":1,"919":1,"924":1,"930":1,"931":2,"932":1,"933":1,"934":1,"937":1,"941":1,"945":1,"951":1,"967":1,"969":1,"972":1},"1":{"2":1,"3":1,"4":1,"5":1,"6":1,"24":1,"25":1,"80":1,"81":1,"160":1,"161":1,"162":2,"163":2,"164":2,"165":1,"258":1,"259":1,"260":2,"261":2,"262":2,"295":1,"296":1,"297":1,"427":1,"428":1,"429":1,"430":1,"447":1,"448":1,"484":1,"485":1,"503":1,"504":1,"505":1,"558":1,"559":1,"560":1,"640":1,"641":1,"652":1,"653":1,"654":1,"655":1,"656":1,"657":1,"675":1,"676":2,"677":2,"678":2,"679":2,"680":3,"681":3,"682":3,"683":1,"684":1,"685":1,"686":1,"687":1,"688":1,"689":1,"690":1,"691":1,"692":1,"693":1,"694":1,"738":1,"739":1,"740":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"878":1,"879":1,"888":1,"889":1,"931":1,"932":1,"933":1,"934":1},"2":{"4":1,"9":3,"11":1,"26":1,"40":10,"41":5,"44":1,"45":10,"46":7,"47":2,"48":8,"50":15,"58":1,"60":1,"80":3,"81":2,"86":2,"87":4,"89":2,"93":1,"94":1,"95":4,"98":2,"99":5,"100":1,"101":1,"104":1,"106":3,"107":1,"110":1,"111":3,"112":12,"113":5,"121":6,"122":1,"124":2,"125":2,"126":5,"128":1,"129":1,"138":1,"147":2,"148":4,"161":2,"168":2,"181":2,"185":5,"194":3,"206":1,"209":1,"215":3,"225":24,"226":7,"227":2,"240":2,"245":4,"247":2,"248":14,"249":1,"274":1,"313":24,"317":2,"322":1,"326":1,"327":2,"328":2,"338":1,"345":3,"356":1,"363":1,"369":1,"373":1,"383":1,"402":1,"403":1,"404":1,"417":2,"418":6,"419":9,"421":1,"427":2,"428":2,"429":1,"430":2,"433":1,"434":1,"436":3,"440":3,"444":3,"445":43,"450":2,"455":2,"456":3,"457":3,"460":4,"462":1,"468":1,"473":3,"474":2,"484":8,"487":11,"490":1,"493":14,"494":1,"495":4,"497":19,"498":15,"499":4,"500":22,"509":1,"513":4,"515":2,"518":2,"519":2,"523":2,"525":2,"526":2,"528":1,"529":2,"533":1,"537":2,"538":2,"539":2,"540":2,"541":2,"542":3,"543":2,"544":1,"545":2,"546":1,"547":1,"548":3,"549":5,"552":1,"556":2,"567":1,"569":2,"580":2,"581":1,"585":1,"588":2,"589":2,"590":3,"595":3,"606":2,"608":3,"620":1,"626":7,"627":2,"632":5,"633":9,"634":54,"647":4,"649":9,"655":1,"671":1,"677":1,"694":1,"726":3,"730":1,"732":1,"746":1,"797":1,"822":1,"827":6,"840":8,"841":1,"849":1,"853":1,"868":1,"931":1,"933":4,"943":2,"945":1,"947":2,"957":2,"958":4}}]],"serializationVersion":2}';export{t as default};
