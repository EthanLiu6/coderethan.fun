import{_ as i,c as a,o as n,a2 as t}from"./chunks/framework.DA-Pb-tg.js";const c=JSON.parse('{"title":"Introduction to PyTorch","description":"","frontmatter":{},"headers":[],"relativePath":"技术问题清单/专英翻转课堂—PyTorch.md","filePath":"技术问题清单/专英翻转课堂—PyTorch.md","lastUpdated":null}'),e={name:"技术问题清单/专英翻转课堂—PyTorch.md"};function h(l,s,r,p,o,k){return n(),a("div",null,s[0]||(s[0]=[t(`<h1 id="introduction-to-pytorch" tabindex="-1">Introduction to PyTorch <a class="header-anchor" href="#introduction-to-pytorch" aria-label="Permalink to &quot;Introduction to PyTorch&quot;">​</a></h1><div class="tip custom-block"><p class="custom-block-title">用途</p><p>仅使用于个人的专英课堂翻转，不过也算是基础了解PyTorch吧</p></div><h2 id="_1-what-is-pytorch" tabindex="-1">1. What is PyTorch? <a class="header-anchor" href="#_1-what-is-pytorch" aria-label="Permalink to &quot;1. What is PyTorch?&quot;">​</a></h2><p>PyTorch is a free, open-source tool developed by Facebook that helps people build and train artificial intelligence (AI) models. It’s especially useful for <strong>deep learning</strong>, a type of AI that tries to imitate how the human brain works to learn from large amounts of data. PyTorch is popular because it is simple to use, flexible, and allows for fast experiments, making it great for both research and real-world applications.</p><h2 id="_2-key-features-of-pytorch" tabindex="-1">2. Key Features of PyTorch <a class="header-anchor" href="#_2-key-features-of-pytorch" aria-label="Permalink to &quot;2. Key Features of PyTorch&quot;">​</a></h2><h3 id="_2-1-dynamic-computation-graphs" tabindex="-1">2.1. <strong>Dynamic Computation Graphs</strong> <a class="header-anchor" href="#_2-1-dynamic-computation-graphs" aria-label="Permalink to &quot;2.1. **Dynamic Computation Graphs**&quot;">​</a></h3><p>PyTorch uses <strong>dynamic computation graphs</strong>, meaning that it builds the graph of calculations step-by-step as you run the code. This makes it easy to try out new ideas, change the model, and find mistakes in the code while you’re working.</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/torch%E5%8A%A8%E6%80%81%E5%9B%BE.gif" alt="img"></p><h3 id="_2-2-autograd-automatic-gradient-calculation" tabindex="-1">2.2. <strong>Autograd (Automatic Gradient Calculation)</strong> <a class="header-anchor" href="#_2-2-autograd-automatic-gradient-calculation" aria-label="Permalink to &quot;2.2. **Autograd (Automatic Gradient Calculation)**&quot;">​</a></h3><p>PyTorch has a system called <strong>autograd</strong> that automatically calculates the gradients, which are needed to update the model during training. This makes training easier because you don’t have to do the math manually.</p><h3 id="_2-3-tensors" tabindex="-1">2.3. <strong>Tensors</strong> <a class="header-anchor" href="#_2-3-tensors" aria-label="Permalink to &quot;2.3. **Tensors**&quot;">​</a></h3><p>At the core of PyTorch are <strong>tensors</strong>, which are like special types of arrays (or lists of numbers). Tensors are used to store and process data. They can run on both a computer’s CPU or GPU, making it faster to train models, especially when working with big data.</p><h3 id="_2-4-easy-to-use-with-python" tabindex="-1">2.4. <strong>Easy to Use with Python</strong> <a class="header-anchor" href="#_2-4-easy-to-use-with-python" aria-label="Permalink to &quot;2.4. **Easy to Use with Python**&quot;">​</a></h3><p>PyTorch works really well with Python, a popular programming language. It’s designed to be intuitive and easy to write, so you can quickly test new ideas and build deep learning models.</p><h3 id="_2-5-rich-ecosystem-of-libraries" tabindex="-1">2.5. <strong>Rich Ecosystem of Libraries</strong> <a class="header-anchor" href="#_2-5-rich-ecosystem-of-libraries" aria-label="Permalink to &quot;2.5. **Rich Ecosystem of Libraries**&quot;">​</a></h3><p>PyTorch has many <strong>extra tools</strong> to help with different kinds of tasks.<strong>TorchVision</strong>, <strong>TorchText</strong>, and <strong>TorchAudio</strong> are specialized PyTorch libraries that make working with images, text, and audio much easier.</p><ul><li><strong>TorchVision</strong> provides pre-trained models, image datasets, and transformation tools for tasks like image classification, object detection, and video analysis.</li><li><strong>TorchText</strong> simplifies natural language processing (NLP) by offering text datasets, pre-trained word embeddings, and tools for processing raw text data for tasks such as sentiment analysis and text classification.</li><li><strong>TorchAudio</strong> supports audio and speech-related tasks, providing pre-trained models, audio transformations, and datasets for tasks like speech recognition and audio classification. Together, these libraries enhance PyTorch’s flexibility across different types of machine learning projects.</li></ul><h2 id="_3-the-application-domains-of-pytorch" tabindex="-1">3. The Application Domains of PyTorch <a class="header-anchor" href="#_3-the-application-domains-of-pytorch" aria-label="Permalink to &quot;3. The Application Domains of PyTorch&quot;">​</a></h2><h3 id="_3-1-research" tabindex="-1">3.1. <strong>Research</strong> <a class="header-anchor" href="#_3-1-research" aria-label="Permalink to &quot;3.1. **Research**&quot;">​</a></h3><p>Owing to its flexibility, PyTorch enjoys great popularity among researchers, enabling them to test new ideas effortlessly. It is extensively employed in cutting-edge AI fields such as language models, image recognition, and reinforcement learning.</p><h3 id="_3-2-industry" tabindex="-1">3.2. <strong>Industry</strong> <a class="header-anchor" href="#_3-2-industry" aria-label="Permalink to &quot;3.2. **Industry**&quot;">​</a></h3><p>Corporations like Facebook, Uber, and Tesla utilize PyTorch for tasks such as image recognition, autonomous vehicles, and recommendation systems.</p><h3 id="_3-3-education" tabindex="-1">3.3. <strong>Education</strong> <a class="header-anchor" href="#_3-3-education" aria-label="Permalink to &quot;3.3. **Education**&quot;">​</a></h3><p>A large number of universities and online courses adopt PyTorch to teach deep learning because it is simple, easy to comprehend, and integrates well with Python.</p><h2 id="_4-how-to-use-pytorch" tabindex="-1">4. How To Use PyTorch？ <a class="header-anchor" href="#_4-how-to-use-pytorch" aria-label="Permalink to &quot;4. How To Use PyTorch？&quot;">​</a></h2><h3 id="_4-1-official-tutorials" tabindex="-1">4.1 Official Tutorials <a class="header-anchor" href="#_4-1-official-tutorials" aria-label="Permalink to &quot;4.1 Official Tutorials&quot;">​</a></h3><p>Link to <a href="https://pytorch.org/" target="_blank" rel="noreferrer"><strong>PyTorch official website</strong></a>.</p><h3 id="_4-2-basic-framework" tabindex="-1">4.2 Basic Framework <a class="header-anchor" href="#_4-2-basic-framework" aria-label="Permalink to &quot;4.2 Basic Framework&quot;">​</a></h3><blockquote><p>test host: 118.24.78.164</p></blockquote><p>Here’s a simple example of building a neural network in PyTorch:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> optim</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> time </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Define a simple neural network</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SimpleNN</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(SimpleNN, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">784</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc3 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.relu(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc1(x))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.relu(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc2(x))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.fc3(x)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create model, loss function, and optimizer</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SimpleNN()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> optim.SGD(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Dummy data (32 samples of size 784)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">784</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">labels </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randint(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Training loop</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 25</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # Set the number of training epochs</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_epochs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Forward pass and calculate loss</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criterion(outputs, labels)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Backward pass and optimize</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer.zero_grad()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Reset gradients to zero</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss.backward()        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Compute gradients</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer.step()       </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Update parameters</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Print loss for each epoch</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Epoch [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_epochs</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">], Loss: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loss.item()</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    time.sleep(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p><strong>Explanation:</strong></p><ul><li>This code creates a simple neural network with three layers.</li><li>Training Loop: A training loop is added, which runs for a specified number of epochs (num_epochs = 25). Each epoch represents one full pass through the dataset.</li><li>Loss Printing: After each epoch, the current loss is printed to track how well the model is learning.</li><li>Zero Gradients: optimizer.zero_grad() ensures the gradients are reset before backpropagation to avoid accumulation.</li><li>Backward and Step: loss.backward() computes the gradients, and optimizer.step() updates the model&#39;s parameters.</li></ul><h2 id="_5-conclusion" tabindex="-1">5. Conclusion <a class="header-anchor" href="#_5-conclusion" aria-label="Permalink to &quot;5. Conclusion&quot;">​</a></h2><p>In conclusion, PyTorch stands out as a leading framework for deep learning due to its flexibility, user-friendliness, and active community support. It is particularly favored in academic research but is also making significant inroads into industry applications. As the deep learning landscape continues to evolve, PyTorch is well-positioned to remain a key player, empowering users to innovate and advance the field.</p>`,35)]))}const E=i(e,[["render",h]]);export{c as __pageData,E as default};
