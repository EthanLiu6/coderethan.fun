# 02-some_detials

- 残差连接别忘了，其前向可以带有原始信息，反向梯度为1，可以保证参数更新
- 残差连接放在前面和后面的区别
- bert是一种动态词向量

- Bert为啥不适用文本生成
- Bert的mask真正做了随机吗（train时）

- kv cache（past_key_values）
- Bert和transformer的区别于联系
- Bert和其他大语言模型