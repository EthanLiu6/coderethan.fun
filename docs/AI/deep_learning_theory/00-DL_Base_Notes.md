# ä¸€. DL_Base_Notes

## 1. ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸNormalization

Batch Normï¼ŒLayer Normï¼ŒInstance Normï¼ŒGroup Norm
$$
y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta
$$
[Batch Normçš„æŠ€æœ¯åšå®¢](https://blog.csdn.net/LoseInVain/article/details/86476010)

**æ€è€ƒï¼šåœ¨è®­ç»ƒå’Œæ¨ç†æ—¶æœ‰ä½•ä¸åŒï¼Ÿï¼Ÿï¼Ÿ**

## 2. ğŸŒŸğŸŒŸğŸŒŸActivation

### 2.1 Non-linear Activations çš„ä¸¤ç§ç±»å‹

ä¸€ç§æ˜¯é€å…ƒç´ æ“ä½œï¼ˆElement wise æˆ–è€…Point wiseï¼‰ï¼Œeg:ReLU,Sigmoid,Tanh,ç­‰ï¼Œå¦ä¸€ç§æ˜¯æ“ä½œå¯¹è±¡ï¼ˆå…ƒç´ ï¼‰ä¹‹é—´å…·æœ‰ç›¸å…³æ€§ï¼Œeg.Softmax

### 2.2

## 3. ğŸŒŸLoss Function

## 4. ğŸŒŸğŸŒŸğŸŒŸğŸŒŸOptimizer

> åŠ¨é‡åé¢çš„Admwé‚£äº›æ®ä¼°è®¡å¿˜äº†

## 5. ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸTransformer

> æ•´ç†æ¥æºäºä½œè€…ï¼šhttps://www.cnblogs.com/rossiXYZ/p/18706134ï¼Œå·²è·å¾—è®¸å¯

### 5.0 å¼•å…¥ï¼Œä¸ºå•¥å‡ºç°ï¼Ÿ

Transformeræœ¬èº«è¿˜æ˜¯seq2seqç»“æ„çš„ä¸€ä¸ªæ¨¡å‹æ¶æ„ï¼Œä½†åƒRNNè¿™æ ·çš„ç½‘ç»œä»–æœ‰å¾ˆå¤šé—®é¢˜ç‚¹ï¼Œæ¯ä¸€æ¬¡çš„é¢„æµ‹è¾“å‡ºæ˜¯å»ºç«‹åœ¨ä¸Šä¸€æ¬¡çš„è¾“å‡ºåŸºç¡€ä¸Šçš„ï¼Œä¹Ÿç®—æ˜¯æ—©èµ·è‡ªå›å½’æ¨¡å‹çš„é—®é¢˜ç‚¹ï¼š

> - ä¸²è¡Œè¿è¡Œï¼Œå¾ˆéš¾ä»¥å¹¶è¡ŒåŒ–çš„æ–¹å¼å¼€å±•è®­ç»ƒã€æå‡æ•ˆç‡ã€‚
> - åªæœ‰$h_{t-1}$æ—¶åˆ»çš„ä¿¡æ¯ï¼Œå®¹æ˜“ä¸¢å¤±ä¿¡æ¯
> - "ä¸€æ­¥é”™ï¼Œæ­¥æ­¥é”™"
> - æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
> - è¾“å…¥è¾“å‡ºåºåˆ—ç­‰é•¿é™åˆ¶ï¼ˆn2nï¼‰

ç”±æ­¤ï¼Œç ”ç©¶è€…ä»¬å°±åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡å‡ºäº†ä¸€ç§"ä¼˜åŒ–ç‰ˆçš„Encoder 2 Decoder"çš„æ¶æ„ï¼Œå…¶ä¸­çš„è¿‡æ¸¡å°±æ˜¯Context Vector (ç”¨Cè¡¨ç¤º)ï¼Œ**è¾“å…¥å¥å­æ¯ä¸ªæ—¶é—´æ­¥çš„ä¿¡æ¯**éƒ½åŒ…å«åœ¨äº†è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ã€‚ç®€å•ç†è§£å¯ä»¥è®¤ä¸ºEncoderè¿›è¡Œç‰¹å¾æå–å¾—åˆ°è¾“å…¥ä¿¡æ¯å¯¹åº”çš„Context Vectorï¼Œç„¶åDecoderè¿›è¡Œè§£ç ï¼š

> - åœ¨æ¯ä¸ªæ—¶åˆ»ï¼Œè§£ç å™¨éƒ½æ˜¯è‡ªå›å½’çš„ï¼Œå³ä¸Šä¸€ä¸ªæ—¶åˆ»çš„è¾“å‡ºï¼ˆäº§ç”Ÿçš„token $y_{tâˆ’1}$ï¼‰ä½œä¸ºä¸‹å½“å‰æ—¶åˆ»$t$çš„è¾“å…¥ä¹‹ä¸€ï¼Œç”Ÿæˆå½“å‰æ—¶åˆ»çš„token $y_t$ã€‚
> - è§£ç å™¨æœ€åˆçš„è¾“å…¥æ˜¯ä¸­é—´è¯­ä¹‰ä¸Šä¸‹æ–‡å‘é‡Cï¼Œè§£ç å™¨ä¾æ®Cè®¡ç®—å‡ºç¬¬ä¸€ä¸ªè¾“å‡ºè¯å’Œæ–°çš„éšçŠ¶æ€ï¼Œå³è§£ç å™¨çš„æ¯ä¸ªé¢„æµ‹éƒ½å—åˆ°å…ˆå‰è¾“å‡ºè¯å’ŒéšçŠ¶æ€çš„å¾®å¦™å½±å“ã€‚
> - è§£ç å™¨æ¥ç€ç”¨æ–°çš„éšçŠ¶æ€å’Œç¬¬ä¸€ä¸ªè¾“å‡ºè¯ä½œä¸ºè”åˆè¾“å…¥æ¥è®¡ç®—ç¬¬äºŒä¸ªè¾“å‡ºè¯ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°è§£ç å™¨äº§ç”Ÿä¸€ä¸ª EOSï¼ˆEnd Of Service/åºåˆ—ç»“æŸï¼‰æ ‡è®°æˆ–è€…è¾¾åˆ°é¢„å®šåºåˆ—é•¿åº¦çš„è¾¹ç•Œã€‚

ä»å®è§‚è§’åº¦çœ‹ï¼Œåºåˆ—å»ºæ¨¡çš„æ ¸å¿ƒå°±æ˜¯ç ”ç©¶å¦‚ä½•æŠŠé•¿åºåˆ—çš„ä¸Šä¸‹æ–‡å‹ç¼©åˆ°ä¸€ä¸ªè¾ƒå°çš„çŠ¶æ€ä¸­ï¼ˆå¥½å¥½é¢†æ‚Ÿè¿™å¥è¯ï¼‰ã€‚

å’‹å‹ç¼©å‘¢ï¼Ÿæ—©æœŸçš„æœ‰é©¬å°”å¯å¤«å‡è®¾ï¼Œä¹Ÿå°±æ˜¯è¿‘å› æ•ˆåº”ï¼Œå¦‚æœè€ƒè™‘å‰é¢nä¸ªå•è¯ï¼Œè¿™å°±å¾—åˆ°äº†N-gramæ¨¡å‹ï¼Œå³å½“å‰å•è¯çš„æ¦‚ç‡å–å†³äºå‰nä¸ªå•è¯ã€‚

### 5.1 Attentionæœºåˆ¶

è¿™ä¸ªåœ¨transformerä¹‹å‰å°±æœ‰äº†ï¼Œå®ƒå…¶å®æœ‰ä¸€å®šçš„å®é™…æ„ä¹‰ï¼Œæœ‰ä¸‰ç§ä¸»æµç¦…è¯—ï¼š

> - æ³¨æ„åŠ›æœºåˆ¶çš„æœ¬è´¨æ˜¯ä¸Šä¸‹æ–‡å†³å®šä¸€åˆ‡ã€‚
> - æ³¨æ„åŠ›æœºåˆ¶æ˜¯ä¸€ç§èµ„æºåˆ†é…æ–¹æ¡ˆã€‚
> - æ³¨æ„åŠ›æœºåˆ¶æ˜¯ä¿¡æ¯äº¤æ¢ï¼Œæˆ–è€…è¯´æ˜¯æ˜¯â€œå…¨å±€ä¿¡æ¯æŸ¥è¯¢â€ã€‚

> å…¶å®ï¼Œè®ºæ–‡â€œRecurrent Models of Visual Attentionâ€ä¸­æœ‰ä¸€æ®µè¯å°±æ·±åˆ»çš„å°è¯äº†èµ„æºåˆ†é…è¿™ä¸ªè§’åº¦ã€‚å…·ä½“å¦‚ä¸‹ï¼šäººç±»æ„ŸçŸ¥çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯ï¼Œäººä»¬ä¸ä¼šä¸€æ¬¡å¤„ç†æ•´ä¸ªåœºæ™¯ã€‚ç›¸åï¼Œäººç±»æœ‰é€‰æ‹©åœ°å°†æ³¨æ„åŠ›é›†ä¸­åœ¨è§†è§‰ç©ºé—´çš„æŸäº›éƒ¨åˆ†ä¸Šï¼Œä»¥åœ¨éœ€è¦çš„æ—¶é—´å’Œåœ°ç‚¹è·å–ä¿¡æ¯ï¼Œå¹¶éšç€æ—¶é—´çš„æ¨ç§»å°†ä¸åŒæ³¨è§†ç‚¹çš„ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œå»ºç«‹åœºæ™¯çš„å†…éƒ¨è¡¨ç¤ºï¼ŒæŒ‡å¯¼æœªæ¥çš„çœ¼çƒè¿åŠ¨å’Œå†³ç­–ã€‚å°†è®¡ç®—èµ„æºé›†ä¸­åœ¨åœºæ™¯çš„å„ä¸ªéƒ¨åˆ†å¯ä»¥èŠ‚çœâ€œå¸¦å®½â€ï¼Œå› ä¸ºéœ€è¦å¤„ç†çš„â€œåƒç´ â€æ›´å°‘ã€‚ä½†å®ƒä¹Ÿå¤§å¤§é™ä½äº†ä»»åŠ¡çš„å¤æ‚æ€§ï¼Œå› ä¸ºæ„Ÿå…´è¶£çš„å¯¹è±¡å¯ä»¥æ”¾ç½®åœ¨æ³¨è§†çš„ä¸­å¿ƒï¼Œè€Œæ³¨è§†åŒºåŸŸå¤–çš„è§†è§‰ç¯å¢ƒçš„æ— å…³ç‰¹å¾ï¼ˆâ€œæ‚ä¹±â€ï¼‰è‡ªç„¶ä¼šè¢«å¿½ç•¥ã€‚

æ‰€ä»¥ï¼Œæ ¸å¿ƒå°±æ˜¯åˆ†é…ä¸åŒçš„æƒé‡ï¼Œé‚£åˆå¼•å‡ºé—®é¢˜ï¼š

- åœ¨å“ªé‡Œåšæ³¨æ„åŠ›è®¡ç®—ï¼Ÿ
- å¦‚ä½•åšæ³¨æ„åŠ›è®¡ç®—ï¼Ÿ

### 5.2 Q K Vçš„å¼•å…¥

æ³¨æ„åŠ›æ¨¡å‹çš„å†…éƒ¨æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¯¥æ¨¡å‹çš„ç›®æ ‡æ˜¯ç”ŸæˆVä¸­å‘é‡çš„åŠ æƒå¹³å‡å€¼ï¼Œå…·ä½“è®¡ç®—æµç¨‹å¦‚ä¸‹ã€‚

- æ ‡å·1æ˜¯è¾“å…¥ï¼ˆä¸¤ä¸ªè¾“å…¥ï¼‰ï¼Œä»è¾“å…¥ç”Ÿæˆçš„ç‰¹å¾å‘é‡Fä¼šè¿›ä¸€æ­¥ç”Ÿæˆé”®çŸ©é˜µKå’Œå€¼çŸ©é˜µVã€‚

- æ ‡å·2ä½¿ç”¨çŸ©é˜µKå’ŒæŸ¥è¯¢å‘é‡qä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°æ¥è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†å‘é‡eã€‚qè¡¨ç¤ºå¯¹ä¿¡æ¯çš„è¯·æ±‚ï¼Œ$e_l$è¡¨ç¤ºçŸ©é˜µKçš„ç¬¬låˆ—å¯¹äºqçš„é‡è¦æ€§ã€‚

- æ ‡å·3é€šè¿‡å¯¹é½å±‚ï¼ˆæ¯”å¦‚softmaxå‡½æ•°ï¼‰è¿›ä¸€æ­¥å¤„ç†æ³¨æ„åŠ›åˆ†æ•°ï¼Œè¿›è€Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡aã€‚

- æ ‡å·4åˆ©ç”¨æ³¨æ„åŠ›æƒé‡aå’ŒçŸ©é˜µVè¿›è¡Œè®¡ç®—ï¼Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡cã€‚

  ![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209102028813-842747599.jpg)

  ä¸Šå›¾æ³¨æ„åŠ›æ¨¡å‹ä¸­ï¼Œæœ‰ä¸¤ä¸ªè¾“å…¥ï¼šqï¼ˆæ­£åœ¨å¤„ç†çš„åºåˆ—ï¼‰å’ŒFï¼ˆè¢«å…³æ³¨çš„åºåˆ—ï¼‰ï¼ŒFåˆåˆ†åˆ«è½¬æ¢ä¸ºKå’ŒVï¼Œè¿™ä¸‰ä¸ªå˜é‡ç»¼åˆèµ·æ¥ä½¿ç”¨å°±å¯ä»¥æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚ã€‚

  ä»è¯å…¸çš„è§’åº¦æ¥çœ‹ä¹Ÿè®¸å¯ä»¥ä¿ƒè¿›ç†è§£ã€‚queryæ˜¯ä½ è¦æ‰¾çš„å†…å®¹ï¼Œkeyæ˜¯å­—å…¸çš„ç´¢å¼•ï¼ˆå­—å…¸é‡Œé¢æœ‰ä»€ä¹ˆæ ·çš„ä¿¡æ¯ï¼‰ï¼Œvalueæ˜¯å¯¹åº”çš„ä¿¡æ¯ã€‚

  **æ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—æ€»ä½“å¯ä»¥åˆ†ä¸ºä¸¤æ­¥ï¼š**

  1. åœ¨æ‰€æœ‰è¾“å…¥ä¿¡æ¯ä¸Šè®¡ç®—æ³¨æ„åŠ›åˆ†å¸ƒã€‚ç¼–ç å™¨ä¸åªæ˜¯ä¼ é€’æœ€åä¸€ä¸ªéšè—çŠ¶æ€ï¼Œè€Œæ˜¯ä¼ å…¥æ‰€æœ‰çš„éšè—çŠ¶æ€åˆ°è§£ç å™¨ã€‚
  2. æ ¹æ®æ³¨æ„åŠ›åˆ†å¸ƒæ¥è®¡ç®—è¾“å…¥ä¿¡æ¯çš„åŠ æƒå¹³å‡ã€‚éœ€è¦æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ç§æ•°æ®ä¾èµ–çš„åŠ æƒå¹³å‡ï¼Œæ˜¯ä¸€ç§çµæ´»ã€é«˜æ•ˆçš„å…¨å±€æ± åŒ–æ“ä½œã€‚

### 5.3 Transformeræ¶æ„

#### 5.3.1 æ•´ä½“ç»“æ„

ä»ç½‘ç»œç»“æ„æ¥åˆ†æï¼ŒTransformer åŒ…æ‹¬äº†å››ä¸ªä¸»ä½“æ¨¡å—ã€‚

> - è¾“å…¥æ¨¡å—ï¼Œå¯¹åº”ä¸‹å›¾çš„ç»¿è‰²åœˆã€‚
> - ç¼–ç å™¨ï¼ˆEncoderï¼‰ï¼Œå¯¹åº”ä¸‹å›¾çš„è“è‰²åœˆã€‚
> - è§£ç å™¨ï¼ˆDecoderï¼‰ï¼Œå¯¹åº”ä¸‹å›¾çš„çº¢è‰²åœˆã€‚ç¼–ç å™¨å’Œè§£ç å™¨éƒ½æœ‰è‡ªå·±çš„è¾“å…¥å’Œè¾“å‡ºï¼Œç¼–ç å™¨çš„è¾“å‡ºä¼šä½œä¸ºè§£ç å™¨è¾“å…¥çš„ä¸€éƒ¨åˆ†ï¼ˆä½äºè§£ç å™¨çš„ä¸­é—´çš„æ©™è‰²åœˆï¼‰ã€‚
> - è¾“å‡ºæ¨¡å—ï¼Œå¯¹åº”ä¸‹å›¾çš„ç´«è‰²åœˆã€‚

ç¡®åˆ‡çš„è¯´ï¼Œè“è‰²åœˆæ˜¯ç¼–ç å™¨å±‚ï¼ˆEncoder layerï¼‰ï¼Œçº¢è‰²åœˆæ˜¯è§£ç å™¨å±‚ï¼ˆDecoder layerï¼‰ã€‚å›¾ä¸­çš„ NÃ—ä»£è¡¨æŠŠè‹¥å¹²å…·æœ‰ç›¸åŒç»“æ„çš„å±‚å †å èµ·æ¥ï¼Œè¿™ç§å°†åŒä¸€ç»“æ„é‡å¤å¤šæ¬¡çš„åˆ†å±‚æœºåˆ¶å°±æ˜¯æ ˆã€‚ä¸ºäº†é¿å…æ··æ·†ï¼Œæˆ‘ä»¬åç»­æŠŠå•ä¸ªå±‚ç§°ä¸ºç¼–ç å™¨å±‚æˆ–è§£ç å™¨å±‚ï¼ŒæŠŠå †å çš„ç»“æœç§°ä¸ºç¼–ç å™¨æˆ–è§£ç å™¨ã€‚åœ¨Transformerè®ºæ–‡ä¸­ï¼ŒTransformerä½¿ç”¨äº†6å±‚å †å æ¥è¿›è¡Œå­¦ä¹ ã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209144200970-309684502.jpg)

#### 5.3.2 Attentionç»“æ„

åœ¨Transformerä¸­æœ‰ä¸‰ç§æ³¨æ„åŠ›ç»“æ„ï¼šå…¨å±€è‡ªæ³¨æ„åŠ›ï¼Œæ©ç è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›ï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209144227590-945674250.jpg)

![img](https://img2024.cnblogs.com/blog/1850883/202502/1850883-20250209144236400-880372719.jpg)

è®ºæ–‡è§£è¯»ä¸‰ä¸ªAttentionï¼š

> Transformer æ¨¡å‹ä»¥ä¸‰ç§ä¸åŒçš„æ–¹å¼ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼š
>
> - åœ¨â€œç¼–ç å™¨ - è§£ç å™¨æ³¨æ„åŠ›â€å±‚ä¸­ï¼Œquaryæ¥è‡ªå‰ä¸€ä¸ªè§£ç å™¨å±‚ï¼Œè€Œè®°å¿†é”®å’Œå€¼æ¥è‡ªç¼–ç å™¨çš„è¾“å‡ºã€‚è¿™ä½¿å¾—è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½èƒ½å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®ã€‚è¿™æ¨¡ä»¿äº†è¯¸å¦‚[38, 2, 9]ç­‰åºåˆ—åˆ°åºåˆ—æ¨¡å‹ä¸­å…¸å‹çš„ç¼–ç å™¨ - è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶ã€‚
> -  ç¼–ç å™¨åŒ…å«è‡ªæ³¨æ„åŠ›å±‚ã€‚åœ¨è‡ªæ³¨æ„åŠ›å±‚ä¸­ï¼Œæ‰€æœ‰çš„é”®ã€å€¼å’ŒæŸ¥è¯¢éƒ½æ¥è‡ªåŒä¸€ä¸ªåœ°æ–¹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¥è‡ªç¼–ç å™¨å‰ä¸€å±‚çš„è¾“å‡ºã€‚ç¼–ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å¯ä»¥å…³æ³¨åˆ°ç¼–ç å™¨å‰ä¸€å±‚ä¸­çš„æ‰€æœ‰ä½ç½®ã€‚
> -  åŒæ ·ï¼Œè§£ç å™¨ä¸­çš„è‡ªæ³¨æ„åŠ›å±‚å…è®¸è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®å…³æ³¨åˆ°è§£ç å™¨ä¸­è¯¥ä½ç½®ä¹‹å‰çš„æ‰€æœ‰ä½ç½®ã€‚æˆ‘ä»¬éœ€è¦é˜²æ­¢è§£ç å™¨ä¸­çš„å·¦å‘ä¿¡æ¯æµä»¥ä¿æŒè‡ªå›å½’å±æ€§ã€‚æˆ‘ä»¬åœ¨ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›å†…éƒ¨é€šè¿‡æ©ç ï¼ˆè®¾ç½®ä¸º -infï¼‰æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œæ©ç æ‰ softmax è¾“å…¥ä¸­å¯¹åº”äºéæ³•è¿æ¥çš„æ‰€æœ‰å€¼ã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209144246216-890349384.jpg)

##### å…¨å±€è‡ªæ³¨æ„åŠ›å±‚

å…¨å±€è‡ªæ³¨æ„åŠ›å±‚ï¼ˆGlobal self attention layerï¼‰ä½äºç¼–ç å™¨ä¸­ï¼Œå®ƒè´Ÿè´£å¤„ç†æ•´ä¸ªè¾“å…¥åºåˆ—ã€‚åœ¨å…¨å±€è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½å¯ä»¥ç›´æ¥è®¿é—®åºåˆ—ä¸­çš„å…¶å®ƒå…ƒç´ ï¼Œä»è€Œä¸åºåˆ—ä¸­çš„å…¶ä»–å…ƒç´ å»ºç«‹åŠ¨æ€çš„å…³è”ï¼Œè¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ›´å¥½åœ°æ•æ‰åºåˆ—ä¸­çš„é‡è¦ä¿¡æ¯ã€‚è‡ªæ³¨æ„åŠ›çš„æ„æ€å°±æ˜¯å…³æ³¨äºåºåˆ—å†…éƒ¨å…³ç³»çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé‚£ä¹ˆæ˜¯å¦‚ä½•å®ç°è®©æ¨¡å‹å…³æ³¨åºåˆ—å†…éƒ¨ä¹‹é—´çš„å…³ç³»å‘¢ï¼Ÿè‡ªæ³¨æ„åŠ›å°†queryã€keyã€valueè®¾ç½®æˆç›¸åŒçš„ä¸œè¥¿ï¼Œéƒ½æ˜¯è¾“å…¥çš„åºåˆ—ï¼Œå°±æ˜¯è®©æ³¨æ„åŠ›æœºåˆ¶åœ¨åºåˆ—çš„æœ¬èº«ä¸­å¯»æ‰¾å…³ç³»ï¼Œæ³¨æ„åˆ°ä¸åŒéƒ¨åˆ†ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

å¯¹äºå…¨å±€è‡ªæ³¨æ„åŠ›æ¥è¯´ï¼ŒQã€Kã€Væœ‰å¦‚ä¸‹å¯èƒ½ï¼š

- Qã€Kã€Véƒ½æ˜¯è¾“å…¥åºåˆ—ã€‚
- Qã€Kã€Véƒ½æ¥è‡ªç¼–ç å™¨ä¸­å‰ä¸€å±‚çš„è¾“å‡ºã€‚ç¼–ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å¯ä»¥å…³æ³¨ç¼–ç å™¨å‰ä¸€å±‚è¾“å‡ºçš„æ‰€æœ‰ä½ç½®ã€‚

å†ç»†åŒ–æ¥è¯´ï¼ŒQæ˜¯åºåˆ—ä¸­å½“å‰ä½ç½®çš„è¯å‘é‡ï¼ŒKå’ŒVæ˜¯åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®çš„è¯å‘é‡ã€‚

##### æ©ç è‡ªæ³¨æ„åŠ›

æ©ç è‡ªæ³¨æ„åŠ›å±‚æˆ–è€…è¯´å› æœè‡ªæ³¨æ„åŠ›å±‚ï¼ˆCausal attention layerï¼‰å¯ä»¥åœ¨è§£ç é˜¶æ®µæ•è·å½“å‰è¯ä¸å·²ç»è§£ç çš„è¯ä¹‹é—´çš„å…³è”ã€‚å®ƒæ˜¯å¯¹è§£ç å™¨çš„è¾“å…¥åºåˆ—æ‰§è¡Œç±»ä¼¼å…¨å±€è‡ªæ³¨æ„åŠ›å±‚çš„å·¥ä½œï¼Œä½†æ˜¯åˆæœ‰ä¸åŒä¹‹å¤„ã€‚

Transformeræ˜¯è‡ªå›å½’æ¨¡å‹ï¼Œå®ƒé€ä¸ªç”Ÿæˆæ–‡æœ¬ï¼Œç„¶åå°†å½“å‰è¾“å‡ºæ–‡æœ¬é™„åŠ åˆ°ä¹‹å‰è¾“å…¥ä¸Šå˜æˆæ–°çš„è¾“å…¥ï¼Œåç»­çš„è¾“å‡ºä¾èµ–äºå‰é¢çš„è¾“å‡ºè¯ï¼Œå…·å¤‡å› æœå…³ç³»ã€‚è¿™ç§ä¸²è¡Œæ“ä½œä¼šæå¤§å½±å“è®­ç»ƒæ¨¡å‹çš„æ—¶é—´ã€‚**ä¸ºäº†å¹¶è¡Œæé€Ÿï¼Œäººä»¬å¼•å…¥äº†æ©ç **ï¼Œè¿™æ ·åœ¨è®¡ç®—æ³¨æ„åŠ›æ—¶ï¼Œé€šè¿‡æ©ç å¯ä»¥ç¡®ä¿åé¢çš„è¯ä¸ä¼šå‚ä¸å‰é¢è¯çš„è®¡ç®—ã€‚

å¯¹äºæ©ç è‡ªæ³¨æ„åŠ›æ¥è¯´ï¼ŒQã€Kã€Væœ‰å¦‚ä¸‹å¯èƒ½ï¼š

- Qã€Kã€Véƒ½æ˜¯è§£ç å™¨çš„è¾“å…¥åºåˆ—ã€‚
- Qã€Kã€Véƒ½æ¥è‡ªè§£ç å™¨ä¸­å‰ä¸€å±‚çš„è¾“å‡ºã€‚è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å¯ä»¥å…³æ³¨è§£ç å™¨å‰ä¸€å±‚çš„æ‰€æœ‰ä½ç½®ã€‚

å†ç»†åŒ–æ¥è¯´ï¼ŒQæ˜¯åºåˆ—ä¸­å½“å‰ä½ç½®çš„è¯å‘é‡ï¼ŒKå’ŒVæ˜¯åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®çš„è¯å‘é‡ã€‚

##### äº¤å‰æ³¨æ„åŠ›å±‚

äº¤å‰æ³¨æ„åŠ›å±‚ï¼ˆCross attention layerï¼‰å…¶å®å°±æ˜¯ä¼ ç»Ÿçš„æ³¨æ„åŠ›æœºåˆ¶ã€‚äº¤å‰æ³¨æ„åŠ›å±‚ä½äºè§£ç å™¨ä¸­ï¼Œä½†æ˜¯å…¶è¿æ¥äº†ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œè¿™æ ·å¯ä»¥åˆ»ç”»è¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—ä¹‹é—´çš„å…¨å±€ä¾èµ–å…³ç³»ï¼Œå®Œæˆè¾“å…¥å’Œè¾“å‡ºåºåˆ—ä¹‹é—´çš„å¯¹é½ã€‚å› æ­¤å®ƒéœ€è¦å°†ç›®æ ‡åºåˆ—ä½œä¸ºQï¼Œå°†ä¸Šä¸‹æ–‡åºåˆ—ä½œä¸ºKå’ŒVã€‚

å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¥è¯´ï¼ŒQã€Kã€Væ¥è‡ªå¦‚ä¸‹ï¼š

- Qæ¥è‡ªå‰ä¸€ä¸ªè§£ç å™¨å±‚ï¼Œæ˜¯å› æœæ³¨æ„åŠ›å±‚çš„è¾“å‡ºå‘é‡ã€‚
- Kå’ŒVæ¥è‡ªç¼–ç å™¨è¾“å‡ºçš„æ³¨æ„åŠ›å‘é‡ã€‚

è¿™ä½¿å¾—è§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®éƒ½èƒ½å…³æ³¨è¾“å…¥åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®ã€‚å¦å¤–ï¼Œç¼–ç å™¨å¹¶éåªä¼ é€’æœ€åä¸€æ­¥çš„éšçŠ¶æ€ï¼Œè€Œæ˜¯æŠŠæ‰€æœ‰æ—¶åˆ»ï¼ˆå¯¹åº”æ¯ä¸ªä½ç½®ï¼‰äº§ç”Ÿçš„æ‰€æœ‰éšçŠ¶æ€éƒ½ä¼ ç»™è§£ç å™¨ï¼Œè¿™å°±è§£å†³äº†ä¸­é—´è¯­ä¹‰ç¼–ç ä¸Šä¸‹æ–‡çš„é•¿åº¦æ˜¯å›ºå®šçš„é—®é¢˜ã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250218212308574-176454824-20250318112643142.jpg)

#### 5.3.3 æ‰§è¡Œæµç¨‹

æˆ‘ä»¬å†æ¥ç»“åˆæ¨¡å‹ç»“æ„å›¾æ¥ç®€è¿°æ¨ç†é˜¶æ®µçš„è®¡ç®—æµç¨‹ï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209144319485-2071213191.jpg)

å‡è®¾æˆ‘ä»¬è¿›è¡Œæœºå™¨ç¿»è¯‘å·¥ä½œï¼ŒæŠŠä¸­æ–‡â€æˆ‘åƒäº†ä¸€ä¸ªè‹¹æœâ€œç¿»è¯‘æˆè‹±æ–‡â€I ate an appleâ€œï¼Œåœ¨å‡è®¾æ¨¡å‹åªæœ‰ä¸€å±‚ï¼Œæ‰§è¡Œæ­¥éª¤å¦‚ä¸‹ï¼š

1. å¤„ç†è¾“å…¥ã€‚ç”¨æˆ·è¾“å…¥è‡ªç„¶è¯­è¨€å¥å­â€æˆ‘åƒäº†ä¸€ä¸ªè‹¹æœâ€œï¼›tokenizerå…ˆæŠŠåºåˆ—è½¬æ¢æˆtokenåºåˆ—ï¼›ç„¶åInput Embeddingå±‚å¯¹æ¯ä¸ªtokenè¿›è¡Œembeddingç¼–ç ï¼Œå†åŠ å…¥Positional Encodingï¼ˆä½ç½®ç¼–ç ï¼‰ï¼Œæœ€ç»ˆå½¢æˆå¸¦æœ‰ä½ç½®ä¿¡æ¯çš„embeddingç¼–ç çŸ©é˜µã€‚ç¼–ç çŸ©é˜µç”¨ Xnâˆ—dXnâˆ—d è¡¨ç¤ºï¼Œ n æ˜¯å¥å­ä¸­å•è¯ä¸ªæ•°ï¼Œd æ˜¯è¡¨ç¤ºå‘é‡çš„ç»´åº¦ï¼ˆè®ºæ–‡ä¸­ d=512ï¼‰ã€‚æ³¨ï¼šåŸè®ºæ–‡å›¾ä¸Šçš„è¾“å…¥æ˜¯tokenï¼Œæœ¬ç¯‡ä¸ºäº†æ›´å¥½çš„è¯´æ˜ï¼ŒæŠŠè¾“å…¥è®¾ç½®ä¸ºè‡ªç„¶è¯­è¨€å¥å­ã€‚
2. ç¼–ç å™¨è¿›è¡Œç¼–ç ã€‚ç¼–ç çŸ©é˜µé¦–å…ˆè¿›å…¥MHAï¼ˆMulti-Head Attentionï¼Œå¤šå¤´æ³¨æ„åŠ›ï¼‰æ¨¡å—ï¼Œåœ¨è¿™é‡Œæ¯ä¸ªtokenä¼šä¾æ®ä¸€å®šæƒé‡æŠŠè‡ªå·±çš„ä¿¡æ¯å’Œå…¶å®ƒtokençš„ä¿¡æ¯è¿›è¡Œäº¤æ¢èåˆï¼›èåˆç»“æœä¼šè¿›å…¥FFNï¼ˆFeed Forward Networkï¼‰æ¨¡å—åšè¿›ä¸€æ­¥å¤„ç†ï¼Œæœ€ç»ˆå¾—åˆ°æ•´ä¸ªå¥å­çš„æ•°å­¦è¡¨ç¤ºï¼Œå¥å­ä¸­æ¯ä¸ªå­—éƒ½ä¼šå¸¦ä¸Šå…¶å®ƒå­—çš„ä¿¡æ¯ã€‚æ•´ä¸ªå¥å­çš„æ•°å­¦è¡¨ç¤ºå°±æ˜¯Encoderçš„è¾“å‡ºã€‚
3. é€šè¿‡è¾“å…¥ç¿»è¯‘å¼€å§‹ç¬¦æ¥å¯åŠ¨è§£ç å™¨ã€‚
4. è§£ç å™¨è¿›è¡Œè§£ç ã€‚è§£ç å™¨é¦–å…ˆè¿›å…¥Masked Multi-Head Attentionæ¨¡å—ï¼Œåœ¨è¿™é‡Œè§£ç å™¨çš„è¾“å…¥åºåˆ—ä¼šè¿›è¡Œå†…éƒ¨ä¿¡æ¯äº¤æ¢ï¼›ç„¶ååœ¨Multi-Head Attentionæ¨¡å—ä¸­ï¼Œè§£ç å™¨æŠŠè‡ªå·±çš„è¾“å…¥åºåˆ—å’Œç¼–ç å™¨çš„è¾“å‡ºè¿›è¡Œèåˆè½¬æ¢ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œè¡¨ç¤ºè¯è¡¨ä¸­æ¯ä¸ªå•è¯ä½œä¸ºä¸‹ä¸€ä¸ªè¾“å‡ºå•è¯çš„æ¦‚ç‡ï¼›æœ€ç»ˆä¾æ®æŸç§ç­–ç•¥è¾“å‡ºä¸€ä¸ªæœ€å¯èƒ½çš„å•è¯ã€‚è¿™é‡Œä¼šé¢„æµ‹å‡ºç¬¬ä¸€ä¸ªå•è¯â€Iâ€œã€‚
5. æŠŠé¢„æµ‹å‡ºçš„ç¬¬ä¸€ä¸ªå•è¯â€Iâ€œå’Œä¸€èµ·ä½œä¸ºè§£ç å™¨çš„è¾“å…¥ï¼Œè¿›è¡Œå†æ¬¡è§£ç ã€‚
6. è§£ç å™¨é¢„æµ‹å‡ºç¬¬äºŒä¸ªå•è¯â€ateâ€œã€‚

é’ˆå¯¹æœ¬ä¾‹ï¼Œè§£ç å™¨çš„æ¯ä¸€æ­¥è¾“å…¥å’Œè¾“å‡ºå…·ä½“å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/1850883-20250209144327875-1762767210.jpg)



**è®ºæ–‡"Attention is not all you need"æŒ‡å‡ºå¦‚æœæ²¡æœ‰skip connectionï¼ˆresidual connection-æ®‹å·®é“¾æ¥ï¼‰å’ŒMLPï¼Œè‡ªæ³¨æ„åŠ›ç½‘ç»œçš„è¾“å‡ºä¼šæœç€ä¸€ä¸ªrank-1çš„çŸ©é˜µæ”¶ç¼©ã€‚å³ï¼Œskip connectionå’ŒMLPå¯ä»¥å¾ˆå¥½åœ°é˜»æ­¢è‡ªæ³¨æ„åŠ›ç½‘ç»œçš„è¿™ç§â€ç§©åå¡Œï¼ˆç§©åå¡Œï¼‰é€€åŒ–â€œã€‚è¿™æ­ç¤ºäº†skip connectionï¼ŒMLPå¯¹self-attentionçš„ä¸å¯æˆ–ç¼ºçš„ä½œç”¨**

### 5.1 ä¸ºå•¥Attentionçš„æ—¶å€™è¦é™¤ä»¥$\sqrt{d_k}$ï¼Ÿ

$$
Attention(Q, K, V ) = softmax(\frac{QÂ·K^T}{\sqrt{d_k}})Â·V
$$

å½“ dk*d**k* çš„å€¼æ¯”è¾ƒå°çš„æ—¶å€™ï¼Œä¸¤ç§ç‚¹ç§¯æœºåˆ¶(additive å’Œ Dot-Product)çš„æ€§èƒ½ç›¸å·®ç›¸è¿‘ï¼Œå½“ dk*d**k* æ¯”è¾ƒå¤§æ—¶ï¼Œadditive attention æ¯”ä¸å¸¦scale çš„ç‚¹ç§¯attentionæ€§èƒ½å¥½ã€‚ æˆ‘ä»¬æ€€ç–‘ï¼Œå¯¹äºå¾ˆå¤§çš„ dk*d**k* å€¼ï¼Œç‚¹ç§¯å¤§å¹…åº¦å¢é•¿ï¼Œå°†softmaxå‡½æ•°æ¨å‘å…·æœ‰æå°æ¢¯åº¦çš„åŒºåŸŸã€‚ ä¸ºäº†æŠµæ¶ˆè¿™ç§å½±å“ï¼Œæˆ‘ä»¬ç¼©å°ç‚¹ç§¯ 1dkâˆš*d**k*1 å€ã€‚

### 5.2 ä¸ºå•¥æ‹†å¤šå¤´ï¼Ÿä¸ºå•¥æ•ˆæœå¥½äº†ï¼Ÿ

### 5.3 Cross Multi-Head Attentionï¼Ÿ

é¦–å…ˆï¼ŒSelf- Attentionä¸ä¼ ç»Ÿçš„Attentionæœºåˆ¶éå¸¸çš„ä¸åŒï¼šä¼ ç»Ÿçš„Attentionæ˜¯åŸºäºsourceç«¯å’Œtargetç«¯çš„éšå˜é‡ï¼ˆhidden stateï¼‰è®¡ç®—Attentionçš„ï¼Œå¾—åˆ°çš„ç»“æœæ˜¯æºç«¯ï¼ˆsourceç«¯ï¼‰çš„æ¯ä¸ªè¯ä¸ç›®æ ‡ç«¯ï¼ˆtargetç«¯ï¼‰æ¯ä¸ªè¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚
    å…¶æ¬¡ï¼ŒSelf-Attentioné¦–å…ˆåˆ†åˆ«åœ¨sourceç«¯å’Œtargetç«¯è¿›è¡Œè‡ªèº«çš„attentionï¼Œä»…ä¸source inputæˆ–è€…target inputè‡ªèº«ç›¸å…³çš„Self -Attentionï¼Œä»¥æ•æ‰sourceç«¯æˆ–targetç«¯è‡ªèº«çš„è¯ä¸è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼›ç„¶åå†æŠŠsourceç«¯çš„å¾—åˆ°çš„self -AttentionåŠ å…¥åˆ°targetç«¯å¾—åˆ°çš„Attentionä¸­ï¼Œç§°ä½œä¸º**Cross-Attention**ï¼Œä»¥æ•æ‰sourceç«¯å’Œtargetç«¯è¯ä¸è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚

###  5.4 Mask Multi-Head Attention

â€‹    ä¸Encoderçš„Multi-Head Attentionè®¡ç®—åŸç†ä¸€æ ·ï¼Œåªæ˜¯å¤šåŠ äº†ä¸€ä¸ªmaskç ã€‚mask è¡¨ç¤ºæ©ç ï¼Œå®ƒå¯¹æŸäº›å€¼è¿›è¡Œæ©ç›–ï¼Œä½¿å…¶åœ¨å‚æ•°æ›´æ–°æ—¶ä¸äº§ç”Ÿæ•ˆæœã€‚Transformer æ¨¡å‹é‡Œé¢æ¶‰åŠä¸¤ç§ maskï¼Œåˆ†åˆ«æ˜¯ padding mask å’Œ sequence maskã€‚

### 5.5 Maskingå®ç°æœºç†

å…·ä½“çš„åšæ³•æ˜¯ï¼ŒæŠŠ**è¿™äº›ä½ç½®**çš„å€¼**åŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°(è´Ÿæ— ç©·)**ï¼Œè¿™æ ·çš„è¯ï¼Œç»è¿‡ softmaxï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šæ¥è¿‘0ï¼

### 5.6 MQAå’ŒGQA

MQAå¤šå¤´å…±ç”¨Kï¼ŒV

GQAå°†å¤´åˆ†ç»„ï¼Œç»„å†…å…±ç”¨KV

## 6. ğŸŒŸğŸŒŸğŸŒŸK-V Cache

## 7. ğŸŒŸğŸŒŸğŸŒŸå¸¸è§çš„æ­£åˆ™åŒ–æ–¹æ³•

# äºŒ. è¯¾å ‚è®°å½•

## ğŸŒŸ0301-0302

- 0301:inputåºåˆ—é•¿åº¦å¤§äºembeddingæ—¶å€™çš„seq_lenæ—¶, inputçš„è¾“å…¥åºåˆ—ä¼šæŒ‰ç…§seq_lenè¿›è¡Œåˆ‡å‰²æ‹¼æ¥åˆ°batchä¸Šå—? (è€å¸ˆè®²äº†encoderæ—¶å€™inputä¸è¶³seq_lenæ—¶å€™ä½¿ç”¨maskç„¶åæƒ³é—®çš„å¦ä¸€ä¸ªé—®é¢˜)
- 0302:`K-V cache`æ—¶å€™å½“é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„æ—¶å€™ä¸ä¹‹å‰çš„åšAttentionçš„æ—¶å€™, ä¸­é€”ä¼šå–å‡ºcacheé‡Œçš„Kâ€”Vå—è¿˜æ˜¯åªå–å‡ºé‡Œé¢çš„Kè¿˜æ˜¯åªåœ¨æœ€åä¸€ä¸ªç»“æŸåæ‰æ•´ä½“å–ä¸€æ¬¡ (æˆ‘æƒ³é—®çš„ä¹Ÿå°±æ˜¯åœ¨ä¸€ä¸ªbatchæˆ–è€…ä¸€ä¸ªseqçš„è®¿å­˜æƒ…å†µ, æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½éœ€è¦è®¿é—®cacheä¸€æ¬¡å—)
- æ˜¯ç›´æ¥ä½¿ç”¨ç¼“å­˜çš„å¡«å……çŸ©é˜µè¿˜æ˜¯éœ€è¦æ‹¿å‡ºç¼“å­˜æ•°æ®(è¯»è¿˜æ˜¯å–)


## 0308-0309â€”â€”PyTorch


> æåŠ: æ··åˆç²¾åº¦è®­ç»ƒ

### 1.1 Tensor ä¸­æ•°æ®çš„è¿ç»­æ€§

reshape, transpose, view, T(è½¬ç½®), permute

transposeä¼šè®©raw dataä¸å˜(å…±ç”¨),  mata dataçš„strideå’Œshapeç­‰å±æ€§å°±å˜äº† is_contiguous()ä¸è¿ç»­, ä½†reshapeå’Œpermuteè¿™äº›æ˜¯ä¸ä¼šå˜çš„,å› ä¸ºä»–ä»¬ä¼šå‘ç”Ÿdata copy,  contiguous()ä¼šå‘ç”Ÿcopy raw dataæ•°æ®

viewå’Œreshapeçš„åŒºåˆ«

viewæ›´åŠ å®‰å…¨, ä¸ä¼šé‡æ–°æ‹·è´æ•°æ®, ä½†æ•°æ®ä¸è¿ç»­ä¸èƒ½ä½¿ç”¨view,ä¹Ÿå°±æ˜¯strideä¸åè°ƒ, reshapeä¸ä¼šé”™è¯¯, ä¼šé‡æ–°æ‹·è´æ•°æ®, æ•°æ®ä¹Ÿè¿ç»­

permuteå’Œtransposeä¼šè®©strideå±æ€§æ”¹å˜, ä»è€Œå‘ç”Ÿæ•°æ®ä¸è¿ç»­, é€šå¸¸ä½¿ç”¨åè¦åŠ ä¸€ä¸ªcontiguous()è®©æ•°æ®è¿ç»­

### 1.2 pytorch autograd

<img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250308163009045.png" alt="image-20250308163009045" style="zoom:36%;" />

â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦

å¶å­ç»“ç‚¹+requests_grad=Trueæ‰æœ‰æœ€ç»ˆçš„grad, éå¶å­ç»“ç‚¹ä¸­é€”å¯èƒ½ä¼šè®¡ç®—grad, ä½†ç”¨äº†å°±ä¼šä¸¢å¼ƒ(requests_grad=Trueçš„)



æ¢¯åº¦ç´¯åŠ ä¹Ÿæœ‰å¯èƒ½, å¤šä¸ªstepçš„æ¢¯åº¦ç´¯åŠ , éšå¼å¢åŠ batch

è‹¥æ²¡è¿›è¡Œxxx.grad.zero_()æˆ–è€…xxx.grad = None, åˆ™ä¼šè¿›è¡Œaccumulate()ç´¯åŠ grad, è¿™ä¸¤ç§æ–¹æ³•æœ‰ä¸€ç‚¹åŒºåˆ«, zero__()ä¼šç½®é›¶,ä¼šå ç”¨æ˜¾å­˜, ä½†=Noneçš„è¯ä¼šé‡Šæ”¾æ˜¾å­˜, ä¸¤è€…å„æœ‰å¥½å



### 1.3 inplace-op

![image-20250309102559857](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250309102559857.png)

å¶å­ç»“ç‚¹çš„Tensorå˜é‡ä¸èƒ½è¿›è¡Œin-placeæ“ä½œ, å› ä¸ºè¦æ›´æ–°æ¢¯åº¦çš„æ—¶å€™è¦ç”¨å¶å­ç»“ç‚¹

<img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250309113212792.png" alt="image-20250309113212792" style="zoom: 50%;" />

<img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250309114217344.png" alt="image-20250309114217344" style="zoom:50%;" />

no_grad()åº•å±‚æ˜¯åŸºäºset_grad_enable(Flase)çš„

### 1.4 è‡ªåŠ¨å¾®åˆ†æœºåˆ¶(auto grad) é‡ç‚¹ï¼š

- pytorchä¸­ æ­£å‘forward å¯¹æˆ‘ä»¬ç”¨æˆ·æ˜¯å¯è§çš„ï¼Œä½†æ˜¯backwardå¯¹æˆ‘ä»¬ç”¨æˆ·æ˜¯ä¸å¯è§çš„ï¼›
- ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæ¯ä¸€ä¸ªæ­£å‘çš„å‡½æ•°ï¼Œéƒ½å¯¹åº”ä¸€ä¸ªåå‘çš„å‡½æ•°ï¼ˆgrad_fn--> Tensorä¸­ï¼‰ï¼›
- tensorï¼šrequires_grad = True
- tensor: grad --> tensor ä¸­å­˜å‚¨gradçš„åœ°æ–¹ï¼›
- tensor: grad_fn --> å­˜å‚¨æˆ‘ä»¬åå‘å‡½æ•°çš„åœ°æ–¹
- tesnor: is_leaf --> è¿™ä¸ªtensor æ˜¯ä¸æ˜¯ å¶å­èŠ‚ç‚¹ï¼›
- net::all weight --> éƒ½æ˜¯leaf
- å¶å­èŠ‚ç‚¹çš„æ¢¯åº¦ä¼šè‡ªåŠ¨ä¿å­˜ä¸‹æ¥çš„ï¼ˆweightï¼‰ï¼›
- ä¸­é—´çš„ activation çš„æ¢¯åº¦ä¼šè®¡ç®—ï¼Œä½†æ˜¯ä¸ä¿ç•™ï¼›
- pytorch åŠ¨æ€å›¾ vs tensorflow é™æ€å›¾ï¼›
- æˆ‘ä»¬ä¸èƒ½æ”¹å˜ä¸€ä¸ªéå¶å­èŠ‚ç‚¹çš„ requires_grad;
- éå¶å­ï¼ˆä¸€ä¸ªå‡½æ•°çš„outputï¼‰èŠ‚ç‚¹å®ƒçš„ requires_grad è‡ªåŠ¨æ¨å¯¼çš„ï¼›
- éå¶å­èŠ‚ç‚¹å¯¹åº”å‡½æ•°çš„inputs ä¸­åªè¦æœ‰ä¸€ä¸ª requires_grad = True, é‚£ä¹ˆè¿™ä¸ªéå¶å­èŠ‚ç‚¹çš„requires_grad = True;
- torch.no_grad() ä¼šä½¿å¾—é‡Œé¢çš„æ–°çš„tensor requires_grad = False
- inplaceçš„æ“ä½œï¼Œéå¸¸å¤§çš„é£é™©ï¼šè¦†ç›–äº†åŸæ¥çš„å€¼ï¼Œå¯¼è‡´åå‘ä¼ æ’­æ—¶è®¡ç®—ä¸å‡†ç¡®ï¼›
- æ ‡é‡çš„æ¢¯åº¦æ‰èƒ½è¢«éšå¼åˆ›å»ºï¼Œéšå¼åˆ›å»ºï¼ˆ.backward(1)ï¼‰ï¼›
- ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ.backward(gradient)æ˜¯æœ‰è¾“å…¥çš„: ;



### 2.1 torch.nn.Module

trainæ¨¡å¼å’Œvealæ¨¡å¼ä¸ä¼šå¯¹gradçš„æƒ…å†µåšä¿®æ”¹,åªæ˜¯å¯¹è®­ç»ƒå’Œæ¨ç†çš„å¯¹åº”çš„ç®—å­åšä¸åŒçš„å¤„ç†(ç­‰ä»·å¤„ç†)

å¸¸ç”¨ç®—å­dropoutå’ŒBachNorm 

xxx.cuda()çš„æ—¶å€™æ¬è¿çš„æ˜¯_parametersåˆ°cuda, è¿˜æœ‰bufferä¹Ÿæ¬è¿åˆ°cuda, å¹¶æ²¡æœ‰å°†æ¨¡å‹ç»“æ„è¿›è¡Œæ¬è¿.

æŒ‰ç…§æ·±åº¦ä¼˜å…ˆéå†sub module,å°†é‡Œé¢çš„_parameterså’Œbufferåˆ°cuda, æ•°æ®ç±»å‹è½¬æ¢ä¹Ÿæ˜¯ä¸€æ ·çš„æ“ä½œ

c++åº•å±‚å®ç°äº†ä¸€ä¸ªdispatheråˆ†å‘æœºåˆ¶,æŒ‰ç…§deviceå±æ€§åˆ†å‘, å¯¹åº”deviceä¼šè°ƒç”¨å¯¹åº”çš„fnç®—å­, è®¡ç®—éƒ¨åˆ†æ‰æ‰§è¡Œ

_parameters()é€å‚æ•°ç»™ä¼˜åŒ–å™¨çš„æ—¶å€™å°†æ‰€æœ‰çš„parametersé€åˆ°optim, ä½†æ•°æ®å…±ç”¨, åŒæ—¶æ›´æ–°

é’©å­å‡½æ•°(æ²¡å¤ªæ‡‚)

---

## 0315-0316ï¼ˆç»­PyTorchï¼‰

### 1.1 å›é¡¾

1.Tensorç±»å’Œé‡è¦å±æ€§
2.autogradï¼ŒåŠ¨æ€å›¾
3.Moduleä»¥åŠå±æ€§å’Œæ–¹æ³•

> training,_parameters,_buffers,_modules(hooksæ˜¯ä¸»è¦ç”¨äºŒæ¬¡å¼€å‘ç­‰æƒ…å†µ)

å­æ¨¡å—å•¥æ—¶å€™å®šä¹‰çš„å‘¢ï¼Ÿ

_parameters,_bufferså“ªäº›æœ‰å“ªäº›æ²¡æœ‰

å°†moduleé‡Œçš„parametersä¼ ç»™optimï¼Œä¼šé€šè¿‡è°ƒç”¨parameters()è¿›è¡Œ

ä¸€ç³»åˆ—æ–¹æ³•å…·ä½“æƒ…å†µ

### 1.2 é—®é¢˜åˆé›†

1. åœ¨è®²transformerçš„padding maskçš„æ—¶å€™æƒ³åˆ°ï¼Œå¦‚æœè¾“å…¥seq_lenå¤§äºäº†å®šä¹‰çš„seq_lenï¼Œä¼šç›´æ¥æˆªæ–­è¿˜æ˜¯æˆªæ–­å†æ‹¼æ¥åˆ°ä¸‹ä¸€ä¸ªbatch
2. åœ¨sequence maskçš„æ—¶å€™ï¼Œå¿˜äº†è¦é—®å•¥äº†
3. åœ¨normalizationå±‚çš„æ—¶å€™ä¸æ˜¯æœ‰ä¸¤ä¸ªå­¦ä¹ çš„å‚æ•°å—ï¼Œè¿™ä¿©å‚æ•°æ˜¯ä¸€æ¬¡forwardè®­ç»ƒä¸€æ¬¡è¿˜æ˜¯å•ç‹¬æœ‰è‡ªå·±çš„è®­ç»ƒï¼Ÿè¿˜æœ‰ï¼Œè¿™ä¿©å‚æ•°æ˜¯å’‹æ›´æ–°çš„ï¼Ÿ
4. datasetä¼šè¿­ä»£çš„å°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜å—ï¼Œç„¶ådataloaderå†ä¸€æ‰¹æ¬¡çš„æå–å—

with  torch.no_grad():
	evalæ—¶å€™ç”¨ï¼Œè®¡ç®—å›¾ä¸å†è¿›è¡Œï¼Œå¯¹require_grads=Trueçš„ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®—ï¼Œæ˜¾å­˜å ç”¨é‡ä¼šå‡å°‘ï¼Œactivationçš„å°±ä¼šä¸¢å¼ƒ

datasetä¼šè¿­ä»£çš„å°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜å—ï¼Œç„¶ådataloaderå†ä¸€æ‰¹æ¬¡ä¸€æ‰¹æ¬¡çš„æå–å—ï¼Ÿè¿˜æ˜¯è¯´dataloaderå‡†å¤‡æ‹¿ä¸€ä¸ªbatchï¼Œç„¶ådatasetæ ¹æ®batch_sizeè¿­ä»£è·å–sizeæ¡ã€‚

> æ˜¯åè€…ï¼Œä¹Ÿå°±æ˜¯I/Oçš„æ—¶å€™ï¼Œbatch_sizeå¤ªå°çš„è¯ä¼šå¢åŠ I/Oè´Ÿæ‹…

### 2.1 torch.optim

å‚æ•°ä¼ paramçš„æ—¶å€™çš„ä¼ é€’å’Œæ‰“åŒ…æ–¹å¼

self.param_groups

==self.state==ï¼šè®­ç»ƒæ—¶å€™æ˜¾å­˜æ¶ˆè€—çš„ä¸»è¦é¡¹ï¼ˆä¼˜åŒ–å™¨çš„åŠ¨é‡é¡¹æœ‰å…³ï¼‰
ä»–æ˜¯ä¸€ä¸ªdictï¼Œkeysæ˜¯tensorï¼Œvaluesä¹Ÿæ˜¯
æ¨¡å‹

>ç§»åŠ¨æŒ‡æ•°å¹³å‡æ˜¯å•¥å¿˜äº†

def load_state_dict

### 2.2 learning rate è°ƒæ•´æ–¹æ¡ˆ

Torch.optim.lr_scheduler

éœ‡è¡ç±»å‹çš„å­¦ä¹ ç‡è°ƒæ•´æ˜¯å‡å°‘è¿›å…¥å±€éƒ¨æœ€ä¼˜è§£çš„æƒ…å†µ

==çŠ¶æ€å­—å…¸==ï¼Œä¸‰ä¸ªåœ°æ–¹è§è¿‡ï¼Œéƒ½ç±»ä¼¼ï¼Œæ¨¡å‹ä¿å­˜æ—¶å€™éœ€è¦æœ‰

### 2.3 æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

==åŠ¨æ€å›¾==

1.save state_dictçš„æ—¶å€™åªæœ‰å‚æ•°ï¼Œsave modelçš„æ—¶å€™æ— æ³•ç›´æ¥ä¿å­˜æ•´ä¸ªç½‘ç»œï¼Œä½†æ˜¯ä»–çš„ææ–™ï¼ˆinitï¼‰çš„é‚£äº›ä¼šä¿å­˜ï¼Œæ¨¡å‹åŠ è½½çš„æ—¶å€™èƒ½é€šè¿‡ï¼Œä½†runing timeæ—¶å€™ï¼Œforwardå¹¶æ²¡æœ‰ï¼Œå¿…é¡»å¯¼å…¥æˆ–è€…è‡ªå·±å®ç°ï¼Œéœ€è¦åŸæ¥Netçš„ç­¾åï¼ˆå…·ä½“å®šä¹‰å¯ä»¥ä¸ä¸€è‡´ï¼Œä¼šæ”¾å…¥_modulesï¼‰

2.å¦‚æœæ˜¯è‡ªå·±å†™çš„ç®—å­ï¼Œåœ¨initæ—¶å€™ä¹Ÿæ”¾å…¥_moduleså—ï¼Ÿ

![img](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/%7B6fbad3cc-1899-4404-b3b3-d91f7da5cb95%7D.png)

3.==onnx==æ¨¡å‹ä¿å­˜å¿…é¡»è¾“å…¥å¯¹åº”çš„inputï¼Œè‡ªå·±runä¸€éï¼Œæ˜¯ä¸€ä¸ªé™æ€å›¾

4.è®­ç»ƒä¸­çš„ä¿å­˜å’ŒåŠ è½½ï¼ˆcheck pointï¼‰==æ¨¡å‹ä¿å­˜çš„å‡ ç§å‚æ•°ç±»å‹==ï¼‰

![image-20250316113313785](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250316113313785.png)

### 3.1 Dataset and Dataloader

> åªå­¦ä¹ pytorchçš„ï¼Œåç»­è‡ªå·±è¡¥hfçš„é‚£äº›

### 4.1 NLP

GPTï¼šè‡ªç›‘ç£è®­ç»ƒå¾—åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé‡‡ç”¨è¿ç§»å­¦ä¹ ï¼‰

Bertï¼šå®Œå½¢å¡«ç©º

è¿ç§»å­¦ä¹ ï¼šé¢„è®­ç»ƒ+å¾®è°ƒï¼ˆå¾®è°ƒçš„æ•°æ®é›†å°±æ˜¯ä¸“ä¸šé¢†åŸŸçš„æ•°æ®é›†ï¼‰

### 4.2 Bert

1.ä¸¤ä¸ªä»»åŠ¡ï¼šMLMå’ŒNSP

2.Embeddingï¼Œè¯åµŒå…¥

è¯ï¼Œå¥å­ï¼ˆåˆ†æ®µï¼‰ï¼Œä½ç½® åµŒå…¥

![image-20250316165604714](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250316165604714.png)

> transformerçš„è¯åµŒå…¥å¼ç”¨ä¸‰è§’ä½ç½®åµŒå…¥

![image-20250316175009793](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250316175009793.png)
