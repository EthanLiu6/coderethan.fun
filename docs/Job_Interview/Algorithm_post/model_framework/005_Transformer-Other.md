<h1 align="center"> <p>005_Transformer-Other</p></h1>

> 在Transformer架构基础上的更多优化，包括软硬件优化



MQA

GQA

Flash Attention

重计算

KV-cache

Page Attention